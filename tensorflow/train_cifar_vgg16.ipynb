{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo:\n",
    "- Experiment with normalization while creating triplets\n",
    "- Do you need dropout in the regressor network?\n",
    "- Simultaneous feature learning?\n",
    "- See when are results bad/equal/better? See which classes they correspond to.. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import cycle\n",
    "import random\n",
    "\n",
    "from utils import optimistic_restore, save\n",
    "import layers\n",
    "\n",
    "PWD = os.getcwd()\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(PWD, '..')))\n",
    "import pickle_utils\n",
    "import cifar_utils\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "HYPERPARAMS\n",
    "'''\n",
    "BATCH_SIZE = 10\n",
    "DATA_PATH = '/media/red/capstone/data/cifar-100/cifar-custom'\n",
    "LEARNING_RATE = 1e-4\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.99\n",
    "NUM_CLASSES = 40\n",
    "NUM_EPOCH = 100\n",
    "RANDOM_SEED = 1234\n",
    "SUMMARY_EVERY = 10\n",
    "VALIDATION_PERCENTAGE = 0.05\n",
    "SNAPSHOT_MAX = 10 # Keeps the last best 10 snapshots (best determined by validation accuracy)\n",
    "SNAPSHOT_DIR = '/media/red/capstone/snapshots/feature_extractor_vgg16'\n",
    "PRETRAINED_WEIGHT_FILE = '/media/red/capstone/pretrained_weights/vgg16_weights.npz'\n",
    "\n",
    "np.random.seed(seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load custom CIFAR data. \n",
    "'''\n",
    "# cifar_raw = pickle_utils.load(DATA_PATH)\n",
    "custom_dataset = pickle_utils.load(DATA_PATH)\n",
    "\n",
    "data_x, data_y = [], []\n",
    "for label in custom_dataset['training'].keys():\n",
    "    for item in custom_dataset['training'][label]:\n",
    "        data_x.append(item) # 28 x 28 x 3\n",
    "        data_y.append(label) # 0-39\n",
    "data_x = np.stack(data_x).astype(np.float32)\n",
    "data_x = np.flip(data_x, axis=-1) # BGR\n",
    "data_y = np.stack(data_y).astype(np.int32)\n",
    "\n",
    "# Normalize x\n",
    "data_x = (data_x / 255.0) - 0.5\n",
    "\n",
    "def round_to(n, precision):\n",
    "    return int( n/precision+0.5 ) * precision\n",
    "\n",
    "n_total_data = data_x.shape[0]\n",
    "n_validation = round_to(VALIDATION_PERCENTAGE * n_total_data, BATCH_SIZE)\n",
    "batches_per_epoch = np.round((n_total_data - n_validation) / BATCH_SIZE)\n",
    "# Shuffle data\n",
    "random_indices = np.random.permutation(n_total_data)\n",
    "train_indices = cycle(random_indices[n_validation:])\n",
    "validation_indices = random_indices[:n_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Declare model\n",
    "'''\n",
    "class vgg16:\n",
    "    '''\n",
    "    VGG16 Model with ImageNet pretrained weight loader method\n",
    "    Weights can be downloaded from:\n",
    "    https://www.cs.toronto.edu/~frossard/vgg16/vgg16_weights.npz\n",
    "    '''\n",
    "\n",
    "    def __init__(self, x, y, phase):\n",
    "        '''\n",
    "        Sets up network enough to do a forward pass.\n",
    "        '''\n",
    "\n",
    "        \"\"\" init the model with hyper-parameters etc \"\"\"\n",
    "\n",
    "        # List used for loading weights from vgg16.npz (if necessary)\n",
    "        self.parameters = []\n",
    "        self.CONV_ACTIVATION = 'relu'\n",
    "        self.FC_ACTIVATION   = 'relu'\n",
    "\n",
    "        ########\n",
    "        # Misc #\n",
    "        ########\n",
    "        self.global_step = tf.get_variable('global_step', dtype=tf.int32, trainable=False,\n",
    "                        initializer=0)\n",
    "        self.learning_rate = LEARNING_RATE\n",
    "        self.IM_SHAPE = [224, 224, 3]\n",
    "\n",
    "        ####################\n",
    "        # I/O placeholders #\n",
    "        ####################\n",
    "        self.x = x\n",
    "        self.x.set_shape([None]+self.IM_SHAPE)\n",
    "        self.y = tf.to_int32(y)\n",
    "\n",
    "        ###############\n",
    "        # Main Layers #\n",
    "        ###############\n",
    "        with tf.variable_scope('conv_layers'):\n",
    "            self._convlayers()\n",
    "        with tf.variable_scope('fc_layers'):\n",
    "            self._fc_layers()\n",
    "\n",
    "        ######################\n",
    "        # Define Collections #\n",
    "        ######################\n",
    "        self.conv_trainable = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                \"conv_layers\")\n",
    "        self.fc_trainable = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                \"fc_layers\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        '''\n",
    "        Returns the count of correct classifications (Tensor).\n",
    "        '''\n",
    "        # Bool Tensor where 1 is correct and 0 is incorrect\n",
    "        correct = tf.nn.in_top_k(self.predictions, self.y, 1)\n",
    "        # Average them to get accuracy.  Must cast to a float32\n",
    "        self.accuracy = tf.reduce_mean(tf.to_float(correct))\n",
    "        return self.accuracy\n",
    "\n",
    "    #####################\n",
    "    # Private Functions #\n",
    "    #####################\n",
    "    def _convlayers(self):\n",
    "        '''\n",
    "        All conv and pooling layers of VGG16\n",
    "        '''\n",
    "        # zero-mean input; resizing has to be done beforehand for uniform tensor shape\n",
    "        with tf.variable_scope('preprocess'):\n",
    "            mean = tf.constant([123.68, 116.779, 103.939],\n",
    "                    dtype=tf.float32,\n",
    "                    shape=[1, 1, 1, 3],\n",
    "                    name='img_mean')\n",
    "            self.images = self.x*255.0 - mean\n",
    "\n",
    "        # conv1_1\n",
    "        self.conv1_1, weights, biases = layers.conv2d(name='conv1_1',\n",
    "                input=self.images,\n",
    "                shape=(3,3,3,64),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # conv1_2\n",
    "        self.conv1_2, weights, biases = layers.conv2d(name='conv1_2',\n",
    "                input=self.conv1_1,\n",
    "                shape=(3,3,64,64),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # pool1\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1_2,\n",
    "                ksize=[1, 2, 2, 1],\n",
    "                strides=[1, 2, 2, 1],\n",
    "                padding='SAME',\n",
    "                name='pool1')\n",
    "\n",
    "        # conv2_1\n",
    "        self.conv2_1, weights, biases = layers.conv2d(name='conv2_1',\n",
    "                input=self.pool1,\n",
    "                shape=(3,3,64,128),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # conv2_2\n",
    "        self.conv2_2, weights, biases = layers.conv2d(name='conv2_2',\n",
    "                input=self.conv2_1,\n",
    "                shape=(3,3,128,128),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # pool2\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2_2,\n",
    "                ksize=[1, 2, 2, 1],\n",
    "                strides=[1, 2, 2, 1],\n",
    "                padding='SAME',\n",
    "                name='pool2')\n",
    "\n",
    "        # conv3_1\n",
    "        self.conv3_1, weights, biases = layers.conv2d(name='conv3_1',\n",
    "                input=self.pool2,\n",
    "                shape=(3,3,128,256),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # conv3_2\n",
    "        self.conv3_2, weights, biases = layers.conv2d(name='conv3_2',\n",
    "                input=self.conv3_1,\n",
    "                shape=(3,3,256,256),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # conv3_3\n",
    "        self.conv3_3, weights, biases = layers.conv2d(name='conv3_3',\n",
    "                input=self.conv3_2,\n",
    "                shape=(3,3,256,256),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # pool3\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_3,\n",
    "                ksize=[1, 2, 2, 1],\n",
    "                strides=[1, 2, 2, 1],\n",
    "                padding='SAME',\n",
    "                name='pool3')\n",
    "\n",
    "        # conv4_1\n",
    "        self.conv4_1, weights, biases = layers.conv2d(name='conv4_1',\n",
    "                input=self.pool3,\n",
    "                shape=(3,3,256,512),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # conv4_2\n",
    "        self.conv4_2, weights, biases = layers.conv2d(name='conv4_2',\n",
    "                input=self.conv4_1,\n",
    "                shape=(3,3,512,512),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # conv4_3\n",
    "        self.conv4_3, weights, biases = layers.conv2d(name='conv4_3',\n",
    "                input=self.conv4_2,\n",
    "                shape=(3,3,512,512),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # pool4\n",
    "        self.pool4 = tf.nn.max_pool(self.conv4_3,\n",
    "                ksize=[1, 2, 2, 1],\n",
    "                strides=[1, 2, 2, 1],\n",
    "                padding='SAME',\n",
    "                name='pool4')\n",
    "\n",
    "        # conv5_1\n",
    "        self.conv5_1, weights, biases = layers.conv2d(name='conv5_1',\n",
    "                input=self.pool4,\n",
    "                shape=(3,3,512,512),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # conv5_2\n",
    "        self.conv5_2, weights, biases = layers.conv2d(name='conv5_2',\n",
    "                input=self.conv5_1,\n",
    "                shape=(3,3,512,512),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # conv5_3\n",
    "        self.conv5_3, weights, biases = layers.conv2d(name='conv5_3',\n",
    "                input=self.conv5_2,\n",
    "                shape=(3,3,512,512),\n",
    "                padding='SAME',\n",
    "                strides = [1,1,1,1],\n",
    "                activation=self.CONV_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # pool5\n",
    "        self.pool5 = tf.nn.max_pool(self.conv5_3,\n",
    "                ksize=[1, 2, 2, 1],\n",
    "                strides=[1, 2, 2, 1],\n",
    "                padding='SAME',\n",
    "                name='pool5')\n",
    "\n",
    "    def _fc_layers(self):\n",
    "        '''\n",
    "        All FC layers of VGG16 (+custom layers)\n",
    "        '''\n",
    "        # fc1\n",
    "        self.fc1, weights, biases = layers.fc(name='fc1',\n",
    "                input=tf.contrib.layers.flatten(self.pool5),\n",
    "                units=4096,\n",
    "                activation=self.FC_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # fc2\n",
    "        self.fc2, weights, biases = layers.fc(name='fc2',\n",
    "                input=self.fc1,\n",
    "                units=4096,\n",
    "                activation=self.FC_ACTIVATION)\n",
    "        self.parameters += [weights, biases]\n",
    "\n",
    "        # fc3\n",
    "        self.fc3, weights, biases = layers.fc(name='fc3',\n",
    "                input=self.fc2,\n",
    "                units=NUM_CLASSES,\n",
    "                activation='linear')\n",
    "\n",
    "    def load_pretrained_weights(self, sess):\n",
    "        '''\n",
    "        Load Pretrained VGG16 weights from .npz file\n",
    "        (weights converted from Caffe)\n",
    "        To only be used when no TensorFlow Snapshot is avaialable.\n",
    "        Assumes layers are properly added to self.parameters.\n",
    "        '''\n",
    "        print(\"Loading Imagenet Weights.\")\n",
    "\n",
    "        weights = np.load(PRETRAINED_WEIGHT_FILE)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            print(i, k, np.shape(weights[k]))\n",
    "            try:\n",
    "                sess.run(self.parameters[i].assign(weights[k]))\n",
    "            except:\n",
    "                print(\"%s layer not found.\" % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Imagenet Weights.\n",
      "0 conv1_1_W (3, 3, 3, 64)\n",
      "1 conv1_1_b (64,)\n",
      "2 conv1_2_W (3, 3, 64, 64)\n",
      "3 conv1_2_b (64,)\n",
      "4 conv2_1_W (3, 3, 64, 128)\n",
      "5 conv2_1_b (128,)\n",
      "6 conv2_2_W (3, 3, 128, 128)\n",
      "7 conv2_2_b (128,)\n",
      "8 conv3_1_W (3, 3, 128, 256)\n",
      "9 conv3_1_b (256,)\n",
      "10 conv3_2_W (3, 3, 256, 256)\n",
      "11 conv3_2_b (256,)\n",
      "12 conv3_3_W (3, 3, 256, 256)\n",
      "13 conv3_3_b (256,)\n",
      "14 conv4_1_W (3, 3, 256, 512)\n",
      "15 conv4_1_b (512,)\n",
      "16 conv4_2_W (3, 3, 512, 512)\n",
      "17 conv4_2_b (512,)\n",
      "18 conv4_3_W (3, 3, 512, 512)\n",
      "19 conv4_3_b (512,)\n",
      "20 conv5_1_W (3, 3, 512, 512)\n",
      "21 conv5_1_b (512,)\n",
      "22 conv5_2_W (3, 3, 512, 512)\n",
      "23 conv5_2_b (512,)\n",
      "24 conv5_3_W (3, 3, 512, 512)\n",
      "25 conv5_3_b (512,)\n",
      "26 fc6_W (25088, 4096)\n",
      "27 fc6_b (4096,)\n",
      "28 fc7_W (4096, 4096)\n",
      "29 fc7_b (4096,)\n",
      "30 fc8_W (4096, 1000)\n",
      "fc8_W layer not found.\n",
      "31 fc8_b (1000,)\n",
      "fc8_b layer not found.\n",
      "step 10 \t loss = 3.749, train_acc = 0.100 (3.224 sec/step)\n",
      "step 20 \t loss = 3.924, train_acc = 0.000 (3.242 sec/step)\n",
      "step 30 \t loss = 3.812, train_acc = 0.100 (3.191 sec/step)\n",
      "step 40 \t loss = 3.663, train_acc = 0.000 (3.239 sec/step)\n",
      "step 50 \t loss = 3.736, train_acc = 0.100 (3.197 sec/step)\n",
      "step 60 \t loss = 3.770, train_acc = 0.100 (3.209 sec/step)\n",
      "step 70 \t loss = 3.609, train_acc = 0.000 (3.224 sec/step)\n",
      "step 80 \t loss = 3.862, train_acc = 0.000 (3.178 sec/step)\n",
      "step 90 \t loss = 3.491, train_acc = 0.200 (3.193 sec/step)\n",
      "step 100 \t loss = 3.687, train_acc = 0.000 (3.193 sec/step)\n",
      "step 110 \t loss = 3.317, train_acc = 0.200 (3.315 sec/step)\n",
      "step 120 \t loss = 3.695, train_acc = 0.000 (3.201 sec/step)\n",
      "step 130 \t loss = 3.367, train_acc = 0.100 (3.185 sec/step)\n",
      "step 140 \t loss = 3.552, train_acc = 0.000 (3.215 sec/step)\n",
      "step 150 \t loss = 3.880, train_acc = 0.000 (3.166 sec/step)\n",
      "step 160 \t loss = 3.772, train_acc = 0.000 (3.178 sec/step)\n",
      "step 170 \t loss = 3.485, train_acc = 0.000 (3.192 sec/step)\n",
      "step 180 \t loss = 3.660, train_acc = 0.000 (3.206 sec/step)\n",
      "step 190 \t loss = 3.580, train_acc = 0.000 (3.193 sec/step)\n",
      "step 200 \t loss = 3.870, train_acc = 0.000 (3.164 sec/step)\n",
      "step 210 \t loss = 3.813, train_acc = 0.000 (3.203 sec/step)\n",
      "step 220 \t loss = 3.541, train_acc = 0.100 (3.208 sec/step)\n",
      "step 230 \t loss = 3.413, train_acc = 0.000 (3.191 sec/step)\n",
      "step 240 \t loss = 3.331, train_acc = 0.200 (3.295 sec/step)\n",
      "step 250 \t loss = 3.420, train_acc = 0.100 (3.186 sec/step)\n",
      "step 260 \t loss = 3.743, train_acc = 0.000 (3.233 sec/step)\n",
      "step 270 \t loss = 3.414, train_acc = 0.100 (3.189 sec/step)\n",
      "step 280 \t loss = 3.919, train_acc = 0.000 (3.220 sec/step)\n",
      "step 290 \t loss = 3.261, train_acc = 0.100 (3.187 sec/step)\n",
      "step 300 \t loss = 3.381, train_acc = 0.100 (3.197 sec/step)\n",
      "step 310 \t loss = 3.582, train_acc = 0.000 (3.243 sec/step)\n",
      "step 320 \t loss = 3.779, train_acc = 0.000 (3.293 sec/step)\n",
      "step 330 \t loss = 3.360, train_acc = 0.100 (3.192 sec/step)\n",
      "step 340 \t loss = 3.624, train_acc = 0.000 (3.236 sec/step)\n",
      "step 350 \t loss = 3.287, train_acc = 0.200 (3.245 sec/step)\n",
      "step 360 \t loss = 3.478, train_acc = 0.100 (3.219 sec/step)\n",
      "step 370 \t loss = 3.961, train_acc = 0.000 (3.160 sec/step)\n",
      "step 380 \t loss = 3.953, train_acc = 0.100 (3.182 sec/step)\n",
      "step 390 \t loss = 3.356, train_acc = 0.100 (3.207 sec/step)\n",
      "step 400 \t loss = 3.489, train_acc = 0.000 (3.178 sec/step)\n",
      "step 410 \t loss = 3.822, train_acc = 0.100 (3.287 sec/step)\n",
      "step 420 \t loss = 3.065, train_acc = 0.200 (3.204 sec/step)\n",
      "step 430 \t loss = 3.400, train_acc = 0.100 (3.171 sec/step)\n",
      "step 440 \t loss = 3.333, train_acc = 0.200 (3.254 sec/step)\n",
      "step 450 \t loss = 3.873, train_acc = 0.100 (3.190 sec/step)\n",
      "step 460 \t loss = 3.055, train_acc = 0.200 (3.173 sec/step)\n",
      "step 470 \t loss = 2.861, train_acc = 0.100 (3.196 sec/step)\n",
      "step 480 \t loss = 3.089, train_acc = 0.100 (3.242 sec/step)\n",
      "step 490 \t loss = 3.548, train_acc = 0.000 (3.206 sec/step)\n",
      "step 500 \t loss = 3.587, train_acc = 0.000 (3.205 sec/step)\n",
      "step 510 \t loss = 2.981, train_acc = 0.300 (3.209 sec/step)\n",
      "step 520 \t loss = 3.169, train_acc = 0.100 (3.180 sec/step)\n",
      "step 530 \t loss = 2.735, train_acc = 0.200 (3.161 sec/step)\n",
      "step 540 \t loss = 2.973, train_acc = 0.100 (3.206 sec/step)\n",
      "step 550 \t loss = 3.063, train_acc = 0.200 (3.230 sec/step)\n",
      "step 560 \t loss = 3.698, train_acc = 0.000 (3.183 sec/step)\n",
      "step 570 \t loss = 3.069, train_acc = 0.200 (3.201 sec/step)\n",
      "step 580 \t loss = 3.473, train_acc = 0.000 (3.207 sec/step)\n",
      "step 590 \t loss = 3.343, train_acc = 0.100 (3.177 sec/step)\n",
      "step 600 \t loss = 3.223, train_acc = 0.200 (3.179 sec/step)\n",
      "step 610 \t loss = 3.174, train_acc = 0.200 (3.196 sec/step)\n",
      "step 620 \t loss = 3.466, train_acc = 0.300 (3.193 sec/step)\n",
      "step 630 \t loss = 3.514, train_acc = 0.100 (3.200 sec/step)\n",
      "step 640 \t loss = 2.835, train_acc = 0.300 (3.228 sec/step)\n",
      "step 650 \t loss = 3.591, train_acc = 0.000 (3.202 sec/step)\n",
      "step 660 \t loss = 3.251, train_acc = 0.000 (3.181 sec/step)\n",
      "step 670 \t loss = 3.758, train_acc = 0.000 (3.193 sec/step)\n",
      "step 680 \t loss = 3.138, train_acc = 0.100 (3.209 sec/step)\n",
      "step 690 \t loss = 3.036, train_acc = 0.300 (3.175 sec/step)\n",
      "step 700 \t loss = 3.376, train_acc = 0.000 (3.201 sec/step)\n",
      "step 710 \t loss = 2.955, train_acc = 0.300 (3.180 sec/step)\n",
      "step 720 \t loss = 3.178, train_acc = 0.200 (3.187 sec/step)\n",
      "step 730 \t loss = 3.447, train_acc = 0.100 (3.190 sec/step)\n",
      "step 740 \t loss = 3.035, train_acc = 0.100 (3.242 sec/step)\n",
      "step 750 \t loss = 3.515, train_acc = 0.000 (3.202 sec/step)\n",
      "step 760 \t loss = 3.681, train_acc = 0.100 (3.198 sec/step)\n",
      "step 770 \t loss = 2.782, train_acc = 0.100 (3.218 sec/step)\n",
      "step 780 \t loss = 2.646, train_acc = 0.300 (3.303 sec/step)\n",
      "step 790 \t loss = 2.569, train_acc = 0.200 (3.286 sec/step)\n",
      "step 800 \t loss = 2.806, train_acc = 0.400 (3.287 sec/step)\n",
      "step 810 \t loss = 3.202, train_acc = 0.000 (3.192 sec/step)\n",
      "step 820 \t loss = 2.516, train_acc = 0.100 (3.203 sec/step)\n",
      "step 830 \t loss = 2.389, train_acc = 0.500 (3.207 sec/step)\n",
      "step 840 \t loss = 3.013, train_acc = 0.100 (3.182 sec/step)\n",
      "step 850 \t loss = 3.388, train_acc = 0.200 (3.200 sec/step)\n",
      "step 860 \t loss = 2.790, train_acc = 0.300 (3.208 sec/step)\n",
      "step 870 \t loss = 2.859, train_acc = 0.100 (3.201 sec/step)\n",
      "step 880 \t loss = 3.392, train_acc = 0.100 (3.227 sec/step)\n",
      "step 890 \t loss = 2.994, train_acc = 0.100 (3.195 sec/step)\n",
      "step 900 \t loss = 3.403, train_acc = 0.000 (3.200 sec/step)\n",
      "step 910 \t loss = 3.615, train_acc = 0.100 (3.197 sec/step)\n",
      "step 920 \t loss = 2.902, train_acc = 0.400 (3.184 sec/step)\n",
      "step 930 \t loss = 3.228, train_acc = 0.100 (3.192 sec/step)\n",
      "step 940 \t loss = 3.192, train_acc = 0.100 (3.226 sec/step)\n",
      "step 950 \t loss = 2.435, train_acc = 0.500 (3.223 sec/step)\n",
      "step 960 \t loss = 3.112, train_acc = 0.100 (3.216 sec/step)\n",
      "step 970 \t loss = 3.190, train_acc = 0.200 (3.210 sec/step)\n",
      "step 980 \t loss = 3.091, train_acc = 0.200 (3.186 sec/step)\n",
      "step 990 \t loss = 3.206, train_acc = 0.200 (3.233 sec/step)\n",
      "step 1000 \t loss = 2.444, train_acc = 0.200 (3.160 sec/step)\n",
      "step 1010 \t loss = 2.805, train_acc = 0.100 (3.172 sec/step)\n",
      "step 1020 \t loss = 3.222, train_acc = 0.200 (3.217 sec/step)\n",
      "step 1030 \t loss = 3.045, train_acc = 0.000 (3.225 sec/step)\n",
      "step 1040 \t loss = 3.148, train_acc = 0.200 (3.256 sec/step)\n",
      "step 1050 \t loss = 3.178, train_acc = 0.300 (3.236 sec/step)\n",
      "step 1060 \t loss = 3.261, train_acc = 0.100 (3.179 sec/step)\n",
      "step 1070 \t loss = 3.294, train_acc = 0.300 (3.180 sec/step)\n",
      "step 1080 \t loss = 2.827, train_acc = 0.200 (3.198 sec/step)\n",
      "step 1090 \t loss = 3.392, train_acc = 0.100 (3.193 sec/step)\n",
      "step 1100 \t loss = 3.132, train_acc = 0.100 (3.170 sec/step)\n",
      "step 1110 \t loss = 3.185, train_acc = 0.200 (3.211 sec/step)\n",
      "step 1120 \t loss = 2.765, train_acc = 0.300 (3.215 sec/step)\n",
      "step 1130 \t loss = 3.131, train_acc = 0.200 (3.209 sec/step)\n",
      "step 1140 \t loss = 2.993, train_acc = 0.100 (3.204 sec/step)\n",
      "step 1150 \t loss = 3.022, train_acc = 0.200 (3.199 sec/step)\n",
      "step 1160 \t loss = 2.854, train_acc = 0.200 (3.180 sec/step)\n",
      "step 1170 \t loss = 3.656, train_acc = 0.100 (3.201 sec/step)\n",
      "step 1180 \t loss = 3.329, train_acc = 0.200 (3.177 sec/step)\n",
      "step 1190 \t loss = 2.766, train_acc = 0.000 (3.185 sec/step)\n",
      "step 1200 \t loss = 3.147, train_acc = 0.300 (3.209 sec/step)\n",
      "step 1210 \t loss = 3.267, train_acc = 0.100 (3.255 sec/step)\n",
      "step 1220 \t loss = 2.764, train_acc = 0.300 (3.178 sec/step)\n",
      "step 1230 \t loss = 3.047, train_acc = 0.200 (3.344 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1240 \t loss = 2.525, train_acc = 0.400 (3.197 sec/step)\n",
      "step 1250 \t loss = 2.940, train_acc = 0.100 (3.203 sec/step)\n",
      "step 1260 \t loss = 2.873, train_acc = 0.300 (3.195 sec/step)\n",
      "step 1270 \t loss = 3.208, train_acc = 0.400 (3.190 sec/step)\n",
      "step 1280 \t loss = 2.925, train_acc = 0.200 (3.194 sec/step)\n",
      "step 1290 \t loss = 2.769, train_acc = 0.200 (3.161 sec/step)\n",
      "step 1300 \t loss = 2.631, train_acc = 0.300 (3.186 sec/step)\n",
      "step 1310 \t loss = 3.048, train_acc = 0.100 (3.290 sec/step)\n",
      "step 1320 \t loss = 2.554, train_acc = 0.300 (3.225 sec/step)\n",
      "step 1330 \t loss = 2.437, train_acc = 0.300 (3.242 sec/step)\n",
      "step 1340 \t loss = 2.954, train_acc = 0.200 (3.270 sec/step)\n",
      "step 1350 \t loss = 2.880, train_acc = 0.300 (3.183 sec/step)\n",
      "step 1360 \t loss = 2.997, train_acc = 0.200 (3.257 sec/step)\n",
      "step 1370 \t loss = 2.674, train_acc = 0.300 (3.181 sec/step)\n",
      "step 1380 \t loss = 3.235, train_acc = 0.000 (3.190 sec/step)\n",
      "step 1390 \t loss = 3.177, train_acc = 0.100 (3.224 sec/step)\n",
      "step 1400 \t loss = 2.540, train_acc = 0.200 (3.181 sec/step)\n",
      "step 1410 \t loss = 3.177, train_acc = 0.200 (3.174 sec/step)\n",
      "step 1420 \t loss = 2.520, train_acc = 0.400 (3.206 sec/step)\n",
      "step 1430 \t loss = 3.084, train_acc = 0.100 (3.212 sec/step)\n",
      "step 1440 \t loss = 2.552, train_acc = 0.400 (3.227 sec/step)\n",
      "step 1450 \t loss = 3.576, train_acc = 0.100 (3.201 sec/step)\n",
      "step 1460 \t loss = 2.487, train_acc = 0.300 (3.188 sec/step)\n",
      "step 1470 \t loss = 2.851, train_acc = 0.200 (3.189 sec/step)\n",
      "step 1480 \t loss = 3.434, train_acc = 0.100 (3.210 sec/step)\n",
      "step 1490 \t loss = 3.440, train_acc = 0.100 (3.192 sec/step)\n",
      "step 1500 \t loss = 3.102, train_acc = 0.000 (3.184 sec/step)\n",
      "step 1510 \t loss = 2.710, train_acc = 0.200 (3.204 sec/step)\n",
      "step 1520 \t loss = 2.934, train_acc = 0.200 (3.183 sec/step)\n",
      "step 1530 \t loss = 2.547, train_acc = 0.500 (3.178 sec/step)\n",
      "step 1540 \t loss = 2.443, train_acc = 0.200 (3.337 sec/step)\n",
      "step 1550 \t loss = 2.314, train_acc = 0.400 (3.197 sec/step)\n",
      "step 1560 \t loss = 2.676, train_acc = 0.300 (3.212 sec/step)\n",
      "step 1570 \t loss = 2.846, train_acc = 0.100 (3.201 sec/step)\n",
      "step 1580 \t loss = 3.102, train_acc = 0.200 (3.208 sec/step)\n",
      "step 1590 \t loss = 2.887, train_acc = 0.400 (3.171 sec/step)\n",
      "step 1600 \t loss = 2.950, train_acc = 0.100 (3.208 sec/step)\n",
      "step 1610 \t loss = 2.124, train_acc = 0.500 (3.170 sec/step)\n",
      "step 1620 \t loss = 2.109, train_acc = 0.400 (3.204 sec/step)\n",
      "step 1630 \t loss = 3.814, train_acc = 0.000 (3.269 sec/step)\n",
      "step 1640 \t loss = 2.923, train_acc = 0.100 (3.261 sec/step)\n",
      "step 1650 \t loss = 3.333, train_acc = 0.000 (3.258 sec/step)\n",
      "step 1660 \t loss = 3.011, train_acc = 0.100 (3.228 sec/step)\n",
      "step 1670 \t loss = 2.846, train_acc = 0.200 (3.182 sec/step)\n",
      "step 1680 \t loss = 2.126, train_acc = 0.300 (3.186 sec/step)\n",
      "step 1690 \t loss = 3.178, train_acc = 0.100 (3.152 sec/step)\n",
      "step 1700 \t loss = 2.379, train_acc = 0.200 (3.182 sec/step)\n",
      "step 1710 \t loss = 2.838, train_acc = 0.100 (3.237 sec/step)\n",
      "step 1720 \t loss = 2.078, train_acc = 0.500 (3.249 sec/step)\n",
      "step 1730 \t loss = 3.604, train_acc = 0.000 (3.168 sec/step)\n",
      "step 1740 \t loss = 2.904, train_acc = 0.300 (3.183 sec/step)\n",
      "step 1750 \t loss = 2.635, train_acc = 0.200 (3.180 sec/step)\n",
      "step 1760 \t loss = 2.513, train_acc = 0.200 (3.191 sec/step)\n",
      "step 1770 \t loss = 1.885, train_acc = 0.500 (3.216 sec/step)\n",
      "step 1780 \t loss = 2.678, train_acc = 0.300 (3.232 sec/step)\n",
      "step 1790 \t loss = 2.541, train_acc = 0.400 (3.152 sec/step)\n",
      "step 1800 \t loss = 2.816, train_acc = 0.500 (3.228 sec/step)\n",
      "step 1810 \t loss = 2.397, train_acc = 0.300 (3.177 sec/step)\n",
      "step 1820 \t loss = 2.290, train_acc = 0.200 (3.166 sec/step)\n",
      "step 1830 \t loss = 2.726, train_acc = 0.300 (3.225 sec/step)\n",
      "step 1840 \t loss = 2.870, train_acc = 0.300 (3.203 sec/step)\n",
      "step 1850 \t loss = 1.888, train_acc = 0.500 (3.261 sec/step)\n",
      "step 1860 \t loss = 2.943, train_acc = 0.400 (3.260 sec/step)\n",
      "step 1870 \t loss = 2.408, train_acc = 0.400 (3.201 sec/step)\n",
      "step 1880 \t loss = 2.295, train_acc = 0.200 (3.234 sec/step)\n",
      "step 1890 \t loss = 3.603, train_acc = 0.100 (3.184 sec/step)\n",
      "VALIDATION \t acc = 0.207 (3.633 sec)\n",
      "New Best Accuracy 0.207 > Old Best 0.000.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 1900 \t loss = 3.928, train_acc = 0.100 (3.277 sec/step)\n",
      "step 1910 \t loss = 2.984, train_acc = 0.200 (3.206 sec/step)\n",
      "step 1920 \t loss = 2.253, train_acc = 0.200 (3.192 sec/step)\n",
      "step 1930 \t loss = 2.733, train_acc = 0.300 (3.183 sec/step)\n",
      "step 1940 \t loss = 2.528, train_acc = 0.100 (3.208 sec/step)\n",
      "step 1950 \t loss = 2.973, train_acc = 0.300 (3.219 sec/step)\n",
      "step 1960 \t loss = 2.188, train_acc = 0.400 (3.230 sec/step)\n",
      "step 1970 \t loss = 2.363, train_acc = 0.100 (3.158 sec/step)\n",
      "step 1980 \t loss = 2.895, train_acc = 0.200 (3.223 sec/step)\n",
      "step 1990 \t loss = 2.331, train_acc = 0.400 (3.213 sec/step)\n",
      "step 2000 \t loss = 2.734, train_acc = 0.300 (3.232 sec/step)\n",
      "step 2010 \t loss = 2.918, train_acc = 0.300 (3.215 sec/step)\n",
      "step 2020 \t loss = 2.567, train_acc = 0.300 (3.196 sec/step)\n",
      "step 2030 \t loss = 1.782, train_acc = 0.400 (3.248 sec/step)\n",
      "step 2040 \t loss = 2.504, train_acc = 0.300 (3.220 sec/step)\n",
      "step 2050 \t loss = 2.683, train_acc = 0.200 (3.186 sec/step)\n",
      "step 2060 \t loss = 2.590, train_acc = 0.400 (3.172 sec/step)\n",
      "step 2070 \t loss = 2.206, train_acc = 0.400 (3.182 sec/step)\n",
      "step 2080 \t loss = 2.674, train_acc = 0.000 (3.209 sec/step)\n",
      "step 2090 \t loss = 2.575, train_acc = 0.200 (3.253 sec/step)\n",
      "step 2100 \t loss = 2.972, train_acc = 0.200 (3.206 sec/step)\n",
      "step 2110 \t loss = 2.718, train_acc = 0.300 (3.257 sec/step)\n",
      "step 2120 \t loss = 3.146, train_acc = 0.300 (3.176 sec/step)\n",
      "step 2130 \t loss = 1.599, train_acc = 0.500 (3.187 sec/step)\n",
      "step 2140 \t loss = 2.012, train_acc = 0.400 (3.240 sec/step)\n",
      "step 2150 \t loss = 2.993, train_acc = 0.100 (3.203 sec/step)\n",
      "step 2160 \t loss = 2.813, train_acc = 0.200 (3.219 sec/step)\n",
      "step 2170 \t loss = 3.018, train_acc = 0.400 (3.190 sec/step)\n",
      "step 2180 \t loss = 2.737, train_acc = 0.300 (3.227 sec/step)\n",
      "step 2190 \t loss = 2.210, train_acc = 0.400 (3.202 sec/step)\n",
      "step 2200 \t loss = 2.879, train_acc = 0.200 (3.201 sec/step)\n",
      "step 2210 \t loss = 2.873, train_acc = 0.200 (3.221 sec/step)\n",
      "step 2220 \t loss = 3.133, train_acc = 0.200 (3.238 sec/step)\n",
      "step 2230 \t loss = 2.646, train_acc = 0.100 (3.229 sec/step)\n",
      "step 2240 \t loss = 2.515, train_acc = 0.300 (3.169 sec/step)\n",
      "step 2250 \t loss = 1.652, train_acc = 0.600 (3.182 sec/step)\n",
      "step 2260 \t loss = 2.667, train_acc = 0.300 (3.199 sec/step)\n",
      "step 2270 \t loss = 1.983, train_acc = 0.400 (3.212 sec/step)\n",
      "step 2280 \t loss = 2.276, train_acc = 0.400 (3.245 sec/step)\n",
      "step 2290 \t loss = 1.312, train_acc = 0.700 (3.220 sec/step)\n",
      "step 2300 \t loss = 2.443, train_acc = 0.300 (3.198 sec/step)\n",
      "step 2310 \t loss = 2.699, train_acc = 0.300 (3.210 sec/step)\n",
      "step 2320 \t loss = 2.271, train_acc = 0.400 (3.236 sec/step)\n",
      "step 2330 \t loss = 1.992, train_acc = 0.400 (3.235 sec/step)\n",
      "step 2340 \t loss = 2.240, train_acc = 0.500 (3.210 sec/step)\n",
      "step 2350 \t loss = 2.856, train_acc = 0.400 (3.172 sec/step)\n",
      "step 2360 \t loss = 2.326, train_acc = 0.500 (3.179 sec/step)\n",
      "step 2370 \t loss = 2.034, train_acc = 0.300 (3.229 sec/step)\n",
      "step 2380 \t loss = 2.113, train_acc = 0.400 (3.242 sec/step)\n",
      "step 2390 \t loss = 2.182, train_acc = 0.400 (3.211 sec/step)\n",
      "step 2400 \t loss = 2.454, train_acc = 0.300 (3.201 sec/step)\n",
      "step 2410 \t loss = 1.654, train_acc = 0.500 (3.186 sec/step)\n",
      "step 2420 \t loss = 2.497, train_acc = 0.200 (3.200 sec/step)\n",
      "step 2430 \t loss = 2.461, train_acc = 0.200 (3.202 sec/step)\n",
      "step 2440 \t loss = 2.065, train_acc = 0.400 (3.210 sec/step)\n",
      "step 2450 \t loss = 1.988, train_acc = 0.300 (3.231 sec/step)\n",
      "step 2460 \t loss = 2.847, train_acc = 0.200 (3.252 sec/step)\n",
      "step 2470 \t loss = 1.730, train_acc = 0.700 (3.205 sec/step)\n",
      "step 2480 \t loss = 3.123, train_acc = 0.200 (3.216 sec/step)\n",
      "step 2490 \t loss = 2.289, train_acc = 0.300 (3.198 sec/step)\n",
      "step 2500 \t loss = 3.085, train_acc = 0.200 (3.208 sec/step)\n",
      "step 2510 \t loss = 2.459, train_acc = 0.200 (3.225 sec/step)\n",
      "step 2520 \t loss = 2.290, train_acc = 0.300 (3.178 sec/step)\n",
      "step 2530 \t loss = 3.457, train_acc = 0.100 (3.247 sec/step)\n",
      "step 2540 \t loss = 1.819, train_acc = 0.300 (3.206 sec/step)\n",
      "step 2550 \t loss = 2.864, train_acc = 0.000 (3.242 sec/step)\n",
      "step 2560 \t loss = 2.228, train_acc = 0.500 (3.234 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2570 \t loss = 3.141, train_acc = 0.100 (3.206 sec/step)\n",
      "step 2580 \t loss = 1.275, train_acc = 0.500 (3.187 sec/step)\n",
      "step 2590 \t loss = 2.228, train_acc = 0.200 (3.216 sec/step)\n",
      "step 2600 \t loss = 3.435, train_acc = 0.100 (3.178 sec/step)\n",
      "step 2610 \t loss = 1.807, train_acc = 0.500 (3.188 sec/step)\n",
      "step 2620 \t loss = 1.691, train_acc = 0.500 (3.209 sec/step)\n",
      "step 2630 \t loss = 2.978, train_acc = 0.200 (3.210 sec/step)\n",
      "step 2640 \t loss = 1.743, train_acc = 0.500 (3.161 sec/step)\n",
      "step 2650 \t loss = 2.362, train_acc = 0.300 (3.236 sec/step)\n",
      "step 2660 \t loss = 2.810, train_acc = 0.200 (3.202 sec/step)\n",
      "step 2670 \t loss = 1.655, train_acc = 0.400 (3.208 sec/step)\n",
      "step 2680 \t loss = 1.747, train_acc = 0.500 (3.178 sec/step)\n",
      "step 2690 \t loss = 2.042, train_acc = 0.300 (3.180 sec/step)\n",
      "step 2700 \t loss = 1.282, train_acc = 0.700 (3.199 sec/step)\n",
      "step 2710 \t loss = 2.180, train_acc = 0.300 (3.216 sec/step)\n",
      "step 2720 \t loss = 1.733, train_acc = 0.600 (3.184 sec/step)\n",
      "step 2730 \t loss = 2.027, train_acc = 0.400 (3.196 sec/step)\n",
      "step 2740 \t loss = 3.035, train_acc = 0.200 (3.219 sec/step)\n",
      "step 2750 \t loss = 2.442, train_acc = 0.500 (3.180 sec/step)\n",
      "step 2760 \t loss = 1.685, train_acc = 0.600 (3.166 sec/step)\n",
      "step 2770 \t loss = 2.394, train_acc = 0.300 (3.205 sec/step)\n",
      "step 2780 \t loss = 2.557, train_acc = 0.300 (3.204 sec/step)\n",
      "step 2790 \t loss = 1.933, train_acc = 0.400 (3.343 sec/step)\n",
      "step 2800 \t loss = 3.714, train_acc = 0.000 (3.209 sec/step)\n",
      "step 2810 \t loss = 2.827, train_acc = 0.200 (3.257 sec/step)\n",
      "step 2820 \t loss = 1.814, train_acc = 0.500 (3.223 sec/step)\n",
      "step 2830 \t loss = 2.398, train_acc = 0.200 (3.194 sec/step)\n",
      "step 2840 \t loss = 2.890, train_acc = 0.200 (3.200 sec/step)\n",
      "step 2850 \t loss = 2.204, train_acc = 0.300 (3.321 sec/step)\n",
      "step 2860 \t loss = 1.565, train_acc = 0.400 (3.215 sec/step)\n",
      "step 2870 \t loss = 2.355, train_acc = 0.300 (3.268 sec/step)\n",
      "step 2880 \t loss = 1.743, train_acc = 0.500 (3.201 sec/step)\n",
      "step 2890 \t loss = 2.201, train_acc = 0.200 (3.209 sec/step)\n",
      "step 2900 \t loss = 1.280, train_acc = 0.700 (3.202 sec/step)\n",
      "step 2910 \t loss = 2.564, train_acc = 0.200 (3.196 sec/step)\n",
      "step 2920 \t loss = 2.619, train_acc = 0.200 (3.247 sec/step)\n",
      "step 2930 \t loss = 1.911, train_acc = 0.500 (3.199 sec/step)\n",
      "step 2940 \t loss = 2.704, train_acc = 0.200 (3.200 sec/step)\n",
      "step 2950 \t loss = 2.474, train_acc = 0.400 (3.263 sec/step)\n",
      "step 2960 \t loss = 2.347, train_acc = 0.300 (3.164 sec/step)\n",
      "step 2970 \t loss = 2.550, train_acc = 0.300 (3.192 sec/step)\n",
      "step 2980 \t loss = 1.964, train_acc = 0.400 (3.197 sec/step)\n",
      "step 2990 \t loss = 3.278, train_acc = 0.100 (3.200 sec/step)\n",
      "step 3000 \t loss = 2.323, train_acc = 0.100 (3.201 sec/step)\n",
      "step 3010 \t loss = 1.892, train_acc = 0.400 (3.180 sec/step)\n",
      "step 3020 \t loss = 1.712, train_acc = 0.400 (3.206 sec/step)\n",
      "step 3030 \t loss = 2.633, train_acc = 0.300 (3.172 sec/step)\n",
      "step 3040 \t loss = 2.942, train_acc = 0.200 (3.197 sec/step)\n",
      "step 3050 \t loss = 1.382, train_acc = 0.700 (3.205 sec/step)\n",
      "step 3060 \t loss = 1.751, train_acc = 0.500 (3.221 sec/step)\n",
      "step 3070 \t loss = 2.681, train_acc = 0.100 (3.195 sec/step)\n",
      "step 3080 \t loss = 2.500, train_acc = 0.500 (3.193 sec/step)\n",
      "step 3090 \t loss = 1.903, train_acc = 0.400 (3.236 sec/step)\n",
      "step 3100 \t loss = 2.183, train_acc = 0.300 (3.310 sec/step)\n",
      "step 3110 \t loss = 2.834, train_acc = 0.400 (3.218 sec/step)\n",
      "step 3120 \t loss = 1.962, train_acc = 0.400 (3.221 sec/step)\n",
      "step 3130 \t loss = 1.838, train_acc = 0.400 (3.229 sec/step)\n",
      "step 3140 \t loss = 2.031, train_acc = 0.500 (3.195 sec/step)\n",
      "step 3150 \t loss = 1.325, train_acc = 0.600 (3.246 sec/step)\n",
      "step 3160 \t loss = 1.998, train_acc = 0.500 (3.217 sec/step)\n",
      "step 3170 \t loss = 2.038, train_acc = 0.500 (3.222 sec/step)\n",
      "step 3180 \t loss = 2.175, train_acc = 0.300 (3.248 sec/step)\n",
      "step 3190 \t loss = 3.402, train_acc = 0.100 (3.196 sec/step)\n",
      "step 3200 \t loss = 1.839, train_acc = 0.400 (3.171 sec/step)\n",
      "step 3210 \t loss = 2.094, train_acc = 0.400 (3.215 sec/step)\n",
      "step 3220 \t loss = 1.972, train_acc = 0.400 (3.225 sec/step)\n",
      "step 3230 \t loss = 1.735, train_acc = 0.500 (3.217 sec/step)\n",
      "step 3240 \t loss = 1.934, train_acc = 0.400 (3.221 sec/step)\n",
      "step 3250 \t loss = 2.813, train_acc = 0.300 (3.233 sec/step)\n",
      "step 3260 \t loss = 2.569, train_acc = 0.300 (3.197 sec/step)\n",
      "step 3270 \t loss = 1.508, train_acc = 0.500 (3.176 sec/step)\n",
      "step 3280 \t loss = 2.074, train_acc = 0.100 (3.210 sec/step)\n",
      "step 3290 \t loss = 2.968, train_acc = 0.200 (3.208 sec/step)\n",
      "step 3300 \t loss = 2.665, train_acc = 0.200 (3.199 sec/step)\n",
      "step 3310 \t loss = 2.461, train_acc = 0.300 (3.176 sec/step)\n",
      "step 3320 \t loss = 1.767, train_acc = 0.700 (3.213 sec/step)\n",
      "step 3330 \t loss = 2.030, train_acc = 0.500 (3.195 sec/step)\n",
      "step 3340 \t loss = 1.777, train_acc = 0.600 (3.204 sec/step)\n",
      "step 3350 \t loss = 2.403, train_acc = 0.100 (3.214 sec/step)\n",
      "step 3360 \t loss = 1.464, train_acc = 0.600 (3.170 sec/step)\n",
      "step 3370 \t loss = 2.788, train_acc = 0.400 (3.191 sec/step)\n",
      "step 3380 \t loss = 2.725, train_acc = 0.100 (3.246 sec/step)\n",
      "step 3390 \t loss = 2.651, train_acc = 0.200 (3.179 sec/step)\n",
      "step 3400 \t loss = 2.306, train_acc = 0.400 (3.221 sec/step)\n",
      "step 3410 \t loss = 2.791, train_acc = 0.300 (3.208 sec/step)\n",
      "step 3420 \t loss = 2.220, train_acc = 0.200 (3.178 sec/step)\n",
      "step 3430 \t loss = 1.590, train_acc = 0.400 (3.203 sec/step)\n",
      "step 3440 \t loss = 2.221, train_acc = 0.200 (3.188 sec/step)\n",
      "step 3450 \t loss = 1.973, train_acc = 0.400 (3.218 sec/step)\n",
      "step 3460 \t loss = 2.333, train_acc = 0.400 (3.215 sec/step)\n",
      "step 3470 \t loss = 2.188, train_acc = 0.200 (3.211 sec/step)\n",
      "step 3480 \t loss = 1.534, train_acc = 0.500 (3.240 sec/step)\n",
      "step 3490 \t loss = 1.504, train_acc = 0.500 (3.241 sec/step)\n",
      "step 3500 \t loss = 3.449, train_acc = 0.100 (3.203 sec/step)\n",
      "step 3510 \t loss = 2.062, train_acc = 0.500 (3.188 sec/step)\n",
      "step 3520 \t loss = 1.684, train_acc = 0.700 (3.212 sec/step)\n",
      "step 3530 \t loss = 3.619, train_acc = 0.000 (3.236 sec/step)\n",
      "step 3540 \t loss = 2.815, train_acc = 0.200 (3.239 sec/step)\n",
      "step 3550 \t loss = 2.395, train_acc = 0.300 (3.213 sec/step)\n",
      "step 3560 \t loss = 2.460, train_acc = 0.100 (3.222 sec/step)\n",
      "step 3570 \t loss = 2.239, train_acc = 0.300 (3.199 sec/step)\n",
      "step 3580 \t loss = 2.331, train_acc = 0.300 (3.214 sec/step)\n",
      "step 3590 \t loss = 2.458, train_acc = 0.200 (3.219 sec/step)\n",
      "step 3600 \t loss = 1.577, train_acc = 0.400 (3.204 sec/step)\n",
      "step 3610 \t loss = 2.288, train_acc = 0.600 (3.208 sec/step)\n",
      "step 3620 \t loss = 1.694, train_acc = 0.500 (3.192 sec/step)\n",
      "step 3630 \t loss = 3.106, train_acc = 0.300 (3.198 sec/step)\n",
      "step 3640 \t loss = 2.565, train_acc = 0.200 (3.223 sec/step)\n",
      "step 3650 \t loss = 1.991, train_acc = 0.400 (3.204 sec/step)\n",
      "step 3660 \t loss = 1.920, train_acc = 0.400 (3.265 sec/step)\n",
      "step 3670 \t loss = 0.797, train_acc = 0.800 (3.191 sec/step)\n",
      "step 3680 \t loss = 1.892, train_acc = 0.300 (3.195 sec/step)\n",
      "step 3690 \t loss = 1.720, train_acc = 0.400 (3.217 sec/step)\n",
      "step 3700 \t loss = 2.836, train_acc = 0.300 (3.257 sec/step)\n",
      "step 3710 \t loss = 2.374, train_acc = 0.100 (3.218 sec/step)\n",
      "step 3720 \t loss = 2.047, train_acc = 0.400 (3.202 sec/step)\n",
      "step 3730 \t loss = 2.315, train_acc = 0.200 (3.214 sec/step)\n",
      "step 3740 \t loss = 2.862, train_acc = 0.100 (3.168 sec/step)\n",
      "step 3750 \t loss = 1.629, train_acc = 0.400 (3.211 sec/step)\n",
      "step 3760 \t loss = 1.771, train_acc = 0.400 (3.224 sec/step)\n",
      "step 3770 \t loss = 1.423, train_acc = 0.400 (3.204 sec/step)\n",
      "step 3780 \t loss = 1.558, train_acc = 0.800 (3.186 sec/step)\n",
      "step 3790 \t loss = 2.888, train_acc = 0.200 (3.204 sec/step)\n",
      "VALIDATION \t acc = 0.406 (3.618 sec)\n",
      "New Best Accuracy 0.406 > Old Best 0.207.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 3800 \t loss = 2.605, train_acc = 0.400 (3.240 sec/step)\n",
      "step 3810 \t loss = 2.130, train_acc = 0.400 (3.166 sec/step)\n",
      "step 3820 \t loss = 1.334, train_acc = 0.600 (3.218 sec/step)\n",
      "step 3830 \t loss = 1.938, train_acc = 0.400 (3.199 sec/step)\n",
      "step 3840 \t loss = 1.080, train_acc = 0.600 (3.217 sec/step)\n",
      "step 3850 \t loss = 2.527, train_acc = 0.200 (3.225 sec/step)\n",
      "step 3860 \t loss = 1.294, train_acc = 0.600 (3.252 sec/step)\n",
      "step 3870 \t loss = 1.460, train_acc = 0.600 (3.214 sec/step)\n",
      "step 3880 \t loss = 2.730, train_acc = 0.300 (3.242 sec/step)\n",
      "step 3890 \t loss = 1.646, train_acc = 0.700 (3.223 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3900 \t loss = 1.886, train_acc = 0.600 (3.227 sec/step)\n",
      "step 3910 \t loss = 1.966, train_acc = 0.300 (3.199 sec/step)\n",
      "step 3920 \t loss = 2.000, train_acc = 0.400 (3.252 sec/step)\n",
      "step 3930 \t loss = 1.020, train_acc = 0.800 (3.213 sec/step)\n",
      "step 3940 \t loss = 2.158, train_acc = 0.400 (3.218 sec/step)\n",
      "step 3950 \t loss = 1.411, train_acc = 0.700 (3.192 sec/step)\n",
      "step 3960 \t loss = 1.787, train_acc = 0.400 (3.247 sec/step)\n",
      "step 3970 \t loss = 1.753, train_acc = 0.500 (3.182 sec/step)\n",
      "step 3980 \t loss = 1.707, train_acc = 0.400 (3.192 sec/step)\n",
      "step 3990 \t loss = 2.017, train_acc = 0.300 (3.193 sec/step)\n",
      "step 4000 \t loss = 1.997, train_acc = 0.400 (3.263 sec/step)\n",
      "step 4010 \t loss = 1.716, train_acc = 0.400 (3.212 sec/step)\n",
      "step 4020 \t loss = 2.587, train_acc = 0.300 (3.209 sec/step)\n",
      "step 4030 \t loss = 1.536, train_acc = 0.500 (3.201 sec/step)\n",
      "step 4040 \t loss = 2.020, train_acc = 0.400 (3.218 sec/step)\n",
      "step 4050 \t loss = 3.048, train_acc = 0.200 (3.247 sec/step)\n",
      "step 4060 \t loss = 2.652, train_acc = 0.300 (3.211 sec/step)\n",
      "step 4070 \t loss = 2.176, train_acc = 0.400 (3.227 sec/step)\n",
      "step 4080 \t loss = 2.042, train_acc = 0.400 (3.241 sec/step)\n",
      "step 4090 \t loss = 1.687, train_acc = 0.400 (3.224 sec/step)\n",
      "step 4100 \t loss = 2.654, train_acc = 0.300 (3.242 sec/step)\n",
      "step 4110 \t loss = 2.571, train_acc = 0.300 (3.267 sec/step)\n",
      "step 4120 \t loss = 2.354, train_acc = 0.300 (3.205 sec/step)\n",
      "step 4130 \t loss = 2.024, train_acc = 0.400 (3.239 sec/step)\n",
      "step 4140 \t loss = 1.846, train_acc = 0.500 (3.190 sec/step)\n",
      "step 4150 \t loss = 1.290, train_acc = 0.700 (3.201 sec/step)\n",
      "step 4160 \t loss = 2.070, train_acc = 0.400 (3.263 sec/step)\n",
      "step 4170 \t loss = 1.493, train_acc = 0.600 (3.236 sec/step)\n",
      "step 4180 \t loss = 1.883, train_acc = 0.500 (3.228 sec/step)\n",
      "step 4190 \t loss = 1.203, train_acc = 0.600 (3.235 sec/step)\n",
      "step 4200 \t loss = 2.191, train_acc = 0.300 (3.253 sec/step)\n",
      "step 4210 \t loss = 2.367, train_acc = 0.200 (3.253 sec/step)\n",
      "step 4220 \t loss = 1.809, train_acc = 0.300 (3.292 sec/step)\n",
      "step 4230 \t loss = 1.129, train_acc = 0.600 (3.239 sec/step)\n",
      "step 4240 \t loss = 1.848, train_acc = 0.400 (3.237 sec/step)\n",
      "step 4250 \t loss = 2.629, train_acc = 0.500 (3.196 sec/step)\n",
      "step 4260 \t loss = 1.902, train_acc = 0.400 (3.219 sec/step)\n",
      "step 4270 \t loss = 1.222, train_acc = 0.400 (3.215 sec/step)\n",
      "step 4280 \t loss = 1.749, train_acc = 0.300 (3.219 sec/step)\n",
      "step 4290 \t loss = 1.891, train_acc = 0.300 (3.237 sec/step)\n",
      "step 4300 \t loss = 2.286, train_acc = 0.500 (3.208 sec/step)\n",
      "step 4310 \t loss = 2.202, train_acc = 0.300 (3.245 sec/step)\n",
      "step 4320 \t loss = 1.768, train_acc = 0.500 (3.213 sec/step)\n",
      "step 4330 \t loss = 2.288, train_acc = 0.200 (3.207 sec/step)\n",
      "step 4340 \t loss = 1.224, train_acc = 0.500 (3.205 sec/step)\n",
      "step 4350 \t loss = 1.101, train_acc = 0.800 (3.241 sec/step)\n",
      "step 4360 \t loss = 2.430, train_acc = 0.500 (3.211 sec/step)\n",
      "step 4370 \t loss = 1.434, train_acc = 0.600 (3.245 sec/step)\n",
      "step 4380 \t loss = 2.465, train_acc = 0.300 (3.199 sec/step)\n",
      "step 4390 \t loss = 1.971, train_acc = 0.400 (3.258 sec/step)\n",
      "step 4400 \t loss = 2.391, train_acc = 0.400 (3.227 sec/step)\n",
      "step 4410 \t loss = 1.571, train_acc = 0.400 (3.210 sec/step)\n",
      "step 4420 \t loss = 1.539, train_acc = 0.600 (3.270 sec/step)\n",
      "step 4430 \t loss = 2.449, train_acc = 0.400 (3.215 sec/step)\n",
      "step 4440 \t loss = 1.073, train_acc = 0.600 (3.268 sec/step)\n",
      "step 4450 \t loss = 2.754, train_acc = 0.100 (3.204 sec/step)\n",
      "step 4460 \t loss = 1.655, train_acc = 0.600 (3.211 sec/step)\n",
      "step 4470 \t loss = 2.962, train_acc = 0.200 (3.280 sec/step)\n",
      "step 4480 \t loss = 1.028, train_acc = 0.700 (3.238 sec/step)\n",
      "step 4490 \t loss = 1.862, train_acc = 0.500 (3.243 sec/step)\n",
      "step 4500 \t loss = 3.380, train_acc = 0.100 (3.208 sec/step)\n",
      "step 4510 \t loss = 1.718, train_acc = 0.700 (3.203 sec/step)\n",
      "step 4520 \t loss = 1.190, train_acc = 0.600 (3.250 sec/step)\n",
      "step 4530 \t loss = 2.558, train_acc = 0.300 (3.223 sec/step)\n",
      "step 4540 \t loss = 1.348, train_acc = 0.600 (3.295 sec/step)\n",
      "step 4550 \t loss = 2.086, train_acc = 0.400 (3.250 sec/step)\n",
      "step 4560 \t loss = 2.171, train_acc = 0.300 (3.251 sec/step)\n",
      "step 4570 \t loss = 1.395, train_acc = 0.700 (3.260 sec/step)\n",
      "step 4580 \t loss = 1.615, train_acc = 0.400 (3.337 sec/step)\n",
      "step 4590 \t loss = 1.414, train_acc = 0.600 (3.224 sec/step)\n",
      "step 4600 \t loss = 1.246, train_acc = 0.700 (3.217 sec/step)\n",
      "step 4610 \t loss = 2.221, train_acc = 0.300 (3.201 sec/step)\n",
      "step 4620 \t loss = 2.394, train_acc = 0.500 (3.267 sec/step)\n",
      "step 4630 \t loss = 1.888, train_acc = 0.600 (3.299 sec/step)\n",
      "step 4640 \t loss = 2.419, train_acc = 0.400 (3.222 sec/step)\n",
      "step 4650 \t loss = 1.969, train_acc = 0.400 (3.223 sec/step)\n",
      "step 4660 \t loss = 1.287, train_acc = 0.500 (3.194 sec/step)\n",
      "step 4670 \t loss = 2.552, train_acc = 0.300 (3.203 sec/step)\n",
      "step 4680 \t loss = 2.197, train_acc = 0.500 (3.241 sec/step)\n",
      "step 4690 \t loss = 1.794, train_acc = 0.500 (3.273 sec/step)\n",
      "step 4700 \t loss = 2.761, train_acc = 0.100 (3.248 sec/step)\n",
      "step 4710 \t loss = 1.986, train_acc = 0.500 (3.230 sec/step)\n",
      "step 4720 \t loss = 1.555, train_acc = 0.600 (3.212 sec/step)\n",
      "step 4730 \t loss = 1.517, train_acc = 0.500 (3.210 sec/step)\n",
      "step 4740 \t loss = 1.862, train_acc = 0.500 (3.250 sec/step)\n",
      "step 4750 \t loss = 2.088, train_acc = 0.300 (3.286 sec/step)\n",
      "step 4760 \t loss = 1.318, train_acc = 0.500 (3.270 sec/step)\n",
      "step 4770 \t loss = 1.689, train_acc = 0.500 (3.359 sec/step)\n",
      "step 4780 \t loss = 1.411, train_acc = 0.600 (3.176 sec/step)\n",
      "step 4790 \t loss = 2.466, train_acc = 0.200 (3.238 sec/step)\n",
      "step 4800 \t loss = 1.209, train_acc = 0.700 (3.199 sec/step)\n",
      "step 4810 \t loss = 2.004, train_acc = 0.300 (3.272 sec/step)\n",
      "step 4820 \t loss = 1.969, train_acc = 0.400 (3.255 sec/step)\n",
      "step 4830 \t loss = 1.755, train_acc = 0.400 (3.227 sec/step)\n",
      "step 4840 \t loss = 1.914, train_acc = 0.500 (3.265 sec/step)\n",
      "step 4850 \t loss = 1.794, train_acc = 0.500 (3.230 sec/step)\n",
      "step 4860 \t loss = 1.420, train_acc = 0.500 (3.215 sec/step)\n",
      "step 4870 \t loss = 2.049, train_acc = 0.400 (3.205 sec/step)\n",
      "step 4880 \t loss = 1.673, train_acc = 0.400 (3.261 sec/step)\n",
      "step 4890 \t loss = 2.420, train_acc = 0.200 (3.221 sec/step)\n",
      "step 4900 \t loss = 2.248, train_acc = 0.300 (3.212 sec/step)\n",
      "step 4910 \t loss = 1.472, train_acc = 0.700 (3.189 sec/step)\n",
      "step 4920 \t loss = 1.324, train_acc = 0.600 (3.237 sec/step)\n",
      "step 4930 \t loss = 1.937, train_acc = 0.500 (3.231 sec/step)\n",
      "step 4940 \t loss = 2.696, train_acc = 0.300 (3.254 sec/step)\n",
      "step 4950 \t loss = 0.536, train_acc = 0.900 (3.220 sec/step)\n",
      "step 4960 \t loss = 1.228, train_acc = 0.500 (3.218 sec/step)\n",
      "step 4970 \t loss = 2.100, train_acc = 0.200 (3.265 sec/step)\n",
      "step 4980 \t loss = 1.601, train_acc = 0.500 (3.213 sec/step)\n",
      "step 4990 \t loss = 2.586, train_acc = 0.600 (3.221 sec/step)\n",
      "step 5000 \t loss = 1.807, train_acc = 0.400 (3.234 sec/step)\n",
      "step 5010 \t loss = 2.679, train_acc = 0.300 (3.181 sec/step)\n",
      "step 5020 \t loss = 1.577, train_acc = 0.500 (3.241 sec/step)\n",
      "step 5030 \t loss = 2.116, train_acc = 0.500 (3.218 sec/step)\n",
      "step 5040 \t loss = 1.733, train_acc = 0.500 (3.222 sec/step)\n",
      "step 5050 \t loss = 1.128, train_acc = 0.600 (3.279 sec/step)\n",
      "step 5060 \t loss = 1.454, train_acc = 0.600 (3.205 sec/step)\n",
      "step 5070 \t loss = 1.993, train_acc = 0.500 (3.262 sec/step)\n",
      "step 5080 \t loss = 1.451, train_acc = 0.400 (3.225 sec/step)\n",
      "step 5090 \t loss = 2.611, train_acc = 0.100 (3.280 sec/step)\n",
      "step 5100 \t loss = 1.350, train_acc = 0.600 (3.225 sec/step)\n",
      "step 5110 \t loss = 2.258, train_acc = 0.400 (3.235 sec/step)\n",
      "step 5120 \t loss = 1.724, train_acc = 0.300 (3.208 sec/step)\n",
      "step 5130 \t loss = 1.342, train_acc = 0.500 (3.189 sec/step)\n",
      "step 5140 \t loss = 1.118, train_acc = 0.600 (3.220 sec/step)\n",
      "step 5150 \t loss = 2.263, train_acc = 0.300 (3.218 sec/step)\n",
      "step 5160 \t loss = 1.905, train_acc = 0.400 (3.214 sec/step)\n",
      "step 5170 \t loss = 1.572, train_acc = 0.500 (3.200 sec/step)\n",
      "step 5180 \t loss = 2.094, train_acc = 0.200 (3.209 sec/step)\n",
      "step 5190 \t loss = 1.948, train_acc = 0.300 (3.213 sec/step)\n",
      "step 5200 \t loss = 1.571, train_acc = 0.600 (3.224 sec/step)\n",
      "step 5210 \t loss = 2.094, train_acc = 0.500 (3.248 sec/step)\n",
      "step 5220 \t loss = 1.742, train_acc = 0.600 (3.244 sec/step)\n",
      "step 5230 \t loss = 1.954, train_acc = 0.500 (3.214 sec/step)\n",
      "step 5240 \t loss = 1.854, train_acc = 0.600 (3.211 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5250 \t loss = 2.475, train_acc = 0.400 (3.228 sec/step)\n",
      "step 5260 \t loss = 1.200, train_acc = 0.700 (3.216 sec/step)\n",
      "step 5270 \t loss = 1.778, train_acc = 0.500 (3.257 sec/step)\n",
      "step 5280 \t loss = 2.650, train_acc = 0.100 (3.245 sec/step)\n",
      "step 5290 \t loss = 2.137, train_acc = 0.300 (3.260 sec/step)\n",
      "step 5300 \t loss = 1.932, train_acc = 0.500 (3.208 sec/step)\n",
      "step 5310 \t loss = 2.287, train_acc = 0.400 (3.259 sec/step)\n",
      "step 5320 \t loss = 2.056, train_acc = 0.400 (3.242 sec/step)\n",
      "step 5330 \t loss = 1.272, train_acc = 0.700 (3.195 sec/step)\n",
      "step 5340 \t loss = 2.052, train_acc = 0.300 (3.248 sec/step)\n",
      "step 5350 \t loss = 1.428, train_acc = 0.600 (3.217 sec/step)\n",
      "step 5360 \t loss = 1.643, train_acc = 0.400 (3.253 sec/step)\n",
      "step 5370 \t loss = 1.944, train_acc = 0.500 (3.200 sec/step)\n",
      "step 5380 \t loss = 1.184, train_acc = 0.600 (3.209 sec/step)\n",
      "step 5390 \t loss = 1.287, train_acc = 0.700 (3.198 sec/step)\n",
      "step 5400 \t loss = 2.349, train_acc = 0.300 (3.237 sec/step)\n",
      "step 5410 \t loss = 1.850, train_acc = 0.500 (3.212 sec/step)\n",
      "step 5420 \t loss = 0.862, train_acc = 0.800 (3.246 sec/step)\n",
      "step 5430 \t loss = 2.381, train_acc = 0.400 (3.226 sec/step)\n",
      "step 5440 \t loss = 2.737, train_acc = 0.200 (3.188 sec/step)\n",
      "step 5450 \t loss = 2.161, train_acc = 0.400 (3.242 sec/step)\n",
      "step 5460 \t loss = 2.038, train_acc = 0.300 (3.195 sec/step)\n",
      "step 5470 \t loss = 2.596, train_acc = 0.500 (3.242 sec/step)\n",
      "step 5480 \t loss = 2.135, train_acc = 0.400 (3.207 sec/step)\n",
      "step 5490 \t loss = 2.287, train_acc = 0.500 (3.282 sec/step)\n",
      "step 5500 \t loss = 0.921, train_acc = 0.600 (3.204 sec/step)\n",
      "step 5510 \t loss = 1.543, train_acc = 0.600 (3.258 sec/step)\n",
      "step 5520 \t loss = 1.045, train_acc = 0.700 (3.292 sec/step)\n",
      "step 5530 \t loss = 2.839, train_acc = 0.400 (3.239 sec/step)\n",
      "step 5540 \t loss = 1.433, train_acc = 0.500 (3.220 sec/step)\n",
      "step 5550 \t loss = 1.193, train_acc = 0.700 (3.220 sec/step)\n",
      "step 5560 \t loss = 1.567, train_acc = 0.500 (3.223 sec/step)\n",
      "step 5570 \t loss = 0.315, train_acc = 0.900 (3.212 sec/step)\n",
      "step 5580 \t loss = 1.401, train_acc = 0.400 (3.237 sec/step)\n",
      "step 5590 \t loss = 1.721, train_acc = 0.400 (3.214 sec/step)\n",
      "step 5600 \t loss = 2.412, train_acc = 0.500 (3.206 sec/step)\n",
      "step 5610 \t loss = 1.934, train_acc = 0.400 (3.238 sec/step)\n",
      "step 5620 \t loss = 1.532, train_acc = 0.500 (3.230 sec/step)\n",
      "step 5630 \t loss = 1.493, train_acc = 0.400 (3.243 sec/step)\n",
      "step 5640 \t loss = 2.371, train_acc = 0.200 (3.219 sec/step)\n",
      "step 5650 \t loss = 0.796, train_acc = 0.600 (3.229 sec/step)\n",
      "step 5660 \t loss = 1.651, train_acc = 0.500 (3.251 sec/step)\n",
      "step 5670 \t loss = 1.119, train_acc = 0.600 (3.266 sec/step)\n",
      "step 5680 \t loss = 1.135, train_acc = 0.800 (3.256 sec/step)\n",
      "step 5690 \t loss = 2.843, train_acc = 0.400 (3.226 sec/step)\n",
      "VALIDATION \t acc = 0.462 (3.620 sec)\n",
      "New Best Accuracy 0.462 > Old Best 0.406.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 5700 \t loss = 1.983, train_acc = 0.400 (3.313 sec/step)\n",
      "step 5710 \t loss = 1.554, train_acc = 0.500 (3.216 sec/step)\n",
      "step 5720 \t loss = 1.098, train_acc = 0.500 (3.247 sec/step)\n",
      "step 5730 \t loss = 1.804, train_acc = 0.200 (3.186 sec/step)\n",
      "step 5740 \t loss = 0.679, train_acc = 0.900 (3.214 sec/step)\n",
      "step 5750 \t loss = 2.100, train_acc = 0.300 (3.272 sec/step)\n",
      "step 5760 \t loss = 0.800, train_acc = 0.900 (3.213 sec/step)\n",
      "step 5770 \t loss = 1.449, train_acc = 0.700 (3.247 sec/step)\n",
      "step 5780 \t loss = 2.281, train_acc = 0.300 (3.247 sec/step)\n",
      "step 5790 \t loss = 1.336, train_acc = 0.600 (3.205 sec/step)\n",
      "step 5800 \t loss = 1.590, train_acc = 0.400 (3.285 sec/step)\n",
      "step 5810 \t loss = 1.236, train_acc = 0.700 (3.220 sec/step)\n",
      "step 5820 \t loss = 1.629, train_acc = 0.700 (3.189 sec/step)\n",
      "step 5830 \t loss = 0.872, train_acc = 0.900 (3.221 sec/step)\n",
      "step 5840 \t loss = 2.171, train_acc = 0.600 (3.239 sec/step)\n",
      "step 5850 \t loss = 1.005, train_acc = 0.800 (3.260 sec/step)\n",
      "step 5860 \t loss = 1.561, train_acc = 0.500 (3.269 sec/step)\n",
      "step 5870 \t loss = 1.648, train_acc = 0.500 (3.268 sec/step)\n",
      "step 5880 \t loss = 1.178, train_acc = 0.600 (3.249 sec/step)\n",
      "step 5890 \t loss = 2.242, train_acc = 0.300 (3.204 sec/step)\n",
      "step 5900 \t loss = 1.518, train_acc = 0.300 (3.257 sec/step)\n",
      "step 5910 \t loss = 1.631, train_acc = 0.400 (3.247 sec/step)\n",
      "step 5920 \t loss = 2.933, train_acc = 0.400 (3.305 sec/step)\n",
      "step 5930 \t loss = 0.928, train_acc = 0.700 (3.223 sec/step)\n",
      "step 5940 \t loss = 1.426, train_acc = 0.400 (3.275 sec/step)\n",
      "step 5950 \t loss = 2.059, train_acc = 0.400 (3.204 sec/step)\n",
      "step 5960 \t loss = 1.857, train_acc = 0.300 (3.215 sec/step)\n",
      "step 5970 \t loss = 1.696, train_acc = 0.400 (3.202 sec/step)\n",
      "step 5980 \t loss = 1.759, train_acc = 0.500 (3.240 sec/step)\n",
      "step 5990 \t loss = 1.325, train_acc = 0.400 (3.243 sec/step)\n",
      "step 6000 \t loss = 2.202, train_acc = 0.400 (3.223 sec/step)\n",
      "step 6010 \t loss = 2.096, train_acc = 0.500 (3.205 sec/step)\n",
      "step 6020 \t loss = 2.132, train_acc = 0.300 (3.239 sec/step)\n",
      "step 6030 \t loss = 1.567, train_acc = 0.700 (3.242 sec/step)\n",
      "step 6040 \t loss = 1.682, train_acc = 0.600 (3.212 sec/step)\n",
      "step 6050 \t loss = 1.193, train_acc = 0.600 (3.189 sec/step)\n",
      "step 6060 \t loss = 1.625, train_acc = 0.500 (3.235 sec/step)\n",
      "step 6070 \t loss = 1.383, train_acc = 0.600 (3.280 sec/step)\n",
      "step 6080 \t loss = 1.281, train_acc = 0.800 (3.222 sec/step)\n",
      "step 6090 \t loss = 0.602, train_acc = 0.900 (3.223 sec/step)\n",
      "step 6100 \t loss = 2.200, train_acc = 0.400 (3.242 sec/step)\n",
      "step 6110 \t loss = 1.429, train_acc = 0.600 (3.248 sec/step)\n",
      "step 6120 \t loss = 1.252, train_acc = 0.600 (3.283 sec/step)\n",
      "step 6130 \t loss = 0.920, train_acc = 0.700 (3.234 sec/step)\n",
      "step 6140 \t loss = 1.375, train_acc = 0.400 (3.213 sec/step)\n",
      "step 6150 \t loss = 3.090, train_acc = 0.300 (3.267 sec/step)\n",
      "step 6160 \t loss = 1.572, train_acc = 0.300 (3.234 sec/step)\n",
      "step 6170 \t loss = 0.958, train_acc = 0.600 (3.416 sec/step)\n",
      "step 6180 \t loss = 1.050, train_acc = 0.600 (3.227 sec/step)\n",
      "step 6190 \t loss = 2.053, train_acc = 0.400 (3.229 sec/step)\n",
      "step 6200 \t loss = 1.775, train_acc = 0.500 (3.241 sec/step)\n",
      "step 6210 \t loss = 1.584, train_acc = 0.400 (3.230 sec/step)\n",
      "step 6220 \t loss = 1.085, train_acc = 0.800 (3.245 sec/step)\n",
      "step 6230 \t loss = 2.581, train_acc = 0.200 (3.259 sec/step)\n",
      "step 6240 \t loss = 1.499, train_acc = 0.600 (3.197 sec/step)\n",
      "step 6250 \t loss = 0.876, train_acc = 0.600 (3.220 sec/step)\n",
      "step 6260 \t loss = 1.274, train_acc = 0.700 (3.251 sec/step)\n",
      "step 6270 \t loss = 0.557, train_acc = 0.900 (3.210 sec/step)\n",
      "step 6280 \t loss = 1.346, train_acc = 0.500 (3.198 sec/step)\n",
      "step 6290 \t loss = 1.598, train_acc = 0.500 (3.221 sec/step)\n",
      "step 6300 \t loss = 2.636, train_acc = 0.300 (3.308 sec/step)\n",
      "step 6310 \t loss = 1.203, train_acc = 0.700 (3.262 sec/step)\n",
      "step 6320 \t loss = 1.146, train_acc = 0.700 (3.245 sec/step)\n",
      "step 6330 \t loss = 2.411, train_acc = 0.200 (3.241 sec/step)\n",
      "step 6340 \t loss = 0.842, train_acc = 0.800 (3.225 sec/step)\n",
      "step 6350 \t loss = 1.943, train_acc = 0.400 (3.247 sec/step)\n",
      "step 6360 \t loss = 2.238, train_acc = 0.500 (3.188 sec/step)\n",
      "step 6370 \t loss = 1.692, train_acc = 0.300 (3.210 sec/step)\n",
      "step 6380 \t loss = 0.859, train_acc = 0.700 (3.243 sec/step)\n",
      "step 6390 \t loss = 1.192, train_acc = 0.700 (3.220 sec/step)\n",
      "step 6400 \t loss = 2.654, train_acc = 0.200 (3.222 sec/step)\n",
      "step 6410 \t loss = 1.219, train_acc = 0.700 (3.239 sec/step)\n",
      "step 6420 \t loss = 0.844, train_acc = 0.600 (3.231 sec/step)\n",
      "step 6430 \t loss = 1.523, train_acc = 0.500 (3.245 sec/step)\n",
      "step 6440 \t loss = 0.753, train_acc = 0.700 (3.243 sec/step)\n",
      "step 6450 \t loss = 1.278, train_acc = 0.600 (3.228 sec/step)\n",
      "step 6460 \t loss = 2.000, train_acc = 0.400 (3.254 sec/step)\n",
      "step 6470 \t loss = 0.958, train_acc = 0.700 (3.214 sec/step)\n",
      "step 6480 \t loss = 1.644, train_acc = 0.500 (3.190 sec/step)\n",
      "step 6490 \t loss = 0.756, train_acc = 0.700 (3.284 sec/step)\n",
      "step 6500 \t loss = 0.889, train_acc = 0.700 (3.245 sec/step)\n",
      "step 6510 \t loss = 1.516, train_acc = 0.400 (3.297 sec/step)\n",
      "step 6520 \t loss = 1.919, train_acc = 0.300 (3.213 sec/step)\n",
      "step 6530 \t loss = 1.083, train_acc = 0.600 (3.229 sec/step)\n",
      "step 6540 \t loss = 1.723, train_acc = 0.600 (3.357 sec/step)\n",
      "step 6550 \t loss = 1.577, train_acc = 0.600 (3.197 sec/step)\n",
      "step 6560 \t loss = 0.979, train_acc = 0.700 (3.228 sec/step)\n",
      "step 6570 \t loss = 1.796, train_acc = 0.500 (3.236 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6580 \t loss = 1.774, train_acc = 0.500 (3.399 sec/step)\n",
      "step 6590 \t loss = 1.236, train_acc = 0.600 (3.239 sec/step)\n",
      "step 6600 \t loss = 1.773, train_acc = 0.500 (3.254 sec/step)\n",
      "step 6610 \t loss = 1.816, train_acc = 0.400 (3.220 sec/step)\n",
      "step 6620 \t loss = 1.116, train_acc = 0.500 (3.267 sec/step)\n",
      "step 6630 \t loss = 1.026, train_acc = 0.600 (3.243 sec/step)\n",
      "step 6640 \t loss = 1.847, train_acc = 0.500 (3.235 sec/step)\n",
      "step 6650 \t loss = 2.745, train_acc = 0.300 (3.235 sec/step)\n",
      "step 6660 \t loss = 1.084, train_acc = 0.800 (3.252 sec/step)\n",
      "step 6670 \t loss = 3.211, train_acc = 0.600 (3.207 sec/step)\n",
      "step 6680 \t loss = 0.758, train_acc = 0.800 (3.249 sec/step)\n",
      "step 6690 \t loss = 1.594, train_acc = 0.600 (3.220 sec/step)\n",
      "step 6700 \t loss = 0.762, train_acc = 0.800 (3.237 sec/step)\n",
      "step 6710 \t loss = 2.008, train_acc = 0.300 (3.244 sec/step)\n",
      "step 6720 \t loss = 1.503, train_acc = 0.600 (3.234 sec/step)\n",
      "step 6730 \t loss = 1.603, train_acc = 0.400 (3.205 sec/step)\n",
      "step 6740 \t loss = 1.909, train_acc = 0.400 (3.289 sec/step)\n",
      "step 6750 \t loss = 1.905, train_acc = 0.500 (3.209 sec/step)\n",
      "step 6760 \t loss = 1.595, train_acc = 0.600 (3.228 sec/step)\n",
      "step 6770 \t loss = 1.949, train_acc = 0.600 (3.272 sec/step)\n",
      "step 6780 \t loss = 1.377, train_acc = 0.500 (3.267 sec/step)\n",
      "step 6790 \t loss = 1.817, train_acc = 0.300 (3.245 sec/step)\n",
      "step 6800 \t loss = 1.905, train_acc = 0.600 (3.229 sec/step)\n",
      "step 6810 \t loss = 1.703, train_acc = 0.700 (3.294 sec/step)\n",
      "step 6820 \t loss = 0.834, train_acc = 0.800 (3.235 sec/step)\n",
      "step 6830 \t loss = 1.458, train_acc = 0.500 (3.231 sec/step)\n",
      "step 6840 \t loss = 2.219, train_acc = 0.200 (3.316 sec/step)\n",
      "step 6850 \t loss = 0.863, train_acc = 0.700 (3.262 sec/step)\n",
      "step 6860 \t loss = 0.807, train_acc = 0.700 (3.283 sec/step)\n",
      "step 6870 \t loss = 1.604, train_acc = 0.400 (3.246 sec/step)\n",
      "step 6880 \t loss = 1.202, train_acc = 0.600 (3.249 sec/step)\n",
      "step 6890 \t loss = 1.396, train_acc = 0.500 (3.249 sec/step)\n",
      "step 6900 \t loss = 1.464, train_acc = 0.400 (3.239 sec/step)\n",
      "step 6910 \t loss = 1.527, train_acc = 0.500 (3.242 sec/step)\n",
      "step 6920 \t loss = 1.233, train_acc = 0.600 (3.261 sec/step)\n",
      "step 6930 \t loss = 1.151, train_acc = 0.600 (3.225 sec/step)\n",
      "step 6940 \t loss = 1.188, train_acc = 0.500 (3.254 sec/step)\n",
      "step 6950 \t loss = 0.454, train_acc = 0.900 (3.246 sec/step)\n",
      "step 6960 \t loss = 1.684, train_acc = 0.400 (3.217 sec/step)\n",
      "step 6970 \t loss = 1.173, train_acc = 0.600 (3.250 sec/step)\n",
      "step 6980 \t loss = 1.398, train_acc = 0.500 (3.234 sec/step)\n",
      "step 6990 \t loss = 1.533, train_acc = 0.600 (3.246 sec/step)\n",
      "step 7000 \t loss = 0.395, train_acc = 1.000 (3.196 sec/step)\n",
      "step 7010 \t loss = 2.568, train_acc = 0.200 (3.252 sec/step)\n",
      "step 7020 \t loss = 1.380, train_acc = 0.400 (3.236 sec/step)\n",
      "step 7030 \t loss = 1.212, train_acc = 0.700 (3.273 sec/step)\n",
      "step 7040 \t loss = 1.434, train_acc = 0.600 (3.242 sec/step)\n",
      "step 7050 \t loss = 2.027, train_acc = 0.400 (3.257 sec/step)\n",
      "step 7060 \t loss = 1.692, train_acc = 0.500 (3.236 sec/step)\n",
      "step 7070 \t loss = 1.052, train_acc = 0.700 (3.267 sec/step)\n",
      "step 7080 \t loss = 1.772, train_acc = 0.300 (3.259 sec/step)\n",
      "step 7090 \t loss = 1.709, train_acc = 0.600 (3.265 sec/step)\n",
      "step 7100 \t loss = 0.869, train_acc = 0.900 (3.209 sec/step)\n",
      "step 7110 \t loss = 1.869, train_acc = 0.500 (3.227 sec/step)\n",
      "step 7120 \t loss = 1.360, train_acc = 0.700 (3.285 sec/step)\n",
      "step 7130 \t loss = 1.173, train_acc = 0.700 (3.241 sec/step)\n",
      "step 7140 \t loss = 1.184, train_acc = 0.600 (3.314 sec/step)\n",
      "step 7150 \t loss = 1.415, train_acc = 0.700 (3.216 sec/step)\n",
      "step 7160 \t loss = 1.076, train_acc = 0.700 (3.263 sec/step)\n",
      "step 7170 \t loss = 1.228, train_acc = 0.600 (3.259 sec/step)\n",
      "step 7180 \t loss = 2.154, train_acc = 0.300 (3.274 sec/step)\n",
      "step 7190 \t loss = 1.984, train_acc = 0.500 (3.245 sec/step)\n",
      "step 7200 \t loss = 1.542, train_acc = 0.500 (3.240 sec/step)\n",
      "step 7210 \t loss = 1.555, train_acc = 0.400 (3.240 sec/step)\n",
      "step 7220 \t loss = 1.264, train_acc = 0.600 (3.229 sec/step)\n",
      "step 7230 \t loss = 1.308, train_acc = 0.600 (3.248 sec/step)\n",
      "step 7240 \t loss = 2.795, train_acc = 0.500 (3.261 sec/step)\n",
      "step 7250 \t loss = 0.900, train_acc = 0.800 (3.227 sec/step)\n",
      "step 7260 \t loss = 2.035, train_acc = 0.400 (3.232 sec/step)\n",
      "step 7270 \t loss = 1.485, train_acc = 0.500 (3.210 sec/step)\n",
      "step 7280 \t loss = 0.891, train_acc = 0.500 (3.305 sec/step)\n",
      "step 7290 \t loss = 0.815, train_acc = 0.700 (3.208 sec/step)\n",
      "step 7300 \t loss = 3.105, train_acc = 0.300 (3.238 sec/step)\n",
      "step 7310 \t loss = 1.549, train_acc = 0.600 (3.229 sec/step)\n",
      "step 7320 \t loss = 0.717, train_acc = 0.700 (3.265 sec/step)\n",
      "step 7330 \t loss = 1.818, train_acc = 0.500 (3.264 sec/step)\n",
      "step 7340 \t loss = 2.229, train_acc = 0.300 (3.226 sec/step)\n",
      "step 7350 \t loss = 1.615, train_acc = 0.400 (3.248 sec/step)\n",
      "step 7360 \t loss = 1.666, train_acc = 0.600 (3.239 sec/step)\n",
      "step 7370 \t loss = 2.039, train_acc = 0.400 (3.215 sec/step)\n",
      "step 7380 \t loss = 1.123, train_acc = 0.700 (3.239 sec/step)\n",
      "step 7390 \t loss = 2.036, train_acc = 0.400 (3.246 sec/step)\n",
      "step 7400 \t loss = 0.322, train_acc = 0.900 (3.232 sec/step)\n",
      "step 7410 \t loss = 1.884, train_acc = 0.500 (3.338 sec/step)\n",
      "step 7420 \t loss = 1.084, train_acc = 0.600 (3.251 sec/step)\n",
      "step 7430 \t loss = 3.653, train_acc = 0.200 (3.249 sec/step)\n",
      "step 7440 \t loss = 1.533, train_acc = 0.400 (3.247 sec/step)\n",
      "step 7450 \t loss = 1.689, train_acc = 0.600 (3.229 sec/step)\n",
      "step 7460 \t loss = 1.124, train_acc = 0.700 (3.253 sec/step)\n",
      "step 7470 \t loss = 0.388, train_acc = 0.900 (3.249 sec/step)\n",
      "step 7480 \t loss = 1.282, train_acc = 0.600 (3.214 sec/step)\n",
      "step 7490 \t loss = 1.101, train_acc = 0.500 (3.243 sec/step)\n",
      "step 7500 \t loss = 2.141, train_acc = 0.400 (3.244 sec/step)\n",
      "step 7510 \t loss = 1.412, train_acc = 0.600 (3.230 sec/step)\n",
      "step 7520 \t loss = 1.333, train_acc = 0.500 (3.217 sec/step)\n",
      "step 7530 \t loss = 2.108, train_acc = 0.200 (3.195 sec/step)\n",
      "step 7540 \t loss = 1.903, train_acc = 0.500 (3.251 sec/step)\n",
      "step 7550 \t loss = 1.328, train_acc = 0.700 (3.219 sec/step)\n",
      "step 7560 \t loss = 1.900, train_acc = 0.500 (3.233 sec/step)\n",
      "step 7570 \t loss = 0.738, train_acc = 0.800 (3.242 sec/step)\n",
      "step 7580 \t loss = 1.389, train_acc = 0.700 (3.221 sec/step)\n",
      "step 7590 \t loss = 2.181, train_acc = 0.300 (3.261 sec/step)\n",
      "VALIDATION \t acc = 0.494 (3.630 sec)\n",
      "New Best Accuracy 0.494 > Old Best 0.462.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 7600 \t loss = 1.037, train_acc = 0.800 (3.261 sec/step)\n",
      "step 7610 \t loss = 1.518, train_acc = 0.500 (3.323 sec/step)\n",
      "step 7620 \t loss = 1.674, train_acc = 0.400 (3.359 sec/step)\n",
      "step 7630 \t loss = 0.965, train_acc = 0.600 (3.253 sec/step)\n",
      "step 7640 \t loss = 0.711, train_acc = 0.800 (3.210 sec/step)\n",
      "step 7650 \t loss = 2.485, train_acc = 0.300 (3.217 sec/step)\n",
      "step 7660 \t loss = 0.361, train_acc = 0.900 (3.235 sec/step)\n",
      "step 7670 \t loss = 1.169, train_acc = 0.700 (3.218 sec/step)\n",
      "step 7680 \t loss = 1.418, train_acc = 0.700 (3.292 sec/step)\n",
      "step 7690 \t loss = 1.286, train_acc = 0.500 (3.263 sec/step)\n",
      "step 7700 \t loss = 1.029, train_acc = 0.800 (3.242 sec/step)\n",
      "step 7710 \t loss = 1.324, train_acc = 0.600 (3.244 sec/step)\n",
      "step 7720 \t loss = 1.404, train_acc = 0.500 (3.211 sec/step)\n",
      "step 7730 \t loss = 0.537, train_acc = 0.800 (3.320 sec/step)\n",
      "step 7740 \t loss = 1.094, train_acc = 0.700 (3.260 sec/step)\n",
      "step 7750 \t loss = 2.006, train_acc = 0.300 (3.235 sec/step)\n",
      "step 7760 \t loss = 0.756, train_acc = 0.800 (3.311 sec/step)\n",
      "step 7770 \t loss = 0.852, train_acc = 0.900 (3.298 sec/step)\n",
      "step 7780 \t loss = 0.471, train_acc = 0.900 (3.239 sec/step)\n",
      "step 7790 \t loss = 1.450, train_acc = 0.600 (3.212 sec/step)\n",
      "step 7800 \t loss = 1.050, train_acc = 0.700 (3.223 sec/step)\n",
      "step 7810 \t loss = 1.320, train_acc = 0.500 (3.247 sec/step)\n",
      "step 7820 \t loss = 2.256, train_acc = 0.400 (3.255 sec/step)\n",
      "step 7830 \t loss = 0.880, train_acc = 0.800 (3.321 sec/step)\n",
      "step 7840 \t loss = 1.330, train_acc = 0.400 (3.244 sec/step)\n",
      "step 7850 \t loss = 1.467, train_acc = 0.500 (3.244 sec/step)\n",
      "step 7860 \t loss = 1.406, train_acc = 0.700 (3.260 sec/step)\n",
      "step 7870 \t loss = 1.619, train_acc = 0.700 (3.218 sec/step)\n",
      "step 7880 \t loss = 1.017, train_acc = 0.700 (3.238 sec/step)\n",
      "step 7890 \t loss = 1.030, train_acc = 0.700 (3.230 sec/step)\n",
      "step 7900 \t loss = 2.020, train_acc = 0.400 (3.229 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7910 \t loss = 1.668, train_acc = 0.600 (3.220 sec/step)\n",
      "step 7920 \t loss = 1.469, train_acc = 0.400 (3.262 sec/step)\n",
      "step 7930 \t loss = 1.608, train_acc = 0.600 (3.230 sec/step)\n",
      "step 7940 \t loss = 1.229, train_acc = 0.700 (3.275 sec/step)\n",
      "step 7950 \t loss = 0.903, train_acc = 0.600 (3.240 sec/step)\n",
      "step 7960 \t loss = 1.971, train_acc = 0.500 (3.255 sec/step)\n",
      "step 7970 \t loss = 1.356, train_acc = 0.600 (3.284 sec/step)\n",
      "step 7980 \t loss = 0.522, train_acc = 0.800 (3.244 sec/step)\n",
      "step 7990 \t loss = 0.994, train_acc = 0.600 (3.305 sec/step)\n",
      "step 8000 \t loss = 3.372, train_acc = 0.200 (3.215 sec/step)\n",
      "step 8010 \t loss = 1.631, train_acc = 0.400 (3.250 sec/step)\n",
      "step 8020 \t loss = 1.178, train_acc = 0.500 (3.275 sec/step)\n",
      "step 8030 \t loss = 0.883, train_acc = 0.800 (3.261 sec/step)\n",
      "step 8040 \t loss = 1.495, train_acc = 0.500 (3.235 sec/step)\n",
      "step 8050 \t loss = 1.549, train_acc = 0.400 (3.231 sec/step)\n",
      "step 8060 \t loss = 1.147, train_acc = 0.600 (3.202 sec/step)\n",
      "step 8070 \t loss = 0.850, train_acc = 0.700 (3.215 sec/step)\n",
      "step 8080 \t loss = 0.887, train_acc = 0.800 (3.247 sec/step)\n",
      "step 8090 \t loss = 1.403, train_acc = 0.500 (3.256 sec/step)\n",
      "step 8100 \t loss = 1.361, train_acc = 0.600 (3.273 sec/step)\n",
      "step 8110 \t loss = 1.530, train_acc = 0.400 (3.228 sec/step)\n",
      "step 8120 \t loss = 1.312, train_acc = 0.700 (3.289 sec/step)\n",
      "step 8130 \t loss = 1.773, train_acc = 0.500 (3.234 sec/step)\n",
      "step 8140 \t loss = 1.113, train_acc = 0.700 (3.252 sec/step)\n",
      "step 8150 \t loss = 1.037, train_acc = 0.600 (3.225 sec/step)\n",
      "step 8160 \t loss = 0.760, train_acc = 0.700 (3.225 sec/step)\n",
      "step 8170 \t loss = 0.433, train_acc = 0.900 (3.204 sec/step)\n",
      "step 8180 \t loss = 2.304, train_acc = 0.300 (3.228 sec/step)\n",
      "step 8190 \t loss = 1.281, train_acc = 0.500 (3.226 sec/step)\n",
      "step 8200 \t loss = 1.708, train_acc = 0.500 (3.239 sec/step)\n",
      "step 8210 \t loss = 1.244, train_acc = 0.500 (3.206 sec/step)\n",
      "step 8220 \t loss = 0.586, train_acc = 0.900 (3.246 sec/step)\n",
      "step 8230 \t loss = 3.386, train_acc = 0.400 (3.224 sec/step)\n",
      "step 8240 \t loss = 1.524, train_acc = 0.500 (3.224 sec/step)\n",
      "step 8250 \t loss = 2.117, train_acc = 0.400 (3.219 sec/step)\n",
      "step 8260 \t loss = 1.253, train_acc = 0.800 (3.226 sec/step)\n",
      "step 8270 \t loss = 0.876, train_acc = 0.800 (3.250 sec/step)\n",
      "step 8280 \t loss = 0.323, train_acc = 0.900 (3.238 sec/step)\n",
      "step 8290 \t loss = 1.444, train_acc = 0.400 (3.213 sec/step)\n",
      "step 8300 \t loss = 1.718, train_acc = 0.500 (3.250 sec/step)\n",
      "step 8310 \t loss = 1.237, train_acc = 0.800 (3.245 sec/step)\n",
      "step 8320 \t loss = 0.616, train_acc = 0.800 (3.226 sec/step)\n",
      "step 8330 \t loss = 1.700, train_acc = 0.500 (3.233 sec/step)\n",
      "step 8340 \t loss = 0.648, train_acc = 0.800 (3.242 sec/step)\n",
      "step 8350 \t loss = 2.036, train_acc = 0.500 (3.206 sec/step)\n",
      "step 8360 \t loss = 1.338, train_acc = 0.400 (3.275 sec/step)\n",
      "step 8370 \t loss = 0.761, train_acc = 0.800 (3.285 sec/step)\n",
      "step 8380 \t loss = 0.915, train_acc = 0.900 (3.258 sec/step)\n",
      "step 8390 \t loss = 0.913, train_acc = 0.600 (3.261 sec/step)\n",
      "step 8400 \t loss = 0.797, train_acc = 0.700 (3.242 sec/step)\n",
      "step 8410 \t loss = 1.912, train_acc = 0.400 (3.275 sec/step)\n",
      "step 8420 \t loss = 1.123, train_acc = 0.600 (3.234 sec/step)\n",
      "step 8430 \t loss = 1.102, train_acc = 0.600 (3.266 sec/step)\n",
      "step 8440 \t loss = 2.022, train_acc = 0.400 (3.228 sec/step)\n",
      "step 8450 \t loss = 1.831, train_acc = 0.400 (3.271 sec/step)\n",
      "step 8460 \t loss = 0.802, train_acc = 0.800 (3.259 sec/step)\n",
      "step 8470 \t loss = 1.185, train_acc = 0.700 (3.239 sec/step)\n",
      "step 8480 \t loss = 1.353, train_acc = 0.600 (3.246 sec/step)\n",
      "step 8490 \t loss = 0.940, train_acc = 0.600 (3.243 sec/step)\n",
      "step 8500 \t loss = 1.946, train_acc = 0.500 (3.211 sec/step)\n",
      "step 8510 \t loss = 1.442, train_acc = 0.500 (3.238 sec/step)\n",
      "step 8520 \t loss = 0.510, train_acc = 0.900 (3.248 sec/step)\n",
      "step 8530 \t loss = 1.526, train_acc = 0.500 (3.221 sec/step)\n",
      "step 8540 \t loss = 1.824, train_acc = 0.500 (3.250 sec/step)\n",
      "step 8550 \t loss = 0.988, train_acc = 0.700 (3.222 sec/step)\n",
      "step 8560 \t loss = 0.739, train_acc = 0.700 (3.211 sec/step)\n",
      "step 8570 \t loss = 0.948, train_acc = 0.800 (3.262 sec/step)\n",
      "step 8580 \t loss = 0.440, train_acc = 0.900 (3.250 sec/step)\n",
      "step 8590 \t loss = 1.507, train_acc = 0.600 (3.265 sec/step)\n",
      "step 8600 \t loss = 0.797, train_acc = 0.700 (3.212 sec/step)\n",
      "step 8610 \t loss = 2.023, train_acc = 0.500 (3.250 sec/step)\n",
      "step 8620 \t loss = 0.688, train_acc = 0.700 (3.263 sec/step)\n",
      "step 8630 \t loss = 0.861, train_acc = 0.800 (3.220 sec/step)\n",
      "step 8640 \t loss = 1.064, train_acc = 0.600 (3.263 sec/step)\n",
      "step 8650 \t loss = 1.420, train_acc = 0.500 (3.372 sec/step)\n",
      "step 8660 \t loss = 1.276, train_acc = 0.500 (3.273 sec/step)\n",
      "step 8670 \t loss = 0.988, train_acc = 0.700 (3.255 sec/step)\n",
      "step 8680 \t loss = 1.352, train_acc = 0.600 (3.248 sec/step)\n",
      "step 8690 \t loss = 1.015, train_acc = 0.600 (3.292 sec/step)\n",
      "step 8700 \t loss = 1.333, train_acc = 0.700 (3.382 sec/step)\n",
      "step 8710 \t loss = 1.203, train_acc = 0.600 (3.250 sec/step)\n",
      "step 8720 \t loss = 0.442, train_acc = 0.900 (3.269 sec/step)\n",
      "step 8730 \t loss = 2.272, train_acc = 0.400 (3.240 sec/step)\n",
      "step 8740 \t loss = 1.686, train_acc = 0.400 (3.217 sec/step)\n",
      "step 8750 \t loss = 0.401, train_acc = 0.900 (3.245 sec/step)\n",
      "step 8760 \t loss = 0.964, train_acc = 0.700 (3.223 sec/step)\n",
      "step 8770 \t loss = 1.438, train_acc = 0.400 (3.240 sec/step)\n",
      "step 8780 \t loss = 0.816, train_acc = 0.900 (3.309 sec/step)\n",
      "step 8790 \t loss = 1.090, train_acc = 0.500 (3.229 sec/step)\n",
      "step 8800 \t loss = 1.281, train_acc = 0.400 (3.260 sec/step)\n",
      "step 8810 \t loss = 1.273, train_acc = 0.600 (3.252 sec/step)\n",
      "step 8820 \t loss = 0.634, train_acc = 0.800 (3.266 sec/step)\n",
      "step 8830 \t loss = 0.686, train_acc = 0.800 (3.286 sec/step)\n",
      "step 8840 \t loss = 0.540, train_acc = 0.700 (3.252 sec/step)\n",
      "step 8850 \t loss = 0.500, train_acc = 0.800 (3.221 sec/step)\n",
      "step 8860 \t loss = 0.979, train_acc = 0.800 (3.265 sec/step)\n",
      "step 8870 \t loss = 0.780, train_acc = 0.900 (3.267 sec/step)\n",
      "step 8880 \t loss = 1.286, train_acc = 0.600 (3.229 sec/step)\n",
      "step 8890 \t loss = 0.728, train_acc = 0.700 (3.245 sec/step)\n",
      "step 8900 \t loss = 1.206, train_acc = 0.600 (3.280 sec/step)\n",
      "step 8910 \t loss = 1.383, train_acc = 0.500 (3.273 sec/step)\n",
      "step 8920 \t loss = 1.997, train_acc = 0.400 (3.228 sec/step)\n",
      "step 8930 \t loss = 1.247, train_acc = 0.600 (3.210 sec/step)\n",
      "step 8940 \t loss = 0.981, train_acc = 0.700 (3.252 sec/step)\n",
      "step 8950 \t loss = 1.551, train_acc = 0.300 (3.217 sec/step)\n",
      "step 8960 \t loss = 1.257, train_acc = 0.800 (3.227 sec/step)\n",
      "step 8970 \t loss = 1.159, train_acc = 0.800 (3.241 sec/step)\n",
      "step 8980 \t loss = 1.110, train_acc = 0.600 (3.264 sec/step)\n",
      "step 8990 \t loss = 0.846, train_acc = 0.800 (3.241 sec/step)\n",
      "step 9000 \t loss = 0.592, train_acc = 1.000 (3.214 sec/step)\n",
      "step 9010 \t loss = 1.089, train_acc = 0.700 (3.271 sec/step)\n",
      "step 9020 \t loss = 1.278, train_acc = 0.700 (3.258 sec/step)\n",
      "step 9030 \t loss = 0.816, train_acc = 0.800 (3.233 sec/step)\n",
      "step 9040 \t loss = 0.673, train_acc = 0.800 (3.206 sec/step)\n",
      "step 9050 \t loss = 1.177, train_acc = 0.700 (3.297 sec/step)\n",
      "step 9060 \t loss = 0.498, train_acc = 0.800 (3.240 sec/step)\n",
      "step 9070 \t loss = 0.898, train_acc = 0.700 (3.242 sec/step)\n",
      "step 9080 \t loss = 0.948, train_acc = 0.600 (3.242 sec/step)\n",
      "step 9090 \t loss = 0.998, train_acc = 0.600 (3.263 sec/step)\n",
      "step 9100 \t loss = 0.699, train_acc = 0.800 (3.271 sec/step)\n",
      "step 9110 \t loss = 1.035, train_acc = 0.500 (3.238 sec/step)\n",
      "step 9120 \t loss = 0.896, train_acc = 0.700 (3.219 sec/step)\n",
      "step 9130 \t loss = 0.791, train_acc = 0.900 (3.229 sec/step)\n",
      "step 9140 \t loss = 1.285, train_acc = 0.800 (3.217 sec/step)\n",
      "step 9150 \t loss = 0.572, train_acc = 0.900 (3.329 sec/step)\n",
      "step 9160 \t loss = 1.108, train_acc = 0.600 (3.207 sec/step)\n",
      "step 9170 \t loss = 0.891, train_acc = 0.800 (3.226 sec/step)\n",
      "step 9180 \t loss = 1.058, train_acc = 0.600 (3.240 sec/step)\n",
      "step 9190 \t loss = 0.988, train_acc = 0.800 (3.294 sec/step)\n",
      "step 9200 \t loss = 2.191, train_acc = 0.500 (3.264 sec/step)\n",
      "step 9210 \t loss = 1.002, train_acc = 0.800 (3.215 sec/step)\n",
      "step 9220 \t loss = 1.324, train_acc = 0.500 (3.224 sec/step)\n",
      "step 9230 \t loss = 1.470, train_acc = 0.400 (3.287 sec/step)\n",
      "step 9240 \t loss = 2.431, train_acc = 0.300 (3.264 sec/step)\n",
      "step 9250 \t loss = 1.109, train_acc = 0.600 (3.285 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9260 \t loss = 0.890, train_acc = 0.800 (3.280 sec/step)\n",
      "step 9270 \t loss = 1.439, train_acc = 0.700 (3.286 sec/step)\n",
      "step 9280 \t loss = 1.206, train_acc = 0.700 (3.242 sec/step)\n",
      "step 9290 \t loss = 1.310, train_acc = 0.600 (3.313 sec/step)\n",
      "step 9300 \t loss = 0.568, train_acc = 0.900 (3.263 sec/step)\n",
      "step 9310 \t loss = 0.661, train_acc = 0.900 (3.266 sec/step)\n",
      "step 9320 \t loss = 1.768, train_acc = 0.500 (3.219 sec/step)\n",
      "step 9330 \t loss = 2.137, train_acc = 0.400 (3.242 sec/step)\n",
      "step 9340 \t loss = 0.913, train_acc = 0.600 (3.269 sec/step)\n",
      "step 9350 \t loss = 0.823, train_acc = 0.900 (3.256 sec/step)\n",
      "step 9360 \t loss = 0.842, train_acc = 0.800 (3.265 sec/step)\n",
      "step 9370 \t loss = 0.120, train_acc = 1.000 (3.256 sec/step)\n",
      "step 9380 \t loss = 0.872, train_acc = 0.700 (3.251 sec/step)\n",
      "step 9390 \t loss = 0.674, train_acc = 0.900 (3.220 sec/step)\n",
      "step 9400 \t loss = 1.268, train_acc = 0.700 (3.257 sec/step)\n",
      "step 9410 \t loss = 0.897, train_acc = 0.700 (3.244 sec/step)\n",
      "step 9420 \t loss = 0.597, train_acc = 0.900 (3.288 sec/step)\n",
      "step 9430 \t loss = 1.185, train_acc = 0.600 (3.233 sec/step)\n",
      "step 9440 \t loss = 1.309, train_acc = 0.600 (3.264 sec/step)\n",
      "step 9450 \t loss = 0.375, train_acc = 0.900 (3.262 sec/step)\n",
      "step 9460 \t loss = 0.564, train_acc = 0.800 (3.246 sec/step)\n",
      "step 9470 \t loss = 0.470, train_acc = 0.900 (3.236 sec/step)\n",
      "step 9480 \t loss = 0.863, train_acc = 0.800 (3.254 sec/step)\n",
      "step 9490 \t loss = 1.786, train_acc = 0.600 (3.241 sec/step)\n",
      "VALIDATION \t acc = 0.489 (3.620 sec)\n",
      "step 9500 \t loss = 1.858, train_acc = 0.600 (3.199 sec/step)\n",
      "step 9510 \t loss = 0.956, train_acc = 0.700 (3.266 sec/step)\n",
      "step 9520 \t loss = 1.637, train_acc = 0.500 (3.284 sec/step)\n",
      "step 9530 \t loss = 1.227, train_acc = 0.700 (3.256 sec/step)\n",
      "step 9540 \t loss = 0.159, train_acc = 1.000 (3.214 sec/step)\n",
      "step 9550 \t loss = 1.263, train_acc = 0.700 (3.276 sec/step)\n",
      "step 9560 \t loss = 0.836, train_acc = 0.700 (3.275 sec/step)\n",
      "step 9570 \t loss = 1.189, train_acc = 0.600 (3.278 sec/step)\n",
      "step 9580 \t loss = 0.950, train_acc = 0.700 (3.339 sec/step)\n",
      "step 9590 \t loss = 0.780, train_acc = 0.800 (3.231 sec/step)\n",
      "step 9600 \t loss = 0.720, train_acc = 0.800 (3.222 sec/step)\n",
      "step 9610 \t loss = 0.935, train_acc = 0.800 (3.293 sec/step)\n",
      "step 9620 \t loss = 1.517, train_acc = 0.700 (3.219 sec/step)\n",
      "step 9630 \t loss = 1.068, train_acc = 0.700 (3.335 sec/step)\n",
      "step 9640 \t loss = 0.857, train_acc = 0.800 (3.214 sec/step)\n",
      "step 9650 \t loss = 1.032, train_acc = 0.500 (3.272 sec/step)\n",
      "step 9660 \t loss = 0.485, train_acc = 0.900 (3.247 sec/step)\n",
      "step 9670 \t loss = 0.350, train_acc = 1.000 (3.237 sec/step)\n",
      "step 9680 \t loss = 0.643, train_acc = 0.800 (3.251 sec/step)\n",
      "step 9690 \t loss = 1.240, train_acc = 0.600 (3.264 sec/step)\n",
      "step 9700 \t loss = 0.895, train_acc = 0.800 (3.280 sec/step)\n",
      "step 9710 \t loss = 1.500, train_acc = 0.600 (3.231 sec/step)\n",
      "step 9720 \t loss = 1.718, train_acc = 0.500 (3.265 sec/step)\n",
      "step 9730 \t loss = 0.346, train_acc = 0.900 (3.266 sec/step)\n",
      "step 9740 \t loss = 1.554, train_acc = 0.500 (3.216 sec/step)\n",
      "step 9750 \t loss = 1.661, train_acc = 0.400 (3.235 sec/step)\n",
      "step 9760 \t loss = 1.306, train_acc = 0.500 (3.267 sec/step)\n",
      "step 9770 \t loss = 2.203, train_acc = 0.400 (3.289 sec/step)\n",
      "step 9780 \t loss = 0.361, train_acc = 0.900 (3.254 sec/step)\n",
      "step 9790 \t loss = 0.462, train_acc = 0.800 (3.268 sec/step)\n",
      "step 9800 \t loss = 3.149, train_acc = 0.600 (3.244 sec/step)\n",
      "step 9810 \t loss = 1.097, train_acc = 0.800 (3.279 sec/step)\n",
      "step 9820 \t loss = 0.511, train_acc = 0.900 (3.382 sec/step)\n",
      "step 9830 \t loss = 0.826, train_acc = 0.700 (3.281 sec/step)\n",
      "step 9840 \t loss = 1.028, train_acc = 0.700 (3.282 sec/step)\n",
      "step 9850 \t loss = 0.561, train_acc = 0.800 (3.273 sec/step)\n",
      "step 9860 \t loss = 1.752, train_acc = 0.600 (3.270 sec/step)\n",
      "step 9870 \t loss = 1.028, train_acc = 0.600 (3.237 sec/step)\n",
      "step 9880 \t loss = 0.315, train_acc = 0.800 (3.216 sec/step)\n",
      "step 9890 \t loss = 0.654, train_acc = 0.900 (3.265 sec/step)\n",
      "step 9900 \t loss = 1.650, train_acc = 0.500 (3.283 sec/step)\n",
      "step 9910 \t loss = 1.758, train_acc = 0.300 (3.245 sec/step)\n",
      "step 9920 \t loss = 0.939, train_acc = 0.500 (3.241 sec/step)\n",
      "step 9930 \t loss = 0.448, train_acc = 0.700 (3.225 sec/step)\n",
      "step 9940 \t loss = 1.863, train_acc = 0.200 (3.262 sec/step)\n",
      "step 9950 \t loss = 0.890, train_acc = 0.700 (3.221 sec/step)\n",
      "step 9960 \t loss = 1.461, train_acc = 0.600 (3.271 sec/step)\n",
      "step 9970 \t loss = 0.577, train_acc = 0.800 (3.217 sec/step)\n",
      "step 9980 \t loss = 1.127, train_acc = 0.600 (3.215 sec/step)\n",
      "step 9990 \t loss = 0.808, train_acc = 0.700 (3.303 sec/step)\n",
      "step 10000 \t loss = 0.631, train_acc = 0.800 (3.254 sec/step)\n",
      "step 10010 \t loss = 0.972, train_acc = 0.700 (3.234 sec/step)\n",
      "step 10020 \t loss = 0.844, train_acc = 0.700 (3.260 sec/step)\n",
      "step 10030 \t loss = 1.479, train_acc = 0.600 (3.282 sec/step)\n",
      "step 10040 \t loss = 1.219, train_acc = 0.600 (3.266 sec/step)\n",
      "step 10050 \t loss = 0.157, train_acc = 1.000 (3.271 sec/step)\n",
      "step 10060 \t loss = 0.597, train_acc = 0.900 (3.238 sec/step)\n",
      "step 10070 \t loss = 0.148, train_acc = 1.000 (3.277 sec/step)\n",
      "step 10080 \t loss = 1.468, train_acc = 0.800 (3.259 sec/step)\n",
      "step 10090 \t loss = 0.795, train_acc = 0.700 (3.283 sec/step)\n",
      "step 10100 \t loss = 1.484, train_acc = 0.600 (3.228 sec/step)\n",
      "step 10110 \t loss = 1.056, train_acc = 0.600 (3.269 sec/step)\n",
      "step 10120 \t loss = 0.658, train_acc = 0.800 (3.308 sec/step)\n",
      "step 10130 \t loss = 1.198, train_acc = 0.600 (3.263 sec/step)\n",
      "step 10140 \t loss = 0.471, train_acc = 0.900 (3.269 sec/step)\n",
      "step 10150 \t loss = 1.620, train_acc = 0.600 (3.217 sec/step)\n",
      "step 10160 \t loss = 0.821, train_acc = 0.700 (3.240 sec/step)\n",
      "step 10170 \t loss = 1.330, train_acc = 0.500 (3.283 sec/step)\n",
      "step 10180 \t loss = 0.172, train_acc = 1.000 (3.221 sec/step)\n",
      "step 10190 \t loss = 0.830, train_acc = 0.600 (3.288 sec/step)\n",
      "step 10200 \t loss = 2.788, train_acc = 0.200 (3.230 sec/step)\n",
      "step 10210 \t loss = 0.734, train_acc = 0.800 (3.280 sec/step)\n",
      "step 10220 \t loss = 0.873, train_acc = 0.700 (3.290 sec/step)\n",
      "step 10230 \t loss = 1.205, train_acc = 0.800 (3.339 sec/step)\n",
      "step 10240 \t loss = 0.589, train_acc = 0.900 (3.226 sec/step)\n",
      "step 10250 \t loss = 0.825, train_acc = 0.600 (3.279 sec/step)\n",
      "step 10260 \t loss = 2.879, train_acc = 0.400 (3.233 sec/step)\n",
      "step 10270 \t loss = 0.795, train_acc = 0.600 (3.226 sec/step)\n",
      "step 10280 \t loss = 0.975, train_acc = 0.600 (3.279 sec/step)\n",
      "step 10290 \t loss = 0.512, train_acc = 0.900 (3.229 sec/step)\n",
      "step 10300 \t loss = 0.220, train_acc = 1.000 (3.258 sec/step)\n",
      "step 10310 \t loss = 1.163, train_acc = 0.600 (3.230 sec/step)\n",
      "step 10320 \t loss = 0.468, train_acc = 0.800 (3.255 sec/step)\n",
      "step 10330 \t loss = 0.667, train_acc = 0.900 (3.255 sec/step)\n",
      "step 10340 \t loss = 1.196, train_acc = 0.600 (3.232 sec/step)\n",
      "step 10350 \t loss = 0.948, train_acc = 0.700 (3.301 sec/step)\n",
      "step 10360 \t loss = 0.962, train_acc = 0.900 (3.241 sec/step)\n",
      "step 10370 \t loss = 0.938, train_acc = 0.700 (3.230 sec/step)\n",
      "step 10380 \t loss = 2.013, train_acc = 0.400 (3.215 sec/step)\n",
      "step 10390 \t loss = 0.740, train_acc = 0.700 (3.268 sec/step)\n",
      "step 10400 \t loss = 0.526, train_acc = 0.700 (3.238 sec/step)\n",
      "step 10410 \t loss = 0.798, train_acc = 0.800 (3.209 sec/step)\n",
      "step 10420 \t loss = 0.959, train_acc = 0.700 (3.242 sec/step)\n",
      "step 10430 \t loss = 0.997, train_acc = 0.700 (3.246 sec/step)\n",
      "step 10440 \t loss = 1.620, train_acc = 0.600 (3.277 sec/step)\n",
      "step 10450 \t loss = 2.200, train_acc = 0.600 (3.286 sec/step)\n",
      "step 10460 \t loss = 1.175, train_acc = 0.600 (3.239 sec/step)\n",
      "step 10470 \t loss = 1.460, train_acc = 0.700 (3.254 sec/step)\n",
      "step 10480 \t loss = 0.946, train_acc = 0.700 (3.218 sec/step)\n",
      "step 10490 \t loss = 0.577, train_acc = 0.900 (3.235 sec/step)\n",
      "step 10500 \t loss = 0.763, train_acc = 0.800 (3.253 sec/step)\n",
      "step 10510 \t loss = 1.650, train_acc = 0.400 (3.288 sec/step)\n",
      "step 10520 \t loss = 1.797, train_acc = 0.600 (3.238 sec/step)\n",
      "step 10530 \t loss = 0.733, train_acc = 0.800 (3.265 sec/step)\n",
      "step 10540 \t loss = 0.734, train_acc = 0.900 (3.235 sec/step)\n",
      "step 10550 \t loss = 1.196, train_acc = 0.600 (3.222 sec/step)\n",
      "step 10560 \t loss = 0.514, train_acc = 0.900 (3.282 sec/step)\n",
      "step 10570 \t loss = 0.670, train_acc = 0.800 (3.224 sec/step)\n",
      "step 10580 \t loss = 1.640, train_acc = 0.500 (3.265 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10590 \t loss = 1.383, train_acc = 0.600 (3.283 sec/step)\n",
      "step 10600 \t loss = 0.446, train_acc = 0.800 (3.254 sec/step)\n",
      "step 10610 \t loss = 1.038, train_acc = 0.600 (3.256 sec/step)\n",
      "step 10620 \t loss = 0.471, train_acc = 0.900 (3.274 sec/step)\n",
      "step 10630 \t loss = 1.055, train_acc = 0.800 (3.297 sec/step)\n",
      "step 10640 \t loss = 1.284, train_acc = 0.500 (3.236 sec/step)\n",
      "step 10650 \t loss = 0.578, train_acc = 0.800 (3.284 sec/step)\n",
      "step 10660 \t loss = 1.069, train_acc = 0.700 (3.262 sec/step)\n",
      "step 10670 \t loss = 0.767, train_acc = 0.900 (3.267 sec/step)\n",
      "step 10680 \t loss = 2.041, train_acc = 0.700 (3.270 sec/step)\n",
      "step 10690 \t loss = 0.742, train_acc = 0.800 (3.256 sec/step)\n",
      "step 10700 \t loss = 1.251, train_acc = 0.600 (3.242 sec/step)\n",
      "step 10710 \t loss = 1.060, train_acc = 0.600 (3.265 sec/step)\n",
      "step 10720 \t loss = 0.185, train_acc = 1.000 (3.243 sec/step)\n",
      "step 10730 \t loss = 0.457, train_acc = 0.700 (3.341 sec/step)\n",
      "step 10740 \t loss = 1.975, train_acc = 0.500 (3.260 sec/step)\n",
      "step 10750 \t loss = 0.703, train_acc = 0.800 (3.241 sec/step)\n",
      "step 10760 \t loss = 0.780, train_acc = 0.600 (3.271 sec/step)\n",
      "step 10770 \t loss = 0.817, train_acc = 0.700 (3.219 sec/step)\n",
      "step 10780 \t loss = 1.292, train_acc = 0.700 (3.229 sec/step)\n",
      "step 10790 \t loss = 1.947, train_acc = 0.600 (3.254 sec/step)\n",
      "step 10800 \t loss = 0.152, train_acc = 1.000 (3.251 sec/step)\n",
      "step 10810 \t loss = 0.610, train_acc = 0.700 (3.247 sec/step)\n",
      "step 10820 \t loss = 1.427, train_acc = 0.500 (3.253 sec/step)\n",
      "step 10830 \t loss = 1.087, train_acc = 0.600 (3.244 sec/step)\n",
      "step 10840 \t loss = 0.481, train_acc = 0.800 (3.253 sec/step)\n",
      "step 10850 \t loss = 1.098, train_acc = 0.700 (3.220 sec/step)\n",
      "step 10860 \t loss = 0.405, train_acc = 1.000 (3.255 sec/step)\n",
      "step 10870 \t loss = 0.490, train_acc = 0.900 (3.210 sec/step)\n",
      "step 10880 \t loss = 1.163, train_acc = 0.500 (3.241 sec/step)\n",
      "step 10890 \t loss = 0.561, train_acc = 0.900 (3.262 sec/step)\n",
      "step 10900 \t loss = 1.052, train_acc = 0.700 (3.267 sec/step)\n",
      "step 10910 \t loss = 1.634, train_acc = 0.500 (3.265 sec/step)\n",
      "step 10920 \t loss = 1.134, train_acc = 0.700 (3.261 sec/step)\n",
      "step 10930 \t loss = 1.185, train_acc = 0.600 (3.206 sec/step)\n",
      "step 10940 \t loss = 1.447, train_acc = 0.700 (3.277 sec/step)\n",
      "step 10950 \t loss = 0.524, train_acc = 0.900 (3.233 sec/step)\n",
      "step 10960 \t loss = 0.393, train_acc = 0.900 (3.214 sec/step)\n",
      "step 10970 \t loss = 0.525, train_acc = 0.800 (3.214 sec/step)\n",
      "step 10980 \t loss = 2.824, train_acc = 0.400 (3.244 sec/step)\n",
      "step 10990 \t loss = 1.821, train_acc = 0.400 (3.261 sec/step)\n",
      "step 11000 \t loss = 1.452, train_acc = 0.700 (3.214 sec/step)\n",
      "step 11010 \t loss = 0.754, train_acc = 0.900 (3.274 sec/step)\n",
      "step 11020 \t loss = 1.534, train_acc = 0.300 (3.242 sec/step)\n",
      "step 11030 \t loss = 0.481, train_acc = 0.900 (3.248 sec/step)\n",
      "step 11040 \t loss = 1.541, train_acc = 0.700 (3.265 sec/step)\n",
      "step 11050 \t loss = 0.780, train_acc = 0.800 (3.274 sec/step)\n",
      "step 11060 \t loss = 0.339, train_acc = 0.900 (3.237 sec/step)\n",
      "step 11070 \t loss = 0.535, train_acc = 0.900 (3.221 sec/step)\n",
      "step 11080 \t loss = 0.420, train_acc = 1.000 (3.228 sec/step)\n",
      "step 11090 \t loss = 0.223, train_acc = 1.000 (3.278 sec/step)\n",
      "step 11100 \t loss = 2.097, train_acc = 0.500 (3.296 sec/step)\n",
      "step 11110 \t loss = 1.584, train_acc = 0.500 (3.357 sec/step)\n",
      "step 11120 \t loss = 0.297, train_acc = 1.000 (3.239 sec/step)\n",
      "step 11130 \t loss = 2.073, train_acc = 0.300 (3.266 sec/step)\n",
      "step 11140 \t loss = 1.883, train_acc = 0.400 (3.222 sec/step)\n",
      "step 11150 \t loss = 0.636, train_acc = 0.800 (3.251 sec/step)\n",
      "step 11160 \t loss = 1.628, train_acc = 0.500 (3.245 sec/step)\n",
      "step 11170 \t loss = 0.581, train_acc = 0.800 (3.237 sec/step)\n",
      "step 11180 \t loss = 0.534, train_acc = 0.900 (3.317 sec/step)\n",
      "step 11190 \t loss = 1.007, train_acc = 0.700 (3.242 sec/step)\n",
      "step 11200 \t loss = 0.711, train_acc = 0.800 (3.233 sec/step)\n",
      "step 11210 \t loss = 0.257, train_acc = 1.000 (3.303 sec/step)\n",
      "step 11220 \t loss = 2.014, train_acc = 0.700 (3.251 sec/step)\n",
      "step 11230 \t loss = 1.850, train_acc = 0.500 (3.271 sec/step)\n",
      "step 11240 \t loss = 0.465, train_acc = 0.900 (3.261 sec/step)\n",
      "step 11250 \t loss = 0.995, train_acc = 0.800 (3.209 sec/step)\n",
      "step 11260 \t loss = 1.146, train_acc = 0.500 (3.277 sec/step)\n",
      "step 11270 \t loss = 0.325, train_acc = 1.000 (3.288 sec/step)\n",
      "step 11280 \t loss = 0.651, train_acc = 0.700 (3.253 sec/step)\n",
      "step 11290 \t loss = 0.796, train_acc = 0.700 (3.243 sec/step)\n",
      "step 11300 \t loss = 0.446, train_acc = 0.900 (3.271 sec/step)\n",
      "step 11310 \t loss = 1.809, train_acc = 0.400 (3.235 sec/step)\n",
      "step 11320 \t loss = 0.439, train_acc = 0.900 (3.264 sec/step)\n",
      "step 11330 \t loss = 1.795, train_acc = 0.500 (3.236 sec/step)\n",
      "step 11340 \t loss = 2.603, train_acc = 0.300 (3.218 sec/step)\n",
      "step 11350 \t loss = 0.413, train_acc = 0.800 (3.238 sec/step)\n",
      "step 11360 \t loss = 0.823, train_acc = 0.700 (3.266 sec/step)\n",
      "step 11370 \t loss = 1.148, train_acc = 0.500 (3.260 sec/step)\n",
      "step 11380 \t loss = 0.401, train_acc = 0.900 (3.259 sec/step)\n",
      "step 11390 \t loss = 1.481, train_acc = 0.500 (3.218 sec/step)\n",
      "VALIDATION \t acc = 0.524 (3.640 sec)\n",
      "New Best Accuracy 0.524 > Old Best 0.494.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 11400 \t loss = 2.175, train_acc = 0.500 (3.288 sec/step)\n",
      "step 11410 \t loss = 0.913, train_acc = 0.800 (3.256 sec/step)\n",
      "step 11420 \t loss = 0.642, train_acc = 0.800 (3.262 sec/step)\n",
      "step 11430 \t loss = 0.871, train_acc = 0.800 (3.248 sec/step)\n",
      "step 11440 \t loss = 0.097, train_acc = 1.000 (3.230 sec/step)\n",
      "step 11450 \t loss = 0.888, train_acc = 0.600 (3.264 sec/step)\n",
      "step 11460 \t loss = 0.273, train_acc = 0.900 (3.246 sec/step)\n",
      "step 11470 \t loss = 0.380, train_acc = 1.000 (3.268 sec/step)\n",
      "step 11480 \t loss = 1.241, train_acc = 0.600 (3.285 sec/step)\n",
      "step 11490 \t loss = 0.315, train_acc = 0.900 (3.222 sec/step)\n",
      "step 11500 \t loss = 0.402, train_acc = 1.000 (3.252 sec/step)\n",
      "step 11510 \t loss = 1.360, train_acc = 0.500 (3.240 sec/step)\n",
      "step 11520 \t loss = 0.826, train_acc = 0.700 (3.252 sec/step)\n",
      "step 11530 \t loss = 0.503, train_acc = 0.900 (3.212 sec/step)\n",
      "step 11540 \t loss = 0.473, train_acc = 0.800 (3.247 sec/step)\n",
      "step 11550 \t loss = 0.876, train_acc = 0.800 (3.263 sec/step)\n",
      "step 11560 \t loss = 0.377, train_acc = 0.900 (3.323 sec/step)\n",
      "step 11570 \t loss = 0.485, train_acc = 0.800 (3.259 sec/step)\n",
      "step 11580 \t loss = 0.134, train_acc = 1.000 (3.247 sec/step)\n",
      "step 11590 \t loss = 0.891, train_acc = 0.800 (3.289 sec/step)\n",
      "step 11600 \t loss = 0.346, train_acc = 1.000 (3.241 sec/step)\n",
      "step 11610 \t loss = 0.638, train_acc = 0.800 (3.246 sec/step)\n",
      "step 11620 \t loss = 0.936, train_acc = 0.600 (3.251 sec/step)\n",
      "step 11630 \t loss = 1.061, train_acc = 0.800 (3.221 sec/step)\n",
      "step 11640 \t loss = 1.179, train_acc = 0.600 (3.271 sec/step)\n",
      "step 11650 \t loss = 1.129, train_acc = 0.700 (3.268 sec/step)\n",
      "step 11660 \t loss = 0.540, train_acc = 0.900 (3.268 sec/step)\n",
      "step 11670 \t loss = 1.301, train_acc = 0.600 (3.332 sec/step)\n",
      "step 11680 \t loss = 1.370, train_acc = 0.500 (3.220 sec/step)\n",
      "step 11690 \t loss = 0.991, train_acc = 0.600 (3.232 sec/step)\n",
      "step 11700 \t loss = 1.858, train_acc = 0.500 (3.227 sec/step)\n",
      "step 11710 \t loss = 1.828, train_acc = 0.600 (3.276 sec/step)\n",
      "step 11720 \t loss = 0.750, train_acc = 0.700 (3.245 sec/step)\n",
      "step 11730 \t loss = 0.536, train_acc = 0.900 (3.249 sec/step)\n",
      "step 11740 \t loss = 0.934, train_acc = 0.800 (3.371 sec/step)\n",
      "step 11750 \t loss = 0.460, train_acc = 0.800 (3.240 sec/step)\n",
      "step 11760 \t loss = 1.657, train_acc = 0.600 (3.241 sec/step)\n",
      "step 11770 \t loss = 1.277, train_acc = 0.500 (3.236 sec/step)\n",
      "step 11780 \t loss = 0.246, train_acc = 0.900 (3.336 sec/step)\n",
      "step 11790 \t loss = 0.572, train_acc = 0.900 (3.311 sec/step)\n",
      "step 11800 \t loss = 2.104, train_acc = 0.600 (3.251 sec/step)\n",
      "step 11810 \t loss = 1.008, train_acc = 0.800 (3.316 sec/step)\n",
      "step 11820 \t loss = 1.002, train_acc = 0.700 (3.264 sec/step)\n",
      "step 11830 \t loss = 0.683, train_acc = 0.700 (3.295 sec/step)\n",
      "step 11840 \t loss = 0.649, train_acc = 0.800 (3.243 sec/step)\n",
      "step 11850 \t loss = 1.779, train_acc = 0.400 (3.292 sec/step)\n",
      "step 11860 \t loss = 2.739, train_acc = 0.500 (3.283 sec/step)\n",
      "step 11870 \t loss = 0.359, train_acc = 0.900 (3.275 sec/step)\n",
      "step 11880 \t loss = 0.737, train_acc = 0.800 (3.222 sec/step)\n",
      "step 11890 \t loss = 1.449, train_acc = 0.500 (3.262 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11900 \t loss = 0.477, train_acc = 0.800 (3.255 sec/step)\n",
      "step 11910 \t loss = 1.383, train_acc = 0.700 (3.373 sec/step)\n",
      "step 11920 \t loss = 0.460, train_acc = 0.900 (3.254 sec/step)\n",
      "step 11930 \t loss = 0.527, train_acc = 0.800 (3.253 sec/step)\n",
      "step 11940 \t loss = 0.806, train_acc = 0.700 (3.274 sec/step)\n",
      "step 11950 \t loss = 1.055, train_acc = 0.600 (3.283 sec/step)\n",
      "step 11960 \t loss = 0.421, train_acc = 0.800 (3.227 sec/step)\n",
      "step 11970 \t loss = 0.575, train_acc = 0.900 (3.231 sec/step)\n",
      "step 11980 \t loss = 1.466, train_acc = 0.600 (3.236 sec/step)\n",
      "step 11990 \t loss = 0.718, train_acc = 0.700 (3.213 sec/step)\n",
      "step 12000 \t loss = 0.752, train_acc = 0.800 (3.225 sec/step)\n",
      "step 12010 \t loss = 1.141, train_acc = 0.600 (3.291 sec/step)\n",
      "step 12020 \t loss = 0.332, train_acc = 0.900 (3.248 sec/step)\n",
      "step 12030 \t loss = 1.291, train_acc = 0.600 (3.266 sec/step)\n",
      "step 12040 \t loss = 0.399, train_acc = 0.900 (3.228 sec/step)\n",
      "step 12050 \t loss = 0.635, train_acc = 0.800 (3.228 sec/step)\n",
      "step 12060 \t loss = 1.806, train_acc = 0.400 (3.277 sec/step)\n",
      "step 12070 \t loss = 0.525, train_acc = 0.700 (3.268 sec/step)\n",
      "step 12080 \t loss = 1.113, train_acc = 0.800 (3.237 sec/step)\n",
      "step 12090 \t loss = 1.119, train_acc = 0.500 (3.245 sec/step)\n",
      "step 12100 \t loss = 1.000, train_acc = 0.600 (3.220 sec/step)\n",
      "step 12110 \t loss = 0.640, train_acc = 0.800 (3.278 sec/step)\n",
      "step 12120 \t loss = 1.039, train_acc = 0.700 (3.273 sec/step)\n",
      "step 12130 \t loss = 0.487, train_acc = 0.900 (3.272 sec/step)\n",
      "step 12140 \t loss = 0.331, train_acc = 0.800 (3.289 sec/step)\n",
      "step 12150 \t loss = 0.988, train_acc = 0.800 (3.295 sec/step)\n",
      "step 12160 \t loss = 1.446, train_acc = 0.600 (3.254 sec/step)\n",
      "step 12170 \t loss = 0.134, train_acc = 1.000 (3.296 sec/step)\n",
      "step 12180 \t loss = 0.375, train_acc = 0.900 (3.244 sec/step)\n",
      "step 12190 \t loss = 0.558, train_acc = 0.700 (3.245 sec/step)\n",
      "step 12200 \t loss = 0.147, train_acc = 1.000 (3.335 sec/step)\n",
      "step 12210 \t loss = 0.744, train_acc = 0.800 (3.306 sec/step)\n",
      "step 12220 \t loss = 0.572, train_acc = 0.800 (3.253 sec/step)\n",
      "step 12230 \t loss = 0.445, train_acc = 0.900 (3.288 sec/step)\n",
      "step 12240 \t loss = 3.404, train_acc = 0.300 (3.250 sec/step)\n",
      "step 12250 \t loss = 0.919, train_acc = 0.500 (3.268 sec/step)\n",
      "step 12260 \t loss = 0.658, train_acc = 0.800 (3.272 sec/step)\n",
      "step 12270 \t loss = 0.407, train_acc = 0.900 (3.288 sec/step)\n",
      "step 12280 \t loss = 0.494, train_acc = 0.800 (3.265 sec/step)\n",
      "step 12290 \t loss = 0.875, train_acc = 0.800 (3.226 sec/step)\n",
      "step 12300 \t loss = 0.907, train_acc = 0.600 (3.294 sec/step)\n",
      "step 12310 \t loss = 0.566, train_acc = 0.800 (3.252 sec/step)\n",
      "step 12320 \t loss = 0.614, train_acc = 0.700 (3.301 sec/step)\n",
      "step 12330 \t loss = 0.663, train_acc = 0.800 (3.297 sec/step)\n",
      "step 12340 \t loss = 1.054, train_acc = 0.700 (3.301 sec/step)\n",
      "step 12350 \t loss = 1.025, train_acc = 0.800 (3.269 sec/step)\n",
      "step 12360 \t loss = 0.832, train_acc = 0.700 (3.280 sec/step)\n",
      "step 12370 \t loss = 0.184, train_acc = 1.000 (3.257 sec/step)\n",
      "step 12380 \t loss = 0.322, train_acc = 0.900 (3.235 sec/step)\n",
      "step 12390 \t loss = 0.360, train_acc = 0.900 (3.239 sec/step)\n",
      "step 12400 \t loss = 0.339, train_acc = 0.800 (3.283 sec/step)\n",
      "step 12410 \t loss = 0.541, train_acc = 0.900 (3.225 sec/step)\n",
      "step 12420 \t loss = 0.334, train_acc = 0.900 (3.263 sec/step)\n",
      "step 12430 \t loss = 1.447, train_acc = 0.700 (3.368 sec/step)\n",
      "step 12440 \t loss = 0.380, train_acc = 0.800 (3.238 sec/step)\n",
      "step 12450 \t loss = 0.573, train_acc = 0.900 (3.281 sec/step)\n",
      "step 12460 \t loss = 0.818, train_acc = 0.800 (3.244 sec/step)\n",
      "step 12470 \t loss = 0.755, train_acc = 0.800 (3.261 sec/step)\n",
      "step 12480 \t loss = 0.956, train_acc = 0.600 (3.269 sec/step)\n",
      "step 12490 \t loss = 1.938, train_acc = 0.600 (3.224 sec/step)\n",
      "step 12500 \t loss = 0.614, train_acc = 0.800 (3.275 sec/step)\n",
      "step 12510 \t loss = 1.680, train_acc = 0.600 (3.223 sec/step)\n",
      "step 12520 \t loss = 0.190, train_acc = 0.900 (3.257 sec/step)\n",
      "step 12530 \t loss = 1.037, train_acc = 0.600 (3.233 sec/step)\n",
      "step 12540 \t loss = 2.748, train_acc = 0.300 (3.260 sec/step)\n",
      "step 12550 \t loss = 0.353, train_acc = 0.900 (3.240 sec/step)\n",
      "step 12560 \t loss = 0.271, train_acc = 1.000 (3.286 sec/step)\n",
      "step 12570 \t loss = 0.588, train_acc = 0.800 (3.242 sec/step)\n",
      "step 12580 \t loss = 0.836, train_acc = 0.800 (3.219 sec/step)\n",
      "step 12590 \t loss = 1.570, train_acc = 0.600 (3.241 sec/step)\n",
      "step 12600 \t loss = 0.745, train_acc = 0.800 (3.217 sec/step)\n",
      "step 12610 \t loss = 1.736, train_acc = 0.600 (3.351 sec/step)\n",
      "step 12620 \t loss = 0.899, train_acc = 0.800 (3.246 sec/step)\n",
      "step 12630 \t loss = 0.564, train_acc = 0.800 (3.257 sec/step)\n",
      "step 12640 \t loss = 0.611, train_acc = 0.700 (3.272 sec/step)\n",
      "step 12650 \t loss = 0.742, train_acc = 0.600 (3.280 sec/step)\n",
      "step 12660 \t loss = 0.750, train_acc = 0.700 (3.294 sec/step)\n",
      "step 12670 \t loss = 0.991, train_acc = 0.600 (3.250 sec/step)\n",
      "step 12680 \t loss = 0.618, train_acc = 0.600 (3.349 sec/step)\n",
      "step 12690 \t loss = 0.694, train_acc = 0.800 (3.287 sec/step)\n",
      "step 12700 \t loss = 0.727, train_acc = 0.900 (3.443 sec/step)\n",
      "step 12710 \t loss = 1.904, train_acc = 0.500 (3.249 sec/step)\n",
      "step 12720 \t loss = 0.825, train_acc = 0.800 (3.266 sec/step)\n",
      "step 12730 \t loss = 1.063, train_acc = 0.700 (3.294 sec/step)\n",
      "step 12740 \t loss = 0.195, train_acc = 1.000 (3.297 sec/step)\n",
      "step 12750 \t loss = 1.408, train_acc = 0.700 (3.295 sec/step)\n",
      "step 12760 \t loss = 1.978, train_acc = 0.400 (3.360 sec/step)\n",
      "step 12770 \t loss = 0.559, train_acc = 0.800 (3.319 sec/step)\n",
      "step 12780 \t loss = 0.632, train_acc = 0.700 (3.250 sec/step)\n",
      "step 12790 \t loss = 2.139, train_acc = 0.500 (3.235 sec/step)\n",
      "step 12800 \t loss = 0.685, train_acc = 0.800 (3.233 sec/step)\n",
      "step 12810 \t loss = 0.681, train_acc = 0.800 (3.259 sec/step)\n",
      "step 12820 \t loss = 0.558, train_acc = 0.900 (3.243 sec/step)\n",
      "step 12830 \t loss = 0.209, train_acc = 1.000 (3.302 sec/step)\n",
      "step 12840 \t loss = 0.512, train_acc = 0.900 (3.305 sec/step)\n",
      "step 12850 \t loss = 0.305, train_acc = 0.900 (3.265 sec/step)\n",
      "step 12860 \t loss = 0.119, train_acc = 1.000 (3.371 sec/step)\n",
      "step 12870 \t loss = 0.316, train_acc = 0.900 (3.234 sec/step)\n",
      "step 12880 \t loss = 1.543, train_acc = 0.400 (3.231 sec/step)\n",
      "step 12890 \t loss = 0.329, train_acc = 0.900 (3.279 sec/step)\n",
      "step 12900 \t loss = 0.376, train_acc = 0.900 (3.232 sec/step)\n",
      "step 12910 \t loss = 2.318, train_acc = 0.400 (3.244 sec/step)\n",
      "step 12920 \t loss = 0.221, train_acc = 1.000 (3.245 sec/step)\n",
      "step 12930 \t loss = 0.581, train_acc = 0.800 (3.280 sec/step)\n",
      "step 12940 \t loss = 0.214, train_acc = 1.000 (3.229 sec/step)\n",
      "step 12950 \t loss = 1.124, train_acc = 0.800 (3.277 sec/step)\n",
      "step 12960 \t loss = 1.308, train_acc = 0.500 (3.260 sec/step)\n",
      "step 12970 \t loss = 0.988, train_acc = 0.600 (3.231 sec/step)\n",
      "step 12980 \t loss = 0.501, train_acc = 0.900 (3.247 sec/step)\n",
      "step 12990 \t loss = 0.373, train_acc = 0.800 (3.259 sec/step)\n",
      "step 13000 \t loss = 1.302, train_acc = 0.800 (3.252 sec/step)\n",
      "step 13010 \t loss = 0.685, train_acc = 0.800 (3.239 sec/step)\n",
      "step 13020 \t loss = 0.817, train_acc = 0.900 (3.322 sec/step)\n",
      "step 13030 \t loss = 0.970, train_acc = 0.700 (3.251 sec/step)\n",
      "step 13040 \t loss = 1.579, train_acc = 0.500 (3.265 sec/step)\n",
      "step 13050 \t loss = 0.201, train_acc = 0.900 (3.366 sec/step)\n",
      "step 13060 \t loss = 0.722, train_acc = 0.800 (3.257 sec/step)\n",
      "step 13070 \t loss = 0.781, train_acc = 0.800 (3.259 sec/step)\n",
      "step 13080 \t loss = 0.466, train_acc = 0.800 (3.256 sec/step)\n",
      "step 13090 \t loss = 0.426, train_acc = 0.900 (3.286 sec/step)\n",
      "step 13100 \t loss = 0.030, train_acc = 1.000 (3.293 sec/step)\n",
      "step 13110 \t loss = 0.069, train_acc = 1.000 (3.249 sec/step)\n",
      "step 13120 \t loss = 1.239, train_acc = 0.600 (3.324 sec/step)\n",
      "step 13130 \t loss = 2.283, train_acc = 0.400 (3.294 sec/step)\n",
      "step 13140 \t loss = 2.056, train_acc = 0.500 (3.245 sec/step)\n",
      "step 13150 \t loss = 0.567, train_acc = 0.800 (3.209 sec/step)\n",
      "step 13160 \t loss = 0.701, train_acc = 0.800 (3.287 sec/step)\n",
      "step 13170 \t loss = 0.119, train_acc = 1.000 (3.314 sec/step)\n",
      "step 13180 \t loss = 0.211, train_acc = 1.000 (3.271 sec/step)\n",
      "step 13190 \t loss = 0.609, train_acc = 0.900 (3.333 sec/step)\n",
      "step 13200 \t loss = 3.007, train_acc = 0.700 (3.253 sec/step)\n",
      "step 13210 \t loss = 0.410, train_acc = 1.000 (3.297 sec/step)\n",
      "step 13220 \t loss = 0.354, train_acc = 1.000 (3.243 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13230 \t loss = 1.466, train_acc = 0.300 (3.292 sec/step)\n",
      "step 13240 \t loss = 1.267, train_acc = 0.600 (3.251 sec/step)\n",
      "step 13250 \t loss = 0.539, train_acc = 0.900 (3.279 sec/step)\n",
      "step 13260 \t loss = 0.341, train_acc = 0.900 (3.257 sec/step)\n",
      "step 13270 \t loss = 0.492, train_acc = 0.800 (3.246 sec/step)\n",
      "step 13280 \t loss = 1.149, train_acc = 0.800 (3.264 sec/step)\n",
      "step 13290 \t loss = 2.541, train_acc = 0.200 (3.261 sec/step)\n",
      "VALIDATION \t acc = 0.512 (3.636 sec)\n",
      "step 13300 \t loss = 0.848, train_acc = 0.700 (3.282 sec/step)\n",
      "step 13310 \t loss = 0.890, train_acc = 0.700 (3.291 sec/step)\n",
      "step 13320 \t loss = 0.313, train_acc = 0.900 (3.247 sec/step)\n",
      "step 13330 \t loss = 0.598, train_acc = 0.700 (3.245 sec/step)\n",
      "step 13340 \t loss = 0.325, train_acc = 0.900 (3.219 sec/step)\n",
      "step 13350 \t loss = 1.737, train_acc = 0.600 (3.232 sec/step)\n",
      "step 13360 \t loss = 0.227, train_acc = 0.800 (3.295 sec/step)\n",
      "step 13370 \t loss = 0.128, train_acc = 1.000 (3.233 sec/step)\n",
      "step 13380 \t loss = 0.235, train_acc = 1.000 (3.281 sec/step)\n",
      "step 13390 \t loss = 1.056, train_acc = 0.700 (3.247 sec/step)\n",
      "step 13400 \t loss = 0.489, train_acc = 0.800 (3.270 sec/step)\n",
      "step 13410 \t loss = 0.558, train_acc = 0.800 (3.249 sec/step)\n",
      "step 13420 \t loss = 0.933, train_acc = 0.800 (3.216 sec/step)\n",
      "step 13430 \t loss = 0.360, train_acc = 0.900 (3.243 sec/step)\n",
      "step 13440 \t loss = 0.795, train_acc = 0.800 (3.254 sec/step)\n",
      "step 13450 \t loss = 0.422, train_acc = 0.900 (3.266 sec/step)\n",
      "step 13460 \t loss = 1.486, train_acc = 0.600 (3.240 sec/step)\n",
      "step 13470 \t loss = 0.286, train_acc = 1.000 (3.262 sec/step)\n",
      "step 13480 \t loss = 0.126, train_acc = 1.000 (3.309 sec/step)\n",
      "step 13490 \t loss = 0.406, train_acc = 0.900 (3.254 sec/step)\n",
      "step 13500 \t loss = 1.858, train_acc = 0.500 (3.259 sec/step)\n",
      "step 13510 \t loss = 0.330, train_acc = 0.900 (3.283 sec/step)\n",
      "step 13520 \t loss = 0.450, train_acc = 0.900 (3.252 sec/step)\n",
      "step 13530 \t loss = 0.834, train_acc = 0.800 (3.237 sec/step)\n",
      "step 13540 \t loss = 0.655, train_acc = 0.800 (3.254 sec/step)\n",
      "step 13550 \t loss = 0.895, train_acc = 0.700 (3.239 sec/step)\n",
      "step 13560 \t loss = 0.871, train_acc = 0.700 (3.260 sec/step)\n",
      "step 13570 \t loss = 2.332, train_acc = 0.400 (3.247 sec/step)\n",
      "step 13580 \t loss = 0.373, train_acc = 0.900 (3.274 sec/step)\n",
      "step 13590 \t loss = 0.437, train_acc = 0.800 (3.254 sec/step)\n",
      "step 13600 \t loss = 1.101, train_acc = 0.800 (3.260 sec/step)\n",
      "step 13610 \t loss = 1.409, train_acc = 0.600 (3.229 sec/step)\n",
      "step 13620 \t loss = 0.195, train_acc = 0.900 (3.262 sec/step)\n",
      "step 13630 \t loss = 0.861, train_acc = 0.800 (3.228 sec/step)\n",
      "step 13640 \t loss = 0.178, train_acc = 0.900 (3.266 sec/step)\n",
      "step 13650 \t loss = 0.909, train_acc = 0.600 (3.226 sec/step)\n",
      "step 13660 \t loss = 0.733, train_acc = 0.800 (3.278 sec/step)\n",
      "step 13670 \t loss = 0.290, train_acc = 0.900 (3.248 sec/step)\n",
      "step 13680 \t loss = 0.044, train_acc = 1.000 (3.221 sec/step)\n",
      "step 13690 \t loss = 0.189, train_acc = 0.900 (3.285 sec/step)\n",
      "step 13700 \t loss = 1.462, train_acc = 0.600 (3.301 sec/step)\n",
      "step 13710 \t loss = 0.553, train_acc = 0.800 (3.343 sec/step)\n",
      "step 13720 \t loss = 0.452, train_acc = 0.700 (3.229 sec/step)\n",
      "step 13730 \t loss = 0.250, train_acc = 0.900 (3.237 sec/step)\n",
      "step 13740 \t loss = 0.972, train_acc = 0.600 (3.286 sec/step)\n",
      "step 13750 \t loss = 0.233, train_acc = 1.000 (3.252 sec/step)\n",
      "step 13760 \t loss = 0.402, train_acc = 0.900 (3.247 sec/step)\n",
      "step 13770 \t loss = 0.190, train_acc = 1.000 (3.257 sec/step)\n",
      "step 13780 \t loss = 0.492, train_acc = 0.800 (3.257 sec/step)\n",
      "step 13790 \t loss = 0.524, train_acc = 0.800 (3.304 sec/step)\n",
      "step 13800 \t loss = 1.206, train_acc = 0.700 (3.248 sec/step)\n",
      "step 13810 \t loss = 0.619, train_acc = 0.800 (3.248 sec/step)\n",
      "step 13820 \t loss = 0.460, train_acc = 0.900 (3.251 sec/step)\n",
      "step 13830 \t loss = 1.506, train_acc = 0.600 (3.286 sec/step)\n",
      "step 13840 \t loss = 2.037, train_acc = 0.500 (3.302 sec/step)\n",
      "step 13850 \t loss = 0.475, train_acc = 0.800 (3.311 sec/step)\n",
      "step 13860 \t loss = 0.835, train_acc = 0.800 (3.287 sec/step)\n",
      "step 13870 \t loss = 0.888, train_acc = 0.800 (3.234 sec/step)\n",
      "step 13880 \t loss = 0.495, train_acc = 0.800 (3.240 sec/step)\n",
      "step 13890 \t loss = 0.941, train_acc = 0.600 (3.236 sec/step)\n",
      "step 13900 \t loss = 2.234, train_acc = 0.600 (3.275 sec/step)\n",
      "step 13910 \t loss = 1.062, train_acc = 0.600 (3.283 sec/step)\n",
      "step 13920 \t loss = 0.379, train_acc = 0.800 (3.305 sec/step)\n",
      "step 13930 \t loss = 0.479, train_acc = 0.800 (3.253 sec/step)\n",
      "step 13940 \t loss = 0.401, train_acc = 0.800 (3.280 sec/step)\n",
      "step 13950 \t loss = 0.261, train_acc = 1.000 (3.249 sec/step)\n",
      "step 13960 \t loss = 0.662, train_acc = 0.900 (3.256 sec/step)\n",
      "step 13970 \t loss = 0.150, train_acc = 1.000 (3.251 sec/step)\n",
      "step 13980 \t loss = 0.099, train_acc = 0.900 (3.295 sec/step)\n",
      "step 13990 \t loss = 0.282, train_acc = 1.000 (3.263 sec/step)\n",
      "step 14000 \t loss = 0.837, train_acc = 0.800 (3.282 sec/step)\n",
      "step 14010 \t loss = 0.403, train_acc = 0.900 (3.300 sec/step)\n",
      "step 14020 \t loss = 0.524, train_acc = 0.800 (3.270 sec/step)\n",
      "step 14030 \t loss = 2.644, train_acc = 0.400 (3.268 sec/step)\n",
      "step 14040 \t loss = 0.142, train_acc = 1.000 (3.257 sec/step)\n",
      "step 14050 \t loss = 1.247, train_acc = 0.600 (3.254 sec/step)\n",
      "step 14060 \t loss = 1.151, train_acc = 0.600 (3.362 sec/step)\n",
      "step 14070 \t loss = 0.320, train_acc = 0.800 (3.293 sec/step)\n",
      "step 14080 \t loss = 0.726, train_acc = 0.700 (3.283 sec/step)\n",
      "step 14090 \t loss = 0.426, train_acc = 0.900 (3.273 sec/step)\n",
      "step 14100 \t loss = 0.293, train_acc = 0.900 (3.252 sec/step)\n",
      "step 14110 \t loss = 1.020, train_acc = 0.700 (3.264 sec/step)\n",
      "step 14120 \t loss = 0.278, train_acc = 0.900 (3.265 sec/step)\n",
      "step 14130 \t loss = 0.655, train_acc = 0.800 (3.257 sec/step)\n",
      "step 14140 \t loss = 1.173, train_acc = 0.700 (3.272 sec/step)\n",
      "step 14150 \t loss = 0.725, train_acc = 0.900 (3.297 sec/step)\n",
      "step 14160 \t loss = 0.320, train_acc = 0.900 (3.225 sec/step)\n",
      "step 14170 \t loss = 0.366, train_acc = 0.900 (3.312 sec/step)\n",
      "step 14180 \t loss = 0.779, train_acc = 0.600 (3.335 sec/step)\n",
      "step 14190 \t loss = 0.377, train_acc = 0.800 (3.297 sec/step)\n",
      "step 14200 \t loss = 0.493, train_acc = 0.800 (3.277 sec/step)\n",
      "step 14210 \t loss = 0.360, train_acc = 0.800 (3.348 sec/step)\n",
      "step 14220 \t loss = 0.248, train_acc = 0.900 (3.254 sec/step)\n",
      "step 14230 \t loss = 0.590, train_acc = 0.700 (3.263 sec/step)\n",
      "step 14240 \t loss = 0.661, train_acc = 0.700 (3.229 sec/step)\n",
      "step 14250 \t loss = 0.867, train_acc = 0.800 (3.294 sec/step)\n",
      "step 14260 \t loss = 0.597, train_acc = 0.800 (3.306 sec/step)\n",
      "step 14270 \t loss = 2.506, train_acc = 0.500 (3.241 sec/step)\n",
      "step 14280 \t loss = 0.332, train_acc = 0.800 (3.228 sec/step)\n",
      "step 14290 \t loss = 3.546, train_acc = 0.300 (3.223 sec/step)\n",
      "step 14300 \t loss = 0.301, train_acc = 0.900 (3.258 sec/step)\n",
      "step 14310 \t loss = 1.066, train_acc = 0.700 (3.251 sec/step)\n",
      "step 14320 \t loss = 0.334, train_acc = 0.900 (3.245 sec/step)\n",
      "step 14330 \t loss = 0.620, train_acc = 0.700 (3.275 sec/step)\n",
      "step 14340 \t loss = 1.377, train_acc = 0.600 (3.295 sec/step)\n",
      "step 14350 \t loss = 0.804, train_acc = 0.600 (3.249 sec/step)\n",
      "step 14360 \t loss = 0.744, train_acc = 0.700 (3.223 sec/step)\n",
      "step 14370 \t loss = 0.201, train_acc = 0.900 (3.236 sec/step)\n",
      "step 14380 \t loss = 0.417, train_acc = 0.900 (3.306 sec/step)\n",
      "step 14390 \t loss = 1.119, train_acc = 0.600 (3.261 sec/step)\n",
      "step 14400 \t loss = 0.209, train_acc = 1.000 (3.270 sec/step)\n",
      "step 14410 \t loss = 0.582, train_acc = 0.800 (3.301 sec/step)\n",
      "step 14420 \t loss = 0.127, train_acc = 0.900 (3.254 sec/step)\n",
      "step 14430 \t loss = 0.491, train_acc = 0.800 (3.248 sec/step)\n",
      "step 14440 \t loss = 1.480, train_acc = 0.700 (3.317 sec/step)\n",
      "step 14450 \t loss = 0.222, train_acc = 0.900 (3.267 sec/step)\n",
      "step 14460 \t loss = 0.455, train_acc = 0.800 (3.273 sec/step)\n",
      "step 14470 \t loss = 0.665, train_acc = 0.700 (3.296 sec/step)\n",
      "step 14480 \t loss = 0.840, train_acc = 0.700 (3.223 sec/step)\n",
      "step 14490 \t loss = 0.599, train_acc = 0.800 (3.272 sec/step)\n",
      "step 14500 \t loss = 1.263, train_acc = 0.500 (3.291 sec/step)\n",
      "step 14510 \t loss = 0.517, train_acc = 0.800 (3.314 sec/step)\n",
      "step 14520 \t loss = 0.873, train_acc = 0.800 (3.261 sec/step)\n",
      "step 14530 \t loss = 0.240, train_acc = 0.900 (3.256 sec/step)\n",
      "step 14540 \t loss = 0.957, train_acc = 0.800 (3.308 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14550 \t loss = 0.256, train_acc = 1.000 (3.258 sec/step)\n",
      "step 14560 \t loss = 0.987, train_acc = 0.500 (3.269 sec/step)\n",
      "step 14570 \t loss = 2.063, train_acc = 0.800 (3.286 sec/step)\n",
      "step 14580 \t loss = 0.065, train_acc = 1.000 (3.279 sec/step)\n",
      "step 14590 \t loss = 0.412, train_acc = 0.900 (3.255 sec/step)\n",
      "step 14600 \t loss = 0.915, train_acc = 0.700 (3.249 sec/step)\n",
      "step 14610 \t loss = 0.704, train_acc = 0.800 (3.252 sec/step)\n",
      "step 14620 \t loss = 1.050, train_acc = 0.700 (3.240 sec/step)\n",
      "step 14630 \t loss = 0.790, train_acc = 0.700 (3.333 sec/step)\n",
      "step 14640 \t loss = 0.207, train_acc = 0.900 (3.302 sec/step)\n",
      "step 14650 \t loss = 1.475, train_acc = 0.500 (3.281 sec/step)\n",
      "step 14660 \t loss = 0.777, train_acc = 0.800 (3.390 sec/step)\n",
      "step 14670 \t loss = 0.366, train_acc = 0.900 (3.258 sec/step)\n",
      "step 14680 \t loss = 0.309, train_acc = 0.900 (3.345 sec/step)\n",
      "step 14690 \t loss = 0.977, train_acc = 0.600 (3.250 sec/step)\n",
      "step 14700 \t loss = 0.417, train_acc = 0.900 (3.307 sec/step)\n",
      "step 14710 \t loss = 0.898, train_acc = 0.800 (3.271 sec/step)\n",
      "step 14720 \t loss = 0.044, train_acc = 1.000 (3.262 sec/step)\n",
      "step 14730 \t loss = 0.463, train_acc = 0.800 (3.259 sec/step)\n",
      "step 14740 \t loss = 0.330, train_acc = 0.900 (3.273 sec/step)\n",
      "step 14750 \t loss = 2.266, train_acc = 0.500 (3.217 sec/step)\n",
      "step 14760 \t loss = 0.269, train_acc = 0.800 (3.264 sec/step)\n",
      "step 14770 \t loss = 1.135, train_acc = 0.500 (3.422 sec/step)\n",
      "step 14780 \t loss = 1.145, train_acc = 0.700 (3.327 sec/step)\n",
      "step 14790 \t loss = 0.710, train_acc = 0.900 (3.225 sec/step)\n",
      "step 14800 \t loss = 0.255, train_acc = 0.800 (3.220 sec/step)\n",
      "step 14810 \t loss = 0.633, train_acc = 0.700 (3.265 sec/step)\n",
      "step 14820 \t loss = 0.366, train_acc = 0.900 (3.373 sec/step)\n",
      "step 14830 \t loss = 0.742, train_acc = 0.800 (3.315 sec/step)\n",
      "step 14840 \t loss = 0.371, train_acc = 1.000 (3.266 sec/step)\n",
      "step 14850 \t loss = 0.449, train_acc = 0.700 (3.250 sec/step)\n",
      "step 14860 \t loss = 0.457, train_acc = 0.800 (3.293 sec/step)\n",
      "step 14870 \t loss = 0.386, train_acc = 0.900 (3.232 sec/step)\n",
      "step 14880 \t loss = 0.410, train_acc = 0.800 (3.237 sec/step)\n",
      "step 14890 \t loss = 0.027, train_acc = 1.000 (3.242 sec/step)\n",
      "step 14900 \t loss = 1.110, train_acc = 0.700 (3.301 sec/step)\n",
      "step 14910 \t loss = 0.382, train_acc = 0.800 (3.269 sec/step)\n",
      "step 14920 \t loss = 0.076, train_acc = 1.000 (3.295 sec/step)\n",
      "step 14930 \t loss = 0.731, train_acc = 0.700 (3.256 sec/step)\n",
      "step 14940 \t loss = 1.422, train_acc = 0.600 (3.283 sec/step)\n",
      "step 14950 \t loss = 3.158, train_acc = 0.400 (3.236 sec/step)\n",
      "step 14960 \t loss = 0.299, train_acc = 0.900 (3.272 sec/step)\n",
      "step 14970 \t loss = 0.414, train_acc = 0.900 (3.277 sec/step)\n",
      "step 14980 \t loss = 0.243, train_acc = 1.000 (3.278 sec/step)\n",
      "step 14990 \t loss = 0.076, train_acc = 1.000 (3.270 sec/step)\n",
      "step 15000 \t loss = 1.471, train_acc = 0.800 (3.250 sec/step)\n",
      "step 15010 \t loss = 2.235, train_acc = 0.600 (3.349 sec/step)\n",
      "step 15020 \t loss = 1.749, train_acc = 0.600 (3.291 sec/step)\n",
      "step 15030 \t loss = 1.253, train_acc = 0.500 (3.265 sec/step)\n",
      "step 15040 \t loss = 0.362, train_acc = 0.900 (3.298 sec/step)\n",
      "step 15050 \t loss = 0.217, train_acc = 0.900 (3.256 sec/step)\n",
      "step 15060 \t loss = 0.620, train_acc = 0.800 (3.288 sec/step)\n",
      "step 15070 \t loss = 0.248, train_acc = 0.900 (3.260 sec/step)\n",
      "step 15080 \t loss = 0.962, train_acc = 0.700 (3.247 sec/step)\n",
      "step 15090 \t loss = 0.531, train_acc = 0.800 (3.297 sec/step)\n",
      "step 15100 \t loss = 0.491, train_acc = 0.700 (3.245 sec/step)\n",
      "step 15110 \t loss = 0.242, train_acc = 0.900 (3.267 sec/step)\n",
      "step 15120 \t loss = 0.356, train_acc = 1.000 (3.227 sec/step)\n",
      "step 15130 \t loss = 1.392, train_acc = 0.500 (3.338 sec/step)\n",
      "step 15140 \t loss = 2.412, train_acc = 0.400 (3.294 sec/step)\n",
      "step 15150 \t loss = 0.316, train_acc = 0.800 (3.261 sec/step)\n",
      "step 15160 \t loss = 0.534, train_acc = 0.800 (3.303 sec/step)\n",
      "step 15170 \t loss = 0.425, train_acc = 0.900 (3.279 sec/step)\n",
      "step 15180 \t loss = 0.368, train_acc = 0.900 (3.254 sec/step)\n",
      "step 15190 \t loss = 0.901, train_acc = 0.700 (3.307 sec/step)\n",
      "VALIDATION \t acc = 0.524 (3.637 sec)\n",
      "New Best Accuracy 0.524 > Old Best 0.524.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 15200 \t loss = 0.633, train_acc = 0.700 (3.251 sec/step)\n",
      "step 15210 \t loss = 1.485, train_acc = 0.900 (3.327 sec/step)\n",
      "step 15220 \t loss = 1.407, train_acc = 0.500 (3.270 sec/step)\n",
      "step 15230 \t loss = 0.224, train_acc = 1.000 (3.286 sec/step)\n",
      "step 15240 \t loss = 0.055, train_acc = 1.000 (3.254 sec/step)\n",
      "step 15250 \t loss = 0.582, train_acc = 0.800 (3.292 sec/step)\n",
      "step 15260 \t loss = 0.327, train_acc = 0.800 (3.244 sec/step)\n",
      "step 15270 \t loss = 0.191, train_acc = 1.000 (3.305 sec/step)\n",
      "step 15280 \t loss = 0.716, train_acc = 0.700 (3.272 sec/step)\n",
      "step 15290 \t loss = 0.443, train_acc = 1.000 (3.277 sec/step)\n",
      "step 15300 \t loss = 1.310, train_acc = 0.700 (3.279 sec/step)\n",
      "step 15310 \t loss = 0.332, train_acc = 0.800 (3.249 sec/step)\n",
      "step 15320 \t loss = 0.565, train_acc = 0.800 (3.292 sec/step)\n",
      "step 15330 \t loss = 0.282, train_acc = 0.900 (3.251 sec/step)\n",
      "step 15340 \t loss = 0.291, train_acc = 0.900 (3.274 sec/step)\n",
      "step 15350 \t loss = 0.216, train_acc = 1.000 (3.330 sec/step)\n",
      "step 15360 \t loss = 0.584, train_acc = 0.900 (3.318 sec/step)\n",
      "step 15370 \t loss = 0.386, train_acc = 0.900 (3.296 sec/step)\n",
      "step 15380 \t loss = 0.155, train_acc = 0.900 (3.243 sec/step)\n",
      "step 15390 \t loss = 1.329, train_acc = 0.600 (3.250 sec/step)\n",
      "step 15400 \t loss = 0.903, train_acc = 0.700 (3.290 sec/step)\n",
      "step 15410 \t loss = 0.327, train_acc = 0.900 (3.237 sec/step)\n",
      "step 15420 \t loss = 2.093, train_acc = 0.500 (3.253 sec/step)\n",
      "step 15430 \t loss = 0.353, train_acc = 0.900 (3.254 sec/step)\n",
      "step 15440 \t loss = 0.535, train_acc = 0.800 (3.296 sec/step)\n",
      "step 15450 \t loss = 0.648, train_acc = 0.800 (3.281 sec/step)\n",
      "step 15460 \t loss = 1.886, train_acc = 0.600 (3.233 sec/step)\n",
      "step 15470 \t loss = 1.256, train_acc = 0.700 (3.301 sec/step)\n",
      "step 15480 \t loss = 0.159, train_acc = 1.000 (3.261 sec/step)\n",
      "step 15490 \t loss = 0.027, train_acc = 1.000 (3.231 sec/step)\n",
      "step 15500 \t loss = 0.646, train_acc = 0.900 (3.223 sec/step)\n",
      "step 15510 \t loss = 1.491, train_acc = 0.500 (3.279 sec/step)\n",
      "step 15520 \t loss = 0.692, train_acc = 0.800 (3.242 sec/step)\n",
      "step 15530 \t loss = 1.520, train_acc = 0.600 (3.293 sec/step)\n",
      "step 15540 \t loss = 0.138, train_acc = 1.000 (3.279 sec/step)\n",
      "step 15550 \t loss = 0.136, train_acc = 1.000 (3.258 sec/step)\n",
      "step 15560 \t loss = 0.296, train_acc = 0.900 (3.256 sec/step)\n",
      "step 15570 \t loss = 0.415, train_acc = 0.800 (3.259 sec/step)\n",
      "step 15580 \t loss = 0.026, train_acc = 1.000 (3.258 sec/step)\n",
      "step 15590 \t loss = 0.219, train_acc = 0.900 (3.289 sec/step)\n",
      "step 15600 \t loss = 0.933, train_acc = 0.600 (3.243 sec/step)\n",
      "step 15610 \t loss = 0.515, train_acc = 0.900 (3.263 sec/step)\n",
      "step 15620 \t loss = 0.455, train_acc = 0.900 (3.302 sec/step)\n",
      "step 15630 \t loss = 0.031, train_acc = 1.000 (3.257 sec/step)\n",
      "step 15640 \t loss = 0.185, train_acc = 0.900 (3.283 sec/step)\n",
      "step 15650 \t loss = 0.308, train_acc = 0.900 (3.280 sec/step)\n",
      "step 15660 \t loss = 0.185, train_acc = 1.000 (3.290 sec/step)\n",
      "step 15670 \t loss = 0.029, train_acc = 1.000 (3.264 sec/step)\n",
      "step 15680 \t loss = 0.658, train_acc = 0.900 (3.288 sec/step)\n",
      "step 15690 \t loss = 0.720, train_acc = 0.800 (3.247 sec/step)\n",
      "step 15700 \t loss = 0.622, train_acc = 0.800 (3.276 sec/step)\n",
      "step 15710 \t loss = 0.154, train_acc = 1.000 (3.262 sec/step)\n",
      "step 15720 \t loss = 0.651, train_acc = 0.800 (3.240 sec/step)\n",
      "step 15730 \t loss = 0.555, train_acc = 0.700 (3.271 sec/step)\n",
      "step 15740 \t loss = 1.628, train_acc = 0.600 (3.255 sec/step)\n",
      "step 15750 \t loss = 0.017, train_acc = 1.000 (3.413 sec/step)\n",
      "step 15760 \t loss = 0.912, train_acc = 0.700 (3.273 sec/step)\n",
      "step 15770 \t loss = 0.235, train_acc = 0.900 (3.265 sec/step)\n",
      "step 15780 \t loss = 0.396, train_acc = 0.800 (3.293 sec/step)\n",
      "step 15790 \t loss = 0.434, train_acc = 0.900 (3.280 sec/step)\n",
      "step 15800 \t loss = 1.056, train_acc = 0.600 (3.247 sec/step)\n",
      "step 15810 \t loss = 0.735, train_acc = 0.700 (3.273 sec/step)\n",
      "step 15820 \t loss = 1.111, train_acc = 0.600 (3.233 sec/step)\n",
      "step 15830 \t loss = 1.526, train_acc = 0.700 (3.259 sec/step)\n",
      "step 15840 \t loss = 0.311, train_acc = 0.900 (3.298 sec/step)\n",
      "step 15850 \t loss = 1.755, train_acc = 0.300 (3.258 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15860 \t loss = 0.645, train_acc = 0.700 (3.259 sec/step)\n",
      "step 15870 \t loss = 0.225, train_acc = 0.900 (3.281 sec/step)\n",
      "step 15880 \t loss = 0.050, train_acc = 1.000 (3.283 sec/step)\n",
      "step 15890 \t loss = 0.932, train_acc = 0.700 (3.291 sec/step)\n",
      "step 15900 \t loss = 2.275, train_acc = 0.400 (3.304 sec/step)\n",
      "step 15910 \t loss = 0.809, train_acc = 0.900 (3.294 sec/step)\n",
      "step 15920 \t loss = 0.313, train_acc = 0.900 (3.267 sec/step)\n",
      "step 15930 \t loss = 1.544, train_acc = 0.600 (3.242 sec/step)\n",
      "step 15940 \t loss = 0.056, train_acc = 1.000 (3.317 sec/step)\n",
      "step 15950 \t loss = 0.213, train_acc = 1.000 (3.318 sec/step)\n",
      "step 15960 \t loss = 0.274, train_acc = 0.900 (3.285 sec/step)\n",
      "step 15970 \t loss = 0.106, train_acc = 1.000 (3.278 sec/step)\n",
      "step 15980 \t loss = 1.050, train_acc = 0.600 (3.284 sec/step)\n",
      "step 15990 \t loss = 0.315, train_acc = 1.000 (3.276 sec/step)\n",
      "step 16000 \t loss = 1.098, train_acc = 0.700 (3.287 sec/step)\n",
      "step 16010 \t loss = 0.461, train_acc = 0.900 (3.284 sec/step)\n",
      "step 16020 \t loss = 0.528, train_acc = 0.900 (3.313 sec/step)\n",
      "step 16030 \t loss = 0.056, train_acc = 1.000 (3.252 sec/step)\n",
      "step 16040 \t loss = 0.501, train_acc = 0.800 (3.290 sec/step)\n",
      "step 16050 \t loss = 0.454, train_acc = 0.800 (3.278 sec/step)\n",
      "step 16060 \t loss = 0.897, train_acc = 0.800 (3.313 sec/step)\n",
      "step 16070 \t loss = 0.618, train_acc = 0.800 (3.313 sec/step)\n",
      "step 16080 \t loss = 0.374, train_acc = 0.900 (3.228 sec/step)\n",
      "step 16090 \t loss = 0.116, train_acc = 1.000 (3.264 sec/step)\n",
      "step 16100 \t loss = 0.574, train_acc = 0.800 (3.404 sec/step)\n",
      "step 16110 \t loss = 0.764, train_acc = 0.800 (3.290 sec/step)\n",
      "step 16120 \t loss = 0.229, train_acc = 0.900 (3.255 sec/step)\n",
      "step 16130 \t loss = 0.373, train_acc = 0.800 (3.256 sec/step)\n",
      "step 16140 \t loss = 0.251, train_acc = 0.900 (3.306 sec/step)\n",
      "step 16150 \t loss = 1.208, train_acc = 0.800 (3.270 sec/step)\n",
      "step 16160 \t loss = 0.626, train_acc = 0.800 (3.337 sec/step)\n",
      "step 16170 \t loss = 0.061, train_acc = 1.000 (3.256 sec/step)\n",
      "step 16180 \t loss = 0.912, train_acc = 0.800 (3.250 sec/step)\n",
      "step 16190 \t loss = 0.987, train_acc = 0.700 (3.250 sec/step)\n",
      "step 16200 \t loss = 0.373, train_acc = 0.800 (3.268 sec/step)\n",
      "step 16210 \t loss = 0.849, train_acc = 0.700 (3.265 sec/step)\n",
      "step 16220 \t loss = 0.389, train_acc = 0.900 (3.334 sec/step)\n",
      "step 16230 \t loss = 0.405, train_acc = 0.900 (3.270 sec/step)\n",
      "step 16240 \t loss = 0.110, train_acc = 1.000 (3.264 sec/step)\n",
      "step 16250 \t loss = 0.188, train_acc = 1.000 (3.251 sec/step)\n",
      "step 16260 \t loss = 0.256, train_acc = 0.900 (3.275 sec/step)\n",
      "step 16270 \t loss = 0.673, train_acc = 0.600 (3.237 sec/step)\n",
      "step 16280 \t loss = 0.859, train_acc = 0.700 (3.297 sec/step)\n",
      "step 16290 \t loss = 0.232, train_acc = 0.900 (3.287 sec/step)\n",
      "step 16300 \t loss = 1.237, train_acc = 0.700 (3.285 sec/step)\n",
      "step 16310 \t loss = 0.506, train_acc = 0.800 (3.282 sec/step)\n",
      "step 16320 \t loss = 0.460, train_acc = 0.900 (3.246 sec/step)\n",
      "step 16330 \t loss = 1.996, train_acc = 0.600 (3.268 sec/step)\n",
      "step 16340 \t loss = 0.336, train_acc = 0.900 (3.349 sec/step)\n",
      "step 16350 \t loss = 0.109, train_acc = 1.000 (3.319 sec/step)\n",
      "step 16360 \t loss = 0.061, train_acc = 1.000 (3.258 sec/step)\n",
      "step 16370 \t loss = 0.703, train_acc = 0.700 (3.226 sec/step)\n",
      "step 16380 \t loss = 0.299, train_acc = 0.900 (3.289 sec/step)\n",
      "step 16390 \t loss = 0.961, train_acc = 0.800 (3.272 sec/step)\n",
      "step 16400 \t loss = 0.769, train_acc = 0.900 (3.300 sec/step)\n",
      "step 16410 \t loss = 0.396, train_acc = 0.800 (3.291 sec/step)\n",
      "step 16420 \t loss = 0.350, train_acc = 0.800 (3.315 sec/step)\n",
      "step 16430 \t loss = 0.104, train_acc = 1.000 (3.293 sec/step)\n",
      "step 16440 \t loss = 1.303, train_acc = 0.700 (3.266 sec/step)\n",
      "step 16450 \t loss = 0.486, train_acc = 0.800 (3.282 sec/step)\n",
      "step 16460 \t loss = 0.043, train_acc = 1.000 (3.391 sec/step)\n",
      "step 16470 \t loss = 0.483, train_acc = 0.800 (3.292 sec/step)\n",
      "step 16480 \t loss = 0.553, train_acc = 0.800 (3.246 sec/step)\n",
      "step 16490 \t loss = 0.128, train_acc = 1.000 (3.244 sec/step)\n",
      "step 16500 \t loss = 0.210, train_acc = 0.900 (3.244 sec/step)\n",
      "step 16510 \t loss = 0.499, train_acc = 0.800 (3.250 sec/step)\n",
      "step 16520 \t loss = 0.321, train_acc = 0.900 (3.260 sec/step)\n",
      "step 16530 \t loss = 0.912, train_acc = 0.700 (3.276 sec/step)\n",
      "step 16540 \t loss = 1.156, train_acc = 0.600 (3.287 sec/step)\n",
      "step 16550 \t loss = 1.247, train_acc = 0.700 (3.231 sec/step)\n",
      "step 16560 \t loss = 1.309, train_acc = 0.500 (3.262 sec/step)\n",
      "step 16570 \t loss = 0.728, train_acc = 0.800 (3.259 sec/step)\n",
      "step 16580 \t loss = 0.669, train_acc = 0.800 (3.334 sec/step)\n",
      "step 16590 \t loss = 0.153, train_acc = 1.000 (3.228 sec/step)\n",
      "step 16600 \t loss = 0.530, train_acc = 0.900 (3.298 sec/step)\n",
      "step 16610 \t loss = 0.196, train_acc = 1.000 (3.279 sec/step)\n",
      "step 16620 \t loss = 0.461, train_acc = 0.800 (3.258 sec/step)\n",
      "step 16630 \t loss = 0.091, train_acc = 1.000 (3.280 sec/step)\n",
      "step 16640 \t loss = 0.825, train_acc = 0.700 (3.301 sec/step)\n",
      "step 16650 \t loss = 1.151, train_acc = 0.600 (3.245 sec/step)\n",
      "step 16660 \t loss = 0.175, train_acc = 0.900 (3.384 sec/step)\n",
      "step 16670 \t loss = 0.136, train_acc = 1.000 (3.315 sec/step)\n",
      "step 16680 \t loss = 0.766, train_acc = 0.600 (3.308 sec/step)\n",
      "step 16690 \t loss = 0.413, train_acc = 0.900 (3.297 sec/step)\n",
      "step 16700 \t loss = 0.841, train_acc = 0.700 (3.333 sec/step)\n",
      "step 16710 \t loss = 0.843, train_acc = 0.700 (3.250 sec/step)\n",
      "step 16720 \t loss = 0.036, train_acc = 1.000 (3.315 sec/step)\n",
      "step 16730 \t loss = 0.720, train_acc = 0.800 (3.272 sec/step)\n",
      "step 16740 \t loss = 0.194, train_acc = 0.900 (3.248 sec/step)\n",
      "step 16750 \t loss = 0.169, train_acc = 1.000 (3.297 sec/step)\n",
      "step 16760 \t loss = 0.246, train_acc = 0.900 (3.307 sec/step)\n",
      "step 16770 \t loss = 0.257, train_acc = 0.900 (3.280 sec/step)\n",
      "step 16780 \t loss = 0.056, train_acc = 1.000 (3.287 sec/step)\n",
      "step 16790 \t loss = 0.140, train_acc = 1.000 (3.262 sec/step)\n",
      "step 16800 \t loss = 0.886, train_acc = 0.800 (3.288 sec/step)\n",
      "step 16810 \t loss = 0.506, train_acc = 0.900 (3.332 sec/step)\n",
      "step 16820 \t loss = 0.149, train_acc = 0.900 (3.271 sec/step)\n",
      "step 16830 \t loss = 1.281, train_acc = 0.600 (3.348 sec/step)\n",
      "step 16840 \t loss = 0.721, train_acc = 0.800 (3.306 sec/step)\n",
      "step 16850 \t loss = 0.880, train_acc = 0.900 (3.237 sec/step)\n",
      "step 16860 \t loss = 0.390, train_acc = 0.900 (3.287 sec/step)\n",
      "step 16870 \t loss = 1.786, train_acc = 0.600 (3.260 sec/step)\n",
      "step 16880 \t loss = 0.104, train_acc = 1.000 (3.284 sec/step)\n",
      "step 16890 \t loss = 1.794, train_acc = 0.500 (3.232 sec/step)\n",
      "step 16900 \t loss = 0.143, train_acc = 0.900 (3.359 sec/step)\n",
      "step 16910 \t loss = 0.883, train_acc = 0.700 (3.261 sec/step)\n",
      "step 16920 \t loss = 0.475, train_acc = 0.800 (3.257 sec/step)\n",
      "step 16930 \t loss = 0.554, train_acc = 0.800 (3.260 sec/step)\n",
      "step 16940 \t loss = 1.419, train_acc = 0.800 (3.265 sec/step)\n",
      "step 16950 \t loss = 0.181, train_acc = 1.000 (3.283 sec/step)\n",
      "step 16960 \t loss = 0.510, train_acc = 0.900 (3.269 sec/step)\n",
      "step 16970 \t loss = 0.493, train_acc = 0.900 (3.308 sec/step)\n",
      "step 16980 \t loss = 0.244, train_acc = 0.900 (3.280 sec/step)\n",
      "step 16990 \t loss = 0.641, train_acc = 0.800 (3.249 sec/step)\n",
      "step 17000 \t loss = 0.168, train_acc = 0.900 (3.253 sec/step)\n",
      "step 17010 \t loss = 0.867, train_acc = 0.500 (3.321 sec/step)\n",
      "step 17020 \t loss = 0.386, train_acc = 0.900 (3.282 sec/step)\n",
      "step 17030 \t loss = 0.487, train_acc = 0.800 (3.256 sec/step)\n",
      "step 17040 \t loss = 1.495, train_acc = 0.600 (3.254 sec/step)\n",
      "step 17050 \t loss = 0.123, train_acc = 0.900 (3.273 sec/step)\n",
      "step 17060 \t loss = 0.039, train_acc = 1.000 (3.267 sec/step)\n",
      "step 17070 \t loss = 0.227, train_acc = 0.900 (3.285 sec/step)\n",
      "step 17080 \t loss = 1.052, train_acc = 0.700 (3.329 sec/step)\n",
      "step 17090 \t loss = 0.502, train_acc = 0.900 (3.280 sec/step)\n",
      "VALIDATION \t acc = 0.512 (3.695 sec)\n",
      "step 17100 \t loss = 0.891, train_acc = 0.700 (3.251 sec/step)\n",
      "step 17110 \t loss = 0.578, train_acc = 0.900 (3.260 sec/step)\n",
      "step 17120 \t loss = 0.677, train_acc = 0.800 (3.315 sec/step)\n",
      "step 17130 \t loss = 0.146, train_acc = 1.000 (3.251 sec/step)\n",
      "step 17140 \t loss = 0.059, train_acc = 1.000 (3.372 sec/step)\n",
      "step 17150 \t loss = 0.532, train_acc = 0.900 (3.335 sec/step)\n",
      "step 17160 \t loss = 0.361, train_acc = 0.800 (3.295 sec/step)\n",
      "step 17170 \t loss = 0.083, train_acc = 1.000 (3.279 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17180 \t loss = 0.107, train_acc = 1.000 (3.283 sec/step)\n",
      "step 17190 \t loss = 0.021, train_acc = 1.000 (3.266 sec/step)\n",
      "step 17200 \t loss = 0.225, train_acc = 0.900 (3.283 sec/step)\n",
      "step 17210 \t loss = 0.500, train_acc = 0.800 (3.286 sec/step)\n",
      "step 17220 \t loss = 0.662, train_acc = 0.600 (3.335 sec/step)\n",
      "step 17230 \t loss = 0.580, train_acc = 0.800 (3.269 sec/step)\n",
      "step 17240 \t loss = 0.065, train_acc = 1.000 (3.259 sec/step)\n",
      "step 17250 \t loss = 1.896, train_acc = 0.500 (3.321 sec/step)\n",
      "step 17260 \t loss = 0.348, train_acc = 0.900 (3.267 sec/step)\n",
      "step 17270 \t loss = 0.168, train_acc = 1.000 (3.259 sec/step)\n",
      "step 17280 \t loss = 0.286, train_acc = 0.900 (3.288 sec/step)\n",
      "step 17290 \t loss = 0.293, train_acc = 0.900 (3.309 sec/step)\n",
      "step 17300 \t loss = 0.745, train_acc = 0.800 (3.245 sec/step)\n",
      "step 17310 \t loss = 0.488, train_acc = 0.900 (3.303 sec/step)\n",
      "step 17320 \t loss = 0.153, train_acc = 1.000 (3.422 sec/step)\n",
      "step 17330 \t loss = 0.086, train_acc = 1.000 (3.398 sec/step)\n",
      "step 17340 \t loss = 0.429, train_acc = 0.900 (3.266 sec/step)\n",
      "step 17350 \t loss = 0.304, train_acc = 0.900 (3.382 sec/step)\n",
      "step 17360 \t loss = 0.183, train_acc = 0.900 (3.279 sec/step)\n",
      "step 17370 \t loss = 0.733, train_acc = 0.800 (3.286 sec/step)\n",
      "step 17380 \t loss = 0.909, train_acc = 0.500 (3.245 sec/step)\n",
      "step 17390 \t loss = 1.185, train_acc = 0.500 (3.334 sec/step)\n",
      "step 17400 \t loss = 0.807, train_acc = 0.800 (3.313 sec/step)\n",
      "step 17410 \t loss = 2.164, train_acc = 0.700 (3.253 sec/step)\n",
      "step 17420 \t loss = 1.831, train_acc = 0.700 (3.324 sec/step)\n",
      "step 17430 \t loss = 0.258, train_acc = 1.000 (3.283 sec/step)\n",
      "step 17440 \t loss = 1.824, train_acc = 0.500 (3.273 sec/step)\n",
      "step 17450 \t loss = 0.756, train_acc = 0.600 (3.279 sec/step)\n",
      "step 17460 \t loss = 0.473, train_acc = 0.800 (3.262 sec/step)\n",
      "step 17470 \t loss = 0.138, train_acc = 1.000 (3.251 sec/step)\n",
      "step 17480 \t loss = 1.072, train_acc = 0.800 (3.317 sec/step)\n",
      "step 17490 \t loss = 0.470, train_acc = 0.800 (3.280 sec/step)\n",
      "step 17500 \t loss = 1.534, train_acc = 0.800 (3.290 sec/step)\n",
      "step 17510 \t loss = 0.356, train_acc = 0.900 (3.317 sec/step)\n",
      "step 17520 \t loss = 0.224, train_acc = 0.800 (3.299 sec/step)\n",
      "step 17530 \t loss = 0.706, train_acc = 0.600 (3.235 sec/step)\n",
      "step 17540 \t loss = 1.085, train_acc = 0.600 (3.321 sec/step)\n",
      "step 17550 \t loss = 0.126, train_acc = 1.000 (3.267 sec/step)\n",
      "step 17560 \t loss = 0.120, train_acc = 1.000 (3.276 sec/step)\n",
      "step 17570 \t loss = 0.134, train_acc = 1.000 (3.295 sec/step)\n",
      "step 17580 \t loss = 0.082, train_acc = 1.000 (3.270 sec/step)\n",
      "step 17590 \t loss = 0.691, train_acc = 0.800 (3.318 sec/step)\n",
      "step 17600 \t loss = 0.167, train_acc = 0.900 (3.285 sec/step)\n",
      "step 17610 \t loss = 0.752, train_acc = 0.900 (3.242 sec/step)\n",
      "step 17620 \t loss = 0.179, train_acc = 0.900 (3.252 sec/step)\n",
      "step 17630 \t loss = 1.184, train_acc = 0.600 (3.264 sec/step)\n",
      "step 17640 \t loss = 0.586, train_acc = 0.900 (3.307 sec/step)\n",
      "step 17650 \t loss = 0.233, train_acc = 0.800 (3.266 sec/step)\n",
      "step 17660 \t loss = 0.068, train_acc = 1.000 (3.280 sec/step)\n",
      "step 17670 \t loss = 0.425, train_acc = 0.800 (3.231 sec/step)\n",
      "step 17680 \t loss = 0.138, train_acc = 1.000 (3.258 sec/step)\n",
      "step 17690 \t loss = 0.794, train_acc = 0.700 (3.308 sec/step)\n",
      "step 17700 \t loss = 0.927, train_acc = 0.800 (3.316 sec/step)\n",
      "step 17710 \t loss = 0.224, train_acc = 0.900 (3.322 sec/step)\n",
      "step 17720 \t loss = 0.246, train_acc = 1.000 (3.274 sec/step)\n",
      "step 17730 \t loss = 0.259, train_acc = 0.900 (3.289 sec/step)\n",
      "step 17740 \t loss = 0.284, train_acc = 0.900 (3.328 sec/step)\n",
      "step 17750 \t loss = 0.105, train_acc = 1.000 (3.312 sec/step)\n",
      "step 17760 \t loss = 0.084, train_acc = 1.000 (3.268 sec/step)\n",
      "step 17770 \t loss = 0.009, train_acc = 1.000 (3.270 sec/step)\n",
      "step 17780 \t loss = 0.314, train_acc = 0.900 (3.303 sec/step)\n",
      "step 17790 \t loss = 0.238, train_acc = 0.900 (3.323 sec/step)\n",
      "step 17800 \t loss = 0.477, train_acc = 0.900 (3.333 sec/step)\n",
      "step 17810 \t loss = 0.281, train_acc = 0.900 (3.274 sec/step)\n",
      "step 17820 \t loss = 0.481, train_acc = 0.800 (3.336 sec/step)\n",
      "step 17830 \t loss = 0.827, train_acc = 0.600 (3.281 sec/step)\n",
      "step 17840 \t loss = 0.034, train_acc = 1.000 (3.266 sec/step)\n",
      "step 17850 \t loss = 0.091, train_acc = 1.000 (3.244 sec/step)\n",
      "step 17860 \t loss = 0.723, train_acc = 0.700 (3.296 sec/step)\n",
      "step 17870 \t loss = 0.661, train_acc = 0.900 (3.303 sec/step)\n",
      "step 17880 \t loss = 0.263, train_acc = 0.900 (3.346 sec/step)\n",
      "step 17890 \t loss = 0.075, train_acc = 1.000 (3.303 sec/step)\n",
      "step 17900 \t loss = 0.138, train_acc = 0.900 (3.286 sec/step)\n",
      "step 17910 \t loss = 0.681, train_acc = 0.600 (3.328 sec/step)\n",
      "step 17920 \t loss = 0.171, train_acc = 1.000 (3.294 sec/step)\n",
      "step 17930 \t loss = 0.067, train_acc = 1.000 (3.330 sec/step)\n",
      "step 17940 \t loss = 0.376, train_acc = 0.900 (3.240 sec/step)\n",
      "step 17950 \t loss = 0.240, train_acc = 0.900 (3.280 sec/step)\n",
      "step 17960 \t loss = 0.551, train_acc = 0.700 (3.307 sec/step)\n",
      "step 17970 \t loss = 0.217, train_acc = 0.900 (3.269 sec/step)\n",
      "step 17980 \t loss = 0.634, train_acc = 0.800 (3.307 sec/step)\n",
      "step 17990 \t loss = 0.853, train_acc = 0.700 (3.260 sec/step)\n",
      "step 18000 \t loss = 0.552, train_acc = 0.900 (3.322 sec/step)\n",
      "step 18010 \t loss = 2.188, train_acc = 0.500 (3.418 sec/step)\n",
      "step 18020 \t loss = 0.069, train_acc = 1.000 (3.274 sec/step)\n",
      "step 18030 \t loss = 0.598, train_acc = 0.800 (3.267 sec/step)\n",
      "step 18040 \t loss = 0.714, train_acc = 0.800 (3.286 sec/step)\n",
      "step 18050 \t loss = 1.253, train_acc = 0.800 (3.232 sec/step)\n",
      "step 18060 \t loss = 0.599, train_acc = 0.900 (3.228 sec/step)\n",
      "step 18070 \t loss = 0.091, train_acc = 1.000 (3.268 sec/step)\n",
      "step 18080 \t loss = 0.089, train_acc = 1.000 (3.232 sec/step)\n",
      "step 18090 \t loss = 0.499, train_acc = 0.900 (3.302 sec/step)\n",
      "step 18100 \t loss = 0.326, train_acc = 0.800 (3.323 sec/step)\n",
      "step 18110 \t loss = 0.254, train_acc = 0.900 (3.297 sec/step)\n",
      "step 18120 \t loss = 0.026, train_acc = 1.000 (3.289 sec/step)\n",
      "step 18130 \t loss = 0.336, train_acc = 0.900 (3.276 sec/step)\n",
      "step 18140 \t loss = 0.374, train_acc = 0.900 (3.393 sec/step)\n",
      "step 18150 \t loss = 0.492, train_acc = 0.800 (3.264 sec/step)\n",
      "step 18160 \t loss = 0.571, train_acc = 0.900 (3.234 sec/step)\n",
      "step 18170 \t loss = 0.298, train_acc = 0.900 (3.239 sec/step)\n",
      "step 18180 \t loss = 0.157, train_acc = 1.000 (3.254 sec/step)\n",
      "step 18190 \t loss = 0.226, train_acc = 0.900 (3.329 sec/step)\n",
      "step 18200 \t loss = 0.366, train_acc = 0.900 (3.259 sec/step)\n",
      "step 18210 \t loss = 0.060, train_acc = 1.000 (3.296 sec/step)\n",
      "step 18220 \t loss = 0.014, train_acc = 1.000 (3.294 sec/step)\n",
      "step 18230 \t loss = 0.496, train_acc = 0.900 (3.305 sec/step)\n",
      "step 18240 \t loss = 2.164, train_acc = 0.400 (3.290 sec/step)\n",
      "step 18250 \t loss = 0.194, train_acc = 0.900 (3.273 sec/step)\n",
      "step 18260 \t loss = 0.185, train_acc = 0.900 (3.279 sec/step)\n",
      "step 18270 \t loss = 0.629, train_acc = 0.800 (3.294 sec/step)\n",
      "step 18280 \t loss = 0.758, train_acc = 0.800 (3.325 sec/step)\n",
      "step 18290 \t loss = 0.425, train_acc = 0.800 (3.317 sec/step)\n",
      "step 18300 \t loss = 0.664, train_acc = 0.800 (3.301 sec/step)\n",
      "step 18310 \t loss = 0.491, train_acc = 0.800 (3.319 sec/step)\n",
      "step 18320 \t loss = 0.152, train_acc = 1.000 (3.224 sec/step)\n",
      "step 18330 \t loss = 0.437, train_acc = 0.900 (3.261 sec/step)\n",
      "step 18340 \t loss = 0.134, train_acc = 1.000 (3.284 sec/step)\n",
      "step 18350 \t loss = 0.068, train_acc = 1.000 (3.322 sec/step)\n",
      "step 18360 \t loss = 0.531, train_acc = 0.800 (3.289 sec/step)\n",
      "step 18370 \t loss = 0.216, train_acc = 0.900 (3.378 sec/step)\n",
      "step 18380 \t loss = 0.318, train_acc = 0.900 (3.420 sec/step)\n",
      "step 18390 \t loss = 0.145, train_acc = 0.900 (3.259 sec/step)\n",
      "step 18400 \t loss = 0.382, train_acc = 0.900 (3.312 sec/step)\n",
      "step 18410 \t loss = 0.134, train_acc = 1.000 (3.269 sec/step)\n",
      "step 18420 \t loss = 0.334, train_acc = 0.900 (3.242 sec/step)\n",
      "step 18430 \t loss = 0.308, train_acc = 0.800 (3.284 sec/step)\n",
      "step 18440 \t loss = 0.008, train_acc = 1.000 (3.296 sec/step)\n",
      "step 18450 \t loss = 0.426, train_acc = 0.900 (3.280 sec/step)\n",
      "step 18460 \t loss = 0.306, train_acc = 0.900 (3.289 sec/step)\n",
      "step 18470 \t loss = 0.159, train_acc = 0.900 (3.328 sec/step)\n",
      "step 18480 \t loss = 0.852, train_acc = 0.700 (3.284 sec/step)\n",
      "step 18490 \t loss = 0.538, train_acc = 0.900 (3.308 sec/step)\n",
      "step 18500 \t loss = 0.357, train_acc = 0.900 (3.266 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18510 \t loss = 2.099, train_acc = 0.700 (3.271 sec/step)\n",
      "step 18520 \t loss = 0.095, train_acc = 1.000 (3.257 sec/step)\n",
      "step 18530 \t loss = 0.210, train_acc = 0.900 (3.324 sec/step)\n",
      "step 18540 \t loss = 0.210, train_acc = 1.000 (3.335 sec/step)\n",
      "step 18550 \t loss = 0.247, train_acc = 0.900 (3.281 sec/step)\n",
      "step 18560 \t loss = 0.062, train_acc = 1.000 (3.266 sec/step)\n",
      "step 18570 \t loss = 0.078, train_acc = 1.000 (3.356 sec/step)\n",
      "step 18580 \t loss = 0.403, train_acc = 0.900 (3.368 sec/step)\n",
      "step 18590 \t loss = 0.606, train_acc = 0.900 (3.391 sec/step)\n",
      "step 18600 \t loss = 0.113, train_acc = 1.000 (3.230 sec/step)\n",
      "step 18610 \t loss = 0.532, train_acc = 0.900 (3.313 sec/step)\n",
      "step 18620 \t loss = 0.077, train_acc = 1.000 (3.246 sec/step)\n",
      "step 18630 \t loss = 0.377, train_acc = 0.900 (3.262 sec/step)\n",
      "step 18640 \t loss = 1.340, train_acc = 0.700 (3.290 sec/step)\n",
      "step 18650 \t loss = 0.106, train_acc = 1.000 (3.331 sec/step)\n",
      "step 18660 \t loss = 0.399, train_acc = 0.800 (3.255 sec/step)\n",
      "step 18670 \t loss = 0.537, train_acc = 0.800 (3.278 sec/step)\n",
      "step 18680 \t loss = 0.402, train_acc = 0.900 (3.261 sec/step)\n",
      "step 18690 \t loss = 0.046, train_acc = 1.000 (3.267 sec/step)\n",
      "step 18700 \t loss = 0.535, train_acc = 0.900 (3.303 sec/step)\n",
      "step 18710 \t loss = 0.186, train_acc = 0.900 (3.277 sec/step)\n",
      "step 18720 \t loss = 0.262, train_acc = 0.800 (3.268 sec/step)\n",
      "step 18730 \t loss = 0.250, train_acc = 0.900 (3.290 sec/step)\n",
      "step 18740 \t loss = 0.996, train_acc = 0.600 (3.263 sec/step)\n",
      "step 18750 \t loss = 0.193, train_acc = 0.900 (3.295 sec/step)\n",
      "step 18760 \t loss = 0.440, train_acc = 0.800 (3.258 sec/step)\n",
      "step 18770 \t loss = 0.460, train_acc = 0.900 (3.281 sec/step)\n",
      "step 18780 \t loss = 0.084, train_acc = 1.000 (3.417 sec/step)\n",
      "step 18790 \t loss = 0.040, train_acc = 1.000 (3.276 sec/step)\n",
      "step 18800 \t loss = 0.053, train_acc = 1.000 (3.376 sec/step)\n",
      "step 18810 \t loss = 0.422, train_acc = 0.900 (3.265 sec/step)\n",
      "step 18820 \t loss = 0.376, train_acc = 0.800 (3.268 sec/step)\n",
      "step 18830 \t loss = 0.770, train_acc = 0.800 (3.258 sec/step)\n",
      "step 18840 \t loss = 0.449, train_acc = 0.800 (3.298 sec/step)\n",
      "step 18850 \t loss = 0.285, train_acc = 0.900 (3.242 sec/step)\n",
      "step 18860 \t loss = 0.380, train_acc = 0.900 (3.259 sec/step)\n",
      "step 18870 \t loss = 0.068, train_acc = 1.000 (3.269 sec/step)\n",
      "step 18880 \t loss = 0.115, train_acc = 1.000 (3.286 sec/step)\n",
      "step 18890 \t loss = 0.130, train_acc = 1.000 (3.292 sec/step)\n",
      "step 18900 \t loss = 0.210, train_acc = 0.900 (3.261 sec/step)\n",
      "step 18910 \t loss = 0.074, train_acc = 1.000 (3.293 sec/step)\n",
      "step 18920 \t loss = 0.671, train_acc = 0.800 (3.254 sec/step)\n",
      "step 18930 \t loss = 0.321, train_acc = 0.900 (3.295 sec/step)\n",
      "step 18940 \t loss = 1.336, train_acc = 0.700 (3.302 sec/step)\n",
      "step 18950 \t loss = 0.052, train_acc = 1.000 (3.338 sec/step)\n",
      "step 18960 \t loss = 0.015, train_acc = 1.000 (3.332 sec/step)\n",
      "step 18970 \t loss = 0.121, train_acc = 0.900 (3.242 sec/step)\n",
      "step 18980 \t loss = 0.257, train_acc = 1.000 (3.279 sec/step)\n",
      "step 18990 \t loss = 2.174, train_acc = 0.700 (3.248 sec/step)\n",
      "VALIDATION \t acc = 0.518 (3.659 sec)\n",
      "step 19000 \t loss = 0.420, train_acc = 0.900 (3.319 sec/step)\n",
      "step 19010 \t loss = 0.276, train_acc = 0.900 (3.249 sec/step)\n",
      "step 19020 \t loss = 0.774, train_acc = 0.700 (3.242 sec/step)\n",
      "step 19030 \t loss = 0.020, train_acc = 1.000 (3.311 sec/step)\n",
      "step 19040 \t loss = 0.039, train_acc = 1.000 (3.226 sec/step)\n",
      "step 19050 \t loss = 0.355, train_acc = 0.900 (3.258 sec/step)\n",
      "step 19060 \t loss = 0.149, train_acc = 0.900 (3.274 sec/step)\n",
      "step 19070 \t loss = 0.356, train_acc = 0.900 (3.342 sec/step)\n",
      "step 19080 \t loss = 0.025, train_acc = 1.000 (3.296 sec/step)\n",
      "step 19090 \t loss = 0.578, train_acc = 0.800 (3.290 sec/step)\n",
      "step 19100 \t loss = 1.641, train_acc = 0.800 (3.233 sec/step)\n",
      "step 19110 \t loss = 0.041, train_acc = 1.000 (3.239 sec/step)\n",
      "step 19120 \t loss = 1.040, train_acc = 0.600 (3.296 sec/step)\n",
      "step 19130 \t loss = 0.750, train_acc = 0.700 (3.312 sec/step)\n",
      "step 19140 \t loss = 0.634, train_acc = 0.800 (3.273 sec/step)\n",
      "step 19150 \t loss = 0.111, train_acc = 1.000 (3.241 sec/step)\n",
      "step 19160 \t loss = 1.772, train_acc = 0.800 (3.297 sec/step)\n",
      "step 19170 \t loss = 0.178, train_acc = 0.900 (3.324 sec/step)\n",
      "step 19180 \t loss = 0.016, train_acc = 1.000 (3.244 sec/step)\n",
      "step 19190 \t loss = 0.412, train_acc = 0.800 (3.291 sec/step)\n",
      "step 19200 \t loss = 0.716, train_acc = 0.800 (3.288 sec/step)\n",
      "step 19210 \t loss = 0.429, train_acc = 0.900 (3.280 sec/step)\n",
      "step 19220 \t loss = 0.899, train_acc = 0.700 (3.235 sec/step)\n",
      "step 19230 \t loss = 0.409, train_acc = 0.900 (3.245 sec/step)\n",
      "step 19240 \t loss = 0.397, train_acc = 0.900 (3.266 sec/step)\n",
      "step 19250 \t loss = 0.173, train_acc = 1.000 (3.292 sec/step)\n",
      "step 19260 \t loss = 0.115, train_acc = 1.000 (3.261 sec/step)\n",
      "step 19270 \t loss = 0.869, train_acc = 0.600 (3.244 sec/step)\n",
      "step 19280 \t loss = 0.077, train_acc = 1.000 (3.272 sec/step)\n",
      "step 19290 \t loss = 0.074, train_acc = 1.000 (3.295 sec/step)\n",
      "step 19300 \t loss = 0.814, train_acc = 0.800 (3.270 sec/step)\n",
      "step 19310 \t loss = 0.907, train_acc = 0.700 (3.299 sec/step)\n",
      "step 19320 \t loss = 0.074, train_acc = 1.000 (3.313 sec/step)\n",
      "step 19330 \t loss = 0.179, train_acc = 1.000 (3.299 sec/step)\n",
      "step 19340 \t loss = 0.052, train_acc = 1.000 (3.306 sec/step)\n",
      "step 19350 \t loss = 0.110, train_acc = 1.000 (3.366 sec/step)\n",
      "step 19360 \t loss = 0.198, train_acc = 0.900 (3.297 sec/step)\n",
      "step 19370 \t loss = 0.187, train_acc = 1.000 (3.234 sec/step)\n",
      "step 19380 \t loss = 0.490, train_acc = 0.800 (3.278 sec/step)\n",
      "step 19390 \t loss = 0.115, train_acc = 0.900 (3.294 sec/step)\n",
      "step 19400 \t loss = 1.096, train_acc = 0.600 (3.304 sec/step)\n",
      "step 19410 \t loss = 0.174, train_acc = 0.900 (3.287 sec/step)\n",
      "step 19420 \t loss = 0.126, train_acc = 1.000 (3.289 sec/step)\n",
      "step 19430 \t loss = 0.752, train_acc = 0.800 (3.265 sec/step)\n",
      "step 19440 \t loss = 0.710, train_acc = 0.900 (3.280 sec/step)\n",
      "step 19450 \t loss = 0.815, train_acc = 0.800 (3.312 sec/step)\n",
      "step 19460 \t loss = 0.185, train_acc = 0.900 (3.302 sec/step)\n",
      "step 19470 \t loss = 0.171, train_acc = 0.900 (3.262 sec/step)\n",
      "step 19480 \t loss = 0.205, train_acc = 1.000 (3.332 sec/step)\n",
      "step 19490 \t loss = 0.140, train_acc = 1.000 (3.318 sec/step)\n",
      "step 19500 \t loss = 0.082, train_acc = 1.000 (3.264 sec/step)\n",
      "step 19510 \t loss = 0.766, train_acc = 0.900 (3.252 sec/step)\n",
      "step 19520 \t loss = 0.585, train_acc = 0.900 (3.325 sec/step)\n",
      "step 19530 \t loss = 0.191, train_acc = 0.900 (3.287 sec/step)\n",
      "step 19540 \t loss = 0.234, train_acc = 0.800 (3.312 sec/step)\n",
      "step 19550 \t loss = 0.101, train_acc = 1.000 (3.313 sec/step)\n",
      "step 19560 \t loss = 0.887, train_acc = 0.800 (3.261 sec/step)\n",
      "step 19570 \t loss = 0.092, train_acc = 1.000 (3.351 sec/step)\n",
      "step 19580 \t loss = 0.719, train_acc = 0.600 (3.282 sec/step)\n",
      "step 19590 \t loss = 1.303, train_acc = 0.700 (3.309 sec/step)\n",
      "step 19600 \t loss = 2.097, train_acc = 0.500 (3.264 sec/step)\n",
      "step 19610 \t loss = 0.083, train_acc = 1.000 (3.273 sec/step)\n",
      "step 19620 \t loss = 0.128, train_acc = 1.000 (3.258 sec/step)\n",
      "step 19630 \t loss = 0.545, train_acc = 0.800 (3.254 sec/step)\n",
      "step 19640 \t loss = 1.940, train_acc = 0.600 (3.286 sec/step)\n",
      "step 19650 \t loss = 0.196, train_acc = 1.000 (3.292 sec/step)\n",
      "step 19660 \t loss = 0.281, train_acc = 1.000 (3.340 sec/step)\n",
      "step 19670 \t loss = 0.002, train_acc = 1.000 (3.363 sec/step)\n",
      "step 19680 \t loss = 0.887, train_acc = 0.800 (3.307 sec/step)\n",
      "step 19690 \t loss = 0.013, train_acc = 1.000 (3.295 sec/step)\n",
      "step 19700 \t loss = 0.755, train_acc = 0.700 (3.274 sec/step)\n",
      "step 19710 \t loss = 0.208, train_acc = 0.900 (3.255 sec/step)\n",
      "step 19720 \t loss = 0.152, train_acc = 0.900 (3.280 sec/step)\n",
      "step 19730 \t loss = 0.244, train_acc = 1.000 (3.289 sec/step)\n",
      "step 19740 \t loss = 0.242, train_acc = 0.900 (3.275 sec/step)\n",
      "step 19750 \t loss = 1.128, train_acc = 0.600 (3.322 sec/step)\n",
      "step 19760 \t loss = 0.052, train_acc = 1.000 (3.316 sec/step)\n",
      "step 19770 \t loss = 0.375, train_acc = 0.800 (3.269 sec/step)\n",
      "step 19780 \t loss = 0.380, train_acc = 0.800 (3.323 sec/step)\n",
      "step 19790 \t loss = 0.446, train_acc = 0.900 (3.321 sec/step)\n",
      "step 19800 \t loss = 0.083, train_acc = 1.000 (3.292 sec/step)\n",
      "step 19810 \t loss = 0.706, train_acc = 0.900 (3.288 sec/step)\n",
      "step 19820 \t loss = 0.228, train_acc = 0.900 (3.253 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19830 \t loss = 0.223, train_acc = 0.900 (3.299 sec/step)\n",
      "step 19840 \t loss = 0.009, train_acc = 1.000 (3.299 sec/step)\n",
      "step 19850 \t loss = 0.265, train_acc = 0.900 (3.297 sec/step)\n",
      "step 19860 \t loss = 0.724, train_acc = 0.800 (3.326 sec/step)\n",
      "step 19870 \t loss = 2.135, train_acc = 0.700 (3.295 sec/step)\n",
      "step 19880 \t loss = 0.277, train_acc = 0.900 (3.228 sec/step)\n",
      "step 19890 \t loss = 0.629, train_acc = 0.800 (3.313 sec/step)\n",
      "step 19900 \t loss = 0.887, train_acc = 0.900 (3.317 sec/step)\n",
      "step 19910 \t loss = 0.683, train_acc = 0.700 (3.237 sec/step)\n",
      "step 19920 \t loss = 0.388, train_acc = 0.800 (3.322 sec/step)\n",
      "step 19930 \t loss = 0.138, train_acc = 0.900 (3.286 sec/step)\n",
      "step 19940 \t loss = 1.090, train_acc = 0.500 (3.314 sec/step)\n",
      "step 19950 \t loss = 0.395, train_acc = 0.800 (3.311 sec/step)\n",
      "step 19960 \t loss = 0.342, train_acc = 0.800 (3.286 sec/step)\n",
      "step 19970 \t loss = 0.370, train_acc = 0.900 (3.321 sec/step)\n",
      "step 19980 \t loss = 0.472, train_acc = 0.900 (3.285 sec/step)\n",
      "step 19990 \t loss = 0.637, train_acc = 0.800 (3.391 sec/step)\n",
      "step 20000 \t loss = 0.379, train_acc = 0.900 (3.296 sec/step)\n",
      "step 20010 \t loss = 0.178, train_acc = 1.000 (3.273 sec/step)\n",
      "step 20020 \t loss = 0.798, train_acc = 0.800 (3.296 sec/step)\n",
      "step 20030 \t loss = 0.047, train_acc = 1.000 (3.420 sec/step)\n",
      "step 20040 \t loss = 1.108, train_acc = 0.700 (3.307 sec/step)\n",
      "step 20050 \t loss = 0.274, train_acc = 0.900 (3.236 sec/step)\n",
      "step 20060 \t loss = 0.185, train_acc = 0.900 (3.279 sec/step)\n",
      "step 20070 \t loss = 0.427, train_acc = 0.800 (3.268 sec/step)\n",
      "step 20080 \t loss = 0.634, train_acc = 0.800 (3.305 sec/step)\n",
      "step 20090 \t loss = 0.401, train_acc = 0.700 (3.241 sec/step)\n",
      "step 20100 \t loss = 0.437, train_acc = 0.800 (3.272 sec/step)\n",
      "step 20110 \t loss = 0.360, train_acc = 0.900 (3.241 sec/step)\n",
      "step 20120 \t loss = 0.287, train_acc = 0.900 (3.252 sec/step)\n",
      "step 20130 \t loss = 0.118, train_acc = 1.000 (3.297 sec/step)\n",
      "step 20140 \t loss = 0.606, train_acc = 0.800 (3.268 sec/step)\n",
      "step 20150 \t loss = 0.608, train_acc = 0.800 (3.452 sec/step)\n",
      "step 20160 \t loss = 0.223, train_acc = 1.000 (3.231 sec/step)\n",
      "step 20170 \t loss = 0.168, train_acc = 0.900 (3.286 sec/step)\n",
      "step 20180 \t loss = 0.591, train_acc = 0.800 (3.326 sec/step)\n",
      "step 20190 \t loss = 0.284, train_acc = 0.800 (3.296 sec/step)\n",
      "step 20200 \t loss = 0.982, train_acc = 0.600 (3.427 sec/step)\n",
      "step 20210 \t loss = 0.761, train_acc = 0.800 (3.285 sec/step)\n",
      "step 20220 \t loss = 0.146, train_acc = 1.000 (3.278 sec/step)\n",
      "step 20230 \t loss = 0.619, train_acc = 0.800 (3.267 sec/step)\n",
      "step 20240 \t loss = 0.182, train_acc = 1.000 (3.242 sec/step)\n",
      "step 20250 \t loss = 0.578, train_acc = 0.800 (3.283 sec/step)\n",
      "step 20260 \t loss = 0.124, train_acc = 1.000 (3.259 sec/step)\n",
      "step 20270 \t loss = 0.109, train_acc = 1.000 (3.309 sec/step)\n",
      "step 20280 \t loss = 0.224, train_acc = 0.900 (3.325 sec/step)\n",
      "step 20290 \t loss = 0.128, train_acc = 0.900 (3.249 sec/step)\n",
      "step 20300 \t loss = 0.065, train_acc = 1.000 (3.239 sec/step)\n",
      "step 20310 \t loss = 0.707, train_acc = 0.800 (3.319 sec/step)\n",
      "step 20320 \t loss = 0.092, train_acc = 1.000 (3.347 sec/step)\n",
      "step 20330 \t loss = 0.303, train_acc = 0.900 (3.319 sec/step)\n",
      "step 20340 \t loss = 0.537, train_acc = 0.700 (3.324 sec/step)\n",
      "step 20350 \t loss = 0.259, train_acc = 0.900 (3.240 sec/step)\n",
      "step 20360 \t loss = 0.452, train_acc = 0.900 (3.339 sec/step)\n",
      "step 20370 \t loss = 0.108, train_acc = 1.000 (3.260 sec/step)\n",
      "step 20380 \t loss = 0.056, train_acc = 1.000 (3.331 sec/step)\n",
      "step 20390 \t loss = 1.561, train_acc = 0.700 (3.265 sec/step)\n",
      "step 20400 \t loss = 0.034, train_acc = 1.000 (3.305 sec/step)\n",
      "step 20410 \t loss = 1.056, train_acc = 0.700 (3.312 sec/step)\n",
      "step 20420 \t loss = 0.656, train_acc = 0.900 (3.316 sec/step)\n",
      "step 20430 \t loss = 0.551, train_acc = 0.900 (3.278 sec/step)\n",
      "step 20440 \t loss = 0.688, train_acc = 0.700 (3.251 sec/step)\n",
      "step 20450 \t loss = 0.718, train_acc = 0.900 (3.304 sec/step)\n",
      "step 20460 \t loss = 0.370, train_acc = 0.700 (3.252 sec/step)\n",
      "step 20470 \t loss = 1.112, train_acc = 0.600 (3.302 sec/step)\n",
      "step 20480 \t loss = 1.426, train_acc = 0.800 (3.301 sec/step)\n",
      "step 20490 \t loss = 0.091, train_acc = 1.000 (3.293 sec/step)\n",
      "step 20500 \t loss = 0.244, train_acc = 0.900 (3.262 sec/step)\n",
      "step 20510 \t loss = 0.408, train_acc = 0.800 (3.305 sec/step)\n",
      "step 20520 \t loss = 1.624, train_acc = 0.700 (3.329 sec/step)\n",
      "step 20530 \t loss = 0.223, train_acc = 1.000 (3.261 sec/step)\n",
      "step 20540 \t loss = 0.019, train_acc = 1.000 (3.323 sec/step)\n",
      "step 20550 \t loss = 0.009, train_acc = 1.000 (3.264 sec/step)\n",
      "step 20560 \t loss = 0.242, train_acc = 0.800 (3.269 sec/step)\n",
      "step 20570 \t loss = 0.036, train_acc = 1.000 (3.237 sec/step)\n",
      "step 20580 \t loss = 0.316, train_acc = 0.900 (3.278 sec/step)\n",
      "step 20590 \t loss = 0.037, train_acc = 1.000 (3.255 sec/step)\n",
      "step 20600 \t loss = 0.285, train_acc = 0.800 (3.271 sec/step)\n",
      "step 20610 \t loss = 1.884, train_acc = 0.600 (3.289 sec/step)\n",
      "step 20620 \t loss = 0.272, train_acc = 0.900 (3.256 sec/step)\n",
      "step 20630 \t loss = 1.141, train_acc = 0.600 (3.249 sec/step)\n",
      "step 20640 \t loss = 1.288, train_acc = 0.600 (3.272 sec/step)\n",
      "step 20650 \t loss = 0.061, train_acc = 1.000 (3.256 sec/step)\n",
      "step 20660 \t loss = 0.467, train_acc = 0.800 (3.254 sec/step)\n",
      "step 20670 \t loss = 0.164, train_acc = 0.900 (3.286 sec/step)\n",
      "step 20680 \t loss = 0.124, train_acc = 1.000 (3.320 sec/step)\n",
      "step 20690 \t loss = 0.378, train_acc = 0.900 (3.295 sec/step)\n",
      "step 20700 \t loss = 0.579, train_acc = 0.700 (3.309 sec/step)\n",
      "step 20710 \t loss = 0.031, train_acc = 1.000 (3.306 sec/step)\n",
      "step 20720 \t loss = 0.829, train_acc = 0.800 (3.252 sec/step)\n",
      "step 20730 \t loss = 0.747, train_acc = 0.700 (3.242 sec/step)\n",
      "step 20740 \t loss = 0.134, train_acc = 1.000 (3.283 sec/step)\n",
      "step 20750 \t loss = 0.025, train_acc = 1.000 (3.279 sec/step)\n",
      "step 20760 \t loss = 0.053, train_acc = 1.000 (3.302 sec/step)\n",
      "step 20770 \t loss = 0.070, train_acc = 1.000 (3.276 sec/step)\n",
      "step 20780 \t loss = 0.418, train_acc = 0.800 (3.287 sec/step)\n",
      "step 20790 \t loss = 0.090, train_acc = 1.000 (3.328 sec/step)\n",
      "step 20800 \t loss = 2.417, train_acc = 0.700 (3.352 sec/step)\n",
      "step 20810 \t loss = 0.217, train_acc = 1.000 (3.259 sec/step)\n",
      "step 20820 \t loss = 0.016, train_acc = 1.000 (3.284 sec/step)\n",
      "step 20830 \t loss = 0.528, train_acc = 0.800 (3.308 sec/step)\n",
      "step 20840 \t loss = 0.506, train_acc = 0.900 (3.280 sec/step)\n",
      "step 20850 \t loss = 0.380, train_acc = 0.800 (3.321 sec/step)\n",
      "step 20860 \t loss = 0.322, train_acc = 0.900 (3.258 sec/step)\n",
      "step 20870 \t loss = 0.470, train_acc = 0.800 (3.272 sec/step)\n",
      "step 20880 \t loss = 0.016, train_acc = 1.000 (3.278 sec/step)\n",
      "step 20890 \t loss = 0.474, train_acc = 0.900 (3.240 sec/step)\n",
      "VALIDATION \t acc = 0.526 (3.617 sec)\n",
      "New Best Accuracy 0.526 > Old Best 0.524.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 20900 \t loss = 0.128, train_acc = 0.900 (3.441 sec/step)\n",
      "step 20910 \t loss = 0.123, train_acc = 1.000 (3.303 sec/step)\n",
      "step 20920 \t loss = 0.165, train_acc = 1.000 (3.323 sec/step)\n",
      "step 20930 \t loss = 1.508, train_acc = 0.400 (3.304 sec/step)\n",
      "step 20940 \t loss = 0.135, train_acc = 1.000 (3.261 sec/step)\n",
      "step 20950 \t loss = 0.341, train_acc = 0.900 (3.329 sec/step)\n",
      "step 20960 \t loss = 0.005, train_acc = 1.000 (3.299 sec/step)\n",
      "step 20970 \t loss = 0.561, train_acc = 0.800 (3.296 sec/step)\n",
      "step 20980 \t loss = 0.282, train_acc = 0.900 (3.300 sec/step)\n",
      "step 20990 \t loss = 0.106, train_acc = 1.000 (3.329 sec/step)\n",
      "step 21000 \t loss = 0.216, train_acc = 0.800 (3.250 sec/step)\n",
      "step 21010 \t loss = 0.165, train_acc = 0.900 (3.279 sec/step)\n",
      "step 21020 \t loss = 0.012, train_acc = 1.000 (3.280 sec/step)\n",
      "step 21030 \t loss = 0.669, train_acc = 0.800 (3.277 sec/step)\n",
      "step 21040 \t loss = 0.219, train_acc = 0.900 (3.317 sec/step)\n",
      "step 21050 \t loss = 0.089, train_acc = 1.000 (3.300 sec/step)\n",
      "step 21060 \t loss = 0.085, train_acc = 1.000 (3.301 sec/step)\n",
      "step 21070 \t loss = 0.077, train_acc = 0.900 (3.316 sec/step)\n",
      "step 21080 \t loss = 0.060, train_acc = 1.000 (3.276 sec/step)\n",
      "step 21090 \t loss = 0.768, train_acc = 0.700 (3.274 sec/step)\n",
      "step 21100 \t loss = 0.701, train_acc = 0.700 (3.268 sec/step)\n",
      "step 21110 \t loss = 0.242, train_acc = 0.900 (3.258 sec/step)\n",
      "step 21120 \t loss = 0.685, train_acc = 0.800 (3.335 sec/step)\n",
      "step 21130 \t loss = 0.177, train_acc = 1.000 (3.268 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 21140 \t loss = 0.050, train_acc = 1.000 (3.247 sec/step)\n",
      "step 21150 \t loss = 0.197, train_acc = 0.900 (3.269 sec/step)\n",
      "step 21160 \t loss = 0.190, train_acc = 1.000 (3.316 sec/step)\n",
      "step 21170 \t loss = 0.244, train_acc = 0.900 (3.264 sec/step)\n",
      "step 21180 \t loss = 0.565, train_acc = 0.800 (3.336 sec/step)\n",
      "step 21190 \t loss = 0.025, train_acc = 1.000 (3.282 sec/step)\n",
      "step 21200 \t loss = 0.399, train_acc = 0.900 (3.245 sec/step)\n",
      "step 21210 \t loss = 0.494, train_acc = 0.800 (3.275 sec/step)\n",
      "step 21220 \t loss = 0.881, train_acc = 0.800 (3.280 sec/step)\n",
      "step 21230 \t loss = 0.342, train_acc = 0.900 (3.319 sec/step)\n",
      "step 21240 \t loss = 0.384, train_acc = 0.900 (3.248 sec/step)\n",
      "step 21250 \t loss = 0.127, train_acc = 1.000 (3.321 sec/step)\n",
      "step 21260 \t loss = 1.222, train_acc = 0.800 (3.279 sec/step)\n",
      "step 21270 \t loss = 0.107, train_acc = 1.000 (3.317 sec/step)\n",
      "step 21280 \t loss = 0.036, train_acc = 1.000 (3.299 sec/step)\n",
      "step 21290 \t loss = 0.282, train_acc = 0.900 (3.301 sec/step)\n",
      "step 21300 \t loss = 0.347, train_acc = 0.900 (3.308 sec/step)\n",
      "step 21310 \t loss = 1.100, train_acc = 0.700 (3.285 sec/step)\n",
      "step 21320 \t loss = 1.345, train_acc = 0.600 (3.269 sec/step)\n",
      "step 21330 \t loss = 0.490, train_acc = 0.900 (3.281 sec/step)\n",
      "step 21340 \t loss = 0.715, train_acc = 0.700 (3.279 sec/step)\n",
      "step 21350 \t loss = 0.096, train_acc = 1.000 (3.260 sec/step)\n",
      "step 21360 \t loss = 0.258, train_acc = 0.900 (3.330 sec/step)\n",
      "step 21370 \t loss = 0.091, train_acc = 0.900 (3.242 sec/step)\n",
      "step 21380 \t loss = 0.168, train_acc = 1.000 (3.244 sec/step)\n",
      "step 21390 \t loss = 0.102, train_acc = 1.000 (3.303 sec/step)\n",
      "step 21400 \t loss = 0.258, train_acc = 0.900 (3.288 sec/step)\n",
      "step 21410 \t loss = 0.154, train_acc = 1.000 (3.277 sec/step)\n",
      "step 21420 \t loss = 0.313, train_acc = 0.900 (3.312 sec/step)\n",
      "step 21430 \t loss = 0.310, train_acc = 0.900 (3.302 sec/step)\n",
      "step 21440 \t loss = 0.112, train_acc = 0.900 (3.313 sec/step)\n",
      "step 21450 \t loss = 0.516, train_acc = 0.800 (3.267 sec/step)\n",
      "step 21460 \t loss = 0.221, train_acc = 0.900 (3.349 sec/step)\n",
      "step 21470 \t loss = 0.040, train_acc = 1.000 (3.267 sec/step)\n",
      "step 21480 \t loss = 1.362, train_acc = 0.500 (3.335 sec/step)\n",
      "step 21490 \t loss = 0.595, train_acc = 0.800 (3.280 sec/step)\n",
      "step 21500 \t loss = 0.496, train_acc = 0.700 (3.269 sec/step)\n",
      "step 21510 \t loss = 0.532, train_acc = 0.800 (3.362 sec/step)\n",
      "step 21520 \t loss = 0.409, train_acc = 0.800 (3.276 sec/step)\n",
      "step 21530 \t loss = 1.445, train_acc = 0.400 (3.294 sec/step)\n",
      "step 21540 \t loss = 0.015, train_acc = 1.000 (3.332 sec/step)\n",
      "step 21550 \t loss = 0.907, train_acc = 0.700 (3.327 sec/step)\n",
      "step 21560 \t loss = 0.185, train_acc = 1.000 (3.282 sec/step)\n",
      "step 21570 \t loss = 2.420, train_acc = 0.500 (3.306 sec/step)\n",
      "step 21580 \t loss = 0.413, train_acc = 0.900 (3.290 sec/step)\n",
      "step 21590 \t loss = 0.004, train_acc = 1.000 (3.279 sec/step)\n",
      "step 21600 \t loss = 0.269, train_acc = 0.900 (3.295 sec/step)\n",
      "step 21610 \t loss = 0.899, train_acc = 0.700 (3.303 sec/step)\n",
      "step 21620 \t loss = 0.324, train_acc = 0.900 (3.295 sec/step)\n",
      "step 21630 \t loss = 0.038, train_acc = 1.000 (3.306 sec/step)\n",
      "step 21640 \t loss = 0.120, train_acc = 0.900 (3.296 sec/step)\n",
      "step 21650 \t loss = 0.254, train_acc = 0.900 (3.329 sec/step)\n",
      "step 21660 \t loss = 0.201, train_acc = 0.900 (3.296 sec/step)\n",
      "step 21670 \t loss = 0.310, train_acc = 0.800 (3.249 sec/step)\n",
      "step 21680 \t loss = 0.218, train_acc = 0.900 (3.283 sec/step)\n",
      "step 21690 \t loss = 0.226, train_acc = 1.000 (3.274 sec/step)\n",
      "step 21700 \t loss = 0.600, train_acc = 0.700 (3.301 sec/step)\n",
      "step 21710 \t loss = 0.260, train_acc = 0.900 (3.436 sec/step)\n",
      "step 21720 \t loss = 0.439, train_acc = 0.900 (3.267 sec/step)\n",
      "step 21730 \t loss = 0.318, train_acc = 1.000 (3.319 sec/step)\n",
      "step 21740 \t loss = 1.017, train_acc = 0.500 (3.245 sec/step)\n",
      "step 21750 \t loss = 0.155, train_acc = 0.900 (3.268 sec/step)\n",
      "step 21760 \t loss = 0.136, train_acc = 0.900 (3.273 sec/step)\n",
      "step 21770 \t loss = 0.003, train_acc = 1.000 (3.298 sec/step)\n",
      "step 21780 \t loss = 0.138, train_acc = 1.000 (3.235 sec/step)\n",
      "step 21790 \t loss = 0.543, train_acc = 0.900 (3.352 sec/step)\n",
      "step 21800 \t loss = 0.018, train_acc = 1.000 (3.250 sec/step)\n",
      "step 21810 \t loss = 0.126, train_acc = 1.000 (3.293 sec/step)\n",
      "step 21820 \t loss = 0.038, train_acc = 1.000 (3.343 sec/step)\n",
      "step 21830 \t loss = 0.368, train_acc = 0.900 (3.293 sec/step)\n",
      "step 21840 \t loss = 0.210, train_acc = 0.900 (3.327 sec/step)\n",
      "step 21850 \t loss = 0.131, train_acc = 1.000 (3.328 sec/step)\n",
      "step 21860 \t loss = 0.686, train_acc = 0.800 (3.267 sec/step)\n",
      "step 21870 \t loss = 0.007, train_acc = 1.000 (3.291 sec/step)\n",
      "step 21880 \t loss = 0.242, train_acc = 0.900 (3.385 sec/step)\n",
      "step 21890 \t loss = 0.101, train_acc = 1.000 (3.381 sec/step)\n",
      "step 21900 \t loss = 0.024, train_acc = 1.000 (3.307 sec/step)\n",
      "step 21910 \t loss = 1.108, train_acc = 0.700 (3.253 sec/step)\n",
      "step 21920 \t loss = 0.384, train_acc = 0.900 (3.285 sec/step)\n",
      "step 21930 \t loss = 2.201, train_acc = 0.500 (3.277 sec/step)\n",
      "step 21940 \t loss = 0.343, train_acc = 0.900 (3.274 sec/step)\n",
      "step 21950 \t loss = 0.058, train_acc = 1.000 (3.296 sec/step)\n",
      "step 21960 \t loss = 0.170, train_acc = 0.900 (3.284 sec/step)\n",
      "step 21970 \t loss = 0.224, train_acc = 0.900 (3.295 sec/step)\n",
      "step 21980 \t loss = 0.109, train_acc = 1.000 (3.311 sec/step)\n",
      "step 21990 \t loss = 0.704, train_acc = 0.900 (3.246 sec/step)\n",
      "step 22000 \t loss = 0.184, train_acc = 1.000 (3.336 sec/step)\n",
      "step 22010 \t loss = 0.872, train_acc = 0.700 (3.295 sec/step)\n",
      "step 22020 \t loss = 0.160, train_acc = 0.900 (3.330 sec/step)\n",
      "step 22030 \t loss = 1.197, train_acc = 0.700 (3.243 sec/step)\n",
      "step 22040 \t loss = 0.429, train_acc = 0.700 (3.262 sec/step)\n",
      "step 22050 \t loss = 0.091, train_acc = 1.000 (3.251 sec/step)\n",
      "step 22060 \t loss = 0.477, train_acc = 0.900 (3.270 sec/step)\n",
      "step 22070 \t loss = 0.103, train_acc = 1.000 (3.269 sec/step)\n",
      "step 22080 \t loss = 0.580, train_acc = 0.900 (3.251 sec/step)\n",
      "step 22090 \t loss = 1.692, train_acc = 0.600 (3.294 sec/step)\n",
      "step 22100 \t loss = 0.223, train_acc = 0.900 (3.303 sec/step)\n",
      "step 22110 \t loss = 0.432, train_acc = 0.900 (3.268 sec/step)\n",
      "step 22120 \t loss = 0.028, train_acc = 1.000 (3.276 sec/step)\n",
      "step 22130 \t loss = 0.266, train_acc = 0.900 (3.305 sec/step)\n",
      "step 22140 \t loss = 0.330, train_acc = 0.900 (3.246 sec/step)\n",
      "step 22150 \t loss = 0.188, train_acc = 1.000 (3.321 sec/step)\n",
      "step 22160 \t loss = 0.492, train_acc = 0.800 (3.278 sec/step)\n",
      "step 22170 \t loss = 0.709, train_acc = 0.900 (3.300 sec/step)\n",
      "step 22180 \t loss = 0.659, train_acc = 0.900 (3.309 sec/step)\n",
      "step 22190 \t loss = 1.432, train_acc = 0.800 (3.302 sec/step)\n",
      "step 22200 \t loss = 0.553, train_acc = 0.900 (3.247 sec/step)\n",
      "step 22210 \t loss = 0.385, train_acc = 0.900 (3.229 sec/step)\n",
      "step 22220 \t loss = 0.097, train_acc = 0.900 (3.319 sec/step)\n",
      "step 22230 \t loss = 0.020, train_acc = 1.000 (3.394 sec/step)\n",
      "step 22240 \t loss = 0.148, train_acc = 1.000 (3.282 sec/step)\n",
      "step 22250 \t loss = 0.287, train_acc = 0.800 (3.340 sec/step)\n",
      "step 22260 \t loss = 0.145, train_acc = 0.900 (3.271 sec/step)\n",
      "step 22270 \t loss = 0.826, train_acc = 0.700 (3.326 sec/step)\n",
      "step 22280 \t loss = 0.541, train_acc = 0.900 (3.281 sec/step)\n",
      "step 22290 \t loss = 0.835, train_acc = 0.600 (3.262 sec/step)\n",
      "step 22300 \t loss = 0.338, train_acc = 0.900 (3.347 sec/step)\n",
      "step 22310 \t loss = 0.916, train_acc = 0.700 (3.315 sec/step)\n",
      "step 22320 \t loss = 2.127, train_acc = 0.700 (3.335 sec/step)\n",
      "step 22330 \t loss = 0.027, train_acc = 1.000 (3.305 sec/step)\n",
      "step 22340 \t loss = 0.227, train_acc = 0.900 (3.327 sec/step)\n",
      "step 22350 \t loss = 0.081, train_acc = 1.000 (3.258 sec/step)\n",
      "step 22360 \t loss = 0.017, train_acc = 1.000 (3.254 sec/step)\n",
      "step 22370 \t loss = 0.029, train_acc = 1.000 (3.368 sec/step)\n",
      "step 22380 \t loss = 0.412, train_acc = 0.800 (3.336 sec/step)\n",
      "step 22390 \t loss = 0.039, train_acc = 1.000 (3.358 sec/step)\n",
      "step 22400 \t loss = 0.112, train_acc = 1.000 (3.306 sec/step)\n",
      "step 22410 \t loss = 0.133, train_acc = 0.900 (3.248 sec/step)\n",
      "step 22420 \t loss = 0.080, train_acc = 1.000 (3.285 sec/step)\n",
      "step 22430 \t loss = 0.072, train_acc = 1.000 (3.289 sec/step)\n",
      "step 22440 \t loss = 1.053, train_acc = 0.700 (3.255 sec/step)\n",
      "step 22450 \t loss = 0.267, train_acc = 0.900 (3.230 sec/step)\n",
      "step 22460 \t loss = 0.105, train_acc = 1.000 (3.267 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22470 \t loss = 0.111, train_acc = 1.000 (3.284 sec/step)\n",
      "step 22480 \t loss = 0.020, train_acc = 1.000 (3.302 sec/step)\n",
      "step 22490 \t loss = 0.288, train_acc = 0.800 (3.326 sec/step)\n",
      "step 22500 \t loss = 0.467, train_acc = 0.900 (3.268 sec/step)\n",
      "step 22510 \t loss = 1.050, train_acc = 0.700 (3.354 sec/step)\n",
      "step 22520 \t loss = 0.034, train_acc = 1.000 (3.300 sec/step)\n",
      "step 22530 \t loss = 0.307, train_acc = 0.900 (3.267 sec/step)\n",
      "step 22540 \t loss = 0.305, train_acc = 0.900 (3.262 sec/step)\n",
      "step 22550 \t loss = 0.419, train_acc = 0.800 (3.272 sec/step)\n",
      "step 22560 \t loss = 0.454, train_acc = 0.800 (3.244 sec/step)\n",
      "step 22570 \t loss = 1.469, train_acc = 0.700 (3.284 sec/step)\n",
      "step 22580 \t loss = 0.832, train_acc = 0.900 (3.290 sec/step)\n",
      "step 22590 \t loss = 1.046, train_acc = 0.500 (3.297 sec/step)\n",
      "step 22600 \t loss = 0.097, train_acc = 1.000 (3.290 sec/step)\n",
      "step 22610 \t loss = 1.549, train_acc = 0.700 (3.269 sec/step)\n",
      "step 22620 \t loss = 0.109, train_acc = 1.000 (3.269 sec/step)\n",
      "step 22630 \t loss = 0.228, train_acc = 0.900 (3.251 sec/step)\n",
      "step 22640 \t loss = 1.138, train_acc = 0.800 (3.289 sec/step)\n",
      "step 22650 \t loss = 1.006, train_acc = 0.800 (3.360 sec/step)\n",
      "step 22660 \t loss = 0.043, train_acc = 1.000 (3.383 sec/step)\n",
      "step 22670 \t loss = 0.137, train_acc = 0.900 (3.269 sec/step)\n",
      "step 22680 \t loss = 0.184, train_acc = 0.900 (3.334 sec/step)\n",
      "step 22690 \t loss = 0.056, train_acc = 1.000 (3.257 sec/step)\n",
      "step 22700 \t loss = 0.426, train_acc = 0.800 (3.258 sec/step)\n",
      "step 22710 \t loss = 0.336, train_acc = 0.900 (3.270 sec/step)\n",
      "step 22720 \t loss = 1.028, train_acc = 0.600 (3.338 sec/step)\n",
      "step 22730 \t loss = 0.599, train_acc = 0.800 (3.293 sec/step)\n",
      "step 22740 \t loss = 0.647, train_acc = 0.700 (3.316 sec/step)\n",
      "step 22750 \t loss = 0.072, train_acc = 1.000 (3.298 sec/step)\n",
      "step 22760 \t loss = 2.704, train_acc = 0.300 (3.348 sec/step)\n",
      "step 22770 \t loss = 0.233, train_acc = 0.900 (3.286 sec/step)\n",
      "step 22780 \t loss = 0.103, train_acc = 0.900 (3.252 sec/step)\n",
      "step 22790 \t loss = 0.146, train_acc = 0.900 (3.295 sec/step)\n",
      "VALIDATION \t acc = 0.540 (3.647 sec)\n",
      "New Best Accuracy 0.540 > Old Best 0.526.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 22800 \t loss = 0.251, train_acc = 0.900 (3.321 sec/step)\n",
      "step 22810 \t loss = 0.733, train_acc = 0.800 (3.229 sec/step)\n",
      "step 22820 \t loss = 0.486, train_acc = 0.800 (3.336 sec/step)\n",
      "step 22830 \t loss = 0.435, train_acc = 0.900 (3.301 sec/step)\n",
      "step 22840 \t loss = 1.008, train_acc = 0.700 (3.318 sec/step)\n",
      "step 22850 \t loss = 0.425, train_acc = 0.900 (3.277 sec/step)\n",
      "step 22860 \t loss = 0.028, train_acc = 1.000 (3.303 sec/step)\n",
      "step 22870 \t loss = 0.017, train_acc = 1.000 (3.251 sec/step)\n",
      "step 22880 \t loss = 0.564, train_acc = 0.900 (3.347 sec/step)\n",
      "step 22890 \t loss = 1.571, train_acc = 0.600 (3.304 sec/step)\n",
      "step 22900 \t loss = 0.395, train_acc = 0.900 (3.315 sec/step)\n",
      "step 22910 \t loss = 0.222, train_acc = 0.900 (3.320 sec/step)\n",
      "step 22920 \t loss = 0.325, train_acc = 0.900 (3.279 sec/step)\n",
      "step 22930 \t loss = 0.254, train_acc = 0.900 (3.283 sec/step)\n",
      "step 22940 \t loss = 0.839, train_acc = 0.700 (3.287 sec/step)\n",
      "step 22950 \t loss = 2.116, train_acc = 0.600 (3.328 sec/step)\n",
      "step 22960 \t loss = 0.028, train_acc = 1.000 (3.372 sec/step)\n",
      "step 22970 \t loss = 1.310, train_acc = 0.900 (3.285 sec/step)\n",
      "step 22980 \t loss = 0.030, train_acc = 1.000 (3.275 sec/step)\n",
      "step 22990 \t loss = 0.209, train_acc = 0.900 (3.322 sec/step)\n",
      "step 23000 \t loss = 0.258, train_acc = 0.900 (3.312 sec/step)\n",
      "step 23010 \t loss = 0.047, train_acc = 1.000 (3.311 sec/step)\n",
      "step 23020 \t loss = 1.297, train_acc = 0.600 (3.322 sec/step)\n",
      "step 23030 \t loss = 0.206, train_acc = 0.900 (3.300 sec/step)\n",
      "step 23040 \t loss = 0.470, train_acc = 0.700 (3.289 sec/step)\n",
      "step 23050 \t loss = 0.708, train_acc = 0.700 (3.282 sec/step)\n",
      "step 23060 \t loss = 0.138, train_acc = 1.000 (3.277 sec/step)\n",
      "step 23070 \t loss = 0.805, train_acc = 0.700 (3.307 sec/step)\n",
      "step 23080 \t loss = 0.292, train_acc = 0.900 (3.377 sec/step)\n",
      "step 23090 \t loss = 0.901, train_acc = 0.600 (3.346 sec/step)\n",
      "step 23100 \t loss = 0.206, train_acc = 0.900 (3.315 sec/step)\n",
      "step 23110 \t loss = 0.314, train_acc = 0.900 (3.290 sec/step)\n",
      "step 23120 \t loss = 0.139, train_acc = 1.000 (3.272 sec/step)\n",
      "step 23130 \t loss = 0.031, train_acc = 1.000 (3.317 sec/step)\n",
      "step 23140 \t loss = 0.166, train_acc = 0.900 (3.326 sec/step)\n",
      "step 23150 \t loss = 0.056, train_acc = 1.000 (3.279 sec/step)\n",
      "step 23160 \t loss = 0.082, train_acc = 1.000 (3.269 sec/step)\n",
      "step 23170 \t loss = 0.614, train_acc = 0.900 (3.274 sec/step)\n",
      "step 23180 \t loss = 0.741, train_acc = 0.900 (3.285 sec/step)\n",
      "step 23190 \t loss = 0.034, train_acc = 1.000 (3.290 sec/step)\n",
      "step 23200 \t loss = 0.834, train_acc = 0.800 (3.325 sec/step)\n",
      "step 23210 \t loss = 0.441, train_acc = 0.900 (3.302 sec/step)\n",
      "step 23220 \t loss = 0.469, train_acc = 0.900 (3.299 sec/step)\n",
      "step 23230 \t loss = 0.210, train_acc = 0.900 (3.275 sec/step)\n",
      "step 23240 \t loss = 0.330, train_acc = 0.900 (3.325 sec/step)\n",
      "step 23250 \t loss = 0.777, train_acc = 0.700 (3.315 sec/step)\n",
      "step 23260 \t loss = 0.085, train_acc = 1.000 (3.329 sec/step)\n",
      "step 23270 \t loss = 0.010, train_acc = 1.000 (3.285 sec/step)\n",
      "step 23280 \t loss = 0.574, train_acc = 0.700 (3.289 sec/step)\n",
      "step 23290 \t loss = 0.764, train_acc = 0.800 (3.256 sec/step)\n",
      "step 23300 \t loss = 1.369, train_acc = 0.700 (3.311 sec/step)\n",
      "step 23310 \t loss = 0.570, train_acc = 0.700 (3.278 sec/step)\n",
      "step 23320 \t loss = 0.245, train_acc = 0.800 (3.272 sec/step)\n",
      "step 23330 \t loss = 0.419, train_acc = 0.800 (3.320 sec/step)\n",
      "step 23340 \t loss = 0.004, train_acc = 1.000 (3.322 sec/step)\n",
      "step 23350 \t loss = 0.082, train_acc = 1.000 (3.313 sec/step)\n",
      "step 23360 \t loss = 0.034, train_acc = 1.000 (3.329 sec/step)\n",
      "step 23370 \t loss = 0.287, train_acc = 0.900 (3.330 sec/step)\n",
      "step 23380 \t loss = 0.622, train_acc = 0.800 (3.320 sec/step)\n",
      "step 23390 \t loss = 0.938, train_acc = 0.700 (3.295 sec/step)\n",
      "step 23400 \t loss = 0.234, train_acc = 0.900 (3.311 sec/step)\n",
      "step 23410 \t loss = 0.302, train_acc = 0.900 (3.266 sec/step)\n",
      "step 23420 \t loss = 0.027, train_acc = 1.000 (3.272 sec/step)\n",
      "step 23430 \t loss = 0.024, train_acc = 1.000 (3.309 sec/step)\n",
      "step 23440 \t loss = 0.026, train_acc = 1.000 (3.301 sec/step)\n",
      "step 23450 \t loss = 0.025, train_acc = 1.000 (3.285 sec/step)\n",
      "step 23460 \t loss = 0.058, train_acc = 1.000 (3.320 sec/step)\n",
      "step 23470 \t loss = 0.052, train_acc = 1.000 (3.264 sec/step)\n",
      "step 23480 \t loss = 0.503, train_acc = 0.900 (3.339 sec/step)\n",
      "step 23490 \t loss = 0.404, train_acc = 0.900 (3.237 sec/step)\n",
      "step 23500 \t loss = 0.604, train_acc = 0.900 (3.389 sec/step)\n",
      "step 23510 \t loss = 0.049, train_acc = 1.000 (3.284 sec/step)\n",
      "step 23520 \t loss = 0.121, train_acc = 1.000 (3.331 sec/step)\n",
      "step 23530 \t loss = 1.392, train_acc = 0.600 (3.295 sec/step)\n",
      "step 23540 \t loss = 0.228, train_acc = 0.900 (3.313 sec/step)\n",
      "step 23550 \t loss = 0.669, train_acc = 0.900 (3.295 sec/step)\n",
      "step 23560 \t loss = 0.457, train_acc = 0.900 (3.287 sec/step)\n",
      "step 23570 \t loss = 0.199, train_acc = 1.000 (3.295 sec/step)\n",
      "step 23580 \t loss = 0.166, train_acc = 0.900 (3.296 sec/step)\n",
      "step 23590 \t loss = 0.229, train_acc = 1.000 (3.266 sec/step)\n",
      "step 23600 \t loss = 0.191, train_acc = 0.900 (3.282 sec/step)\n",
      "step 23610 \t loss = 0.081, train_acc = 1.000 (3.294 sec/step)\n",
      "step 23620 \t loss = 0.067, train_acc = 1.000 (3.320 sec/step)\n",
      "step 23630 \t loss = 0.456, train_acc = 0.800 (3.288 sec/step)\n",
      "step 23640 \t loss = 0.578, train_acc = 0.900 (3.286 sec/step)\n",
      "step 23650 \t loss = 0.231, train_acc = 0.900 (3.310 sec/step)\n",
      "step 23660 \t loss = 0.520, train_acc = 0.600 (3.267 sec/step)\n",
      "step 23670 \t loss = 0.281, train_acc = 0.900 (3.343 sec/step)\n",
      "step 23680 \t loss = 0.133, train_acc = 0.900 (3.293 sec/step)\n",
      "step 23690 \t loss = 0.116, train_acc = 0.900 (3.349 sec/step)\n",
      "step 23700 \t loss = 0.094, train_acc = 1.000 (3.263 sec/step)\n",
      "step 23710 \t loss = 0.678, train_acc = 0.800 (3.289 sec/step)\n",
      "step 23720 \t loss = 0.869, train_acc = 0.900 (3.301 sec/step)\n",
      "step 23730 \t loss = 0.060, train_acc = 1.000 (3.256 sec/step)\n",
      "step 23740 \t loss = 0.052, train_acc = 1.000 (3.290 sec/step)\n",
      "step 23750 \t loss = 0.147, train_acc = 1.000 (3.304 sec/step)\n",
      "step 23760 \t loss = 0.291, train_acc = 0.900 (3.277 sec/step)\n",
      "step 23770 \t loss = 0.179, train_acc = 0.900 (3.297 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 23780 \t loss = 0.047, train_acc = 1.000 (3.297 sec/step)\n",
      "step 23790 \t loss = 0.453, train_acc = 0.900 (3.271 sec/step)\n",
      "step 23800 \t loss = 0.137, train_acc = 1.000 (3.289 sec/step)\n",
      "step 23810 \t loss = 0.204, train_acc = 0.900 (3.312 sec/step)\n",
      "step 23820 \t loss = 0.100, train_acc = 1.000 (3.297 sec/step)\n",
      "step 23830 \t loss = 0.624, train_acc = 0.800 (3.286 sec/step)\n",
      "step 23840 \t loss = 0.345, train_acc = 0.900 (3.290 sec/step)\n",
      "step 23850 \t loss = 0.121, train_acc = 0.900 (3.291 sec/step)\n",
      "step 23860 \t loss = 0.043, train_acc = 1.000 (3.318 sec/step)\n",
      "step 23870 \t loss = 1.102, train_acc = 0.800 (3.332 sec/step)\n",
      "step 23880 \t loss = 0.438, train_acc = 0.800 (3.300 sec/step)\n",
      "step 23890 \t loss = 0.901, train_acc = 0.700 (3.275 sec/step)\n",
      "step 23900 \t loss = 0.563, train_acc = 0.800 (3.272 sec/step)\n",
      "step 23910 \t loss = 1.015, train_acc = 0.800 (3.295 sec/step)\n",
      "step 23920 \t loss = 0.006, train_acc = 1.000 (3.318 sec/step)\n",
      "step 23930 \t loss = 0.256, train_acc = 0.900 (3.306 sec/step)\n",
      "step 23940 \t loss = 0.147, train_acc = 1.000 (3.306 sec/step)\n",
      "step 23950 \t loss = 0.055, train_acc = 1.000 (3.350 sec/step)\n",
      "step 23960 \t loss = 0.010, train_acc = 1.000 (3.280 sec/step)\n",
      "step 23970 \t loss = 0.137, train_acc = 1.000 (3.401 sec/step)\n",
      "step 23980 \t loss = 0.097, train_acc = 1.000 (3.252 sec/step)\n",
      "step 23990 \t loss = 1.054, train_acc = 0.700 (3.328 sec/step)\n",
      "step 24000 \t loss = 0.159, train_acc = 1.000 (3.297 sec/step)\n",
      "step 24010 \t loss = 0.028, train_acc = 1.000 (3.310 sec/step)\n",
      "step 24020 \t loss = 0.005, train_acc = 1.000 (3.289 sec/step)\n",
      "step 24030 \t loss = 0.220, train_acc = 0.900 (3.281 sec/step)\n",
      "step 24040 \t loss = 0.171, train_acc = 0.900 (3.310 sec/step)\n",
      "step 24050 \t loss = 0.182, train_acc = 0.900 (3.350 sec/step)\n",
      "step 24060 \t loss = 0.084, train_acc = 1.000 (3.273 sec/step)\n",
      "step 24070 \t loss = 1.210, train_acc = 0.600 (3.339 sec/step)\n",
      "step 24080 \t loss = 0.000, train_acc = 1.000 (3.325 sec/step)\n",
      "step 24090 \t loss = 0.672, train_acc = 0.800 (3.298 sec/step)\n",
      "step 24100 \t loss = 0.047, train_acc = 1.000 (3.291 sec/step)\n",
      "step 24110 \t loss = 0.318, train_acc = 0.900 (3.344 sec/step)\n",
      "step 24120 \t loss = 0.051, train_acc = 1.000 (3.263 sec/step)\n",
      "step 24130 \t loss = 0.261, train_acc = 0.900 (3.284 sec/step)\n",
      "step 24140 \t loss = 0.371, train_acc = 0.900 (3.304 sec/step)\n",
      "step 24150 \t loss = 0.749, train_acc = 0.900 (3.276 sec/step)\n",
      "step 24160 \t loss = 0.055, train_acc = 1.000 (3.279 sec/step)\n",
      "step 24170 \t loss = 0.047, train_acc = 1.000 (3.285 sec/step)\n",
      "step 24180 \t loss = 0.904, train_acc = 0.800 (3.270 sec/step)\n",
      "step 24190 \t loss = 1.280, train_acc = 0.600 (3.289 sec/step)\n",
      "step 24200 \t loss = 0.048, train_acc = 1.000 (3.273 sec/step)\n",
      "step 24210 \t loss = 0.686, train_acc = 0.900 (3.296 sec/step)\n",
      "step 24220 \t loss = 0.460, train_acc = 0.800 (3.280 sec/step)\n",
      "step 24230 \t loss = 0.021, train_acc = 1.000 (3.291 sec/step)\n",
      "step 24240 \t loss = 0.006, train_acc = 1.000 (3.393 sec/step)\n",
      "step 24250 \t loss = 0.665, train_acc = 0.700 (3.316 sec/step)\n",
      "step 24260 \t loss = 0.059, train_acc = 1.000 (3.310 sec/step)\n",
      "step 24270 \t loss = 0.275, train_acc = 0.800 (3.252 sec/step)\n",
      "step 24280 \t loss = 1.406, train_acc = 0.500 (3.319 sec/step)\n",
      "step 24290 \t loss = 0.230, train_acc = 0.900 (3.310 sec/step)\n",
      "step 24300 \t loss = 0.187, train_acc = 0.900 (3.296 sec/step)\n",
      "step 24310 \t loss = 0.125, train_acc = 1.000 (3.295 sec/step)\n",
      "step 24320 \t loss = 0.114, train_acc = 1.000 (3.307 sec/step)\n",
      "step 24330 \t loss = 1.545, train_acc = 0.600 (3.344 sec/step)\n",
      "step 24340 \t loss = 0.356, train_acc = 0.900 (3.305 sec/step)\n",
      "step 24350 \t loss = 0.258, train_acc = 0.900 (3.332 sec/step)\n",
      "step 24360 \t loss = 0.563, train_acc = 0.800 (3.310 sec/step)\n",
      "step 24370 \t loss = 0.028, train_acc = 1.000 (3.298 sec/step)\n",
      "step 24380 \t loss = 0.274, train_acc = 0.900 (3.307 sec/step)\n",
      "step 24390 \t loss = 0.073, train_acc = 1.000 (3.316 sec/step)\n",
      "step 24400 \t loss = 0.217, train_acc = 1.000 (3.310 sec/step)\n",
      "step 24410 \t loss = 0.628, train_acc = 0.800 (3.303 sec/step)\n",
      "step 24420 \t loss = 0.088, train_acc = 1.000 (3.351 sec/step)\n",
      "step 24430 \t loss = 0.074, train_acc = 1.000 (3.299 sec/step)\n",
      "step 24440 \t loss = 0.099, train_acc = 1.000 (3.304 sec/step)\n",
      "step 24450 \t loss = 0.117, train_acc = 1.000 (3.297 sec/step)\n",
      "step 24460 \t loss = 0.776, train_acc = 0.700 (3.326 sec/step)\n",
      "step 24470 \t loss = 0.233, train_acc = 0.900 (3.277 sec/step)\n",
      "step 24480 \t loss = 0.016, train_acc = 1.000 (3.298 sec/step)\n",
      "step 24490 \t loss = 0.231, train_acc = 0.900 (3.269 sec/step)\n",
      "step 24500 \t loss = 0.020, train_acc = 1.000 (3.266 sec/step)\n",
      "step 24510 \t loss = 0.014, train_acc = 1.000 (3.284 sec/step)\n",
      "step 24520 \t loss = 0.407, train_acc = 0.800 (3.276 sec/step)\n",
      "step 24530 \t loss = 0.591, train_acc = 0.800 (3.297 sec/step)\n",
      "step 24540 \t loss = 0.012, train_acc = 1.000 (3.315 sec/step)\n",
      "step 24550 \t loss = 0.464, train_acc = 0.800 (3.312 sec/step)\n",
      "step 24560 \t loss = 0.635, train_acc = 0.900 (3.288 sec/step)\n",
      "step 24570 \t loss = 0.000, train_acc = 1.000 (3.332 sec/step)\n",
      "step 24580 \t loss = 0.267, train_acc = 0.800 (3.284 sec/step)\n",
      "step 24590 \t loss = 0.675, train_acc = 0.800 (3.251 sec/step)\n",
      "step 24600 \t loss = 0.030, train_acc = 1.000 (3.270 sec/step)\n",
      "step 24610 \t loss = 0.271, train_acc = 0.800 (3.318 sec/step)\n",
      "step 24620 \t loss = 0.012, train_acc = 1.000 (3.289 sec/step)\n",
      "step 24630 \t loss = 0.074, train_acc = 1.000 (3.269 sec/step)\n",
      "step 24640 \t loss = 0.503, train_acc = 0.900 (3.308 sec/step)\n",
      "step 24650 \t loss = 0.031, train_acc = 1.000 (3.318 sec/step)\n",
      "step 24660 \t loss = 1.496, train_acc = 0.700 (3.293 sec/step)\n",
      "step 24670 \t loss = 0.231, train_acc = 0.900 (3.309 sec/step)\n",
      "step 24680 \t loss = 0.018, train_acc = 1.000 (3.320 sec/step)\n",
      "step 24690 \t loss = 0.050, train_acc = 1.000 (3.279 sec/step)\n",
      "VALIDATION \t acc = 0.561 (3.652 sec)\n",
      "New Best Accuracy 0.561 > Old Best 0.540.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 24700 \t loss = 0.408, train_acc = 0.900 (3.290 sec/step)\n",
      "step 24710 \t loss = 0.298, train_acc = 0.800 (3.269 sec/step)\n",
      "step 24720 \t loss = 0.994, train_acc = 0.800 (3.296 sec/step)\n",
      "step 24730 \t loss = 0.826, train_acc = 0.700 (3.357 sec/step)\n",
      "step 24740 \t loss = 0.626, train_acc = 0.800 (3.331 sec/step)\n",
      "step 24750 \t loss = 4.854, train_acc = 0.300 (3.319 sec/step)\n",
      "step 24760 \t loss = 0.070, train_acc = 1.000 (3.268 sec/step)\n",
      "step 24770 \t loss = 0.263, train_acc = 1.000 (3.262 sec/step)\n",
      "step 24780 \t loss = 0.022, train_acc = 1.000 (3.313 sec/step)\n",
      "step 24790 \t loss = 0.206, train_acc = 1.000 (3.319 sec/step)\n",
      "step 24800 \t loss = 0.395, train_acc = 0.900 (3.249 sec/step)\n",
      "step 24810 \t loss = 0.055, train_acc = 1.000 (3.284 sec/step)\n",
      "step 24820 \t loss = 0.427, train_acc = 0.800 (3.262 sec/step)\n",
      "step 24830 \t loss = 0.052, train_acc = 1.000 (3.329 sec/step)\n",
      "step 24840 \t loss = 0.076, train_acc = 1.000 (3.393 sec/step)\n",
      "step 24850 \t loss = 0.137, train_acc = 1.000 (3.349 sec/step)\n",
      "step 24860 \t loss = 0.406, train_acc = 0.900 (3.338 sec/step)\n",
      "step 24870 \t loss = 0.037, train_acc = 1.000 (3.290 sec/step)\n",
      "step 24880 \t loss = 1.634, train_acc = 0.700 (3.332 sec/step)\n",
      "step 24890 \t loss = 0.227, train_acc = 0.900 (3.381 sec/step)\n",
      "step 24900 \t loss = 0.358, train_acc = 0.900 (3.310 sec/step)\n",
      "step 24910 \t loss = 0.034, train_acc = 1.000 (3.273 sec/step)\n",
      "step 24920 \t loss = 0.377, train_acc = 0.800 (3.317 sec/step)\n",
      "step 24930 \t loss = 0.512, train_acc = 0.900 (3.278 sec/step)\n",
      "step 24940 \t loss = 0.008, train_acc = 1.000 (3.309 sec/step)\n",
      "step 24950 \t loss = 0.068, train_acc = 1.000 (3.327 sec/step)\n",
      "step 24960 \t loss = 0.175, train_acc = 0.900 (3.249 sec/step)\n",
      "step 24970 \t loss = 1.015, train_acc = 0.800 (3.273 sec/step)\n",
      "step 24980 \t loss = 0.017, train_acc = 1.000 (3.347 sec/step)\n",
      "step 24990 \t loss = 0.107, train_acc = 1.000 (3.252 sec/step)\n",
      "step 25000 \t loss = 0.441, train_acc = 0.900 (3.323 sec/step)\n",
      "step 25010 \t loss = 0.835, train_acc = 0.800 (3.322 sec/step)\n",
      "step 25020 \t loss = 0.182, train_acc = 0.900 (3.288 sec/step)\n",
      "step 25030 \t loss = 0.053, train_acc = 1.000 (3.275 sec/step)\n",
      "step 25040 \t loss = 0.074, train_acc = 1.000 (3.350 sec/step)\n",
      "step 25050 \t loss = 0.394, train_acc = 0.900 (3.283 sec/step)\n",
      "step 25060 \t loss = 0.225, train_acc = 0.800 (3.310 sec/step)\n",
      "step 25070 \t loss = 0.532, train_acc = 0.900 (3.265 sec/step)\n",
      "step 25080 \t loss = 0.001, train_acc = 1.000 (3.310 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25090 \t loss = 2.732, train_acc = 0.900 (3.280 sec/step)\n",
      "step 25100 \t loss = 0.803, train_acc = 0.800 (3.315 sec/step)\n",
      "step 25110 \t loss = 0.824, train_acc = 0.800 (3.285 sec/step)\n",
      "step 25120 \t loss = 0.668, train_acc = 0.800 (3.325 sec/step)\n",
      "step 25130 \t loss = 0.129, train_acc = 0.900 (3.252 sec/step)\n",
      "step 25140 \t loss = 0.363, train_acc = 0.900 (3.285 sec/step)\n",
      "step 25150 \t loss = 0.558, train_acc = 0.900 (3.278 sec/step)\n",
      "step 25160 \t loss = 0.017, train_acc = 1.000 (3.265 sec/step)\n",
      "step 25170 \t loss = 0.523, train_acc = 0.900 (3.380 sec/step)\n",
      "step 25180 \t loss = 0.499, train_acc = 0.900 (3.304 sec/step)\n",
      "step 25190 \t loss = 0.432, train_acc = 0.800 (3.289 sec/step)\n",
      "step 25200 \t loss = 0.009, train_acc = 1.000 (3.272 sec/step)\n",
      "step 25210 \t loss = 0.006, train_acc = 1.000 (3.267 sec/step)\n",
      "step 25220 \t loss = 0.060, train_acc = 1.000 (3.348 sec/step)\n",
      "step 25230 \t loss = 0.216, train_acc = 0.900 (3.283 sec/step)\n",
      "step 25240 \t loss = 0.721, train_acc = 0.800 (3.283 sec/step)\n",
      "step 25250 \t loss = 0.276, train_acc = 0.900 (3.309 sec/step)\n",
      "step 25260 \t loss = 0.290, train_acc = 0.800 (3.265 sec/step)\n",
      "step 25270 \t loss = 0.183, train_acc = 1.000 (3.256 sec/step)\n",
      "step 25280 \t loss = 0.075, train_acc = 1.000 (3.310 sec/step)\n",
      "step 25290 \t loss = 0.077, train_acc = 1.000 (3.297 sec/step)\n",
      "step 25300 \t loss = 0.076, train_acc = 1.000 (3.290 sec/step)\n",
      "step 25310 \t loss = 0.150, train_acc = 0.900 (3.300 sec/step)\n",
      "step 25320 \t loss = 0.847, train_acc = 0.700 (3.294 sec/step)\n",
      "step 25330 \t loss = 0.448, train_acc = 0.800 (3.356 sec/step)\n",
      "step 25340 \t loss = 0.152, train_acc = 0.900 (3.294 sec/step)\n",
      "step 25350 \t loss = 0.227, train_acc = 0.900 (3.268 sec/step)\n",
      "step 25360 \t loss = 0.701, train_acc = 0.700 (3.306 sec/step)\n",
      "step 25370 \t loss = 0.134, train_acc = 1.000 (3.275 sec/step)\n",
      "step 25380 \t loss = 0.001, train_acc = 1.000 (3.328 sec/step)\n",
      "step 25390 \t loss = 0.003, train_acc = 1.000 (3.246 sec/step)\n",
      "step 25400 \t loss = 0.777, train_acc = 0.800 (3.274 sec/step)\n",
      "step 25410 \t loss = 0.294, train_acc = 0.900 (3.295 sec/step)\n",
      "step 25420 \t loss = 0.240, train_acc = 0.900 (3.258 sec/step)\n",
      "step 25430 \t loss = 0.350, train_acc = 0.900 (3.311 sec/step)\n",
      "step 25440 \t loss = 0.335, train_acc = 0.800 (3.257 sec/step)\n",
      "step 25450 \t loss = 0.058, train_acc = 1.000 (3.327 sec/step)\n",
      "step 25460 \t loss = 0.191, train_acc = 0.900 (3.243 sec/step)\n",
      "step 25470 \t loss = 0.014, train_acc = 1.000 (3.305 sec/step)\n",
      "step 25480 \t loss = 0.147, train_acc = 0.900 (3.310 sec/step)\n",
      "step 25490 \t loss = 0.038, train_acc = 1.000 (3.363 sec/step)\n",
      "step 25500 \t loss = 0.147, train_acc = 0.900 (3.319 sec/step)\n",
      "step 25510 \t loss = 0.113, train_acc = 0.900 (3.273 sec/step)\n",
      "step 25520 \t loss = 0.070, train_acc = 1.000 (3.303 sec/step)\n",
      "step 25530 \t loss = 0.003, train_acc = 1.000 (3.257 sec/step)\n",
      "step 25540 \t loss = 0.297, train_acc = 0.800 (3.258 sec/step)\n",
      "step 25550 \t loss = 0.836, train_acc = 0.700 (3.301 sec/step)\n",
      "step 25560 \t loss = 0.061, train_acc = 1.000 (3.258 sec/step)\n",
      "step 25570 \t loss = 0.090, train_acc = 1.000 (3.319 sec/step)\n",
      "step 25580 \t loss = 0.009, train_acc = 1.000 (3.286 sec/step)\n",
      "step 25590 \t loss = 0.022, train_acc = 1.000 (3.334 sec/step)\n",
      "step 25600 \t loss = 0.631, train_acc = 0.800 (3.332 sec/step)\n",
      "step 25610 \t loss = 0.150, train_acc = 0.900 (3.315 sec/step)\n",
      "step 25620 \t loss = 0.005, train_acc = 1.000 (3.290 sec/step)\n",
      "step 25630 \t loss = 0.068, train_acc = 1.000 (3.305 sec/step)\n",
      "step 25640 \t loss = 0.838, train_acc = 0.800 (3.322 sec/step)\n",
      "step 25650 \t loss = 0.010, train_acc = 1.000 (3.289 sec/step)\n",
      "step 25660 \t loss = 0.410, train_acc = 0.900 (3.270 sec/step)\n",
      "step 25670 \t loss = 3.790, train_acc = 0.700 (3.372 sec/step)\n",
      "step 25680 \t loss = 0.010, train_acc = 1.000 (3.286 sec/step)\n",
      "step 25690 \t loss = 0.669, train_acc = 0.800 (3.358 sec/step)\n",
      "step 25700 \t loss = 0.155, train_acc = 1.000 (3.266 sec/step)\n",
      "step 25710 \t loss = 0.542, train_acc = 0.800 (3.366 sec/step)\n",
      "step 25720 \t loss = 0.103, train_acc = 1.000 (3.314 sec/step)\n",
      "step 25730 \t loss = 0.191, train_acc = 0.900 (3.337 sec/step)\n",
      "step 25740 \t loss = 1.357, train_acc = 0.600 (3.286 sec/step)\n",
      "step 25750 \t loss = 0.577, train_acc = 0.800 (3.302 sec/step)\n",
      "step 25760 \t loss = 0.616, train_acc = 0.800 (3.286 sec/step)\n",
      "step 25770 \t loss = 0.115, train_acc = 0.900 (3.262 sec/step)\n",
      "step 25780 \t loss = 0.490, train_acc = 0.800 (3.280 sec/step)\n",
      "step 25790 \t loss = 0.194, train_acc = 0.800 (3.291 sec/step)\n",
      "step 25800 \t loss = 1.110, train_acc = 0.800 (3.267 sec/step)\n",
      "step 25810 \t loss = 0.530, train_acc = 0.900 (3.325 sec/step)\n",
      "step 25820 \t loss = 0.479, train_acc = 0.900 (3.266 sec/step)\n",
      "step 25830 \t loss = 1.104, train_acc = 0.700 (3.289 sec/step)\n",
      "step 25840 \t loss = 0.920, train_acc = 0.800 (3.280 sec/step)\n",
      "step 25850 \t loss = 0.268, train_acc = 0.900 (3.301 sec/step)\n",
      "step 25860 \t loss = 0.131, train_acc = 0.900 (3.338 sec/step)\n",
      "step 25870 \t loss = 0.532, train_acc = 0.800 (3.318 sec/step)\n",
      "step 25880 \t loss = 0.188, train_acc = 0.900 (3.317 sec/step)\n",
      "step 25890 \t loss = 0.338, train_acc = 0.900 (3.273 sec/step)\n",
      "step 25900 \t loss = 0.216, train_acc = 0.900 (3.315 sec/step)\n",
      "step 25910 \t loss = 0.366, train_acc = 0.800 (3.284 sec/step)\n",
      "step 25920 \t loss = 0.265, train_acc = 0.800 (3.303 sec/step)\n",
      "step 25930 \t loss = 0.502, train_acc = 0.900 (3.291 sec/step)\n",
      "step 25940 \t loss = 0.748, train_acc = 0.900 (3.349 sec/step)\n",
      "step 25950 \t loss = 0.130, train_acc = 1.000 (3.321 sec/step)\n",
      "step 25960 \t loss = 0.306, train_acc = 0.900 (3.277 sec/step)\n",
      "step 25970 \t loss = 0.079, train_acc = 1.000 (3.302 sec/step)\n",
      "step 25980 \t loss = 0.185, train_acc = 0.900 (3.269 sec/step)\n",
      "step 25990 \t loss = 0.001, train_acc = 1.000 (3.304 sec/step)\n",
      "step 26000 \t loss = 0.000, train_acc = 1.000 (3.294 sec/step)\n",
      "step 26010 \t loss = 0.052, train_acc = 1.000 (3.314 sec/step)\n",
      "step 26020 \t loss = 0.036, train_acc = 1.000 (3.271 sec/step)\n",
      "step 26030 \t loss = 0.123, train_acc = 1.000 (3.334 sec/step)\n",
      "step 26040 \t loss = 0.393, train_acc = 0.800 (3.397 sec/step)\n",
      "step 26050 \t loss = 0.083, train_acc = 1.000 (3.346 sec/step)\n",
      "step 26060 \t loss = 1.075, train_acc = 0.600 (3.310 sec/step)\n",
      "step 26070 \t loss = 0.015, train_acc = 1.000 (3.325 sec/step)\n",
      "step 26080 \t loss = 0.314, train_acc = 0.900 (3.337 sec/step)\n",
      "step 26090 \t loss = 0.459, train_acc = 0.900 (3.264 sec/step)\n",
      "step 26100 \t loss = 0.051, train_acc = 1.000 (3.302 sec/step)\n",
      "step 26110 \t loss = 0.053, train_acc = 1.000 (3.392 sec/step)\n",
      "step 26120 \t loss = 0.046, train_acc = 1.000 (3.317 sec/step)\n",
      "step 26130 \t loss = 0.000, train_acc = 1.000 (3.372 sec/step)\n",
      "step 26140 \t loss = 0.619, train_acc = 0.700 (3.339 sec/step)\n",
      "step 26150 \t loss = 0.253, train_acc = 0.900 (3.318 sec/step)\n",
      "step 26160 \t loss = 0.201, train_acc = 0.900 (3.256 sec/step)\n",
      "step 26170 \t loss = 1.123, train_acc = 0.700 (3.298 sec/step)\n",
      "step 26180 \t loss = 0.796, train_acc = 0.900 (3.322 sec/step)\n",
      "step 26190 \t loss = 0.023, train_acc = 1.000 (3.286 sec/step)\n",
      "step 26200 \t loss = 0.038, train_acc = 1.000 (3.267 sec/step)\n",
      "step 26210 \t loss = 0.109, train_acc = 1.000 (3.281 sec/step)\n",
      "step 26220 \t loss = 0.011, train_acc = 1.000 (3.369 sec/step)\n",
      "step 26230 \t loss = 0.007, train_acc = 1.000 (3.333 sec/step)\n",
      "step 26240 \t loss = 0.274, train_acc = 0.900 (3.278 sec/step)\n",
      "step 26250 \t loss = 0.111, train_acc = 0.900 (3.357 sec/step)\n",
      "step 26260 \t loss = 0.050, train_acc = 1.000 (3.302 sec/step)\n",
      "step 26270 \t loss = 0.886, train_acc = 0.600 (3.306 sec/step)\n",
      "step 26280 \t loss = 0.009, train_acc = 1.000 (3.287 sec/step)\n",
      "step 26290 \t loss = 0.021, train_acc = 1.000 (3.314 sec/step)\n",
      "step 26300 \t loss = 0.536, train_acc = 0.900 (3.272 sec/step)\n",
      "step 26310 \t loss = 0.213, train_acc = 1.000 (3.312 sec/step)\n",
      "step 26320 \t loss = 0.217, train_acc = 0.900 (3.272 sec/step)\n",
      "step 26330 \t loss = 0.281, train_acc = 0.900 (3.288 sec/step)\n",
      "step 26340 \t loss = 0.610, train_acc = 0.900 (3.315 sec/step)\n",
      "step 26350 \t loss = 0.512, train_acc = 0.900 (3.277 sec/step)\n",
      "step 26360 \t loss = 0.069, train_acc = 1.000 (3.369 sec/step)\n",
      "step 26370 \t loss = 0.189, train_acc = 0.900 (3.316 sec/step)\n",
      "step 26380 \t loss = 0.234, train_acc = 0.900 (3.252 sec/step)\n",
      "step 26390 \t loss = 0.270, train_acc = 0.900 (3.297 sec/step)\n",
      "step 26400 \t loss = 0.084, train_acc = 1.000 (3.361 sec/step)\n",
      "step 26410 \t loss = 0.535, train_acc = 0.900 (3.313 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26420 \t loss = 0.303, train_acc = 0.900 (3.307 sec/step)\n",
      "step 26430 \t loss = 0.025, train_acc = 1.000 (3.279 sec/step)\n",
      "step 26440 \t loss = 0.019, train_acc = 1.000 (3.333 sec/step)\n",
      "step 26450 \t loss = 0.685, train_acc = 0.800 (3.356 sec/step)\n",
      "step 26460 \t loss = 0.200, train_acc = 0.800 (3.300 sec/step)\n",
      "step 26470 \t loss = 0.050, train_acc = 1.000 (3.277 sec/step)\n",
      "step 26480 \t loss = 0.282, train_acc = 0.900 (3.296 sec/step)\n",
      "step 26490 \t loss = 0.079, train_acc = 1.000 (3.278 sec/step)\n",
      "step 26500 \t loss = 0.005, train_acc = 1.000 (3.319 sec/step)\n",
      "step 26510 \t loss = 0.137, train_acc = 1.000 (3.283 sec/step)\n",
      "step 26520 \t loss = 0.169, train_acc = 0.900 (3.354 sec/step)\n",
      "step 26530 \t loss = 0.406, train_acc = 0.900 (3.261 sec/step)\n",
      "step 26540 \t loss = 1.469, train_acc = 0.600 (3.319 sec/step)\n",
      "step 26550 \t loss = 0.111, train_acc = 1.000 (3.349 sec/step)\n",
      "step 26560 \t loss = 0.845, train_acc = 0.800 (3.296 sec/step)\n",
      "step 26570 \t loss = 0.115, train_acc = 1.000 (3.317 sec/step)\n",
      "step 26580 \t loss = 0.174, train_acc = 1.000 (3.312 sec/step)\n",
      "step 26590 \t loss = 0.034, train_acc = 1.000 (3.292 sec/step)\n",
      "VALIDATION \t acc = 0.534 (3.638 sec)\n",
      "step 26600 \t loss = 0.040, train_acc = 1.000 (3.245 sec/step)\n",
      "step 26610 \t loss = 0.282, train_acc = 0.900 (3.273 sec/step)\n",
      "step 26620 \t loss = 0.033, train_acc = 1.000 (3.291 sec/step)\n",
      "step 26630 \t loss = 0.116, train_acc = 0.900 (3.278 sec/step)\n",
      "step 26640 \t loss = 0.108, train_acc = 0.900 (3.314 sec/step)\n",
      "step 26650 \t loss = 0.034, train_acc = 1.000 (3.387 sec/step)\n",
      "step 26660 \t loss = 0.027, train_acc = 1.000 (3.311 sec/step)\n",
      "step 26670 \t loss = 0.002, train_acc = 1.000 (3.276 sec/step)\n",
      "step 26680 \t loss = 0.851, train_acc = 0.700 (3.343 sec/step)\n",
      "step 26690 \t loss = 0.077, train_acc = 1.000 (3.271 sec/step)\n",
      "step 26700 \t loss = 0.311, train_acc = 0.900 (3.302 sec/step)\n",
      "step 26710 \t loss = 0.064, train_acc = 1.000 (3.317 sec/step)\n",
      "step 26720 \t loss = 0.684, train_acc = 0.700 (3.282 sec/step)\n",
      "step 26730 \t loss = 0.770, train_acc = 0.900 (3.421 sec/step)\n",
      "step 26740 \t loss = 0.012, train_acc = 1.000 (3.274 sec/step)\n",
      "step 26750 \t loss = 0.018, train_acc = 1.000 (3.277 sec/step)\n",
      "step 26760 \t loss = 1.500, train_acc = 0.800 (3.266 sec/step)\n",
      "step 26770 \t loss = 0.220, train_acc = 0.900 (3.270 sec/step)\n",
      "step 26780 \t loss = 0.228, train_acc = 0.900 (3.282 sec/step)\n",
      "step 26790 \t loss = 0.634, train_acc = 0.800 (3.341 sec/step)\n",
      "step 26800 \t loss = 0.364, train_acc = 0.800 (3.305 sec/step)\n",
      "step 26810 \t loss = 0.062, train_acc = 1.000 (3.312 sec/step)\n",
      "step 26820 \t loss = 0.207, train_acc = 0.900 (3.357 sec/step)\n",
      "step 26830 \t loss = 0.103, train_acc = 1.000 (3.263 sec/step)\n",
      "step 26840 \t loss = 1.127, train_acc = 0.700 (3.313 sec/step)\n",
      "step 26850 \t loss = 0.081, train_acc = 1.000 (3.267 sec/step)\n",
      "step 26860 \t loss = 0.054, train_acc = 1.000 (3.321 sec/step)\n",
      "step 26870 \t loss = 0.005, train_acc = 1.000 (3.343 sec/step)\n",
      "step 26880 \t loss = 0.014, train_acc = 1.000 (3.251 sec/step)\n",
      "step 26890 \t loss = 0.006, train_acc = 1.000 (3.293 sec/step)\n",
      "step 26900 \t loss = 0.150, train_acc = 0.900 (3.264 sec/step)\n",
      "step 26910 \t loss = 0.162, train_acc = 0.900 (3.294 sec/step)\n",
      "step 26920 \t loss = 0.852, train_acc = 0.800 (3.283 sec/step)\n",
      "step 26930 \t loss = 0.107, train_acc = 1.000 (3.298 sec/step)\n",
      "step 26940 \t loss = 0.759, train_acc = 0.800 (3.294 sec/step)\n",
      "step 26950 \t loss = 0.043, train_acc = 1.000 (3.307 sec/step)\n",
      "step 26960 \t loss = 1.671, train_acc = 0.600 (3.336 sec/step)\n",
      "step 26970 \t loss = 0.168, train_acc = 0.900 (3.343 sec/step)\n",
      "step 26980 \t loss = 0.053, train_acc = 1.000 (3.403 sec/step)\n",
      "step 26990 \t loss = 0.066, train_acc = 1.000 (3.298 sec/step)\n",
      "step 27000 \t loss = 0.586, train_acc = 0.800 (3.290 sec/step)\n",
      "step 27010 \t loss = 0.054, train_acc = 1.000 (3.245 sec/step)\n",
      "step 27020 \t loss = 0.003, train_acc = 1.000 (3.275 sec/step)\n",
      "step 27030 \t loss = 0.270, train_acc = 0.900 (3.285 sec/step)\n",
      "step 27040 \t loss = 0.142, train_acc = 0.900 (3.268 sec/step)\n",
      "step 27050 \t loss = 1.173, train_acc = 0.700 (3.299 sec/step)\n",
      "step 27060 \t loss = 0.992, train_acc = 0.700 (3.304 sec/step)\n",
      "step 27070 \t loss = 0.035, train_acc = 1.000 (3.275 sec/step)\n",
      "step 27080 \t loss = 0.212, train_acc = 0.900 (3.319 sec/step)\n",
      "step 27090 \t loss = 0.438, train_acc = 0.800 (3.343 sec/step)\n",
      "step 27100 \t loss = 0.484, train_acc = 0.900 (3.318 sec/step)\n",
      "step 27110 \t loss = 0.211, train_acc = 1.000 (3.321 sec/step)\n",
      "step 27120 \t loss = 0.605, train_acc = 0.800 (3.299 sec/step)\n",
      "step 27130 \t loss = 0.500, train_acc = 0.800 (3.354 sec/step)\n",
      "step 27140 \t loss = 0.839, train_acc = 0.800 (3.280 sec/step)\n",
      "step 27150 \t loss = 0.002, train_acc = 1.000 (3.287 sec/step)\n",
      "step 27160 \t loss = 0.018, train_acc = 1.000 (3.253 sec/step)\n",
      "step 27170 \t loss = 0.002, train_acc = 1.000 (3.305 sec/step)\n",
      "step 27180 \t loss = 0.697, train_acc = 0.700 (3.283 sec/step)\n",
      "step 27190 \t loss = 0.289, train_acc = 0.800 (3.268 sec/step)\n",
      "step 27200 \t loss = 0.089, train_acc = 1.000 (3.330 sec/step)\n",
      "step 27210 \t loss = 0.312, train_acc = 0.900 (3.341 sec/step)\n",
      "step 27220 \t loss = 0.012, train_acc = 1.000 (3.241 sec/step)\n",
      "step 27230 \t loss = 0.157, train_acc = 1.000 (3.256 sec/step)\n",
      "step 27240 \t loss = 0.302, train_acc = 0.900 (3.307 sec/step)\n",
      "step 27250 \t loss = 0.133, train_acc = 0.900 (3.298 sec/step)\n",
      "step 27260 \t loss = 0.135, train_acc = 1.000 (3.291 sec/step)\n",
      "step 27270 \t loss = 0.094, train_acc = 1.000 (3.313 sec/step)\n",
      "step 27280 \t loss = 0.009, train_acc = 1.000 (3.288 sec/step)\n",
      "step 27290 \t loss = 0.086, train_acc = 1.000 (3.308 sec/step)\n",
      "step 27300 \t loss = 0.362, train_acc = 0.800 (3.275 sec/step)\n",
      "step 27310 \t loss = 0.143, train_acc = 1.000 (3.285 sec/step)\n",
      "step 27320 \t loss = 0.009, train_acc = 1.000 (3.281 sec/step)\n",
      "step 27330 \t loss = 1.141, train_acc = 0.800 (3.294 sec/step)\n",
      "step 27340 \t loss = 0.404, train_acc = 0.800 (3.286 sec/step)\n",
      "step 27350 \t loss = 0.186, train_acc = 0.900 (3.314 sec/step)\n",
      "step 27360 \t loss = 1.770, train_acc = 0.700 (3.310 sec/step)\n",
      "step 27370 \t loss = 0.946, train_acc = 0.700 (3.268 sec/step)\n",
      "step 27380 \t loss = 0.374, train_acc = 0.800 (3.319 sec/step)\n",
      "step 27390 \t loss = 0.102, train_acc = 0.900 (3.346 sec/step)\n",
      "step 27400 \t loss = 1.193, train_acc = 0.900 (3.252 sec/step)\n",
      "step 27410 \t loss = 0.690, train_acc = 0.800 (3.355 sec/step)\n",
      "step 27420 \t loss = 0.471, train_acc = 0.900 (3.328 sec/step)\n",
      "step 27430 \t loss = 0.162, train_acc = 1.000 (3.319 sec/step)\n",
      "step 27440 \t loss = 0.317, train_acc = 0.900 (3.290 sec/step)\n",
      "step 27450 \t loss = 0.657, train_acc = 0.800 (3.283 sec/step)\n",
      "step 27460 \t loss = 0.190, train_acc = 0.900 (3.324 sec/step)\n",
      "step 27470 \t loss = 0.293, train_acc = 0.900 (3.319 sec/step)\n",
      "step 27480 \t loss = 0.000, train_acc = 1.000 (3.266 sec/step)\n",
      "step 27490 \t loss = 0.008, train_acc = 1.000 (3.455 sec/step)\n",
      "step 27500 \t loss = 0.039, train_acc = 1.000 (3.280 sec/step)\n",
      "step 27510 \t loss = 0.116, train_acc = 1.000 (3.319 sec/step)\n",
      "step 27520 \t loss = 0.043, train_acc = 1.000 (3.294 sec/step)\n",
      "step 27530 \t loss = 0.118, train_acc = 0.900 (3.298 sec/step)\n",
      "step 27540 \t loss = 0.018, train_acc = 1.000 (3.311 sec/step)\n",
      "step 27550 \t loss = 0.008, train_acc = 1.000 (3.269 sec/step)\n",
      "step 27560 \t loss = 0.032, train_acc = 1.000 (3.282 sec/step)\n",
      "step 27570 \t loss = 0.066, train_acc = 1.000 (3.290 sec/step)\n",
      "step 27580 \t loss = 0.245, train_acc = 0.900 (3.301 sec/step)\n",
      "step 27590 \t loss = 0.022, train_acc = 1.000 (3.344 sec/step)\n",
      "step 27600 \t loss = 0.186, train_acc = 0.900 (3.295 sec/step)\n",
      "step 27610 \t loss = 0.156, train_acc = 1.000 (3.285 sec/step)\n",
      "step 27620 \t loss = 0.044, train_acc = 1.000 (3.295 sec/step)\n",
      "step 27630 \t loss = 0.412, train_acc = 0.800 (3.307 sec/step)\n",
      "step 27640 \t loss = 0.393, train_acc = 0.900 (3.273 sec/step)\n",
      "step 27650 \t loss = 0.066, train_acc = 1.000 (3.284 sec/step)\n",
      "step 27660 \t loss = 0.608, train_acc = 0.900 (3.289 sec/step)\n",
      "step 27670 \t loss = 0.008, train_acc = 1.000 (3.296 sec/step)\n",
      "step 27680 \t loss = 0.098, train_acc = 1.000 (3.326 sec/step)\n",
      "step 27690 \t loss = 0.096, train_acc = 1.000 (3.292 sec/step)\n",
      "step 27700 \t loss = 0.171, train_acc = 0.900 (3.295 sec/step)\n",
      "step 27710 \t loss = 1.004, train_acc = 0.800 (3.266 sec/step)\n",
      "step 27720 \t loss = 0.127, train_acc = 0.900 (3.280 sec/step)\n",
      "step 27730 \t loss = 0.689, train_acc = 0.800 (3.317 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 27740 \t loss = 0.437, train_acc = 0.800 (3.272 sec/step)\n",
      "step 27750 \t loss = 0.145, train_acc = 0.900 (3.302 sec/step)\n",
      "step 27760 \t loss = 0.048, train_acc = 1.000 (3.354 sec/step)\n",
      "step 27770 \t loss = 0.145, train_acc = 0.900 (3.291 sec/step)\n",
      "step 27780 \t loss = 0.113, train_acc = 1.000 (3.298 sec/step)\n",
      "step 27790 \t loss = 0.166, train_acc = 1.000 (3.255 sec/step)\n",
      "step 27800 \t loss = 1.047, train_acc = 0.700 (3.294 sec/step)\n",
      "step 27810 \t loss = 0.074, train_acc = 1.000 (3.341 sec/step)\n",
      "step 27820 \t loss = 0.023, train_acc = 1.000 (3.260 sec/step)\n",
      "step 27830 \t loss = 0.105, train_acc = 0.900 (3.283 sec/step)\n",
      "step 27840 \t loss = 1.189, train_acc = 0.600 (3.277 sec/step)\n",
      "step 27850 \t loss = 0.115, train_acc = 1.000 (3.345 sec/step)\n",
      "step 27860 \t loss = 0.907, train_acc = 0.900 (3.279 sec/step)\n",
      "step 27870 \t loss = 0.056, train_acc = 1.000 (3.290 sec/step)\n",
      "step 27880 \t loss = 0.009, train_acc = 1.000 (3.280 sec/step)\n",
      "step 27890 \t loss = 0.401, train_acc = 0.800 (3.291 sec/step)\n",
      "step 27900 \t loss = 0.008, train_acc = 1.000 (3.305 sec/step)\n",
      "step 27910 \t loss = 0.347, train_acc = 0.900 (3.311 sec/step)\n",
      "step 27920 \t loss = 1.764, train_acc = 0.600 (3.300 sec/step)\n",
      "step 27930 \t loss = 0.297, train_acc = 0.900 (3.263 sec/step)\n",
      "step 27940 \t loss = 0.745, train_acc = 0.800 (3.246 sec/step)\n",
      "step 27950 \t loss = 0.953, train_acc = 0.600 (3.312 sec/step)\n",
      "step 27960 \t loss = 1.301, train_acc = 0.700 (3.285 sec/step)\n",
      "step 27970 \t loss = 0.038, train_acc = 1.000 (3.305 sec/step)\n",
      "step 27980 \t loss = 0.038, train_acc = 1.000 (3.329 sec/step)\n",
      "step 27990 \t loss = 0.722, train_acc = 0.600 (3.275 sec/step)\n",
      "step 28000 \t loss = 0.418, train_acc = 0.800 (3.281 sec/step)\n",
      "step 28010 \t loss = 0.045, train_acc = 1.000 (3.324 sec/step)\n",
      "step 28020 \t loss = 0.748, train_acc = 0.900 (3.327 sec/step)\n",
      "step 28030 \t loss = 0.180, train_acc = 0.900 (3.398 sec/step)\n",
      "step 28040 \t loss = 0.058, train_acc = 1.000 (3.286 sec/step)\n",
      "step 28050 \t loss = 0.188, train_acc = 0.900 (3.291 sec/step)\n",
      "step 28060 \t loss = 0.191, train_acc = 1.000 (3.294 sec/step)\n",
      "step 28070 \t loss = 0.168, train_acc = 0.900 (3.327 sec/step)\n",
      "step 28080 \t loss = 0.284, train_acc = 0.900 (3.259 sec/step)\n",
      "step 28090 \t loss = 0.159, train_acc = 0.900 (3.349 sec/step)\n",
      "step 28100 \t loss = 0.013, train_acc = 1.000 (3.293 sec/step)\n",
      "step 28110 \t loss = 0.010, train_acc = 1.000 (3.288 sec/step)\n",
      "step 28120 \t loss = 0.397, train_acc = 0.900 (3.291 sec/step)\n",
      "step 28130 \t loss = 0.178, train_acc = 0.900 (3.287 sec/step)\n",
      "step 28140 \t loss = 0.017, train_acc = 1.000 (3.308 sec/step)\n",
      "step 28150 \t loss = 0.057, train_acc = 1.000 (3.291 sec/step)\n",
      "step 28160 \t loss = 0.400, train_acc = 0.800 (3.322 sec/step)\n",
      "step 28170 \t loss = 0.164, train_acc = 0.900 (3.293 sec/step)\n",
      "step 28180 \t loss = 0.466, train_acc = 0.900 (3.337 sec/step)\n",
      "step 28190 \t loss = 0.200, train_acc = 0.900 (3.296 sec/step)\n",
      "step 28200 \t loss = 1.158, train_acc = 0.700 (3.266 sec/step)\n",
      "step 28210 \t loss = 0.187, train_acc = 1.000 (3.308 sec/step)\n",
      "step 28220 \t loss = 0.055, train_acc = 1.000 (3.294 sec/step)\n",
      "step 28230 \t loss = 0.829, train_acc = 0.800 (3.294 sec/step)\n",
      "step 28240 \t loss = 0.606, train_acc = 0.800 (3.363 sec/step)\n",
      "step 28250 \t loss = 0.427, train_acc = 0.800 (3.312 sec/step)\n",
      "step 28260 \t loss = 0.168, train_acc = 1.000 (3.299 sec/step)\n",
      "step 28270 \t loss = 0.032, train_acc = 1.000 (3.318 sec/step)\n",
      "step 28280 \t loss = 3.068, train_acc = 0.800 (3.284 sec/step)\n",
      "step 28290 \t loss = 0.032, train_acc = 1.000 (3.307 sec/step)\n",
      "step 28300 \t loss = 0.291, train_acc = 0.800 (3.295 sec/step)\n",
      "step 28310 \t loss = 0.313, train_acc = 0.900 (3.293 sec/step)\n",
      "step 28320 \t loss = 0.036, train_acc = 1.000 (3.284 sec/step)\n",
      "step 28330 \t loss = 0.221, train_acc = 1.000 (3.328 sec/step)\n",
      "step 28340 \t loss = 0.288, train_acc = 0.900 (3.327 sec/step)\n",
      "step 28350 \t loss = 0.026, train_acc = 1.000 (3.286 sec/step)\n",
      "step 28360 \t loss = 0.140, train_acc = 1.000 (3.285 sec/step)\n",
      "step 28370 \t loss = 0.039, train_acc = 1.000 (3.317 sec/step)\n",
      "step 28380 \t loss = 0.089, train_acc = 1.000 (3.289 sec/step)\n",
      "step 28390 \t loss = 0.168, train_acc = 0.900 (3.300 sec/step)\n",
      "step 28400 \t loss = 0.203, train_acc = 0.900 (3.334 sec/step)\n",
      "step 28410 \t loss = 0.168, train_acc = 1.000 (3.263 sec/step)\n",
      "step 28420 \t loss = 0.054, train_acc = 1.000 (3.303 sec/step)\n",
      "step 28430 \t loss = 0.527, train_acc = 0.900 (3.264 sec/step)\n",
      "step 28440 \t loss = 0.117, train_acc = 0.900 (3.340 sec/step)\n",
      "step 28450 \t loss = 0.014, train_acc = 1.000 (3.334 sec/step)\n",
      "step 28460 \t loss = 0.839, train_acc = 0.800 (3.255 sec/step)\n",
      "step 28470 \t loss = 0.031, train_acc = 1.000 (3.325 sec/step)\n",
      "step 28480 \t loss = 0.017, train_acc = 1.000 (3.299 sec/step)\n",
      "step 28490 \t loss = 0.061, train_acc = 1.000 (3.371 sec/step)\n",
      "VALIDATION \t acc = 0.534 (3.643 sec)\n",
      "step 28500 \t loss = 1.687, train_acc = 0.800 (3.299 sec/step)\n",
      "step 28510 \t loss = 0.892, train_acc = 0.800 (3.288 sec/step)\n",
      "step 28520 \t loss = 0.706, train_acc = 0.900 (3.280 sec/step)\n",
      "step 28530 \t loss = 0.346, train_acc = 0.900 (3.335 sec/step)\n",
      "step 28540 \t loss = 0.017, train_acc = 1.000 (3.355 sec/step)\n",
      "step 28550 \t loss = 0.626, train_acc = 0.700 (3.284 sec/step)\n",
      "step 28560 \t loss = 0.085, train_acc = 0.900 (3.271 sec/step)\n",
      "step 28570 \t loss = 0.094, train_acc = 1.000 (3.307 sec/step)\n",
      "step 28580 \t loss = 0.217, train_acc = 0.900 (3.324 sec/step)\n",
      "step 28590 \t loss = 0.321, train_acc = 0.900 (3.370 sec/step)\n",
      "step 28600 \t loss = 0.981, train_acc = 0.900 (3.286 sec/step)\n",
      "step 28610 \t loss = 0.297, train_acc = 0.900 (3.279 sec/step)\n",
      "step 28620 \t loss = 0.383, train_acc = 0.900 (3.305 sec/step)\n",
      "step 28630 \t loss = 0.473, train_acc = 0.800 (3.344 sec/step)\n",
      "step 28640 \t loss = 0.025, train_acc = 1.000 (3.317 sec/step)\n",
      "step 28650 \t loss = 0.138, train_acc = 1.000 (3.343 sec/step)\n",
      "step 28660 \t loss = 0.170, train_acc = 0.900 (3.271 sec/step)\n",
      "step 28670 \t loss = 0.016, train_acc = 1.000 (3.290 sec/step)\n",
      "step 28680 \t loss = 0.014, train_acc = 1.000 (3.289 sec/step)\n",
      "step 28690 \t loss = 0.088, train_acc = 1.000 (3.361 sec/step)\n",
      "step 28700 \t loss = 0.816, train_acc = 0.700 (3.282 sec/step)\n",
      "step 28710 \t loss = 0.071, train_acc = 1.000 (3.265 sec/step)\n",
      "step 28720 \t loss = 0.577, train_acc = 0.900 (3.356 sec/step)\n",
      "step 28730 \t loss = 0.685, train_acc = 0.800 (3.289 sec/step)\n",
      "step 28740 \t loss = 0.064, train_acc = 1.000 (3.339 sec/step)\n",
      "step 28750 \t loss = 0.057, train_acc = 1.000 (3.283 sec/step)\n",
      "step 28760 \t loss = 0.153, train_acc = 1.000 (3.287 sec/step)\n",
      "step 28770 \t loss = 0.668, train_acc = 0.800 (3.305 sec/step)\n",
      "step 28780 \t loss = 0.364, train_acc = 0.900 (3.284 sec/step)\n",
      "step 28790 \t loss = 0.211, train_acc = 0.900 (3.309 sec/step)\n",
      "step 28800 \t loss = 0.977, train_acc = 0.900 (3.313 sec/step)\n",
      "step 28810 \t loss = 0.455, train_acc = 0.900 (3.290 sec/step)\n",
      "step 28820 \t loss = 0.794, train_acc = 0.700 (3.257 sec/step)\n",
      "step 28830 \t loss = 0.070, train_acc = 1.000 (3.281 sec/step)\n",
      "step 28840 \t loss = 0.144, train_acc = 0.900 (3.266 sec/step)\n",
      "step 28850 \t loss = 0.201, train_acc = 1.000 (3.339 sec/step)\n",
      "step 28860 \t loss = 0.456, train_acc = 0.900 (3.322 sec/step)\n",
      "step 28870 \t loss = 0.063, train_acc = 1.000 (3.352 sec/step)\n",
      "step 28880 \t loss = 0.003, train_acc = 1.000 (3.328 sec/step)\n",
      "step 28890 \t loss = 0.358, train_acc = 0.900 (3.337 sec/step)\n",
      "step 28900 \t loss = 2.990, train_acc = 0.700 (3.342 sec/step)\n",
      "step 28910 \t loss = 0.359, train_acc = 0.900 (3.268 sec/step)\n",
      "step 28920 \t loss = 0.088, train_acc = 1.000 (3.339 sec/step)\n",
      "step 28930 \t loss = 0.048, train_acc = 1.000 (3.317 sec/step)\n",
      "step 28940 \t loss = 0.070, train_acc = 1.000 (3.271 sec/step)\n",
      "step 28950 \t loss = 0.244, train_acc = 0.900 (3.295 sec/step)\n",
      "step 28960 \t loss = 0.338, train_acc = 0.900 (3.349 sec/step)\n",
      "step 28970 \t loss = 0.247, train_acc = 0.900 (3.284 sec/step)\n",
      "step 28980 \t loss = 0.007, train_acc = 1.000 (3.300 sec/step)\n",
      "step 28990 \t loss = 0.540, train_acc = 0.900 (3.282 sec/step)\n",
      "step 29000 \t loss = 0.023, train_acc = 1.000 (3.349 sec/step)\n",
      "step 29010 \t loss = 0.146, train_acc = 0.900 (3.305 sec/step)\n",
      "step 29020 \t loss = 0.459, train_acc = 0.700 (3.299 sec/step)\n",
      "step 29030 \t loss = 0.911, train_acc = 0.700 (3.305 sec/step)\n",
      "step 29040 \t loss = 0.006, train_acc = 1.000 (3.307 sec/step)\n",
      "step 29050 \t loss = 0.001, train_acc = 1.000 (3.285 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 29060 \t loss = 0.863, train_acc = 0.800 (3.259 sec/step)\n",
      "step 29070 \t loss = 0.146, train_acc = 1.000 (3.335 sec/step)\n",
      "step 29080 \t loss = 0.174, train_acc = 0.900 (3.279 sec/step)\n",
      "step 29090 \t loss = 0.104, train_acc = 1.000 (3.302 sec/step)\n",
      "step 29100 \t loss = 2.195, train_acc = 0.600 (3.356 sec/step)\n",
      "step 29110 \t loss = 0.521, train_acc = 0.900 (3.323 sec/step)\n",
      "step 29120 \t loss = 0.093, train_acc = 1.000 (3.275 sec/step)\n",
      "step 29130 \t loss = 1.625, train_acc = 0.800 (3.277 sec/step)\n",
      "step 29140 \t loss = 0.836, train_acc = 0.900 (3.313 sec/step)\n",
      "step 29150 \t loss = 0.438, train_acc = 0.800 (3.311 sec/step)\n",
      "step 29160 \t loss = 1.549, train_acc = 0.800 (3.409 sec/step)\n",
      "step 29170 \t loss = 0.157, train_acc = 1.000 (3.281 sec/step)\n",
      "step 29180 \t loss = 0.300, train_acc = 0.800 (3.301 sec/step)\n",
      "step 29190 \t loss = 2.745, train_acc = 0.600 (3.258 sec/step)\n",
      "step 29200 \t loss = 0.469, train_acc = 0.800 (3.272 sec/step)\n",
      "step 29210 \t loss = 0.211, train_acc = 0.900 (3.291 sec/step)\n",
      "step 29220 \t loss = 0.088, train_acc = 1.000 (3.286 sec/step)\n",
      "step 29230 \t loss = 0.037, train_acc = 1.000 (3.290 sec/step)\n",
      "step 29240 \t loss = 0.028, train_acc = 1.000 (3.288 sec/step)\n",
      "step 29250 \t loss = 0.148, train_acc = 0.900 (3.282 sec/step)\n",
      "step 29260 \t loss = 0.007, train_acc = 1.000 (3.327 sec/step)\n",
      "step 29270 \t loss = 0.221, train_acc = 0.900 (3.250 sec/step)\n",
      "step 29280 \t loss = 0.337, train_acc = 0.900 (3.311 sec/step)\n",
      "step 29290 \t loss = 0.126, train_acc = 0.900 (3.333 sec/step)\n",
      "step 29300 \t loss = 0.013, train_acc = 1.000 (3.276 sec/step)\n",
      "step 29310 \t loss = 0.005, train_acc = 1.000 (3.365 sec/step)\n",
      "step 29320 \t loss = 0.052, train_acc = 1.000 (3.303 sec/step)\n",
      "step 29330 \t loss = 0.062, train_acc = 1.000 (3.289 sec/step)\n",
      "step 29340 \t loss = 2.248, train_acc = 0.600 (3.319 sec/step)\n",
      "step 29350 \t loss = 0.316, train_acc = 0.900 (3.350 sec/step)\n",
      "step 29360 \t loss = 0.687, train_acc = 0.800 (3.344 sec/step)\n",
      "step 29370 \t loss = 0.195, train_acc = 0.900 (3.322 sec/step)\n",
      "step 29380 \t loss = 0.059, train_acc = 1.000 (3.332 sec/step)\n",
      "step 29390 \t loss = 0.488, train_acc = 0.900 (3.288 sec/step)\n",
      "step 29400 \t loss = 0.015, train_acc = 1.000 (3.333 sec/step)\n",
      "step 29410 \t loss = 0.571, train_acc = 0.800 (3.277 sec/step)\n",
      "step 29420 \t loss = 0.005, train_acc = 1.000 (3.262 sec/step)\n",
      "step 29430 \t loss = 0.181, train_acc = 0.900 (3.338 sec/step)\n",
      "step 29440 \t loss = 0.007, train_acc = 1.000 (3.325 sec/step)\n",
      "step 29450 \t loss = 0.226, train_acc = 0.900 (3.257 sec/step)\n",
      "step 29460 \t loss = 0.185, train_acc = 1.000 (3.350 sec/step)\n",
      "step 29470 \t loss = 0.031, train_acc = 1.000 (3.355 sec/step)\n",
      "step 29480 \t loss = 0.037, train_acc = 1.000 (3.281 sec/step)\n",
      "step 29490 \t loss = 0.375, train_acc = 0.800 (3.350 sec/step)\n",
      "step 29500 \t loss = 0.030, train_acc = 1.000 (3.396 sec/step)\n",
      "step 29510 \t loss = 0.005, train_acc = 1.000 (3.307 sec/step)\n",
      "step 29520 \t loss = 0.053, train_acc = 1.000 (3.306 sec/step)\n",
      "step 29530 \t loss = 0.108, train_acc = 0.900 (3.244 sec/step)\n",
      "step 29540 \t loss = 0.309, train_acc = 0.900 (3.307 sec/step)\n",
      "step 29550 \t loss = 0.154, train_acc = 0.900 (3.315 sec/step)\n",
      "step 29560 \t loss = 0.159, train_acc = 0.900 (3.298 sec/step)\n",
      "step 29570 \t loss = 0.091, train_acc = 1.000 (3.343 sec/step)\n",
      "step 29580 \t loss = 0.101, train_acc = 1.000 (3.274 sec/step)\n",
      "step 29590 \t loss = 0.711, train_acc = 0.900 (3.358 sec/step)\n",
      "step 29600 \t loss = 1.009, train_acc = 0.800 (3.318 sec/step)\n",
      "step 29610 \t loss = 0.005, train_acc = 1.000 (3.316 sec/step)\n",
      "step 29620 \t loss = 0.673, train_acc = 0.900 (3.255 sec/step)\n",
      "step 29630 \t loss = 0.140, train_acc = 0.900 (3.331 sec/step)\n",
      "step 29640 \t loss = 0.879, train_acc = 0.900 (3.269 sec/step)\n",
      "step 29650 \t loss = 0.118, train_acc = 1.000 (3.325 sec/step)\n",
      "step 29660 \t loss = 0.069, train_acc = 1.000 (3.333 sec/step)\n",
      "step 29670 \t loss = 1.149, train_acc = 0.600 (3.308 sec/step)\n",
      "step 29680 \t loss = 0.151, train_acc = 1.000 (3.357 sec/step)\n",
      "step 29690 \t loss = 0.236, train_acc = 0.900 (3.298 sec/step)\n",
      "step 29700 \t loss = 0.173, train_acc = 1.000 (3.272 sec/step)\n",
      "step 29710 \t loss = 0.100, train_acc = 1.000 (3.282 sec/step)\n",
      "step 29720 \t loss = 0.301, train_acc = 0.900 (3.280 sec/step)\n",
      "step 29730 \t loss = 0.235, train_acc = 0.900 (3.269 sec/step)\n",
      "step 29740 \t loss = 0.036, train_acc = 1.000 (3.310 sec/step)\n",
      "step 29750 \t loss = 0.933, train_acc = 0.700 (3.276 sec/step)\n",
      "step 29760 \t loss = 0.096, train_acc = 1.000 (3.338 sec/step)\n",
      "step 29770 \t loss = 0.063, train_acc = 1.000 (3.311 sec/step)\n",
      "step 29780 \t loss = 0.003, train_acc = 1.000 (3.265 sec/step)\n",
      "step 29790 \t loss = 0.172, train_acc = 1.000 (3.311 sec/step)\n",
      "step 29800 \t loss = 0.002, train_acc = 1.000 (3.299 sec/step)\n",
      "step 29810 \t loss = 0.260, train_acc = 0.900 (3.322 sec/step)\n",
      "step 29820 \t loss = 0.907, train_acc = 0.800 (3.344 sec/step)\n",
      "step 29830 \t loss = 0.284, train_acc = 0.900 (3.265 sec/step)\n",
      "step 29840 \t loss = 0.028, train_acc = 1.000 (3.250 sec/step)\n",
      "step 29850 \t loss = 0.660, train_acc = 0.800 (3.296 sec/step)\n",
      "step 29860 \t loss = 0.551, train_acc = 0.900 (3.319 sec/step)\n",
      "step 29870 \t loss = 0.356, train_acc = 0.900 (3.294 sec/step)\n",
      "step 29880 \t loss = 0.464, train_acc = 0.800 (3.306 sec/step)\n",
      "step 29890 \t loss = 0.074, train_acc = 1.000 (3.404 sec/step)\n",
      "step 29900 \t loss = 0.629, train_acc = 0.900 (3.351 sec/step)\n",
      "step 29910 \t loss = 0.272, train_acc = 0.900 (3.310 sec/step)\n",
      "step 29920 \t loss = 0.507, train_acc = 0.900 (3.311 sec/step)\n",
      "step 29930 \t loss = 0.656, train_acc = 0.800 (3.286 sec/step)\n",
      "step 29940 \t loss = 0.007, train_acc = 1.000 (3.320 sec/step)\n",
      "step 29950 \t loss = 0.007, train_acc = 1.000 (3.312 sec/step)\n",
      "step 29960 \t loss = 0.702, train_acc = 0.900 (3.286 sec/step)\n",
      "step 29970 \t loss = 0.017, train_acc = 1.000 (3.308 sec/step)\n",
      "step 29980 \t loss = 0.242, train_acc = 0.900 (3.292 sec/step)\n",
      "step 29990 \t loss = 0.327, train_acc = 0.800 (3.269 sec/step)\n",
      "step 30000 \t loss = 0.092, train_acc = 1.000 (3.294 sec/step)\n",
      "step 30010 \t loss = 0.092, train_acc = 1.000 (3.284 sec/step)\n",
      "step 30020 \t loss = 0.679, train_acc = 0.800 (3.342 sec/step)\n",
      "step 30030 \t loss = 0.183, train_acc = 0.900 (3.352 sec/step)\n",
      "step 30040 \t loss = 0.374, train_acc = 0.800 (3.292 sec/step)\n",
      "step 30050 \t loss = 0.130, train_acc = 1.000 (3.296 sec/step)\n",
      "step 30060 \t loss = 0.519, train_acc = 0.900 (3.328 sec/step)\n",
      "step 30070 \t loss = 0.047, train_acc = 1.000 (3.328 sec/step)\n",
      "step 30080 \t loss = 0.796, train_acc = 0.800 (3.312 sec/step)\n",
      "step 30090 \t loss = 0.386, train_acc = 0.900 (3.327 sec/step)\n",
      "step 30100 \t loss = 0.270, train_acc = 0.900 (3.335 sec/step)\n",
      "step 30110 \t loss = 0.488, train_acc = 0.900 (3.336 sec/step)\n",
      "step 30120 \t loss = 0.052, train_acc = 1.000 (3.283 sec/step)\n",
      "step 30130 \t loss = 0.350, train_acc = 0.900 (3.293 sec/step)\n",
      "step 30140 \t loss = 0.324, train_acc = 0.800 (3.420 sec/step)\n",
      "step 30150 \t loss = 0.171, train_acc = 1.000 (3.307 sec/step)\n",
      "step 30160 \t loss = 0.113, train_acc = 1.000 (3.302 sec/step)\n",
      "step 30170 \t loss = 0.344, train_acc = 0.800 (3.351 sec/step)\n",
      "step 30180 \t loss = 0.474, train_acc = 0.900 (3.299 sec/step)\n",
      "step 30190 \t loss = 0.616, train_acc = 0.800 (3.288 sec/step)\n",
      "step 30200 \t loss = 0.236, train_acc = 0.900 (3.252 sec/step)\n",
      "step 30210 \t loss = 0.474, train_acc = 0.900 (3.316 sec/step)\n",
      "step 30220 \t loss = 0.060, train_acc = 1.000 (3.262 sec/step)\n",
      "step 30230 \t loss = 0.005, train_acc = 1.000 (3.339 sec/step)\n",
      "step 30240 \t loss = 0.327, train_acc = 0.800 (3.286 sec/step)\n",
      "step 30250 \t loss = 0.549, train_acc = 0.800 (3.349 sec/step)\n",
      "step 30260 \t loss = 0.513, train_acc = 0.900 (3.354 sec/step)\n",
      "step 30270 \t loss = 0.293, train_acc = 0.900 (3.290 sec/step)\n",
      "step 30280 \t loss = 0.413, train_acc = 0.900 (3.310 sec/step)\n",
      "step 30290 \t loss = 0.006, train_acc = 1.000 (3.297 sec/step)\n",
      "step 30300 \t loss = 0.025, train_acc = 1.000 (3.319 sec/step)\n",
      "step 30310 \t loss = 0.166, train_acc = 0.900 (3.286 sec/step)\n",
      "step 30320 \t loss = 0.047, train_acc = 1.000 (3.312 sec/step)\n",
      "step 30330 \t loss = 0.111, train_acc = 0.900 (3.272 sec/step)\n",
      "step 30340 \t loss = 0.714, train_acc = 0.800 (3.262 sec/step)\n",
      "step 30350 \t loss = 0.340, train_acc = 0.800 (3.299 sec/step)\n",
      "step 30360 \t loss = 0.220, train_acc = 0.900 (3.285 sec/step)\n",
      "step 30370 \t loss = 0.353, train_acc = 0.900 (3.240 sec/step)\n",
      "step 30380 \t loss = 0.329, train_acc = 0.900 (3.316 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30390 \t loss = 1.245, train_acc = 0.600 (3.311 sec/step)\n",
      "VALIDATION \t acc = 0.516 (3.609 sec)\n",
      "step 30400 \t loss = 0.044, train_acc = 1.000 (3.278 sec/step)\n",
      "step 30410 \t loss = 0.034, train_acc = 1.000 (3.287 sec/step)\n",
      "step 30420 \t loss = 0.247, train_acc = 0.800 (3.321 sec/step)\n",
      "step 30430 \t loss = 0.034, train_acc = 1.000 (3.367 sec/step)\n",
      "step 30440 \t loss = 0.012, train_acc = 1.000 (3.314 sec/step)\n",
      "step 30450 \t loss = 0.149, train_acc = 1.000 (3.326 sec/step)\n",
      "step 30460 \t loss = 0.009, train_acc = 1.000 (3.261 sec/step)\n",
      "step 30470 \t loss = 0.042, train_acc = 1.000 (3.372 sec/step)\n",
      "step 30480 \t loss = 0.115, train_acc = 0.900 (3.254 sec/step)\n",
      "step 30490 \t loss = 0.020, train_acc = 1.000 (3.324 sec/step)\n",
      "step 30500 \t loss = 0.816, train_acc = 0.800 (3.287 sec/step)\n",
      "step 30510 \t loss = 0.734, train_acc = 0.900 (3.355 sec/step)\n",
      "step 30520 \t loss = 0.127, train_acc = 1.000 (3.268 sec/step)\n",
      "step 30530 \t loss = 0.029, train_acc = 1.000 (3.312 sec/step)\n",
      "step 30540 \t loss = 0.126, train_acc = 0.900 (3.261 sec/step)\n",
      "step 30550 \t loss = 0.025, train_acc = 1.000 (3.309 sec/step)\n",
      "step 30560 \t loss = 0.072, train_acc = 1.000 (3.336 sec/step)\n",
      "step 30570 \t loss = 0.189, train_acc = 0.900 (3.277 sec/step)\n",
      "step 30580 \t loss = 0.503, train_acc = 0.800 (3.350 sec/step)\n",
      "step 30590 \t loss = 0.002, train_acc = 1.000 (3.252 sec/step)\n",
      "step 30600 \t loss = 0.245, train_acc = 0.900 (3.319 sec/step)\n",
      "step 30610 \t loss = 0.062, train_acc = 1.000 (3.307 sec/step)\n",
      "step 30620 \t loss = 0.015, train_acc = 1.000 (3.359 sec/step)\n",
      "step 30630 \t loss = 0.053, train_acc = 1.000 (3.285 sec/step)\n",
      "step 30640 \t loss = 0.734, train_acc = 0.900 (3.297 sec/step)\n",
      "step 30650 \t loss = 0.154, train_acc = 1.000 (3.352 sec/step)\n",
      "step 30660 \t loss = 0.062, train_acc = 1.000 (3.339 sec/step)\n",
      "step 30670 \t loss = 0.261, train_acc = 0.900 (3.295 sec/step)\n",
      "step 30680 \t loss = 0.136, train_acc = 0.900 (3.274 sec/step)\n",
      "step 30690 \t loss = 0.057, train_acc = 1.000 (3.266 sec/step)\n",
      "step 30700 \t loss = 0.064, train_acc = 1.000 (3.282 sec/step)\n",
      "step 30710 \t loss = 0.293, train_acc = 0.900 (3.252 sec/step)\n",
      "step 30720 \t loss = 0.073, train_acc = 1.000 (3.255 sec/step)\n",
      "step 30730 \t loss = 0.603, train_acc = 0.900 (3.254 sec/step)\n",
      "step 30740 \t loss = 0.388, train_acc = 0.800 (3.288 sec/step)\n",
      "step 30750 \t loss = 0.261, train_acc = 0.900 (3.256 sec/step)\n",
      "step 30760 \t loss = 1.135, train_acc = 0.800 (3.261 sec/step)\n",
      "step 30770 \t loss = 0.010, train_acc = 1.000 (3.275 sec/step)\n",
      "step 30780 \t loss = 0.007, train_acc = 1.000 (3.301 sec/step)\n",
      "step 30790 \t loss = 0.001, train_acc = 1.000 (3.303 sec/step)\n",
      "step 30800 \t loss = 0.651, train_acc = 0.900 (3.277 sec/step)\n",
      "step 30810 \t loss = 0.267, train_acc = 0.900 (3.274 sec/step)\n",
      "step 30820 \t loss = 0.029, train_acc = 1.000 (3.311 sec/step)\n",
      "step 30830 \t loss = 0.009, train_acc = 1.000 (3.378 sec/step)\n",
      "step 30840 \t loss = 0.610, train_acc = 0.900 (3.273 sec/step)\n",
      "step 30850 \t loss = 0.105, train_acc = 0.900 (3.263 sec/step)\n",
      "step 30860 \t loss = 1.185, train_acc = 0.800 (3.302 sec/step)\n",
      "step 30870 \t loss = 0.061, train_acc = 1.000 (3.275 sec/step)\n",
      "step 30880 \t loss = 0.453, train_acc = 0.800 (3.292 sec/step)\n",
      "step 30890 \t loss = 0.129, train_acc = 1.000 (3.318 sec/step)\n",
      "step 30900 \t loss = 0.042, train_acc = 1.000 (3.334 sec/step)\n",
      "step 30910 \t loss = 0.117, train_acc = 1.000 (3.284 sec/step)\n",
      "step 30920 \t loss = 0.083, train_acc = 1.000 (3.297 sec/step)\n",
      "step 30930 \t loss = 0.230, train_acc = 0.900 (3.368 sec/step)\n",
      "step 30940 \t loss = 0.500, train_acc = 0.800 (3.264 sec/step)\n",
      "step 30950 \t loss = 0.007, train_acc = 1.000 (3.290 sec/step)\n",
      "step 30960 \t loss = 0.335, train_acc = 0.900 (3.299 sec/step)\n",
      "step 30970 \t loss = 0.129, train_acc = 1.000 (3.331 sec/step)\n",
      "step 30980 \t loss = 0.499, train_acc = 0.900 (3.274 sec/step)\n",
      "step 30990 \t loss = 0.119, train_acc = 1.000 (3.317 sec/step)\n",
      "step 31000 \t loss = 0.298, train_acc = 0.900 (3.272 sec/step)\n",
      "step 31010 \t loss = 0.342, train_acc = 0.900 (3.309 sec/step)\n",
      "step 31020 \t loss = 0.069, train_acc = 1.000 (3.350 sec/step)\n",
      "step 31030 \t loss = 1.016, train_acc = 0.900 (3.288 sec/step)\n",
      "step 31040 \t loss = 0.276, train_acc = 0.800 (3.305 sec/step)\n",
      "step 31050 \t loss = 0.053, train_acc = 1.000 (3.360 sec/step)\n",
      "step 31060 \t loss = 0.328, train_acc = 0.900 (3.290 sec/step)\n",
      "step 31070 \t loss = 0.158, train_acc = 0.900 (3.333 sec/step)\n",
      "step 31080 \t loss = 0.320, train_acc = 0.900 (3.273 sec/step)\n",
      "step 31090 \t loss = 0.253, train_acc = 0.900 (3.283 sec/step)\n",
      "step 31100 \t loss = 0.869, train_acc = 0.700 (3.297 sec/step)\n",
      "step 31110 \t loss = 0.135, train_acc = 0.900 (3.313 sec/step)\n",
      "step 31120 \t loss = 0.063, train_acc = 1.000 (3.330 sec/step)\n",
      "step 31130 \t loss = 0.815, train_acc = 0.900 (3.332 sec/step)\n",
      "step 31140 \t loss = 0.194, train_acc = 0.900 (3.253 sec/step)\n",
      "step 31150 \t loss = 0.260, train_acc = 0.900 (3.326 sec/step)\n",
      "step 31160 \t loss = 0.034, train_acc = 1.000 (3.292 sec/step)\n",
      "step 31170 \t loss = 0.335, train_acc = 0.900 (3.312 sec/step)\n",
      "step 31180 \t loss = 0.881, train_acc = 0.800 (3.330 sec/step)\n",
      "step 31190 \t loss = 0.032, train_acc = 1.000 (3.264 sec/step)\n",
      "step 31200 \t loss = 0.081, train_acc = 1.000 (3.343 sec/step)\n",
      "step 31210 \t loss = 0.043, train_acc = 1.000 (3.351 sec/step)\n",
      "step 31220 \t loss = 0.007, train_acc = 1.000 (3.325 sec/step)\n",
      "step 31230 \t loss = 0.033, train_acc = 1.000 (3.281 sec/step)\n",
      "step 31240 \t loss = 0.496, train_acc = 0.800 (3.337 sec/step)\n",
      "step 31250 \t loss = 0.039, train_acc = 1.000 (3.342 sec/step)\n",
      "step 31260 \t loss = 0.089, train_acc = 1.000 (3.253 sec/step)\n",
      "step 31270 \t loss = 0.398, train_acc = 0.900 (3.321 sec/step)\n",
      "step 31280 \t loss = 1.055, train_acc = 0.800 (3.302 sec/step)\n",
      "step 31290 \t loss = 0.629, train_acc = 0.800 (3.282 sec/step)\n",
      "step 31300 \t loss = 0.022, train_acc = 1.000 (3.309 sec/step)\n",
      "step 31310 \t loss = 0.217, train_acc = 0.900 (3.347 sec/step)\n",
      "step 31320 \t loss = 0.046, train_acc = 1.000 (3.316 sec/step)\n",
      "step 31330 \t loss = 0.002, train_acc = 1.000 (3.315 sec/step)\n",
      "step 31340 \t loss = 0.059, train_acc = 1.000 (3.340 sec/step)\n",
      "step 31350 \t loss = 1.238, train_acc = 0.600 (3.281 sec/step)\n",
      "step 31360 \t loss = 0.325, train_acc = 0.900 (3.343 sec/step)\n",
      "step 31370 \t loss = 0.304, train_acc = 0.800 (3.296 sec/step)\n",
      "step 31380 \t loss = 0.358, train_acc = 0.900 (3.285 sec/step)\n",
      "step 31390 \t loss = 0.871, train_acc = 0.800 (3.258 sec/step)\n",
      "step 31400 \t loss = 0.731, train_acc = 0.800 (3.338 sec/step)\n",
      "step 31410 \t loss = 0.290, train_acc = 0.900 (3.357 sec/step)\n",
      "step 31420 \t loss = 0.161, train_acc = 0.900 (3.381 sec/step)\n",
      "step 31430 \t loss = 0.001, train_acc = 1.000 (3.296 sec/step)\n",
      "step 31440 \t loss = 0.224, train_acc = 0.900 (3.298 sec/step)\n",
      "step 31450 \t loss = 0.109, train_acc = 0.900 (3.325 sec/step)\n",
      "step 31460 \t loss = 0.343, train_acc = 0.900 (3.307 sec/step)\n",
      "step 31470 \t loss = 0.002, train_acc = 1.000 (3.300 sec/step)\n",
      "step 31480 \t loss = 0.278, train_acc = 0.900 (3.280 sec/step)\n",
      "step 31490 \t loss = 0.705, train_acc = 0.700 (3.252 sec/step)\n",
      "step 31500 \t loss = 0.041, train_acc = 1.000 (3.335 sec/step)\n",
      "step 31510 \t loss = 0.315, train_acc = 0.800 (3.300 sec/step)\n",
      "step 31520 \t loss = 1.521, train_acc = 0.900 (3.260 sec/step)\n",
      "step 31530 \t loss = 0.152, train_acc = 0.900 (3.303 sec/step)\n",
      "step 31540 \t loss = 1.096, train_acc = 0.900 (3.338 sec/step)\n",
      "step 31550 \t loss = 0.003, train_acc = 1.000 (3.313 sec/step)\n",
      "step 31560 \t loss = 1.408, train_acc = 0.700 (3.347 sec/step)\n",
      "step 31570 \t loss = 0.149, train_acc = 1.000 (3.296 sec/step)\n",
      "step 31580 \t loss = 0.134, train_acc = 1.000 (3.252 sec/step)\n",
      "step 31590 \t loss = 0.111, train_acc = 1.000 (3.351 sec/step)\n",
      "step 31600 \t loss = 0.896, train_acc = 0.700 (3.352 sec/step)\n",
      "step 31610 \t loss = 0.195, train_acc = 0.900 (3.300 sec/step)\n",
      "step 31620 \t loss = 0.034, train_acc = 1.000 (3.277 sec/step)\n",
      "step 31630 \t loss = 0.394, train_acc = 0.900 (3.316 sec/step)\n",
      "step 31640 \t loss = 0.042, train_acc = 1.000 (3.285 sec/step)\n",
      "step 31650 \t loss = 0.076, train_acc = 1.000 (3.331 sec/step)\n",
      "step 31660 \t loss = 0.307, train_acc = 0.900 (3.311 sec/step)\n",
      "step 31670 \t loss = 0.015, train_acc = 1.000 (3.348 sec/step)\n",
      "step 31680 \t loss = 0.002, train_acc = 1.000 (3.393 sec/step)\n",
      "step 31690 \t loss = 0.393, train_acc = 0.900 (3.260 sec/step)\n",
      "step 31700 \t loss = 0.007, train_acc = 1.000 (3.306 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 31710 \t loss = 0.560, train_acc = 0.900 (3.331 sec/step)\n",
      "step 31720 \t loss = 0.166, train_acc = 0.900 (3.267 sec/step)\n",
      "step 31730 \t loss = 0.328, train_acc = 0.900 (3.286 sec/step)\n",
      "step 31740 \t loss = 0.666, train_acc = 0.800 (3.295 sec/step)\n",
      "step 31750 \t loss = 0.005, train_acc = 1.000 (3.268 sec/step)\n",
      "step 31760 \t loss = 0.641, train_acc = 0.800 (3.337 sec/step)\n",
      "step 31770 \t loss = 0.741, train_acc = 0.900 (3.326 sec/step)\n",
      "step 31780 \t loss = 0.041, train_acc = 1.000 (3.316 sec/step)\n",
      "step 31790 \t loss = 0.157, train_acc = 1.000 (3.318 sec/step)\n",
      "step 31800 \t loss = 0.042, train_acc = 1.000 (3.319 sec/step)\n",
      "step 31810 \t loss = 0.144, train_acc = 0.900 (3.256 sec/step)\n",
      "step 31820 \t loss = 0.665, train_acc = 0.700 (3.332 sec/step)\n",
      "step 31830 \t loss = 0.147, train_acc = 0.900 (3.264 sec/step)\n",
      "step 31840 \t loss = 0.137, train_acc = 0.900 (3.286 sec/step)\n",
      "step 31850 \t loss = 0.031, train_acc = 1.000 (3.297 sec/step)\n",
      "step 31860 \t loss = 0.477, train_acc = 0.800 (3.283 sec/step)\n",
      "step 31870 \t loss = 0.020, train_acc = 1.000 (3.315 sec/step)\n",
      "step 31880 \t loss = 0.195, train_acc = 0.900 (3.283 sec/step)\n",
      "step 31890 \t loss = 0.914, train_acc = 0.900 (3.414 sec/step)\n",
      "step 31900 \t loss = 0.015, train_acc = 1.000 (3.266 sec/step)\n",
      "step 31910 \t loss = 1.402, train_acc = 0.800 (3.353 sec/step)\n",
      "step 31920 \t loss = 0.538, train_acc = 0.900 (3.305 sec/step)\n",
      "step 31930 \t loss = 0.023, train_acc = 1.000 (3.366 sec/step)\n",
      "step 31940 \t loss = 0.915, train_acc = 0.800 (3.338 sec/step)\n",
      "step 31950 \t loss = 0.207, train_acc = 0.900 (3.303 sec/step)\n",
      "step 31960 \t loss = 0.652, train_acc = 0.800 (3.292 sec/step)\n",
      "step 31970 \t loss = 0.003, train_acc = 1.000 (3.274 sec/step)\n",
      "step 31980 \t loss = 0.045, train_acc = 1.000 (3.272 sec/step)\n",
      "step 31990 \t loss = 0.050, train_acc = 1.000 (3.298 sec/step)\n",
      "step 32000 \t loss = 0.112, train_acc = 1.000 (3.303 sec/step)\n",
      "step 32010 \t loss = 0.699, train_acc = 0.900 (3.333 sec/step)\n",
      "step 32020 \t loss = 0.026, train_acc = 1.000 (3.251 sec/step)\n",
      "step 32030 \t loss = 0.426, train_acc = 0.800 (3.258 sec/step)\n",
      "step 32040 \t loss = 0.465, train_acc = 0.900 (3.369 sec/step)\n",
      "step 32050 \t loss = 0.699, train_acc = 0.800 (3.323 sec/step)\n",
      "step 32060 \t loss = 0.439, train_acc = 0.800 (3.304 sec/step)\n",
      "step 32070 \t loss = 0.015, train_acc = 1.000 (3.313 sec/step)\n",
      "step 32080 \t loss = 0.004, train_acc = 1.000 (3.284 sec/step)\n",
      "step 32090 \t loss = 0.001, train_acc = 1.000 (3.297 sec/step)\n",
      "step 32100 \t loss = 0.000, train_acc = 1.000 (3.290 sec/step)\n",
      "step 32110 \t loss = 0.607, train_acc = 0.800 (3.292 sec/step)\n",
      "step 32120 \t loss = 0.161, train_acc = 1.000 (3.337 sec/step)\n",
      "step 32130 \t loss = 0.840, train_acc = 0.600 (3.375 sec/step)\n",
      "step 32140 \t loss = 0.012, train_acc = 1.000 (3.327 sec/step)\n",
      "step 32150 \t loss = 0.946, train_acc = 0.700 (3.303 sec/step)\n",
      "step 32160 \t loss = 0.201, train_acc = 1.000 (3.284 sec/step)\n",
      "step 32170 \t loss = 0.015, train_acc = 1.000 (3.306 sec/step)\n",
      "step 32180 \t loss = 0.008, train_acc = 1.000 (3.274 sec/step)\n",
      "step 32190 \t loss = 1.019, train_acc = 0.800 (3.320 sec/step)\n",
      "step 32200 \t loss = 2.159, train_acc = 0.500 (3.292 sec/step)\n",
      "step 32210 \t loss = 1.230, train_acc = 0.800 (3.297 sec/step)\n",
      "step 32220 \t loss = 2.087, train_acc = 0.500 (3.298 sec/step)\n",
      "step 32230 \t loss = 1.304, train_acc = 0.600 (3.306 sec/step)\n",
      "step 32240 \t loss = 1.508, train_acc = 0.500 (3.354 sec/step)\n",
      "step 32250 \t loss = 1.173, train_acc = 0.800 (3.310 sec/step)\n",
      "step 32260 \t loss = 1.201, train_acc = 0.800 (3.310 sec/step)\n",
      "step 32270 \t loss = 0.557, train_acc = 0.900 (3.309 sec/step)\n",
      "step 32280 \t loss = 0.244, train_acc = 1.000 (3.329 sec/step)\n",
      "step 32290 \t loss = 0.223, train_acc = 0.900 (3.274 sec/step)\n",
      "VALIDATION \t acc = 0.526 (3.617 sec)\n",
      "step 32300 \t loss = 0.077, train_acc = 1.000 (3.285 sec/step)\n",
      "step 32310 \t loss = 0.181, train_acc = 0.900 (3.327 sec/step)\n",
      "step 32320 \t loss = 0.033, train_acc = 1.000 (3.286 sec/step)\n",
      "step 32330 \t loss = 0.058, train_acc = 1.000 (3.292 sec/step)\n",
      "step 32340 \t loss = 0.171, train_acc = 0.900 (3.274 sec/step)\n",
      "step 32350 \t loss = 1.088, train_acc = 0.800 (3.301 sec/step)\n",
      "step 32360 \t loss = 0.941, train_acc = 0.800 (3.320 sec/step)\n",
      "step 32370 \t loss = 0.104, train_acc = 0.900 (3.293 sec/step)\n",
      "step 32380 \t loss = 0.081, train_acc = 0.900 (3.329 sec/step)\n",
      "step 32390 \t loss = 0.409, train_acc = 0.900 (3.318 sec/step)\n",
      "step 32400 \t loss = 0.006, train_acc = 1.000 (3.280 sec/step)\n",
      "step 32410 \t loss = 0.000, train_acc = 1.000 (3.311 sec/step)\n",
      "step 32420 \t loss = 0.851, train_acc = 0.900 (3.316 sec/step)\n",
      "step 32430 \t loss = 0.037, train_acc = 1.000 (3.329 sec/step)\n",
      "step 32440 \t loss = 0.854, train_acc = 0.700 (3.342 sec/step)\n",
      "step 32450 \t loss = 0.045, train_acc = 1.000 (3.256 sec/step)\n",
      "step 32460 \t loss = 0.550, train_acc = 0.900 (3.376 sec/step)\n",
      "step 32470 \t loss = 0.015, train_acc = 1.000 (3.304 sec/step)\n",
      "step 32480 \t loss = 0.048, train_acc = 1.000 (3.257 sec/step)\n",
      "step 32490 \t loss = 0.131, train_acc = 0.900 (3.276 sec/step)\n",
      "step 32500 \t loss = 0.562, train_acc = 0.700 (3.334 sec/step)\n",
      "step 32510 \t loss = 0.135, train_acc = 0.900 (3.338 sec/step)\n",
      "step 32520 \t loss = 0.236, train_acc = 0.900 (3.339 sec/step)\n",
      "step 32530 \t loss = 0.084, train_acc = 1.000 (3.325 sec/step)\n",
      "step 32540 \t loss = 0.004, train_acc = 1.000 (3.328 sec/step)\n",
      "step 32550 \t loss = 0.094, train_acc = 1.000 (3.300 sec/step)\n",
      "step 32560 \t loss = 0.369, train_acc = 0.800 (3.394 sec/step)\n",
      "step 32570 \t loss = 0.088, train_acc = 1.000 (3.313 sec/step)\n",
      "step 32580 \t loss = 0.002, train_acc = 1.000 (3.314 sec/step)\n",
      "step 32590 \t loss = 0.010, train_acc = 1.000 (3.329 sec/step)\n",
      "step 32600 \t loss = 0.165, train_acc = 0.900 (3.280 sec/step)\n",
      "step 32610 \t loss = 0.183, train_acc = 0.900 (3.281 sec/step)\n",
      "step 32620 \t loss = 0.322, train_acc = 0.900 (3.319 sec/step)\n",
      "step 32630 \t loss = 0.354, train_acc = 0.900 (3.322 sec/step)\n",
      "step 32640 \t loss = 0.172, train_acc = 1.000 (3.272 sec/step)\n",
      "step 32650 \t loss = 0.211, train_acc = 0.900 (3.365 sec/step)\n",
      "step 32660 \t loss = 0.249, train_acc = 0.800 (3.361 sec/step)\n",
      "step 32670 \t loss = 0.171, train_acc = 0.900 (3.279 sec/step)\n",
      "step 32680 \t loss = 0.602, train_acc = 0.900 (3.270 sec/step)\n",
      "step 32690 \t loss = 0.027, train_acc = 1.000 (3.342 sec/step)\n",
      "step 32700 \t loss = 0.840, train_acc = 0.700 (3.279 sec/step)\n",
      "step 32710 \t loss = 0.324, train_acc = 0.900 (3.317 sec/step)\n",
      "step 32720 \t loss = 0.184, train_acc = 0.900 (3.308 sec/step)\n",
      "step 32730 \t loss = 0.941, train_acc = 0.700 (3.320 sec/step)\n",
      "step 32740 \t loss = 0.251, train_acc = 0.900 (3.306 sec/step)\n",
      "step 32750 \t loss = 0.203, train_acc = 0.900 (3.459 sec/step)\n",
      "step 32760 \t loss = 0.931, train_acc = 0.900 (3.290 sec/step)\n",
      "step 32770 \t loss = 0.111, train_acc = 0.900 (3.291 sec/step)\n",
      "step 32780 \t loss = 0.033, train_acc = 1.000 (3.340 sec/step)\n",
      "step 32790 \t loss = 0.024, train_acc = 1.000 (3.390 sec/step)\n",
      "step 32800 \t loss = 1.066, train_acc = 0.900 (3.266 sec/step)\n",
      "step 32810 \t loss = 0.397, train_acc = 0.900 (3.303 sec/step)\n",
      "step 32820 \t loss = 0.303, train_acc = 0.800 (3.304 sec/step)\n",
      "step 32830 \t loss = 0.180, train_acc = 1.000 (3.354 sec/step)\n",
      "step 32840 \t loss = 0.022, train_acc = 1.000 (3.376 sec/step)\n",
      "step 32850 \t loss = 0.003, train_acc = 1.000 (3.305 sec/step)\n",
      "step 32860 \t loss = 0.006, train_acc = 1.000 (3.262 sec/step)\n",
      "step 32870 \t loss = 0.435, train_acc = 0.800 (3.353 sec/step)\n",
      "step 32880 \t loss = 0.190, train_acc = 0.900 (3.324 sec/step)\n",
      "step 32890 \t loss = 0.039, train_acc = 1.000 (3.306 sec/step)\n",
      "step 32900 \t loss = 0.078, train_acc = 1.000 (3.301 sec/step)\n",
      "step 32910 \t loss = 0.090, train_acc = 1.000 (3.330 sec/step)\n",
      "step 32920 \t loss = 0.298, train_acc = 0.900 (3.317 sec/step)\n",
      "step 32930 \t loss = 0.240, train_acc = 0.900 (3.268 sec/step)\n",
      "step 32940 \t loss = 1.241, train_acc = 0.800 (3.290 sec/step)\n",
      "step 32950 \t loss = 0.035, train_acc = 1.000 (3.319 sec/step)\n",
      "step 32960 \t loss = 0.002, train_acc = 1.000 (3.283 sec/step)\n",
      "step 32970 \t loss = 0.138, train_acc = 0.900 (3.252 sec/step)\n",
      "step 32980 \t loss = 0.068, train_acc = 1.000 (3.352 sec/step)\n",
      "step 32990 \t loss = 0.214, train_acc = 1.000 (3.359 sec/step)\n",
      "step 33000 \t loss = 0.593, train_acc = 0.900 (3.279 sec/step)\n",
      "step 33010 \t loss = 0.004, train_acc = 1.000 (3.302 sec/step)\n",
      "step 33020 \t loss = 0.730, train_acc = 0.800 (3.295 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 33030 \t loss = 0.176, train_acc = 0.900 (3.343 sec/step)\n",
      "step 33040 \t loss = 0.000, train_acc = 1.000 (3.317 sec/step)\n",
      "step 33050 \t loss = 0.055, train_acc = 1.000 (3.306 sec/step)\n",
      "step 33060 \t loss = 0.287, train_acc = 0.900 (3.279 sec/step)\n",
      "step 33070 \t loss = 0.447, train_acc = 0.900 (3.293 sec/step)\n",
      "step 33080 \t loss = 0.026, train_acc = 1.000 (3.291 sec/step)\n",
      "step 33090 \t loss = 0.022, train_acc = 1.000 (3.265 sec/step)\n",
      "step 33100 \t loss = 2.532, train_acc = 0.800 (3.337 sec/step)\n",
      "step 33110 \t loss = 0.315, train_acc = 0.900 (3.332 sec/step)\n",
      "step 33120 \t loss = 0.463, train_acc = 0.800 (3.296 sec/step)\n",
      "step 33130 \t loss = 0.004, train_acc = 1.000 (3.302 sec/step)\n",
      "step 33140 \t loss = 0.780, train_acc = 0.800 (3.308 sec/step)\n",
      "step 33150 \t loss = 0.163, train_acc = 1.000 (3.313 sec/step)\n",
      "step 33160 \t loss = 0.549, train_acc = 0.900 (3.282 sec/step)\n",
      "step 33170 \t loss = 0.157, train_acc = 0.900 (3.303 sec/step)\n",
      "step 33180 \t loss = 0.027, train_acc = 1.000 (3.291 sec/step)\n",
      "step 33190 \t loss = 0.033, train_acc = 1.000 (3.286 sec/step)\n",
      "step 33200 \t loss = 0.002, train_acc = 1.000 (3.269 sec/step)\n",
      "step 33210 \t loss = 0.124, train_acc = 1.000 (3.302 sec/step)\n",
      "step 33220 \t loss = 0.281, train_acc = 0.800 (3.255 sec/step)\n",
      "step 33230 \t loss = 0.004, train_acc = 1.000 (3.320 sec/step)\n",
      "step 33240 \t loss = 0.085, train_acc = 1.000 (3.296 sec/step)\n",
      "step 33250 \t loss = 0.054, train_acc = 1.000 (3.253 sec/step)\n",
      "step 33260 \t loss = 0.260, train_acc = 0.900 (3.301 sec/step)\n",
      "step 33270 \t loss = 0.736, train_acc = 0.900 (3.325 sec/step)\n",
      "step 33280 \t loss = 0.357, train_acc = 0.800 (3.265 sec/step)\n",
      "step 33290 \t loss = 0.137, train_acc = 0.900 (3.251 sec/step)\n",
      "step 33300 \t loss = 0.011, train_acc = 1.000 (3.383 sec/step)\n",
      "step 33310 \t loss = 1.115, train_acc = 0.800 (3.339 sec/step)\n",
      "step 33320 \t loss = 0.280, train_acc = 0.900 (3.257 sec/step)\n",
      "step 33330 \t loss = 0.261, train_acc = 0.900 (3.328 sec/step)\n",
      "step 33340 \t loss = 0.373, train_acc = 0.900 (3.321 sec/step)\n",
      "step 33350 \t loss = 0.675, train_acc = 0.700 (3.319 sec/step)\n",
      "step 33360 \t loss = 0.082, train_acc = 1.000 (3.314 sec/step)\n",
      "step 33370 \t loss = 0.004, train_acc = 1.000 (3.317 sec/step)\n",
      "step 33380 \t loss = 0.225, train_acc = 0.900 (3.297 sec/step)\n",
      "step 33390 \t loss = 0.035, train_acc = 1.000 (3.283 sec/step)\n",
      "step 33400 \t loss = 0.051, train_acc = 1.000 (3.285 sec/step)\n",
      "step 33410 \t loss = 0.063, train_acc = 1.000 (3.326 sec/step)\n",
      "step 33420 \t loss = 0.000, train_acc = 1.000 (3.332 sec/step)\n",
      "step 33430 \t loss = 0.060, train_acc = 1.000 (3.331 sec/step)\n",
      "step 33440 \t loss = 0.096, train_acc = 1.000 (3.332 sec/step)\n",
      "step 33450 \t loss = 0.101, train_acc = 0.900 (3.278 sec/step)\n",
      "step 33460 \t loss = 0.085, train_acc = 1.000 (3.309 sec/step)\n",
      "step 33470 \t loss = 0.245, train_acc = 0.900 (3.328 sec/step)\n",
      "step 33480 \t loss = 0.186, train_acc = 0.900 (3.300 sec/step)\n",
      "step 33490 \t loss = 0.070, train_acc = 1.000 (3.259 sec/step)\n",
      "step 33500 \t loss = 0.192, train_acc = 0.900 (3.357 sec/step)\n",
      "step 33510 \t loss = 0.171, train_acc = 0.900 (3.322 sec/step)\n",
      "step 33520 \t loss = 0.189, train_acc = 0.900 (3.279 sec/step)\n",
      "step 33530 \t loss = 0.183, train_acc = 1.000 (3.317 sec/step)\n",
      "step 33540 \t loss = 0.241, train_acc = 0.900 (3.333 sec/step)\n",
      "step 33550 \t loss = 0.859, train_acc = 0.700 (3.395 sec/step)\n",
      "step 33560 \t loss = 0.678, train_acc = 0.900 (3.295 sec/step)\n",
      "step 33570 \t loss = 0.312, train_acc = 0.900 (3.275 sec/step)\n",
      "step 33580 \t loss = 0.723, train_acc = 0.800 (3.304 sec/step)\n",
      "step 33590 \t loss = 0.718, train_acc = 0.800 (3.313 sec/step)\n",
      "step 33600 \t loss = 0.154, train_acc = 0.900 (3.328 sec/step)\n",
      "step 33610 \t loss = 0.062, train_acc = 1.000 (3.358 sec/step)\n",
      "step 33620 \t loss = 0.092, train_acc = 1.000 (3.332 sec/step)\n",
      "step 33630 \t loss = 0.445, train_acc = 0.900 (3.266 sec/step)\n",
      "step 33640 \t loss = 0.027, train_acc = 1.000 (3.315 sec/step)\n",
      "step 33650 \t loss = 0.322, train_acc = 0.900 (3.295 sec/step)\n",
      "step 33660 \t loss = 0.006, train_acc = 1.000 (3.328 sec/step)\n",
      "step 33670 \t loss = 0.061, train_acc = 1.000 (3.301 sec/step)\n",
      "step 33680 \t loss = 0.349, train_acc = 0.900 (3.292 sec/step)\n",
      "step 33690 \t loss = 1.927, train_acc = 0.600 (3.305 sec/step)\n",
      "step 33700 \t loss = 0.012, train_acc = 1.000 (3.280 sec/step)\n",
      "step 33710 \t loss = 0.316, train_acc = 0.900 (3.274 sec/step)\n",
      "step 33720 \t loss = 0.208, train_acc = 0.900 (3.317 sec/step)\n",
      "step 33730 \t loss = 0.070, train_acc = 1.000 (3.354 sec/step)\n",
      "step 33740 \t loss = 0.224, train_acc = 0.900 (3.332 sec/step)\n",
      "step 33750 \t loss = 0.077, train_acc = 1.000 (3.279 sec/step)\n",
      "step 33760 \t loss = 0.044, train_acc = 1.000 (3.300 sec/step)\n",
      "step 33770 \t loss = 0.142, train_acc = 1.000 (3.282 sec/step)\n",
      "step 33780 \t loss = 0.186, train_acc = 0.900 (3.328 sec/step)\n",
      "step 33790 \t loss = 0.399, train_acc = 0.800 (3.311 sec/step)\n",
      "step 33800 \t loss = 0.285, train_acc = 0.900 (3.305 sec/step)\n",
      "step 33810 \t loss = 0.181, train_acc = 0.900 (3.311 sec/step)\n",
      "step 33820 \t loss = 0.530, train_acc = 0.900 (3.286 sec/step)\n",
      "step 33830 \t loss = 0.208, train_acc = 0.900 (3.262 sec/step)\n",
      "step 33840 \t loss = 1.580, train_acc = 0.700 (3.343 sec/step)\n",
      "step 33850 \t loss = 1.374, train_acc = 0.600 (3.379 sec/step)\n",
      "step 33860 \t loss = 0.364, train_acc = 0.900 (3.341 sec/step)\n",
      "step 33870 \t loss = 0.278, train_acc = 0.900 (3.275 sec/step)\n",
      "step 33880 \t loss = 0.215, train_acc = 0.900 (3.268 sec/step)\n",
      "step 33890 \t loss = 0.001, train_acc = 1.000 (3.273 sec/step)\n",
      "step 33900 \t loss = 0.220, train_acc = 0.900 (3.332 sec/step)\n",
      "step 33910 \t loss = 0.031, train_acc = 1.000 (3.265 sec/step)\n",
      "step 33920 \t loss = 0.229, train_acc = 0.900 (3.317 sec/step)\n",
      "step 33930 \t loss = 0.570, train_acc = 0.800 (3.324 sec/step)\n",
      "step 33940 \t loss = 0.614, train_acc = 0.800 (3.271 sec/step)\n",
      "step 33950 \t loss = 0.305, train_acc = 0.900 (3.438 sec/step)\n",
      "step 33960 \t loss = 0.055, train_acc = 1.000 (3.322 sec/step)\n",
      "step 33970 \t loss = 0.243, train_acc = 0.900 (3.255 sec/step)\n",
      "step 33980 \t loss = 0.917, train_acc = 0.900 (3.287 sec/step)\n",
      "step 33990 \t loss = 0.214, train_acc = 0.900 (3.312 sec/step)\n",
      "step 34000 \t loss = 0.108, train_acc = 1.000 (3.292 sec/step)\n",
      "step 34010 \t loss = 0.074, train_acc = 1.000 (3.268 sec/step)\n",
      "step 34020 \t loss = 0.562, train_acc = 0.700 (3.359 sec/step)\n",
      "step 34030 \t loss = 0.308, train_acc = 0.900 (3.329 sec/step)\n",
      "step 34040 \t loss = 0.022, train_acc = 1.000 (3.311 sec/step)\n",
      "step 34050 \t loss = 0.071, train_acc = 1.000 (3.294 sec/step)\n",
      "step 34060 \t loss = 0.006, train_acc = 1.000 (3.301 sec/step)\n",
      "step 34070 \t loss = 0.227, train_acc = 0.900 (3.301 sec/step)\n",
      "step 34080 \t loss = 0.725, train_acc = 0.800 (3.269 sec/step)\n",
      "step 34090 \t loss = 0.066, train_acc = 1.000 (3.256 sec/step)\n",
      "step 34100 \t loss = 0.635, train_acc = 0.800 (3.326 sec/step)\n",
      "step 34110 \t loss = 0.647, train_acc = 0.800 (3.350 sec/step)\n",
      "step 34120 \t loss = 0.085, train_acc = 1.000 (3.345 sec/step)\n",
      "step 34130 \t loss = 0.131, train_acc = 0.900 (3.296 sec/step)\n",
      "step 34140 \t loss = 1.139, train_acc = 0.800 (3.327 sec/step)\n",
      "step 34150 \t loss = 0.007, train_acc = 1.000 (3.298 sec/step)\n",
      "step 34160 \t loss = 0.113, train_acc = 1.000 (3.278 sec/step)\n",
      "step 34170 \t loss = 0.009, train_acc = 1.000 (3.311 sec/step)\n",
      "step 34180 \t loss = 0.016, train_acc = 1.000 (3.377 sec/step)\n",
      "step 34190 \t loss = 0.121, train_acc = 0.900 (3.323 sec/step)\n",
      "VALIDATION \t acc = 0.543 (3.652 sec)\n",
      "step 34200 \t loss = 0.018, train_acc = 1.000 (3.305 sec/step)\n",
      "step 34210 \t loss = 0.087, train_acc = 1.000 (3.291 sec/step)\n",
      "step 34220 \t loss = 0.208, train_acc = 0.900 (3.278 sec/step)\n",
      "step 34230 \t loss = 0.143, train_acc = 1.000 (3.268 sec/step)\n",
      "step 34240 \t loss = 0.023, train_acc = 1.000 (3.293 sec/step)\n",
      "step 34250 \t loss = 0.536, train_acc = 0.800 (3.280 sec/step)\n",
      "step 34260 \t loss = 0.003, train_acc = 1.000 (3.309 sec/step)\n",
      "step 34270 \t loss = 0.016, train_acc = 1.000 (3.312 sec/step)\n",
      "step 34280 \t loss = 0.173, train_acc = 0.900 (3.334 sec/step)\n",
      "step 34290 \t loss = 0.277, train_acc = 0.800 (3.292 sec/step)\n",
      "step 34300 \t loss = 0.279, train_acc = 0.900 (3.271 sec/step)\n",
      "step 34310 \t loss = 1.419, train_acc = 0.800 (3.351 sec/step)\n",
      "step 34320 \t loss = 0.183, train_acc = 0.900 (3.298 sec/step)\n",
      "step 34330 \t loss = 0.378, train_acc = 0.900 (3.329 sec/step)\n",
      "step 34340 \t loss = 0.001, train_acc = 1.000 (3.283 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 34350 \t loss = 0.570, train_acc = 0.800 (3.380 sec/step)\n",
      "step 34360 \t loss = 0.126, train_acc = 1.000 (3.278 sec/step)\n",
      "step 34370 \t loss = 0.004, train_acc = 1.000 (3.315 sec/step)\n",
      "step 34380 \t loss = 0.004, train_acc = 1.000 (3.330 sec/step)\n",
      "step 34390 \t loss = 0.000, train_acc = 1.000 (3.296 sec/step)\n",
      "step 34400 \t loss = 0.157, train_acc = 1.000 (3.305 sec/step)\n",
      "step 34410 \t loss = 0.180, train_acc = 0.900 (3.301 sec/step)\n",
      "step 34420 \t loss = 1.285, train_acc = 0.800 (3.281 sec/step)\n",
      "step 34430 \t loss = 0.141, train_acc = 0.900 (3.301 sec/step)\n",
      "step 34440 \t loss = 0.344, train_acc = 0.900 (3.296 sec/step)\n",
      "step 34450 \t loss = 0.026, train_acc = 1.000 (3.350 sec/step)\n",
      "step 34460 \t loss = 0.180, train_acc = 1.000 (3.305 sec/step)\n",
      "step 34470 \t loss = 1.182, train_acc = 0.700 (3.323 sec/step)\n",
      "step 34480 \t loss = 0.950, train_acc = 0.800 (3.271 sec/step)\n",
      "step 34490 \t loss = 0.032, train_acc = 1.000 (3.327 sec/step)\n",
      "step 34500 \t loss = 0.006, train_acc = 1.000 (3.321 sec/step)\n",
      "step 34510 \t loss = 0.425, train_acc = 0.800 (3.299 sec/step)\n",
      "step 34520 \t loss = 0.344, train_acc = 0.800 (3.279 sec/step)\n",
      "step 34530 \t loss = 0.539, train_acc = 0.800 (3.272 sec/step)\n",
      "step 34540 \t loss = 0.781, train_acc = 0.800 (3.285 sec/step)\n",
      "step 34550 \t loss = 0.079, train_acc = 1.000 (3.298 sec/step)\n",
      "step 34560 \t loss = 0.047, train_acc = 1.000 (3.316 sec/step)\n",
      "step 34570 \t loss = 0.009, train_acc = 1.000 (3.311 sec/step)\n",
      "step 34580 \t loss = 0.066, train_acc = 1.000 (3.290 sec/step)\n",
      "step 34590 \t loss = 0.045, train_acc = 1.000 (3.260 sec/step)\n",
      "step 34600 \t loss = 1.290, train_acc = 0.700 (3.362 sec/step)\n",
      "step 34610 \t loss = 0.229, train_acc = 0.900 (3.291 sec/step)\n",
      "step 34620 \t loss = 0.214, train_acc = 0.900 (3.273 sec/step)\n",
      "step 34630 \t loss = 0.159, train_acc = 0.900 (3.315 sec/step)\n",
      "step 34640 \t loss = 1.275, train_acc = 0.800 (3.350 sec/step)\n",
      "step 34650 \t loss = 0.351, train_acc = 0.900 (3.337 sec/step)\n",
      "step 34660 \t loss = 0.028, train_acc = 1.000 (3.306 sec/step)\n",
      "step 34670 \t loss = 0.189, train_acc = 0.900 (3.337 sec/step)\n",
      "step 34680 \t loss = 0.001, train_acc = 1.000 (3.309 sec/step)\n",
      "step 34690 \t loss = 1.692, train_acc = 0.800 (3.354 sec/step)\n",
      "step 34700 \t loss = 0.834, train_acc = 0.700 (3.288 sec/step)\n",
      "step 34710 \t loss = 0.315, train_acc = 0.900 (3.331 sec/step)\n",
      "step 34720 \t loss = 0.076, train_acc = 1.000 (3.339 sec/step)\n",
      "step 34730 \t loss = 0.012, train_acc = 1.000 (3.308 sec/step)\n",
      "step 34740 \t loss = 0.039, train_acc = 1.000 (3.286 sec/step)\n",
      "step 34750 \t loss = 0.006, train_acc = 1.000 (3.302 sec/step)\n",
      "step 34760 \t loss = 0.333, train_acc = 0.900 (3.350 sec/step)\n",
      "step 34770 \t loss = 0.200, train_acc = 0.900 (3.343 sec/step)\n",
      "step 34780 \t loss = 0.103, train_acc = 1.000 (3.254 sec/step)\n",
      "step 34790 \t loss = 0.037, train_acc = 1.000 (3.362 sec/step)\n",
      "step 34800 \t loss = 0.039, train_acc = 1.000 (3.288 sec/step)\n",
      "step 34810 \t loss = 2.006, train_acc = 0.900 (3.284 sec/step)\n",
      "step 34820 \t loss = 0.839, train_acc = 0.700 (3.297 sec/step)\n",
      "step 34830 \t loss = 0.207, train_acc = 1.000 (3.287 sec/step)\n",
      "step 34840 \t loss = 0.039, train_acc = 1.000 (3.332 sec/step)\n",
      "step 34850 \t loss = 0.295, train_acc = 0.900 (3.364 sec/step)\n",
      "step 34860 \t loss = 0.002, train_acc = 1.000 (3.339 sec/step)\n",
      "step 34870 \t loss = 0.486, train_acc = 0.900 (3.311 sec/step)\n",
      "step 34880 \t loss = 0.040, train_acc = 1.000 (3.296 sec/step)\n",
      "step 34890 \t loss = 0.052, train_acc = 1.000 (3.412 sec/step)\n",
      "step 34900 \t loss = 0.164, train_acc = 1.000 (3.323 sec/step)\n",
      "step 34910 \t loss = 0.854, train_acc = 0.800 (3.339 sec/step)\n",
      "step 34920 \t loss = 0.507, train_acc = 0.800 (3.281 sec/step)\n",
      "step 34930 \t loss = 0.211, train_acc = 1.000 (3.264 sec/step)\n",
      "step 34940 \t loss = 0.121, train_acc = 0.900 (3.350 sec/step)\n",
      "step 34950 \t loss = 0.379, train_acc = 0.900 (3.276 sec/step)\n",
      "step 34960 \t loss = 0.051, train_acc = 1.000 (3.333 sec/step)\n",
      "step 34970 \t loss = 0.287, train_acc = 0.900 (3.308 sec/step)\n",
      "step 34980 \t loss = 0.012, train_acc = 1.000 (3.294 sec/step)\n",
      "step 34990 \t loss = 0.004, train_acc = 1.000 (3.335 sec/step)\n",
      "step 35000 \t loss = 0.121, train_acc = 0.900 (3.276 sec/step)\n",
      "step 35010 \t loss = 1.074, train_acc = 0.700 (3.259 sec/step)\n",
      "step 35020 \t loss = 0.002, train_acc = 1.000 (3.285 sec/step)\n",
      "step 35030 \t loss = 0.281, train_acc = 0.900 (3.273 sec/step)\n",
      "step 35040 \t loss = 0.176, train_acc = 1.000 (3.289 sec/step)\n",
      "step 35050 \t loss = 0.011, train_acc = 1.000 (3.296 sec/step)\n",
      "step 35060 \t loss = 0.305, train_acc = 0.800 (3.348 sec/step)\n",
      "step 35070 \t loss = 0.211, train_acc = 0.900 (3.312 sec/step)\n",
      "step 35080 \t loss = 0.171, train_acc = 0.900 (3.283 sec/step)\n",
      "step 35090 \t loss = 0.722, train_acc = 0.800 (3.281 sec/step)\n",
      "step 35100 \t loss = 0.367, train_acc = 0.800 (3.343 sec/step)\n",
      "step 35110 \t loss = 0.697, train_acc = 0.800 (3.329 sec/step)\n",
      "step 35120 \t loss = 0.012, train_acc = 1.000 (3.318 sec/step)\n",
      "step 35130 \t loss = 0.016, train_acc = 1.000 (3.315 sec/step)\n",
      "step 35140 \t loss = 0.456, train_acc = 0.900 (3.354 sec/step)\n",
      "step 35150 \t loss = 0.139, train_acc = 0.900 (3.330 sec/step)\n",
      "step 35160 \t loss = 0.002, train_acc = 1.000 (3.309 sec/step)\n",
      "step 35170 \t loss = 0.249, train_acc = 0.900 (3.349 sec/step)\n",
      "step 35180 \t loss = 0.364, train_acc = 0.900 (3.345 sec/step)\n",
      "step 35190 \t loss = 0.284, train_acc = 0.900 (3.304 sec/step)\n",
      "step 35200 \t loss = 0.008, train_acc = 1.000 (3.361 sec/step)\n",
      "step 35210 \t loss = 0.093, train_acc = 1.000 (3.339 sec/step)\n",
      "step 35220 \t loss = 1.192, train_acc = 0.900 (3.330 sec/step)\n",
      "step 35230 \t loss = 0.124, train_acc = 0.900 (3.349 sec/step)\n",
      "step 35240 \t loss = 0.071, train_acc = 1.000 (3.343 sec/step)\n",
      "step 35250 \t loss = 0.043, train_acc = 1.000 (3.289 sec/step)\n",
      "step 35260 \t loss = 0.085, train_acc = 1.000 (3.342 sec/step)\n",
      "step 35270 \t loss = 0.219, train_acc = 0.900 (3.283 sec/step)\n",
      "step 35280 \t loss = 0.525, train_acc = 0.800 (3.286 sec/step)\n",
      "step 35290 \t loss = 0.154, train_acc = 0.900 (3.300 sec/step)\n",
      "step 35300 \t loss = 0.076, train_acc = 1.000 (3.273 sec/step)\n",
      "step 35310 \t loss = 0.317, train_acc = 0.900 (3.294 sec/step)\n",
      "step 35320 \t loss = 0.003, train_acc = 1.000 (3.331 sec/step)\n",
      "step 35330 \t loss = 0.124, train_acc = 0.900 (3.407 sec/step)\n",
      "step 35340 \t loss = 0.205, train_acc = 0.800 (3.286 sec/step)\n",
      "step 35350 \t loss = 0.825, train_acc = 0.800 (3.338 sec/step)\n",
      "step 35360 \t loss = 0.091, train_acc = 1.000 (3.289 sec/step)\n",
      "step 35370 \t loss = 0.064, train_acc = 1.000 (3.316 sec/step)\n",
      "step 35380 \t loss = 0.020, train_acc = 1.000 (3.306 sec/step)\n",
      "step 35390 \t loss = 0.219, train_acc = 1.000 (3.314 sec/step)\n",
      "step 35400 \t loss = 0.166, train_acc = 1.000 (3.371 sec/step)\n",
      "step 35410 \t loss = 0.140, train_acc = 0.900 (3.302 sec/step)\n",
      "step 35420 \t loss = 0.074, train_acc = 1.000 (3.260 sec/step)\n",
      "step 35430 \t loss = 0.006, train_acc = 1.000 (3.333 sec/step)\n",
      "step 35440 \t loss = 0.024, train_acc = 1.000 (3.316 sec/step)\n",
      "step 35450 \t loss = 0.074, train_acc = 1.000 (3.290 sec/step)\n",
      "step 35460 \t loss = 0.221, train_acc = 0.900 (3.291 sec/step)\n",
      "step 35470 \t loss = 0.359, train_acc = 0.900 (3.355 sec/step)\n",
      "step 35480 \t loss = 0.028, train_acc = 1.000 (3.333 sec/step)\n",
      "step 35490 \t loss = 0.006, train_acc = 1.000 (3.285 sec/step)\n",
      "step 35500 \t loss = 0.011, train_acc = 1.000 (3.362 sec/step)\n",
      "step 35510 \t loss = 0.328, train_acc = 0.900 (3.323 sec/step)\n",
      "step 35520 \t loss = 0.630, train_acc = 0.800 (3.343 sec/step)\n",
      "step 35530 \t loss = 0.136, train_acc = 1.000 (3.283 sec/step)\n",
      "step 35540 \t loss = 0.113, train_acc = 0.900 (3.338 sec/step)\n",
      "step 35550 \t loss = 0.628, train_acc = 0.900 (3.375 sec/step)\n",
      "step 35560 \t loss = 0.395, train_acc = 0.900 (3.301 sec/step)\n",
      "step 35570 \t loss = 0.027, train_acc = 1.000 (3.358 sec/step)\n",
      "step 35580 \t loss = 0.056, train_acc = 1.000 (3.335 sec/step)\n",
      "step 35590 \t loss = 0.796, train_acc = 0.800 (3.315 sec/step)\n",
      "step 35600 \t loss = 0.047, train_acc = 1.000 (3.342 sec/step)\n",
      "step 35610 \t loss = 0.927, train_acc = 0.800 (3.337 sec/step)\n",
      "step 35620 \t loss = 0.426, train_acc = 0.800 (3.300 sec/step)\n",
      "step 35630 \t loss = 0.174, train_acc = 0.900 (3.335 sec/step)\n",
      "step 35640 \t loss = 0.015, train_acc = 1.000 (3.279 sec/step)\n",
      "step 35650 \t loss = 1.106, train_acc = 0.700 (3.342 sec/step)\n",
      "step 35660 \t loss = 0.023, train_acc = 1.000 (3.296 sec/step)\n",
      "step 35670 \t loss = 0.173, train_acc = 1.000 (3.349 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35680 \t loss = 0.142, train_acc = 1.000 (3.257 sec/step)\n",
      "step 35690 \t loss = 0.233, train_acc = 0.900 (3.295 sec/step)\n",
      "step 35700 \t loss = 0.752, train_acc = 0.900 (3.298 sec/step)\n",
      "step 35710 \t loss = 0.583, train_acc = 0.900 (3.319 sec/step)\n",
      "step 35720 \t loss = 0.015, train_acc = 1.000 (3.342 sec/step)\n",
      "step 35730 \t loss = 0.010, train_acc = 1.000 (3.294 sec/step)\n",
      "step 35740 \t loss = 0.041, train_acc = 1.000 (3.338 sec/step)\n",
      "step 35750 \t loss = 1.817, train_acc = 0.700 (3.324 sec/step)\n",
      "step 35760 \t loss = 0.122, train_acc = 1.000 (3.326 sec/step)\n",
      "step 35770 \t loss = 0.328, train_acc = 0.800 (3.311 sec/step)\n",
      "step 35780 \t loss = 0.056, train_acc = 1.000 (3.290 sec/step)\n",
      "step 35790 \t loss = 0.081, train_acc = 1.000 (3.315 sec/step)\n",
      "step 35800 \t loss = 0.154, train_acc = 0.900 (3.312 sec/step)\n",
      "step 35810 \t loss = 0.496, train_acc = 0.800 (3.283 sec/step)\n",
      "step 35820 \t loss = 0.005, train_acc = 1.000 (3.358 sec/step)\n",
      "step 35830 \t loss = 0.238, train_acc = 1.000 (3.337 sec/step)\n",
      "step 35840 \t loss = 1.900, train_acc = 0.700 (3.299 sec/step)\n",
      "step 35850 \t loss = 0.064, train_acc = 1.000 (3.311 sec/step)\n",
      "step 35860 \t loss = 0.333, train_acc = 0.900 (3.268 sec/step)\n",
      "step 35870 \t loss = 0.017, train_acc = 1.000 (3.279 sec/step)\n",
      "step 35880 \t loss = 0.014, train_acc = 1.000 (3.333 sec/step)\n",
      "step 35890 \t loss = 0.570, train_acc = 0.600 (3.250 sec/step)\n",
      "step 35900 \t loss = 0.267, train_acc = 1.000 (3.324 sec/step)\n",
      "step 35910 \t loss = 0.229, train_acc = 0.900 (3.334 sec/step)\n",
      "step 35920 \t loss = 0.063, train_acc = 1.000 (3.297 sec/step)\n",
      "step 35930 \t loss = 0.393, train_acc = 0.900 (3.361 sec/step)\n",
      "step 35940 \t loss = 0.170, train_acc = 0.900 (3.301 sec/step)\n",
      "step 35950 \t loss = 0.372, train_acc = 0.900 (3.326 sec/step)\n",
      "step 35960 \t loss = 0.011, train_acc = 1.000 (3.317 sec/step)\n",
      "step 35970 \t loss = 0.009, train_acc = 1.000 (3.322 sec/step)\n",
      "step 35980 \t loss = 0.310, train_acc = 0.900 (3.326 sec/step)\n",
      "step 35990 \t loss = 0.311, train_acc = 0.900 (3.261 sec/step)\n",
      "step 36000 \t loss = 0.349, train_acc = 0.900 (3.312 sec/step)\n",
      "step 36010 \t loss = 1.281, train_acc = 0.700 (3.309 sec/step)\n",
      "step 36020 \t loss = 0.099, train_acc = 0.900 (3.324 sec/step)\n",
      "step 36030 \t loss = 1.412, train_acc = 0.600 (3.302 sec/step)\n",
      "step 36040 \t loss = 1.029, train_acc = 0.600 (3.281 sec/step)\n",
      "step 36050 \t loss = 0.151, train_acc = 1.000 (3.263 sec/step)\n",
      "step 36060 \t loss = 1.142, train_acc = 0.700 (3.317 sec/step)\n",
      "step 36070 \t loss = 1.882, train_acc = 0.600 (3.274 sec/step)\n",
      "step 36080 \t loss = 0.465, train_acc = 0.900 (3.290 sec/step)\n",
      "step 36090 \t loss = 0.902, train_acc = 0.700 (3.292 sec/step)\n",
      "VALIDATION \t acc = 0.509 (3.634 sec)\n",
      "step 36100 \t loss = 0.179, train_acc = 0.900 (3.352 sec/step)\n",
      "step 36110 \t loss = 0.150, train_acc = 1.000 (3.299 sec/step)\n",
      "step 36120 \t loss = 0.272, train_acc = 0.900 (3.445 sec/step)\n",
      "step 36130 \t loss = 0.133, train_acc = 0.900 (3.286 sec/step)\n",
      "step 36140 \t loss = 1.044, train_acc = 0.900 (3.278 sec/step)\n",
      "step 36150 \t loss = 0.549, train_acc = 0.900 (3.256 sec/step)\n",
      "step 36160 \t loss = 0.389, train_acc = 0.900 (3.302 sec/step)\n",
      "step 36170 \t loss = 0.128, train_acc = 0.900 (3.283 sec/step)\n",
      "step 36180 \t loss = 0.000, train_acc = 1.000 (3.324 sec/step)\n",
      "step 36190 \t loss = 0.046, train_acc = 1.000 (3.258 sec/step)\n",
      "step 36200 \t loss = 0.248, train_acc = 0.900 (3.327 sec/step)\n",
      "step 36210 \t loss = 0.344, train_acc = 0.900 (3.333 sec/step)\n",
      "step 36220 \t loss = 0.044, train_acc = 1.000 (3.325 sec/step)\n",
      "step 36230 \t loss = 0.394, train_acc = 0.900 (3.298 sec/step)\n",
      "step 36240 \t loss = 0.839, train_acc = 0.900 (3.311 sec/step)\n",
      "step 36250 \t loss = 0.041, train_acc = 1.000 (3.320 sec/step)\n",
      "step 36260 \t loss = 0.609, train_acc = 0.900 (3.325 sec/step)\n",
      "step 36270 \t loss = 0.086, train_acc = 0.900 (3.336 sec/step)\n",
      "step 36280 \t loss = 0.053, train_acc = 1.000 (3.352 sec/step)\n",
      "step 36290 \t loss = 0.731, train_acc = 0.900 (3.360 sec/step)\n",
      "step 36300 \t loss = 0.567, train_acc = 0.900 (3.317 sec/step)\n",
      "step 36310 \t loss = 0.187, train_acc = 0.900 (3.332 sec/step)\n",
      "step 36320 \t loss = 0.442, train_acc = 0.800 (3.306 sec/step)\n",
      "step 36330 \t loss = 0.065, train_acc = 1.000 (3.418 sec/step)\n",
      "step 36340 \t loss = 0.331, train_acc = 0.900 (3.321 sec/step)\n",
      "step 36350 \t loss = 0.067, train_acc = 1.000 (3.258 sec/step)\n",
      "step 36360 \t loss = 0.614, train_acc = 0.800 (3.317 sec/step)\n",
      "step 36370 \t loss = 0.014, train_acc = 1.000 (3.332 sec/step)\n",
      "step 36380 \t loss = 0.066, train_acc = 1.000 (3.314 sec/step)\n",
      "step 36390 \t loss = 0.293, train_acc = 0.900 (3.281 sec/step)\n",
      "step 36400 \t loss = 0.916, train_acc = 0.900 (3.357 sec/step)\n",
      "step 36410 \t loss = 0.017, train_acc = 1.000 (3.267 sec/step)\n",
      "step 36420 \t loss = 0.022, train_acc = 1.000 (3.351 sec/step)\n",
      "step 36430 \t loss = 0.019, train_acc = 1.000 (3.316 sec/step)\n",
      "step 36440 \t loss = 0.013, train_acc = 1.000 (3.289 sec/step)\n",
      "step 36450 \t loss = 0.124, train_acc = 0.900 (3.299 sec/step)\n",
      "step 36460 \t loss = 1.535, train_acc = 0.800 (3.313 sec/step)\n",
      "step 36470 \t loss = 0.026, train_acc = 1.000 (3.327 sec/step)\n",
      "step 36480 \t loss = 0.001, train_acc = 1.000 (3.318 sec/step)\n",
      "step 36490 \t loss = 0.030, train_acc = 1.000 (3.311 sec/step)\n",
      "step 36500 \t loss = 0.838, train_acc = 0.800 (3.280 sec/step)\n",
      "step 36510 \t loss = 0.765, train_acc = 0.800 (3.296 sec/step)\n",
      "step 36520 \t loss = 0.020, train_acc = 1.000 (3.277 sec/step)\n",
      "step 36530 \t loss = 0.289, train_acc = 0.900 (3.344 sec/step)\n",
      "step 36540 \t loss = 0.013, train_acc = 1.000 (3.331 sec/step)\n",
      "step 36550 \t loss = 0.302, train_acc = 0.800 (3.266 sec/step)\n",
      "step 36560 \t loss = 0.001, train_acc = 1.000 (3.334 sec/step)\n",
      "step 36570 \t loss = 0.463, train_acc = 0.900 (3.310 sec/step)\n",
      "step 36580 \t loss = 0.866, train_acc = 0.800 (3.409 sec/step)\n",
      "step 36590 \t loss = 0.054, train_acc = 1.000 (3.248 sec/step)\n",
      "step 36600 \t loss = 0.007, train_acc = 1.000 (3.282 sec/step)\n",
      "step 36610 \t loss = 0.002, train_acc = 1.000 (3.268 sec/step)\n",
      "step 36620 \t loss = 0.152, train_acc = 0.900 (3.322 sec/step)\n",
      "step 36630 \t loss = 0.092, train_acc = 1.000 (3.319 sec/step)\n",
      "step 36640 \t loss = 0.921, train_acc = 0.800 (3.347 sec/step)\n",
      "step 36650 \t loss = 0.049, train_acc = 1.000 (3.279 sec/step)\n",
      "step 36660 \t loss = 0.970, train_acc = 0.900 (3.273 sec/step)\n",
      "step 36670 \t loss = 0.303, train_acc = 0.900 (3.361 sec/step)\n",
      "step 36680 \t loss = 0.002, train_acc = 1.000 (3.344 sec/step)\n",
      "step 36690 \t loss = 0.767, train_acc = 0.700 (3.341 sec/step)\n",
      "step 36700 \t loss = 0.620, train_acc = 0.800 (3.285 sec/step)\n",
      "step 36710 \t loss = 0.018, train_acc = 1.000 (3.265 sec/step)\n",
      "step 36720 \t loss = 0.002, train_acc = 1.000 (3.361 sec/step)\n",
      "step 36730 \t loss = 0.234, train_acc = 0.900 (3.285 sec/step)\n",
      "step 36740 \t loss = 0.071, train_acc = 1.000 (3.323 sec/step)\n",
      "step 36750 \t loss = 0.000, train_acc = 1.000 (3.303 sec/step)\n",
      "step 36760 \t loss = 1.732, train_acc = 0.800 (3.288 sec/step)\n",
      "step 36770 \t loss = 0.098, train_acc = 0.900 (3.320 sec/step)\n",
      "step 36780 \t loss = 0.583, train_acc = 0.900 (3.317 sec/step)\n",
      "step 36790 \t loss = 0.015, train_acc = 1.000 (3.285 sec/step)\n",
      "step 36800 \t loss = 0.724, train_acc = 0.900 (3.286 sec/step)\n",
      "step 36810 \t loss = 0.098, train_acc = 1.000 (3.263 sec/step)\n",
      "step 36820 \t loss = 0.691, train_acc = 0.900 (3.326 sec/step)\n",
      "step 36830 \t loss = 0.213, train_acc = 1.000 (3.335 sec/step)\n",
      "step 36840 \t loss = 0.077, train_acc = 0.900 (3.293 sec/step)\n",
      "step 36850 \t loss = 0.655, train_acc = 0.900 (3.264 sec/step)\n",
      "step 36860 \t loss = 0.400, train_acc = 0.800 (3.270 sec/step)\n",
      "step 36870 \t loss = 0.077, train_acc = 1.000 (3.379 sec/step)\n",
      "step 36880 \t loss = 0.205, train_acc = 0.900 (3.355 sec/step)\n",
      "step 36890 \t loss = 0.003, train_acc = 1.000 (3.298 sec/step)\n",
      "step 36900 \t loss = 0.157, train_acc = 0.900 (3.297 sec/step)\n",
      "step 36910 \t loss = 0.211, train_acc = 0.900 (3.375 sec/step)\n",
      "step 36920 \t loss = 0.017, train_acc = 1.000 (3.330 sec/step)\n",
      "step 36930 \t loss = 0.624, train_acc = 0.900 (3.292 sec/step)\n",
      "step 36940 \t loss = 0.145, train_acc = 1.000 (3.354 sec/step)\n",
      "step 36950 \t loss = 0.100, train_acc = 0.900 (3.330 sec/step)\n",
      "step 36960 \t loss = 0.009, train_acc = 1.000 (3.323 sec/step)\n",
      "step 36970 \t loss = 0.011, train_acc = 1.000 (3.347 sec/step)\n",
      "step 36980 \t loss = 0.959, train_acc = 0.900 (3.339 sec/step)\n",
      "step 36990 \t loss = 0.376, train_acc = 0.900 (3.356 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 37000 \t loss = 0.198, train_acc = 1.000 (3.270 sec/step)\n",
      "step 37010 \t loss = 0.064, train_acc = 1.000 (3.258 sec/step)\n",
      "step 37020 \t loss = 0.017, train_acc = 1.000 (3.306 sec/step)\n",
      "step 37030 \t loss = 0.001, train_acc = 1.000 (3.400 sec/step)\n",
      "step 37040 \t loss = 0.019, train_acc = 1.000 (3.330 sec/step)\n",
      "step 37050 \t loss = 0.049, train_acc = 1.000 (3.287 sec/step)\n",
      "step 37060 \t loss = 0.075, train_acc = 1.000 (3.287 sec/step)\n",
      "step 37070 \t loss = 0.307, train_acc = 0.900 (3.369 sec/step)\n",
      "step 37080 \t loss = 0.187, train_acc = 0.900 (3.335 sec/step)\n",
      "step 37090 \t loss = 0.951, train_acc = 0.800 (3.337 sec/step)\n",
      "step 37100 \t loss = 0.017, train_acc = 1.000 (3.298 sec/step)\n",
      "step 37110 \t loss = 0.031, train_acc = 1.000 (3.290 sec/step)\n",
      "step 37120 \t loss = 0.225, train_acc = 0.900 (3.358 sec/step)\n",
      "step 37130 \t loss = 0.145, train_acc = 0.900 (3.292 sec/step)\n",
      "step 37140 \t loss = 0.079, train_acc = 1.000 (3.310 sec/step)\n",
      "step 37150 \t loss = 0.016, train_acc = 1.000 (3.282 sec/step)\n",
      "step 37160 \t loss = 0.016, train_acc = 1.000 (3.281 sec/step)\n",
      "step 37170 \t loss = 0.099, train_acc = 1.000 (3.288 sec/step)\n",
      "step 37180 \t loss = 0.025, train_acc = 1.000 (3.302 sec/step)\n",
      "step 37190 \t loss = 0.003, train_acc = 1.000 (3.297 sec/step)\n",
      "step 37200 \t loss = 0.011, train_acc = 1.000 (3.314 sec/step)\n",
      "step 37210 \t loss = 0.776, train_acc = 0.800 (3.315 sec/step)\n",
      "step 37220 \t loss = 0.004, train_acc = 1.000 (3.288 sec/step)\n",
      "step 37230 \t loss = 0.222, train_acc = 0.900 (3.275 sec/step)\n",
      "step 37240 \t loss = 0.692, train_acc = 0.700 (3.311 sec/step)\n",
      "step 37250 \t loss = 0.033, train_acc = 1.000 (3.449 sec/step)\n",
      "step 37260 \t loss = 0.100, train_acc = 1.000 (3.281 sec/step)\n",
      "step 37270 \t loss = 0.002, train_acc = 1.000 (3.320 sec/step)\n",
      "step 37280 \t loss = 1.029, train_acc = 0.900 (3.332 sec/step)\n",
      "step 37290 \t loss = 0.308, train_acc = 0.900 (3.293 sec/step)\n",
      "step 37300 \t loss = 0.091, train_acc = 1.000 (3.296 sec/step)\n",
      "step 37310 \t loss = 0.678, train_acc = 0.800 (3.317 sec/step)\n",
      "step 37320 \t loss = 0.536, train_acc = 0.900 (3.341 sec/step)\n",
      "step 37330 \t loss = 0.049, train_acc = 1.000 (3.338 sec/step)\n",
      "step 37340 \t loss = 0.074, train_acc = 1.000 (3.448 sec/step)\n",
      "step 37350 \t loss = 0.095, train_acc = 1.000 (3.320 sec/step)\n",
      "step 37360 \t loss = 0.007, train_acc = 1.000 (3.294 sec/step)\n",
      "step 37370 \t loss = 0.143, train_acc = 0.900 (3.321 sec/step)\n",
      "step 37380 \t loss = 0.120, train_acc = 0.900 (3.312 sec/step)\n",
      "step 37390 \t loss = 1.175, train_acc = 0.800 (3.367 sec/step)\n",
      "step 37400 \t loss = 0.000, train_acc = 1.000 (3.348 sec/step)\n",
      "step 37410 \t loss = 0.016, train_acc = 1.000 (3.363 sec/step)\n",
      "step 37420 \t loss = 0.199, train_acc = 0.900 (3.316 sec/step)\n",
      "step 37430 \t loss = 0.304, train_acc = 0.900 (3.257 sec/step)\n",
      "step 37440 \t loss = 0.293, train_acc = 0.800 (3.304 sec/step)\n",
      "step 37450 \t loss = 0.174, train_acc = 0.900 (3.332 sec/step)\n",
      "step 37460 \t loss = 0.039, train_acc = 1.000 (3.326 sec/step)\n",
      "step 37470 \t loss = 0.055, train_acc = 1.000 (3.291 sec/step)\n",
      "step 37480 \t loss = 0.028, train_acc = 1.000 (3.308 sec/step)\n",
      "step 37490 \t loss = 0.040, train_acc = 1.000 (3.343 sec/step)\n",
      "step 37500 \t loss = 0.035, train_acc = 1.000 (3.315 sec/step)\n",
      "step 37510 \t loss = 0.097, train_acc = 1.000 (3.289 sec/step)\n",
      "step 37520 \t loss = 0.225, train_acc = 0.900 (3.300 sec/step)\n",
      "step 37530 \t loss = 0.426, train_acc = 0.800 (3.352 sec/step)\n",
      "step 37540 \t loss = 0.341, train_acc = 0.800 (3.357 sec/step)\n",
      "step 37550 \t loss = 0.450, train_acc = 0.900 (3.303 sec/step)\n",
      "step 37560 \t loss = 0.032, train_acc = 1.000 (3.311 sec/step)\n",
      "step 37570 \t loss = 0.003, train_acc = 1.000 (3.364 sec/step)\n",
      "step 37580 \t loss = 0.602, train_acc = 0.800 (3.349 sec/step)\n",
      "step 37590 \t loss = 0.131, train_acc = 0.900 (3.339 sec/step)\n",
      "step 37600 \t loss = 0.087, train_acc = 1.000 (3.343 sec/step)\n",
      "step 37610 \t loss = 0.001, train_acc = 1.000 (3.341 sec/step)\n",
      "step 37620 \t loss = 0.117, train_acc = 0.900 (3.327 sec/step)\n",
      "step 37630 \t loss = 0.511, train_acc = 0.900 (3.293 sec/step)\n",
      "step 37640 \t loss = 0.356, train_acc = 0.800 (3.327 sec/step)\n",
      "step 37650 \t loss = 0.250, train_acc = 0.900 (3.270 sec/step)\n",
      "step 37660 \t loss = 0.219, train_acc = 0.900 (3.291 sec/step)\n",
      "step 37670 \t loss = 0.008, train_acc = 1.000 (3.295 sec/step)\n",
      "step 37680 \t loss = 0.005, train_acc = 1.000 (3.328 sec/step)\n",
      "step 37690 \t loss = 0.157, train_acc = 1.000 (3.309 sec/step)\n",
      "step 37700 \t loss = 0.060, train_acc = 1.000 (3.301 sec/step)\n",
      "step 37710 \t loss = 0.499, train_acc = 0.900 (3.305 sec/step)\n",
      "step 37720 \t loss = 0.067, train_acc = 1.000 (3.307 sec/step)\n",
      "step 37730 \t loss = 0.283, train_acc = 0.900 (3.297 sec/step)\n",
      "step 37740 \t loss = 0.386, train_acc = 0.900 (3.302 sec/step)\n",
      "step 37750 \t loss = 0.793, train_acc = 0.800 (3.409 sec/step)\n",
      "step 37760 \t loss = 0.314, train_acc = 0.800 (3.290 sec/step)\n",
      "step 37770 \t loss = 0.171, train_acc = 1.000 (3.316 sec/step)\n",
      "step 37780 \t loss = 0.001, train_acc = 1.000 (3.464 sec/step)\n",
      "step 37790 \t loss = 0.169, train_acc = 0.900 (3.306 sec/step)\n",
      "step 37800 \t loss = 0.180, train_acc = 0.900 (3.306 sec/step)\n",
      "step 37810 \t loss = 0.219, train_acc = 0.900 (3.275 sec/step)\n",
      "step 37820 \t loss = 0.162, train_acc = 0.900 (3.304 sec/step)\n",
      "step 37830 \t loss = 0.041, train_acc = 1.000 (3.348 sec/step)\n",
      "step 37840 \t loss = 0.408, train_acc = 0.900 (3.335 sec/step)\n",
      "step 37850 \t loss = 0.035, train_acc = 1.000 (3.303 sec/step)\n",
      "step 37860 \t loss = 0.048, train_acc = 1.000 (3.325 sec/step)\n",
      "step 37870 \t loss = 0.051, train_acc = 1.000 (3.401 sec/step)\n",
      "step 37880 \t loss = 1.381, train_acc = 0.700 (3.399 sec/step)\n",
      "step 37890 \t loss = 0.050, train_acc = 1.000 (3.326 sec/step)\n",
      "step 37900 \t loss = 0.167, train_acc = 0.900 (3.356 sec/step)\n",
      "step 37910 \t loss = 0.070, train_acc = 1.000 (3.325 sec/step)\n",
      "step 37920 \t loss = 0.062, train_acc = 1.000 (3.265 sec/step)\n",
      "step 37930 \t loss = 0.326, train_acc = 0.800 (3.342 sec/step)\n",
      "step 37940 \t loss = 0.025, train_acc = 1.000 (3.359 sec/step)\n",
      "step 37950 \t loss = 0.808, train_acc = 0.700 (3.352 sec/step)\n",
      "step 37960 \t loss = 0.237, train_acc = 0.900 (3.352 sec/step)\n",
      "step 37970 \t loss = 0.130, train_acc = 0.900 (3.358 sec/step)\n",
      "step 37980 \t loss = 0.094, train_acc = 1.000 (3.448 sec/step)\n",
      "step 37990 \t loss = 1.008, train_acc = 0.700 (3.320 sec/step)\n",
      "VALIDATION \t acc = 0.563 (3.612 sec)\n",
      "New Best Accuracy 0.563 > Old Best 0.561.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 38000 \t loss = 0.041, train_acc = 1.000 (3.308 sec/step)\n",
      "step 38010 \t loss = 0.073, train_acc = 1.000 (3.287 sec/step)\n",
      "step 38020 \t loss = 0.012, train_acc = 1.000 (3.322 sec/step)\n",
      "step 38030 \t loss = 0.453, train_acc = 0.900 (3.308 sec/step)\n",
      "step 38040 \t loss = 0.002, train_acc = 1.000 (3.328 sec/step)\n",
      "step 38050 \t loss = 0.271, train_acc = 0.900 (3.276 sec/step)\n",
      "step 38060 \t loss = 0.388, train_acc = 0.700 (3.282 sec/step)\n",
      "step 38070 \t loss = 0.056, train_acc = 1.000 (3.277 sec/step)\n",
      "step 38080 \t loss = 0.242, train_acc = 0.900 (3.454 sec/step)\n",
      "step 38090 \t loss = 0.014, train_acc = 1.000 (3.312 sec/step)\n",
      "step 38100 \t loss = 0.449, train_acc = 0.900 (3.286 sec/step)\n",
      "step 38110 \t loss = 0.004, train_acc = 1.000 (3.282 sec/step)\n",
      "step 38120 \t loss = 0.150, train_acc = 0.900 (3.307 sec/step)\n",
      "step 38130 \t loss = 0.016, train_acc = 1.000 (3.309 sec/step)\n",
      "step 38140 \t loss = 0.701, train_acc = 0.900 (3.316 sec/step)\n",
      "step 38150 \t loss = 0.197, train_acc = 0.800 (3.329 sec/step)\n",
      "step 38160 \t loss = 0.336, train_acc = 0.900 (3.354 sec/step)\n",
      "step 38170 \t loss = 0.498, train_acc = 0.900 (3.377 sec/step)\n",
      "step 38180 \t loss = 0.011, train_acc = 1.000 (3.280 sec/step)\n",
      "step 38190 \t loss = 0.009, train_acc = 1.000 (3.345 sec/step)\n",
      "step 38200 \t loss = 1.322, train_acc = 0.900 (3.276 sec/step)\n",
      "step 38210 \t loss = 0.706, train_acc = 0.600 (3.287 sec/step)\n",
      "step 38220 \t loss = 0.442, train_acc = 0.800 (3.308 sec/step)\n",
      "step 38230 \t loss = 0.040, train_acc = 1.000 (3.320 sec/step)\n",
      "step 38240 \t loss = 0.023, train_acc = 1.000 (3.390 sec/step)\n",
      "step 38250 \t loss = 0.126, train_acc = 0.900 (3.372 sec/step)\n",
      "step 38260 \t loss = 0.150, train_acc = 0.900 (3.327 sec/step)\n",
      "step 38270 \t loss = 0.210, train_acc = 0.900 (3.298 sec/step)\n",
      "step 38280 \t loss = 0.142, train_acc = 1.000 (3.310 sec/step)\n",
      "step 38290 \t loss = 0.939, train_acc = 0.900 (3.344 sec/step)\n",
      "step 38300 \t loss = 0.369, train_acc = 0.900 (3.302 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 38310 \t loss = 1.301, train_acc = 0.700 (3.334 sec/step)\n",
      "step 38320 \t loss = 0.130, train_acc = 1.000 (3.294 sec/step)\n",
      "step 38330 \t loss = 0.985, train_acc = 0.700 (3.275 sec/step)\n",
      "step 38340 \t loss = 0.048, train_acc = 1.000 (3.276 sec/step)\n",
      "step 38350 \t loss = 0.001, train_acc = 1.000 (3.291 sec/step)\n",
      "step 38360 \t loss = 0.016, train_acc = 1.000 (3.275 sec/step)\n",
      "step 38370 \t loss = 0.141, train_acc = 0.900 (3.330 sec/step)\n",
      "step 38380 \t loss = 0.079, train_acc = 0.900 (3.269 sec/step)\n",
      "step 38390 \t loss = 0.094, train_acc = 0.900 (3.358 sec/step)\n",
      "step 38400 \t loss = 0.089, train_acc = 0.900 (3.309 sec/step)\n",
      "step 38410 \t loss = 0.509, train_acc = 0.900 (3.288 sec/step)\n",
      "step 38420 \t loss = 0.072, train_acc = 1.000 (3.364 sec/step)\n",
      "step 38430 \t loss = 0.081, train_acc = 1.000 (3.346 sec/step)\n",
      "step 38440 \t loss = 0.104, train_acc = 1.000 (3.267 sec/step)\n",
      "step 38450 \t loss = 0.014, train_acc = 1.000 (3.337 sec/step)\n",
      "step 38460 \t loss = 0.878, train_acc = 0.900 (3.359 sec/step)\n",
      "step 38470 \t loss = 0.048, train_acc = 1.000 (3.271 sec/step)\n",
      "step 38480 \t loss = 0.102, train_acc = 1.000 (3.296 sec/step)\n",
      "step 38490 \t loss = 0.197, train_acc = 0.900 (3.293 sec/step)\n",
      "step 38500 \t loss = 0.619, train_acc = 0.900 (3.325 sec/step)\n",
      "step 38510 \t loss = 0.204, train_acc = 0.900 (3.358 sec/step)\n",
      "step 38520 \t loss = 0.016, train_acc = 1.000 (3.345 sec/step)\n",
      "step 38530 \t loss = 0.162, train_acc = 0.900 (3.318 sec/step)\n",
      "step 38540 \t loss = 1.357, train_acc = 0.500 (3.334 sec/step)\n",
      "step 38550 \t loss = 0.003, train_acc = 1.000 (3.347 sec/step)\n",
      "step 38560 \t loss = 0.002, train_acc = 1.000 (3.308 sec/step)\n",
      "step 38570 \t loss = 0.047, train_acc = 1.000 (3.311 sec/step)\n",
      "step 38580 \t loss = 0.004, train_acc = 1.000 (3.305 sec/step)\n",
      "step 38590 \t loss = 0.028, train_acc = 1.000 (3.317 sec/step)\n",
      "step 38600 \t loss = 0.132, train_acc = 1.000 (3.318 sec/step)\n",
      "step 38610 \t loss = 0.202, train_acc = 0.900 (3.307 sec/step)\n",
      "step 38620 \t loss = 0.001, train_acc = 1.000 (3.296 sec/step)\n",
      "step 38630 \t loss = 0.727, train_acc = 0.600 (3.365 sec/step)\n",
      "step 38640 \t loss = 0.081, train_acc = 1.000 (3.287 sec/step)\n",
      "step 38650 \t loss = 0.007, train_acc = 1.000 (3.343 sec/step)\n",
      "step 38660 \t loss = 0.025, train_acc = 1.000 (3.272 sec/step)\n",
      "step 38670 \t loss = 0.006, train_acc = 1.000 (3.298 sec/step)\n",
      "step 38680 \t loss = 0.047, train_acc = 1.000 (3.376 sec/step)\n",
      "step 38690 \t loss = 0.743, train_acc = 0.800 (3.386 sec/step)\n",
      "step 38700 \t loss = 0.112, train_acc = 1.000 (3.282 sec/step)\n",
      "step 38710 \t loss = 0.571, train_acc = 0.800 (3.359 sec/step)\n",
      "step 38720 \t loss = 0.055, train_acc = 1.000 (3.294 sec/step)\n",
      "step 38730 \t loss = 0.436, train_acc = 0.900 (3.269 sec/step)\n",
      "step 38740 \t loss = 0.000, train_acc = 1.000 (3.312 sec/step)\n",
      "step 38750 \t loss = 0.082, train_acc = 1.000 (3.334 sec/step)\n",
      "step 38760 \t loss = 0.062, train_acc = 1.000 (3.342 sec/step)\n",
      "step 38770 \t loss = 0.020, train_acc = 1.000 (3.295 sec/step)\n",
      "step 38780 \t loss = 0.003, train_acc = 1.000 (3.308 sec/step)\n",
      "step 38790 \t loss = 0.014, train_acc = 1.000 (3.287 sec/step)\n",
      "step 38800 \t loss = 0.054, train_acc = 1.000 (3.365 sec/step)\n",
      "step 38810 \t loss = 0.564, train_acc = 0.800 (3.320 sec/step)\n",
      "step 38820 \t loss = 0.622, train_acc = 0.900 (3.319 sec/step)\n",
      "step 38830 \t loss = 0.004, train_acc = 1.000 (3.369 sec/step)\n",
      "step 38840 \t loss = 0.128, train_acc = 1.000 (3.311 sec/step)\n",
      "step 38850 \t loss = 0.564, train_acc = 0.900 (3.297 sec/step)\n",
      "step 38860 \t loss = 0.019, train_acc = 1.000 (3.276 sec/step)\n",
      "step 38870 \t loss = 0.701, train_acc = 0.800 (3.319 sec/step)\n",
      "step 38880 \t loss = 0.083, train_acc = 1.000 (3.259 sec/step)\n",
      "step 38890 \t loss = 0.012, train_acc = 1.000 (3.361 sec/step)\n",
      "step 38900 \t loss = 1.662, train_acc = 0.700 (3.405 sec/step)\n",
      "step 38910 \t loss = 0.036, train_acc = 1.000 (3.276 sec/step)\n",
      "step 38920 \t loss = 0.060, train_acc = 1.000 (3.301 sec/step)\n",
      "step 38930 \t loss = 0.004, train_acc = 1.000 (3.337 sec/step)\n",
      "step 38940 \t loss = 0.004, train_acc = 1.000 (3.301 sec/step)\n",
      "step 38950 \t loss = 0.484, train_acc = 0.900 (3.320 sec/step)\n",
      "step 38960 \t loss = 0.005, train_acc = 1.000 (3.309 sec/step)\n",
      "step 38970 \t loss = 0.070, train_acc = 1.000 (3.346 sec/step)\n",
      "step 38980 \t loss = 0.045, train_acc = 1.000 (3.321 sec/step)\n",
      "step 38990 \t loss = 0.259, train_acc = 0.900 (3.297 sec/step)\n",
      "step 39000 \t loss = 0.006, train_acc = 1.000 (3.329 sec/step)\n",
      "step 39010 \t loss = 0.077, train_acc = 1.000 (3.313 sec/step)\n",
      "step 39020 \t loss = 0.143, train_acc = 0.900 (3.265 sec/step)\n",
      "step 39030 \t loss = 0.027, train_acc = 1.000 (3.284 sec/step)\n",
      "step 39040 \t loss = 0.213, train_acc = 0.900 (3.339 sec/step)\n",
      "step 39050 \t loss = 0.261, train_acc = 1.000 (3.318 sec/step)\n",
      "step 39060 \t loss = 0.486, train_acc = 0.800 (3.339 sec/step)\n",
      "step 39070 \t loss = 0.201, train_acc = 0.900 (3.266 sec/step)\n",
      "step 39080 \t loss = 0.423, train_acc = 0.800 (3.292 sec/step)\n",
      "step 39090 \t loss = 0.713, train_acc = 0.800 (3.316 sec/step)\n",
      "step 39100 \t loss = 0.743, train_acc = 0.900 (3.380 sec/step)\n",
      "step 39110 \t loss = 3.242, train_acc = 0.800 (3.344 sec/step)\n",
      "step 39120 \t loss = 0.139, train_acc = 0.900 (3.300 sec/step)\n",
      "step 39130 \t loss = 1.179, train_acc = 0.700 (3.341 sec/step)\n",
      "step 39140 \t loss = 0.527, train_acc = 0.800 (3.263 sec/step)\n",
      "step 39150 \t loss = 0.384, train_acc = 0.900 (3.275 sec/step)\n",
      "step 39160 \t loss = 0.230, train_acc = 0.900 (3.297 sec/step)\n",
      "step 39170 \t loss = 0.141, train_acc = 0.900 (3.288 sec/step)\n",
      "step 39180 \t loss = 0.096, train_acc = 1.000 (3.301 sec/step)\n",
      "step 39190 \t loss = 0.027, train_acc = 1.000 (3.289 sec/step)\n",
      "step 39200 \t loss = 0.537, train_acc = 0.900 (3.321 sec/step)\n",
      "step 39210 \t loss = 0.122, train_acc = 0.900 (3.328 sec/step)\n",
      "step 39220 \t loss = 0.237, train_acc = 0.900 (3.317 sec/step)\n",
      "step 39230 \t loss = 0.001, train_acc = 1.000 (3.273 sec/step)\n",
      "step 39240 \t loss = 0.001, train_acc = 1.000 (3.265 sec/step)\n",
      "step 39250 \t loss = 0.021, train_acc = 1.000 (3.310 sec/step)\n",
      "step 39260 \t loss = 0.232, train_acc = 0.900 (3.338 sec/step)\n",
      "step 39270 \t loss = 0.361, train_acc = 0.900 (3.351 sec/step)\n",
      "step 39280 \t loss = 0.614, train_acc = 0.900 (3.320 sec/step)\n",
      "step 39290 \t loss = 0.754, train_acc = 0.900 (3.312 sec/step)\n",
      "step 39300 \t loss = 0.795, train_acc = 0.900 (3.292 sec/step)\n",
      "step 39310 \t loss = 0.099, train_acc = 1.000 (3.372 sec/step)\n",
      "step 39320 \t loss = 0.775, train_acc = 0.800 (3.364 sec/step)\n",
      "step 39330 \t loss = 0.033, train_acc = 1.000 (3.343 sec/step)\n",
      "step 39340 \t loss = 0.005, train_acc = 1.000 (3.348 sec/step)\n",
      "step 39350 \t loss = 0.577, train_acc = 0.900 (3.322 sec/step)\n",
      "step 39360 \t loss = 0.171, train_acc = 0.900 (3.307 sec/step)\n",
      "step 39370 \t loss = 0.903, train_acc = 0.800 (3.317 sec/step)\n",
      "step 39380 \t loss = 0.008, train_acc = 1.000 (3.332 sec/step)\n",
      "step 39390 \t loss = 0.020, train_acc = 1.000 (3.322 sec/step)\n",
      "step 39400 \t loss = 0.799, train_acc = 0.800 (3.288 sec/step)\n",
      "step 39410 \t loss = 0.028, train_acc = 1.000 (3.275 sec/step)\n",
      "step 39420 \t loss = 0.105, train_acc = 0.900 (3.320 sec/step)\n",
      "step 39430 \t loss = 0.054, train_acc = 1.000 (3.278 sec/step)\n",
      "step 39440 \t loss = 0.136, train_acc = 0.900 (3.346 sec/step)\n",
      "step 39450 \t loss = 0.237, train_acc = 0.900 (3.327 sec/step)\n",
      "step 39460 \t loss = 0.043, train_acc = 1.000 (3.305 sec/step)\n",
      "step 39470 \t loss = 0.333, train_acc = 0.800 (3.352 sec/step)\n",
      "step 39480 \t loss = 0.493, train_acc = 0.900 (3.383 sec/step)\n",
      "step 39490 \t loss = 0.032, train_acc = 1.000 (3.341 sec/step)\n",
      "step 39500 \t loss = 0.179, train_acc = 0.900 (3.327 sec/step)\n",
      "step 39510 \t loss = 0.362, train_acc = 0.900 (3.351 sec/step)\n",
      "step 39520 \t loss = 0.160, train_acc = 0.900 (3.262 sec/step)\n",
      "step 39530 \t loss = 0.337, train_acc = 0.900 (3.292 sec/step)\n",
      "step 39540 \t loss = 0.193, train_acc = 0.900 (3.271 sec/step)\n",
      "step 39550 \t loss = 0.032, train_acc = 1.000 (3.367 sec/step)\n",
      "step 39560 \t loss = 0.480, train_acc = 0.800 (3.339 sec/step)\n",
      "step 39570 \t loss = 0.199, train_acc = 0.900 (3.304 sec/step)\n",
      "step 39580 \t loss = 0.534, train_acc = 0.900 (3.297 sec/step)\n",
      "step 39590 \t loss = 0.008, train_acc = 1.000 (3.354 sec/step)\n",
      "step 39600 \t loss = 0.384, train_acc = 0.800 (3.299 sec/step)\n",
      "step 39610 \t loss = 0.011, train_acc = 1.000 (3.268 sec/step)\n",
      "step 39620 \t loss = 0.017, train_acc = 1.000 (3.261 sec/step)\n",
      "step 39630 \t loss = 0.584, train_acc = 0.700 (3.292 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 39640 \t loss = 1.750, train_acc = 0.600 (3.389 sec/step)\n",
      "step 39650 \t loss = 0.027, train_acc = 1.000 (3.261 sec/step)\n",
      "step 39660 \t loss = 1.284, train_acc = 0.600 (3.281 sec/step)\n",
      "step 39670 \t loss = 0.740, train_acc = 0.800 (3.323 sec/step)\n",
      "step 39680 \t loss = 0.156, train_acc = 0.900 (3.363 sec/step)\n",
      "step 39690 \t loss = 0.000, train_acc = 1.000 (3.300 sec/step)\n",
      "step 39700 \t loss = 0.019, train_acc = 1.000 (3.342 sec/step)\n",
      "step 39710 \t loss = 0.001, train_acc = 1.000 (3.333 sec/step)\n",
      "step 39720 \t loss = 0.168, train_acc = 0.900 (3.271 sec/step)\n",
      "step 39730 \t loss = 0.417, train_acc = 0.900 (3.378 sec/step)\n",
      "step 39740 \t loss = 0.002, train_acc = 1.000 (3.318 sec/step)\n",
      "step 39750 \t loss = 0.086, train_acc = 1.000 (3.337 sec/step)\n",
      "step 39760 \t loss = 1.011, train_acc = 0.800 (3.322 sec/step)\n",
      "step 39770 \t loss = 0.539, train_acc = 0.900 (3.260 sec/step)\n",
      "step 39780 \t loss = 0.000, train_acc = 1.000 (3.337 sec/step)\n",
      "step 39790 \t loss = 0.085, train_acc = 1.000 (3.388 sec/step)\n",
      "step 39800 \t loss = 0.146, train_acc = 1.000 (3.320 sec/step)\n",
      "step 39810 \t loss = 0.630, train_acc = 0.900 (3.356 sec/step)\n",
      "step 39820 \t loss = 0.022, train_acc = 1.000 (3.362 sec/step)\n",
      "step 39830 \t loss = 0.439, train_acc = 0.800 (3.267 sec/step)\n",
      "step 39840 \t loss = 0.988, train_acc = 0.800 (3.356 sec/step)\n",
      "step 39850 \t loss = 0.135, train_acc = 1.000 (3.446 sec/step)\n",
      "step 39860 \t loss = 0.003, train_acc = 1.000 (3.267 sec/step)\n",
      "step 39870 \t loss = 0.207, train_acc = 0.900 (3.335 sec/step)\n",
      "step 39880 \t loss = 0.024, train_acc = 1.000 (3.312 sec/step)\n",
      "step 39890 \t loss = 0.024, train_acc = 1.000 (3.297 sec/step)\n",
      "VALIDATION \t acc = 0.555 (3.625 sec)\n",
      "step 39900 \t loss = 0.009, train_acc = 1.000 (3.283 sec/step)\n",
      "step 39910 \t loss = 0.019, train_acc = 1.000 (3.302 sec/step)\n",
      "step 39920 \t loss = 0.124, train_acc = 1.000 (3.374 sec/step)\n",
      "step 39930 \t loss = 0.582, train_acc = 0.900 (3.387 sec/step)\n",
      "step 39940 \t loss = 0.329, train_acc = 0.900 (3.295 sec/step)\n",
      "step 39950 \t loss = 0.310, train_acc = 0.800 (3.359 sec/step)\n",
      "step 39960 \t loss = 0.004, train_acc = 1.000 (3.279 sec/step)\n",
      "step 39970 \t loss = 0.537, train_acc = 0.800 (3.334 sec/step)\n",
      "step 39980 \t loss = 0.000, train_acc = 1.000 (3.296 sec/step)\n",
      "step 39990 \t loss = 0.152, train_acc = 0.900 (3.298 sec/step)\n",
      "step 40000 \t loss = 0.020, train_acc = 1.000 (3.320 sec/step)\n",
      "step 40010 \t loss = 0.002, train_acc = 1.000 (3.324 sec/step)\n",
      "step 40020 \t loss = 0.318, train_acc = 0.900 (3.298 sec/step)\n",
      "step 40030 \t loss = 0.542, train_acc = 0.900 (3.326 sec/step)\n",
      "step 40040 \t loss = 1.337, train_acc = 0.900 (3.350 sec/step)\n",
      "step 40050 \t loss = 0.010, train_acc = 1.000 (3.266 sec/step)\n",
      "step 40060 \t loss = 0.092, train_acc = 1.000 (3.353 sec/step)\n",
      "step 40070 \t loss = 0.505, train_acc = 0.900 (3.338 sec/step)\n",
      "step 40080 \t loss = 0.596, train_acc = 0.900 (3.317 sec/step)\n",
      "step 40090 \t loss = 0.178, train_acc = 0.900 (3.324 sec/step)\n",
      "step 40100 \t loss = 0.357, train_acc = 0.900 (3.321 sec/step)\n",
      "step 40110 \t loss = 0.064, train_acc = 1.000 (3.328 sec/step)\n",
      "step 40120 \t loss = 0.268, train_acc = 0.800 (3.344 sec/step)\n",
      "step 40130 \t loss = 0.627, train_acc = 0.900 (3.325 sec/step)\n",
      "step 40140 \t loss = 0.487, train_acc = 0.900 (3.313 sec/step)\n",
      "step 40150 \t loss = 0.457, train_acc = 0.700 (3.349 sec/step)\n",
      "step 40160 \t loss = 0.035, train_acc = 1.000 (3.381 sec/step)\n",
      "step 40170 \t loss = 0.001, train_acc = 1.000 (3.329 sec/step)\n",
      "step 40180 \t loss = 0.189, train_acc = 0.900 (3.268 sec/step)\n",
      "step 40190 \t loss = 0.912, train_acc = 0.900 (3.352 sec/step)\n",
      "step 40200 \t loss = 0.002, train_acc = 1.000 (3.279 sec/step)\n",
      "step 40210 \t loss = 0.697, train_acc = 0.800 (3.325 sec/step)\n",
      "step 40220 \t loss = 0.003, train_acc = 1.000 (3.341 sec/step)\n",
      "step 40230 \t loss = 0.202, train_acc = 0.900 (3.289 sec/step)\n",
      "step 40240 \t loss = 0.058, train_acc = 1.000 (3.296 sec/step)\n",
      "step 40250 \t loss = 0.104, train_acc = 1.000 (3.295 sec/step)\n",
      "step 40260 \t loss = 0.364, train_acc = 0.800 (3.340 sec/step)\n",
      "step 40270 \t loss = 0.009, train_acc = 1.000 (3.312 sec/step)\n",
      "step 40280 \t loss = 0.164, train_acc = 0.900 (3.324 sec/step)\n",
      "step 40290 \t loss = 0.015, train_acc = 1.000 (3.310 sec/step)\n",
      "step 40300 \t loss = 0.123, train_acc = 0.900 (3.280 sec/step)\n",
      "step 40310 \t loss = 0.003, train_acc = 1.000 (3.298 sec/step)\n",
      "step 40320 \t loss = 0.533, train_acc = 0.700 (3.296 sec/step)\n",
      "step 40330 \t loss = 0.099, train_acc = 1.000 (3.369 sec/step)\n",
      "step 40340 \t loss = 0.206, train_acc = 0.900 (3.334 sec/step)\n",
      "step 40350 \t loss = 0.202, train_acc = 0.800 (3.289 sec/step)\n",
      "step 40360 \t loss = 0.001, train_acc = 1.000 (3.392 sec/step)\n",
      "step 40370 \t loss = 0.000, train_acc = 1.000 (3.342 sec/step)\n",
      "step 40380 \t loss = 0.043, train_acc = 1.000 (3.312 sec/step)\n",
      "step 40390 \t loss = 0.365, train_acc = 0.700 (3.316 sec/step)\n",
      "step 40400 \t loss = 0.030, train_acc = 1.000 (3.287 sec/step)\n",
      "step 40410 \t loss = 0.364, train_acc = 0.900 (3.265 sec/step)\n",
      "step 40420 \t loss = 0.013, train_acc = 1.000 (3.293 sec/step)\n",
      "step 40430 \t loss = 0.387, train_acc = 0.900 (3.304 sec/step)\n",
      "step 40440 \t loss = 0.101, train_acc = 1.000 (3.267 sec/step)\n",
      "step 40450 \t loss = 0.930, train_acc = 0.800 (3.352 sec/step)\n",
      "step 40460 \t loss = 0.667, train_acc = 0.900 (3.393 sec/step)\n",
      "step 40470 \t loss = 0.106, train_acc = 1.000 (3.329 sec/step)\n",
      "step 40480 \t loss = 0.070, train_acc = 1.000 (3.407 sec/step)\n",
      "step 40490 \t loss = 0.497, train_acc = 0.900 (3.318 sec/step)\n",
      "step 40500 \t loss = 0.073, train_acc = 1.000 (3.396 sec/step)\n",
      "step 40510 \t loss = 0.008, train_acc = 1.000 (3.274 sec/step)\n",
      "step 40520 \t loss = 0.019, train_acc = 1.000 (3.324 sec/step)\n",
      "step 40530 \t loss = 0.183, train_acc = 0.900 (3.305 sec/step)\n",
      "step 40540 \t loss = 0.324, train_acc = 0.800 (3.275 sec/step)\n",
      "step 40550 \t loss = 0.763, train_acc = 0.800 (3.324 sec/step)\n",
      "step 40560 \t loss = 0.355, train_acc = 0.900 (3.303 sec/step)\n",
      "step 40570 \t loss = 0.420, train_acc = 0.800 (3.271 sec/step)\n",
      "step 40580 \t loss = 0.001, train_acc = 1.000 (3.353 sec/step)\n",
      "step 40590 \t loss = 0.420, train_acc = 0.800 (3.291 sec/step)\n",
      "step 40600 \t loss = 0.049, train_acc = 1.000 (3.292 sec/step)\n",
      "step 40610 \t loss = 0.197, train_acc = 0.900 (3.335 sec/step)\n",
      "step 40620 \t loss = 0.186, train_acc = 0.900 (3.343 sec/step)\n",
      "step 40630 \t loss = 0.312, train_acc = 0.900 (3.298 sec/step)\n",
      "step 40640 \t loss = 0.006, train_acc = 1.000 (3.318 sec/step)\n",
      "step 40650 \t loss = 0.062, train_acc = 1.000 (3.322 sec/step)\n",
      "step 40660 \t loss = 0.002, train_acc = 1.000 (3.318 sec/step)\n",
      "step 40670 \t loss = 0.603, train_acc = 0.900 (3.331 sec/step)\n",
      "step 40680 \t loss = 0.133, train_acc = 1.000 (3.298 sec/step)\n",
      "step 40690 \t loss = 0.077, train_acc = 1.000 (3.331 sec/step)\n",
      "step 40700 \t loss = 0.059, train_acc = 1.000 (3.276 sec/step)\n",
      "step 40710 \t loss = 0.120, train_acc = 0.900 (3.291 sec/step)\n",
      "step 40720 \t loss = 0.387, train_acc = 0.700 (3.298 sec/step)\n",
      "step 40730 \t loss = 0.208, train_acc = 0.900 (3.325 sec/step)\n",
      "step 40740 \t loss = 0.261, train_acc = 0.900 (3.346 sec/step)\n",
      "step 40750 \t loss = 0.094, train_acc = 0.900 (3.280 sec/step)\n",
      "step 40760 \t loss = 0.843, train_acc = 0.900 (3.336 sec/step)\n",
      "step 40770 \t loss = 0.014, train_acc = 1.000 (3.322 sec/step)\n",
      "step 40780 \t loss = 0.007, train_acc = 1.000 (3.312 sec/step)\n",
      "step 40790 \t loss = 0.159, train_acc = 0.900 (3.296 sec/step)\n",
      "step 40800 \t loss = 0.146, train_acc = 0.900 (3.282 sec/step)\n",
      "step 40810 \t loss = 0.142, train_acc = 0.900 (3.316 sec/step)\n",
      "step 40820 \t loss = 0.011, train_acc = 1.000 (3.359 sec/step)\n",
      "step 40830 \t loss = 0.190, train_acc = 0.900 (3.257 sec/step)\n",
      "step 40840 \t loss = 0.237, train_acc = 0.900 (3.298 sec/step)\n",
      "step 40850 \t loss = 0.076, train_acc = 1.000 (3.334 sec/step)\n",
      "step 40860 \t loss = 0.021, train_acc = 1.000 (3.303 sec/step)\n",
      "step 40870 \t loss = 0.002, train_acc = 1.000 (3.302 sec/step)\n",
      "step 40880 \t loss = 3.499, train_acc = 0.700 (3.302 sec/step)\n",
      "step 40890 \t loss = 0.147, train_acc = 1.000 (3.466 sec/step)\n",
      "step 40900 \t loss = 1.034, train_acc = 0.800 (3.312 sec/step)\n",
      "step 40910 \t loss = 0.849, train_acc = 0.900 (3.339 sec/step)\n",
      "step 40920 \t loss = 0.003, train_acc = 1.000 (3.347 sec/step)\n",
      "step 40930 \t loss = 0.132, train_acc = 0.900 (3.330 sec/step)\n",
      "step 40940 \t loss = 0.164, train_acc = 1.000 (3.323 sec/step)\n",
      "step 40950 \t loss = 0.003, train_acc = 1.000 (3.301 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40960 \t loss = 0.032, train_acc = 1.000 (3.332 sec/step)\n",
      "step 40970 \t loss = 0.223, train_acc = 0.900 (3.303 sec/step)\n",
      "step 40980 \t loss = 0.008, train_acc = 1.000 (3.311 sec/step)\n",
      "step 40990 \t loss = 0.510, train_acc = 0.800 (3.286 sec/step)\n",
      "step 41000 \t loss = 0.020, train_acc = 1.000 (3.350 sec/step)\n",
      "step 41010 \t loss = 0.000, train_acc = 1.000 (3.274 sec/step)\n",
      "step 41020 \t loss = 0.003, train_acc = 1.000 (3.330 sec/step)\n",
      "step 41030 \t loss = 0.110, train_acc = 0.900 (3.341 sec/step)\n",
      "step 41040 \t loss = 0.010, train_acc = 1.000 (3.330 sec/step)\n",
      "step 41050 \t loss = 0.052, train_acc = 1.000 (3.364 sec/step)\n",
      "step 41060 \t loss = 0.957, train_acc = 0.900 (3.330 sec/step)\n",
      "step 41070 \t loss = 0.003, train_acc = 1.000 (3.289 sec/step)\n",
      "step 41080 \t loss = 0.867, train_acc = 0.800 (3.303 sec/step)\n",
      "step 41090 \t loss = 0.333, train_acc = 1.000 (3.313 sec/step)\n",
      "step 41100 \t loss = 0.003, train_acc = 1.000 (3.320 sec/step)\n",
      "step 41110 \t loss = 0.089, train_acc = 0.900 (3.309 sec/step)\n",
      "step 41120 \t loss = 0.256, train_acc = 0.900 (3.295 sec/step)\n",
      "step 41130 \t loss = 0.644, train_acc = 0.900 (3.404 sec/step)\n",
      "step 41140 \t loss = 0.233, train_acc = 1.000 (3.328 sec/step)\n",
      "step 41150 \t loss = 0.259, train_acc = 0.900 (3.350 sec/step)\n",
      "step 41160 \t loss = 0.131, train_acc = 0.900 (3.305 sec/step)\n",
      "step 41170 \t loss = 0.046, train_acc = 1.000 (3.308 sec/step)\n",
      "step 41180 \t loss = 0.240, train_acc = 0.900 (3.356 sec/step)\n",
      "step 41190 \t loss = 0.211, train_acc = 0.900 (3.382 sec/step)\n",
      "step 41200 \t loss = 0.026, train_acc = 1.000 (3.302 sec/step)\n",
      "step 41210 \t loss = 0.020, train_acc = 1.000 (3.295 sec/step)\n",
      "step 41220 \t loss = 0.363, train_acc = 0.900 (3.301 sec/step)\n",
      "step 41230 \t loss = 0.007, train_acc = 1.000 (3.350 sec/step)\n",
      "step 41240 \t loss = 0.410, train_acc = 0.900 (3.375 sec/step)\n",
      "step 41250 \t loss = 0.225, train_acc = 0.800 (3.299 sec/step)\n",
      "step 41260 \t loss = 0.739, train_acc = 0.800 (3.341 sec/step)\n",
      "step 41270 \t loss = 0.313, train_acc = 0.900 (3.277 sec/step)\n",
      "step 41280 \t loss = 0.280, train_acc = 0.900 (3.316 sec/step)\n",
      "step 41290 \t loss = 0.175, train_acc = 0.900 (3.315 sec/step)\n",
      "step 41300 \t loss = 0.893, train_acc = 0.900 (3.323 sec/step)\n",
      "step 41310 \t loss = 0.348, train_acc = 0.900 (3.281 sec/step)\n",
      "step 41320 \t loss = 0.071, train_acc = 1.000 (3.313 sec/step)\n",
      "step 41330 \t loss = 0.138, train_acc = 0.900 (3.344 sec/step)\n",
      "step 41340 \t loss = 0.083, train_acc = 0.900 (3.368 sec/step)\n",
      "step 41350 \t loss = 0.250, train_acc = 0.900 (3.337 sec/step)\n",
      "step 41360 \t loss = 0.018, train_acc = 1.000 (3.354 sec/step)\n",
      "step 41370 \t loss = 0.652, train_acc = 0.900 (3.318 sec/step)\n",
      "step 41380 \t loss = 0.210, train_acc = 0.900 (3.299 sec/step)\n",
      "step 41390 \t loss = 0.001, train_acc = 1.000 (3.314 sec/step)\n",
      "step 41400 \t loss = 0.008, train_acc = 1.000 (3.316 sec/step)\n",
      "step 41410 \t loss = 0.225, train_acc = 0.900 (3.323 sec/step)\n",
      "step 41420 \t loss = 0.002, train_acc = 1.000 (3.306 sec/step)\n",
      "step 41430 \t loss = 0.194, train_acc = 0.900 (3.306 sec/step)\n",
      "step 41440 \t loss = 0.121, train_acc = 1.000 (3.336 sec/step)\n",
      "step 41450 \t loss = 0.003, train_acc = 1.000 (3.259 sec/step)\n",
      "step 41460 \t loss = 0.045, train_acc = 1.000 (3.319 sec/step)\n",
      "step 41470 \t loss = 0.003, train_acc = 1.000 (3.305 sec/step)\n",
      "step 41480 \t loss = 0.006, train_acc = 1.000 (3.342 sec/step)\n",
      "step 41490 \t loss = 0.000, train_acc = 1.000 (3.286 sec/step)\n",
      "step 41500 \t loss = 1.131, train_acc = 0.800 (3.346 sec/step)\n",
      "step 41510 \t loss = 0.517, train_acc = 0.900 (3.319 sec/step)\n",
      "step 41520 \t loss = 0.054, train_acc = 1.000 (3.336 sec/step)\n",
      "step 41530 \t loss = 0.199, train_acc = 1.000 (3.346 sec/step)\n",
      "step 41540 \t loss = 0.001, train_acc = 1.000 (3.478 sec/step)\n",
      "step 41550 \t loss = 0.211, train_acc = 0.900 (3.346 sec/step)\n",
      "step 41560 \t loss = 0.001, train_acc = 1.000 (3.340 sec/step)\n",
      "step 41570 \t loss = 0.079, train_acc = 1.000 (3.322 sec/step)\n",
      "step 41580 \t loss = 0.001, train_acc = 1.000 (3.323 sec/step)\n",
      "step 41590 \t loss = 0.000, train_acc = 1.000 (3.285 sec/step)\n",
      "step 41600 \t loss = 0.006, train_acc = 1.000 (3.324 sec/step)\n",
      "step 41610 \t loss = 0.038, train_acc = 1.000 (3.307 sec/step)\n",
      "step 41620 \t loss = 0.102, train_acc = 1.000 (3.310 sec/step)\n",
      "step 41630 \t loss = 0.167, train_acc = 1.000 (3.323 sec/step)\n",
      "step 41640 \t loss = 0.054, train_acc = 1.000 (3.333 sec/step)\n",
      "step 41650 \t loss = 0.006, train_acc = 1.000 (3.336 sec/step)\n",
      "step 41660 \t loss = 0.032, train_acc = 1.000 (3.316 sec/step)\n",
      "step 41670 \t loss = 0.000, train_acc = 1.000 (3.361 sec/step)\n",
      "step 41680 \t loss = 1.638, train_acc = 0.800 (3.393 sec/step)\n",
      "step 41690 \t loss = 0.061, train_acc = 1.000 (3.292 sec/step)\n",
      "step 41700 \t loss = 0.089, train_acc = 1.000 (3.280 sec/step)\n",
      "step 41710 \t loss = 0.750, train_acc = 0.900 (3.344 sec/step)\n",
      "step 41720 \t loss = 0.646, train_acc = 0.800 (3.268 sec/step)\n",
      "step 41730 \t loss = 0.186, train_acc = 0.900 (3.368 sec/step)\n",
      "step 41740 \t loss = 0.392, train_acc = 0.900 (3.328 sec/step)\n",
      "step 41750 \t loss = 0.247, train_acc = 0.900 (3.310 sec/step)\n",
      "step 41760 \t loss = 0.136, train_acc = 0.900 (3.321 sec/step)\n",
      "step 41770 \t loss = 0.124, train_acc = 1.000 (3.428 sec/step)\n",
      "step 41780 \t loss = 0.478, train_acc = 0.900 (3.344 sec/step)\n",
      "step 41790 \t loss = 0.476, train_acc = 0.800 (3.345 sec/step)\n",
      "VALIDATION \t acc = 0.520 (3.633 sec)\n",
      "step 41800 \t loss = 0.389, train_acc = 0.900 (3.304 sec/step)\n",
      "step 41810 \t loss = 0.460, train_acc = 0.800 (3.281 sec/step)\n",
      "step 41820 \t loss = 0.351, train_acc = 0.800 (3.290 sec/step)\n",
      "step 41830 \t loss = 0.009, train_acc = 1.000 (3.405 sec/step)\n",
      "step 41840 \t loss = 0.426, train_acc = 0.900 (3.350 sec/step)\n",
      "step 41850 \t loss = 0.022, train_acc = 1.000 (3.346 sec/step)\n",
      "step 41860 \t loss = 0.016, train_acc = 1.000 (3.299 sec/step)\n",
      "step 41870 \t loss = 0.481, train_acc = 0.800 (3.266 sec/step)\n",
      "step 41880 \t loss = 0.256, train_acc = 0.900 (3.327 sec/step)\n",
      "step 41890 \t loss = 0.040, train_acc = 1.000 (3.304 sec/step)\n",
      "step 41900 \t loss = 0.206, train_acc = 0.900 (3.289 sec/step)\n",
      "step 41910 \t loss = 0.131, train_acc = 0.900 (3.273 sec/step)\n",
      "step 41920 \t loss = 0.339, train_acc = 0.800 (3.318 sec/step)\n",
      "step 41930 \t loss = 0.270, train_acc = 0.900 (3.303 sec/step)\n",
      "step 41940 \t loss = 0.096, train_acc = 1.000 (3.322 sec/step)\n",
      "step 41950 \t loss = 2.675, train_acc = 0.600 (3.363 sec/step)\n",
      "step 41960 \t loss = 0.382, train_acc = 0.900 (3.383 sec/step)\n",
      "step 41970 \t loss = 0.004, train_acc = 1.000 (3.357 sec/step)\n",
      "step 41980 \t loss = 0.212, train_acc = 0.900 (3.291 sec/step)\n",
      "step 41990 \t loss = 0.630, train_acc = 0.900 (3.276 sec/step)\n",
      "step 42000 \t loss = 0.570, train_acc = 0.900 (3.480 sec/step)\n",
      "step 42010 \t loss = 0.551, train_acc = 0.900 (3.301 sec/step)\n",
      "step 42020 \t loss = 0.505, train_acc = 0.800 (3.314 sec/step)\n",
      "step 42030 \t loss = 0.503, train_acc = 0.900 (3.352 sec/step)\n",
      "step 42040 \t loss = 0.055, train_acc = 1.000 (3.328 sec/step)\n",
      "step 42050 \t loss = 0.086, train_acc = 1.000 (3.374 sec/step)\n",
      "step 42060 \t loss = 0.044, train_acc = 1.000 (3.324 sec/step)\n",
      "step 42070 \t loss = 0.268, train_acc = 1.000 (3.333 sec/step)\n",
      "step 42080 \t loss = 0.067, train_acc = 1.000 (3.344 sec/step)\n",
      "step 42090 \t loss = 0.108, train_acc = 0.900 (3.332 sec/step)\n",
      "step 42100 \t loss = 0.671, train_acc = 0.800 (3.316 sec/step)\n",
      "step 42110 \t loss = 0.040, train_acc = 1.000 (3.319 sec/step)\n",
      "step 42120 \t loss = 0.161, train_acc = 0.900 (3.319 sec/step)\n",
      "step 42130 \t loss = 0.483, train_acc = 0.900 (3.344 sec/step)\n",
      "step 42140 \t loss = 0.322, train_acc = 0.800 (3.289 sec/step)\n",
      "step 42150 \t loss = 0.306, train_acc = 0.900 (3.304 sec/step)\n",
      "step 42160 \t loss = 0.156, train_acc = 1.000 (3.325 sec/step)\n",
      "step 42170 \t loss = 0.118, train_acc = 1.000 (3.354 sec/step)\n",
      "step 42180 \t loss = 0.008, train_acc = 1.000 (3.331 sec/step)\n",
      "step 42190 \t loss = 0.116, train_acc = 0.900 (3.342 sec/step)\n",
      "step 42200 \t loss = 0.342, train_acc = 0.900 (3.296 sec/step)\n",
      "step 42210 \t loss = 0.125, train_acc = 1.000 (3.360 sec/step)\n",
      "step 42220 \t loss = 0.003, train_acc = 1.000 (3.308 sec/step)\n",
      "step 42230 \t loss = 0.023, train_acc = 1.000 (3.298 sec/step)\n",
      "step 42240 \t loss = 1.113, train_acc = 0.700 (3.279 sec/step)\n",
      "step 42250 \t loss = 0.020, train_acc = 1.000 (3.360 sec/step)\n",
      "step 42260 \t loss = 0.003, train_acc = 1.000 (3.332 sec/step)\n",
      "step 42270 \t loss = 0.003, train_acc = 1.000 (3.317 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 42280 \t loss = 0.504, train_acc = 0.800 (3.352 sec/step)\n",
      "step 42290 \t loss = 0.041, train_acc = 1.000 (3.310 sec/step)\n",
      "step 42300 \t loss = 0.003, train_acc = 1.000 (3.290 sec/step)\n",
      "step 42310 \t loss = 0.022, train_acc = 1.000 (3.312 sec/step)\n",
      "step 42320 \t loss = 0.342, train_acc = 0.900 (3.305 sec/step)\n",
      "step 42330 \t loss = 0.666, train_acc = 0.800 (3.362 sec/step)\n",
      "step 42340 \t loss = 0.126, train_acc = 1.000 (3.314 sec/step)\n",
      "step 42350 \t loss = 0.054, train_acc = 1.000 (3.282 sec/step)\n",
      "step 42360 \t loss = 0.002, train_acc = 1.000 (3.345 sec/step)\n",
      "step 42370 \t loss = 0.125, train_acc = 0.900 (3.286 sec/step)\n",
      "step 42380 \t loss = 0.916, train_acc = 0.900 (3.306 sec/step)\n",
      "step 42390 \t loss = 0.147, train_acc = 0.900 (3.336 sec/step)\n",
      "step 42400 \t loss = 0.260, train_acc = 0.900 (3.280 sec/step)\n",
      "step 42410 \t loss = 0.294, train_acc = 0.900 (3.374 sec/step)\n",
      "step 42420 \t loss = 0.007, train_acc = 1.000 (3.330 sec/step)\n",
      "step 42430 \t loss = 0.256, train_acc = 0.900 (3.334 sec/step)\n",
      "step 42440 \t loss = 0.242, train_acc = 0.900 (3.303 sec/step)\n",
      "step 42450 \t loss = 0.000, train_acc = 1.000 (3.294 sec/step)\n",
      "step 42460 \t loss = 0.038, train_acc = 1.000 (3.268 sec/step)\n",
      "step 42470 \t loss = 0.423, train_acc = 0.900 (3.296 sec/step)\n",
      "step 42480 \t loss = 0.001, train_acc = 1.000 (3.278 sec/step)\n",
      "step 42490 \t loss = 0.147, train_acc = 1.000 (3.286 sec/step)\n",
      "step 42500 \t loss = 0.671, train_acc = 0.700 (3.313 sec/step)\n",
      "step 42510 \t loss = 0.002, train_acc = 1.000 (3.307 sec/step)\n",
      "step 42520 \t loss = 0.517, train_acc = 0.800 (3.260 sec/step)\n",
      "step 42530 \t loss = 0.144, train_acc = 0.900 (3.324 sec/step)\n",
      "step 42540 \t loss = 0.000, train_acc = 1.000 (3.357 sec/step)\n",
      "step 42550 \t loss = 0.017, train_acc = 1.000 (3.250 sec/step)\n",
      "step 42560 \t loss = 0.019, train_acc = 1.000 (3.269 sec/step)\n",
      "step 42570 \t loss = 0.115, train_acc = 1.000 (3.322 sec/step)\n",
      "step 42580 \t loss = 0.396, train_acc = 0.800 (3.335 sec/step)\n",
      "step 42590 \t loss = 0.021, train_acc = 1.000 (3.297 sec/step)\n",
      "step 42600 \t loss = 0.261, train_acc = 0.900 (3.306 sec/step)\n",
      "step 42610 \t loss = 0.021, train_acc = 1.000 (3.339 sec/step)\n",
      "step 42620 \t loss = 0.100, train_acc = 1.000 (3.308 sec/step)\n",
      "step 42630 \t loss = 0.266, train_acc = 0.900 (3.293 sec/step)\n",
      "step 42640 \t loss = 0.015, train_acc = 1.000 (3.338 sec/step)\n",
      "step 42650 \t loss = 0.764, train_acc = 0.700 (3.283 sec/step)\n",
      "step 42660 \t loss = 0.013, train_acc = 1.000 (3.310 sec/step)\n",
      "step 42670 \t loss = 0.286, train_acc = 0.900 (3.364 sec/step)\n",
      "step 42680 \t loss = 0.067, train_acc = 1.000 (3.284 sec/step)\n",
      "step 42690 \t loss = 0.703, train_acc = 0.800 (3.305 sec/step)\n",
      "step 42700 \t loss = 0.040, train_acc = 1.000 (3.300 sec/step)\n",
      "step 42710 \t loss = 0.193, train_acc = 0.900 (3.268 sec/step)\n",
      "step 42720 \t loss = 0.235, train_acc = 0.900 (3.447 sec/step)\n",
      "step 42730 \t loss = 0.311, train_acc = 0.800 (3.288 sec/step)\n",
      "step 42740 \t loss = 0.046, train_acc = 1.000 (3.419 sec/step)\n",
      "step 42750 \t loss = 0.000, train_acc = 1.000 (3.319 sec/step)\n",
      "step 42760 \t loss = 0.293, train_acc = 0.900 (3.319 sec/step)\n",
      "step 42770 \t loss = 0.032, train_acc = 1.000 (3.299 sec/step)\n",
      "step 42780 \t loss = 0.396, train_acc = 0.900 (3.304 sec/step)\n",
      "step 42790 \t loss = 0.015, train_acc = 1.000 (3.315 sec/step)\n",
      "step 42800 \t loss = 0.025, train_acc = 1.000 (3.302 sec/step)\n",
      "step 42810 \t loss = 0.095, train_acc = 1.000 (3.307 sec/step)\n",
      "step 42820 \t loss = 0.505, train_acc = 0.900 (3.317 sec/step)\n",
      "step 42830 \t loss = 0.008, train_acc = 1.000 (3.323 sec/step)\n",
      "step 42840 \t loss = 0.292, train_acc = 0.800 (3.337 sec/step)\n",
      "step 42850 \t loss = 0.026, train_acc = 1.000 (3.339 sec/step)\n",
      "step 42860 \t loss = 0.118, train_acc = 1.000 (3.335 sec/step)\n",
      "step 42870 \t loss = 0.001, train_acc = 1.000 (3.344 sec/step)\n",
      "step 42880 \t loss = 0.062, train_acc = 1.000 (3.264 sec/step)\n",
      "step 42890 \t loss = 0.014, train_acc = 1.000 (3.296 sec/step)\n",
      "step 42900 \t loss = 0.246, train_acc = 0.900 (3.321 sec/step)\n",
      "step 42910 \t loss = 0.059, train_acc = 1.000 (3.333 sec/step)\n",
      "step 42920 \t loss = 0.088, train_acc = 1.000 (3.331 sec/step)\n",
      "step 42930 \t loss = 0.442, train_acc = 0.700 (3.346 sec/step)\n",
      "step 42940 \t loss = 0.785, train_acc = 0.800 (3.281 sec/step)\n",
      "step 42950 \t loss = 0.862, train_acc = 0.900 (3.286 sec/step)\n",
      "step 42960 \t loss = 0.001, train_acc = 1.000 (3.317 sec/step)\n",
      "step 42970 \t loss = 0.178, train_acc = 0.900 (3.306 sec/step)\n",
      "step 42980 \t loss = 0.019, train_acc = 1.000 (3.295 sec/step)\n",
      "step 42990 \t loss = 0.682, train_acc = 0.700 (3.310 sec/step)\n",
      "step 43000 \t loss = 0.154, train_acc = 0.900 (3.327 sec/step)\n",
      "step 43010 \t loss = 0.026, train_acc = 1.000 (3.306 sec/step)\n",
      "step 43020 \t loss = 0.128, train_acc = 0.900 (3.293 sec/step)\n",
      "step 43030 \t loss = 0.015, train_acc = 1.000 (3.340 sec/step)\n",
      "step 43040 \t loss = 0.292, train_acc = 0.900 (3.301 sec/step)\n",
      "step 43050 \t loss = 0.404, train_acc = 0.800 (3.337 sec/step)\n",
      "step 43060 \t loss = 0.045, train_acc = 1.000 (3.326 sec/step)\n",
      "step 43070 \t loss = 0.028, train_acc = 1.000 (3.317 sec/step)\n",
      "step 43080 \t loss = 0.178, train_acc = 0.900 (3.316 sec/step)\n",
      "step 43090 \t loss = 0.357, train_acc = 0.900 (3.357 sec/step)\n",
      "step 43100 \t loss = 0.036, train_acc = 1.000 (3.314 sec/step)\n",
      "step 43110 \t loss = 0.059, train_acc = 1.000 (3.276 sec/step)\n",
      "step 43120 \t loss = 0.106, train_acc = 0.900 (3.286 sec/step)\n",
      "step 43130 \t loss = 0.255, train_acc = 0.900 (3.303 sec/step)\n",
      "step 43140 \t loss = 0.003, train_acc = 1.000 (3.291 sec/step)\n",
      "step 43150 \t loss = 0.540, train_acc = 0.900 (3.322 sec/step)\n",
      "step 43160 \t loss = 0.144, train_acc = 1.000 (3.309 sec/step)\n",
      "step 43170 \t loss = 0.264, train_acc = 0.900 (3.296 sec/step)\n",
      "step 43180 \t loss = 0.101, train_acc = 1.000 (3.301 sec/step)\n",
      "step 43190 \t loss = 0.310, train_acc = 0.800 (3.333 sec/step)\n",
      "step 43200 \t loss = 0.608, train_acc = 0.900 (3.285 sec/step)\n",
      "step 43210 \t loss = 0.025, train_acc = 1.000 (3.290 sec/step)\n",
      "step 43220 \t loss = 0.336, train_acc = 0.900 (3.316 sec/step)\n",
      "step 43230 \t loss = 0.004, train_acc = 1.000 (3.264 sec/step)\n",
      "step 43240 \t loss = 0.046, train_acc = 1.000 (3.315 sec/step)\n",
      "step 43250 \t loss = 0.193, train_acc = 0.900 (3.327 sec/step)\n",
      "step 43260 \t loss = 0.001, train_acc = 1.000 (3.364 sec/step)\n",
      "step 43270 \t loss = 0.021, train_acc = 1.000 (3.354 sec/step)\n",
      "step 43280 \t loss = 0.085, train_acc = 1.000 (3.305 sec/step)\n",
      "step 43290 \t loss = 1.013, train_acc = 0.900 (3.298 sec/step)\n",
      "step 43300 \t loss = 0.030, train_acc = 1.000 (3.318 sec/step)\n",
      "step 43310 \t loss = 0.470, train_acc = 0.900 (3.302 sec/step)\n",
      "step 43320 \t loss = 0.606, train_acc = 0.900 (3.294 sec/step)\n",
      "step 43330 \t loss = 0.485, train_acc = 0.800 (3.275 sec/step)\n",
      "step 43340 \t loss = 0.073, train_acc = 1.000 (3.339 sec/step)\n",
      "step 43350 \t loss = 0.041, train_acc = 1.000 (3.357 sec/step)\n",
      "step 43360 \t loss = 0.191, train_acc = 1.000 (3.362 sec/step)\n",
      "step 43370 \t loss = 0.103, train_acc = 0.900 (3.315 sec/step)\n",
      "step 43380 \t loss = 0.019, train_acc = 1.000 (3.306 sec/step)\n",
      "step 43390 \t loss = 0.016, train_acc = 1.000 (3.438 sec/step)\n",
      "step 43400 \t loss = 0.084, train_acc = 0.900 (3.318 sec/step)\n",
      "step 43410 \t loss = 0.093, train_acc = 1.000 (3.345 sec/step)\n",
      "step 43420 \t loss = 0.001, train_acc = 1.000 (3.330 sec/step)\n",
      "step 43430 \t loss = 0.055, train_acc = 1.000 (3.357 sec/step)\n",
      "step 43440 \t loss = 0.004, train_acc = 1.000 (3.318 sec/step)\n",
      "step 43450 \t loss = 0.501, train_acc = 0.700 (3.357 sec/step)\n",
      "step 43460 \t loss = 0.052, train_acc = 1.000 (3.319 sec/step)\n",
      "step 43470 \t loss = 0.111, train_acc = 0.900 (3.326 sec/step)\n",
      "step 43480 \t loss = 0.358, train_acc = 0.800 (3.320 sec/step)\n",
      "step 43490 \t loss = 0.057, train_acc = 1.000 (3.309 sec/step)\n",
      "step 43500 \t loss = 0.017, train_acc = 1.000 (3.342 sec/step)\n",
      "step 43510 \t loss = 0.086, train_acc = 1.000 (3.361 sec/step)\n",
      "step 43520 \t loss = 0.235, train_acc = 0.900 (3.284 sec/step)\n",
      "step 43530 \t loss = 0.216, train_acc = 0.900 (3.279 sec/step)\n",
      "step 43540 \t loss = 0.302, train_acc = 0.900 (3.272 sec/step)\n",
      "step 43550 \t loss = 0.186, train_acc = 0.900 (3.346 sec/step)\n",
      "step 43560 \t loss = 0.300, train_acc = 0.900 (3.323 sec/step)\n",
      "step 43570 \t loss = 0.002, train_acc = 1.000 (3.340 sec/step)\n",
      "step 43580 \t loss = 0.122, train_acc = 0.900 (3.321 sec/step)\n",
      "step 43590 \t loss = 0.288, train_acc = 0.900 (3.374 sec/step)\n",
      "step 43600 \t loss = 0.663, train_acc = 0.900 (3.281 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 43610 \t loss = 0.075, train_acc = 1.000 (3.317 sec/step)\n",
      "step 43620 \t loss = 0.191, train_acc = 0.900 (3.280 sec/step)\n",
      "step 43630 \t loss = 0.021, train_acc = 1.000 (3.301 sec/step)\n",
      "step 43640 \t loss = 0.019, train_acc = 1.000 (3.300 sec/step)\n",
      "step 43650 \t loss = 0.052, train_acc = 1.000 (3.339 sec/step)\n",
      "step 43660 \t loss = 0.004, train_acc = 1.000 (3.283 sec/step)\n",
      "step 43670 \t loss = 0.155, train_acc = 0.900 (3.353 sec/step)\n",
      "step 43680 \t loss = 0.764, train_acc = 0.800 (3.281 sec/step)\n",
      "step 43690 \t loss = 0.050, train_acc = 1.000 (3.330 sec/step)\n",
      "VALIDATION \t acc = 0.543 (3.631 sec)\n",
      "step 43700 \t loss = 0.941, train_acc = 0.700 (3.344 sec/step)\n",
      "step 43710 \t loss = 0.079, train_acc = 1.000 (3.295 sec/step)\n",
      "step 43720 \t loss = 1.023, train_acc = 0.700 (3.295 sec/step)\n",
      "step 43730 \t loss = 0.234, train_acc = 0.900 (3.330 sec/step)\n",
      "step 43740 \t loss = 0.000, train_acc = 1.000 (3.374 sec/step)\n",
      "step 43750 \t loss = 0.885, train_acc = 0.800 (3.318 sec/step)\n",
      "step 43760 \t loss = 0.006, train_acc = 1.000 (3.315 sec/step)\n",
      "step 43770 \t loss = 0.000, train_acc = 1.000 (3.266 sec/step)\n",
      "step 43780 \t loss = 0.217, train_acc = 0.900 (3.329 sec/step)\n",
      "step 43790 \t loss = 0.181, train_acc = 0.900 (3.364 sec/step)\n",
      "step 43800 \t loss = 0.999, train_acc = 0.800 (3.299 sec/step)\n",
      "step 43810 \t loss = 0.460, train_acc = 0.900 (3.333 sec/step)\n",
      "step 43820 \t loss = 0.125, train_acc = 0.900 (3.290 sec/step)\n",
      "step 43830 \t loss = 0.937, train_acc = 0.900 (3.355 sec/step)\n",
      "step 43840 \t loss = 0.101, train_acc = 1.000 (3.330 sec/step)\n",
      "step 43850 \t loss = 0.008, train_acc = 1.000 (3.306 sec/step)\n",
      "step 43860 \t loss = 0.056, train_acc = 1.000 (3.346 sec/step)\n",
      "step 43870 \t loss = 0.062, train_acc = 1.000 (3.324 sec/step)\n",
      "step 43880 \t loss = 0.054, train_acc = 1.000 (3.350 sec/step)\n",
      "step 43890 \t loss = 0.375, train_acc = 0.900 (3.316 sec/step)\n",
      "step 43900 \t loss = 0.302, train_acc = 0.900 (3.447 sec/step)\n",
      "step 43910 \t loss = 0.516, train_acc = 0.900 (3.279 sec/step)\n",
      "step 43920 \t loss = 0.064, train_acc = 1.000 (3.306 sec/step)\n",
      "step 43930 \t loss = 0.001, train_acc = 1.000 (3.307 sec/step)\n",
      "step 43940 \t loss = 0.605, train_acc = 0.900 (3.355 sec/step)\n",
      "step 43950 \t loss = 0.132, train_acc = 1.000 (3.307 sec/step)\n",
      "step 43960 \t loss = 0.003, train_acc = 1.000 (3.359 sec/step)\n",
      "step 43970 \t loss = 0.132, train_acc = 0.900 (3.352 sec/step)\n",
      "step 43980 \t loss = 0.013, train_acc = 1.000 (3.306 sec/step)\n",
      "step 43990 \t loss = 0.236, train_acc = 0.900 (3.327 sec/step)\n",
      "step 44000 \t loss = 0.002, train_acc = 1.000 (3.276 sec/step)\n",
      "step 44010 \t loss = 0.754, train_acc = 0.800 (3.317 sec/step)\n",
      "step 44020 \t loss = 0.232, train_acc = 1.000 (3.315 sec/step)\n",
      "step 44030 \t loss = 0.149, train_acc = 0.900 (3.351 sec/step)\n",
      "step 44040 \t loss = 0.151, train_acc = 0.900 (3.311 sec/step)\n",
      "step 44050 \t loss = 0.579, train_acc = 0.900 (3.295 sec/step)\n",
      "step 44060 \t loss = 0.049, train_acc = 1.000 (3.317 sec/step)\n",
      "step 44070 \t loss = 0.057, train_acc = 1.000 (3.317 sec/step)\n",
      "step 44080 \t loss = 0.000, train_acc = 1.000 (3.281 sec/step)\n",
      "step 44090 \t loss = 0.140, train_acc = 0.900 (3.360 sec/step)\n",
      "step 44100 \t loss = 0.330, train_acc = 0.900 (3.301 sec/step)\n",
      "step 44110 \t loss = 0.596, train_acc = 0.800 (3.312 sec/step)\n",
      "step 44120 \t loss = 0.558, train_acc = 0.800 (3.347 sec/step)\n",
      "step 44130 \t loss = 0.018, train_acc = 1.000 (3.287 sec/step)\n",
      "step 44140 \t loss = 0.276, train_acc = 0.900 (3.275 sec/step)\n",
      "step 44150 \t loss = 0.608, train_acc = 0.900 (3.308 sec/step)\n",
      "step 44160 \t loss = 0.934, train_acc = 0.800 (3.339 sec/step)\n",
      "step 44170 \t loss = 0.001, train_acc = 1.000 (3.357 sec/step)\n",
      "step 44180 \t loss = 0.256, train_acc = 0.900 (3.296 sec/step)\n",
      "step 44190 \t loss = 0.431, train_acc = 0.900 (3.326 sec/step)\n",
      "step 44200 \t loss = 0.075, train_acc = 1.000 (3.274 sec/step)\n",
      "step 44210 \t loss = 0.233, train_acc = 0.800 (3.300 sec/step)\n",
      "step 44220 \t loss = 0.062, train_acc = 1.000 (3.298 sec/step)\n",
      "step 44230 \t loss = 0.249, train_acc = 0.900 (3.299 sec/step)\n",
      "step 44240 \t loss = 0.652, train_acc = 0.900 (3.325 sec/step)\n",
      "step 44250 \t loss = 0.109, train_acc = 1.000 (3.339 sec/step)\n",
      "step 44260 \t loss = 0.001, train_acc = 1.000 (3.282 sec/step)\n",
      "step 44270 \t loss = 0.019, train_acc = 1.000 (3.287 sec/step)\n",
      "step 44280 \t loss = 0.002, train_acc = 1.000 (3.289 sec/step)\n",
      "step 44290 \t loss = 0.371, train_acc = 0.800 (3.342 sec/step)\n",
      "step 44300 \t loss = 0.443, train_acc = 0.800 (3.319 sec/step)\n",
      "step 44310 \t loss = 0.003, train_acc = 1.000 (3.298 sec/step)\n",
      "step 44320 \t loss = 0.001, train_acc = 1.000 (3.304 sec/step)\n",
      "step 44330 \t loss = 0.185, train_acc = 0.900 (3.304 sec/step)\n",
      "step 44340 \t loss = 0.880, train_acc = 0.900 (3.351 sec/step)\n",
      "step 44350 \t loss = 0.001, train_acc = 1.000 (3.306 sec/step)\n",
      "step 44360 \t loss = 0.031, train_acc = 1.000 (3.344 sec/step)\n",
      "step 44370 \t loss = 0.176, train_acc = 1.000 (3.278 sec/step)\n",
      "step 44380 \t loss = 0.006, train_acc = 1.000 (3.453 sec/step)\n",
      "step 44390 \t loss = 0.232, train_acc = 0.900 (3.282 sec/step)\n",
      "step 44400 \t loss = 0.553, train_acc = 0.800 (3.281 sec/step)\n",
      "step 44410 \t loss = 0.024, train_acc = 1.000 (3.352 sec/step)\n",
      "step 44420 \t loss = 0.001, train_acc = 1.000 (3.273 sec/step)\n",
      "step 44430 \t loss = 0.113, train_acc = 1.000 (3.348 sec/step)\n",
      "step 44440 \t loss = 0.146, train_acc = 0.900 (3.359 sec/step)\n",
      "step 44450 \t loss = 0.048, train_acc = 1.000 (3.404 sec/step)\n",
      "step 44460 \t loss = 0.302, train_acc = 0.900 (3.323 sec/step)\n",
      "step 44470 \t loss = 0.185, train_acc = 1.000 (3.265 sec/step)\n",
      "step 44480 \t loss = 0.012, train_acc = 1.000 (3.299 sec/step)\n",
      "step 44490 \t loss = 0.008, train_acc = 1.000 (3.368 sec/step)\n",
      "step 44500 \t loss = 0.025, train_acc = 1.000 (3.308 sec/step)\n",
      "step 44510 \t loss = 0.411, train_acc = 0.900 (3.346 sec/step)\n",
      "step 44520 \t loss = 0.001, train_acc = 1.000 (3.338 sec/step)\n",
      "step 44530 \t loss = 0.045, train_acc = 1.000 (3.310 sec/step)\n",
      "step 44540 \t loss = 0.597, train_acc = 0.800 (3.358 sec/step)\n",
      "step 44550 \t loss = 0.112, train_acc = 1.000 (3.299 sec/step)\n",
      "step 44560 \t loss = 0.509, train_acc = 0.900 (3.282 sec/step)\n",
      "step 44570 \t loss = 0.005, train_acc = 1.000 (3.332 sec/step)\n",
      "step 44580 \t loss = 0.054, train_acc = 1.000 (3.371 sec/step)\n",
      "step 44590 \t loss = 0.000, train_acc = 1.000 (3.386 sec/step)\n",
      "step 44600 \t loss = 0.023, train_acc = 1.000 (3.280 sec/step)\n",
      "step 44610 \t loss = 0.040, train_acc = 1.000 (3.347 sec/step)\n",
      "step 44620 \t loss = 0.427, train_acc = 0.900 (3.352 sec/step)\n",
      "step 44630 \t loss = 0.253, train_acc = 0.900 (3.302 sec/step)\n",
      "step 44640 \t loss = 0.063, train_acc = 1.000 (3.345 sec/step)\n",
      "step 44650 \t loss = 0.001, train_acc = 1.000 (3.322 sec/step)\n",
      "step 44660 \t loss = 0.099, train_acc = 1.000 (3.348 sec/step)\n",
      "step 44670 \t loss = 0.845, train_acc = 0.900 (3.332 sec/step)\n",
      "step 44680 \t loss = 0.001, train_acc = 1.000 (3.319 sec/step)\n",
      "step 44690 \t loss = 0.924, train_acc = 0.900 (3.385 sec/step)\n",
      "step 44700 \t loss = 0.329, train_acc = 0.800 (3.340 sec/step)\n",
      "step 44710 \t loss = 0.056, train_acc = 1.000 (3.323 sec/step)\n",
      "step 44720 \t loss = 0.017, train_acc = 1.000 (3.354 sec/step)\n",
      "step 44730 \t loss = 0.000, train_acc = 1.000 (3.337 sec/step)\n",
      "step 44740 \t loss = 0.589, train_acc = 0.900 (3.323 sec/step)\n",
      "step 44750 \t loss = 0.957, train_acc = 0.900 (3.331 sec/step)\n",
      "step 44760 \t loss = 0.317, train_acc = 0.900 (3.315 sec/step)\n",
      "step 44770 \t loss = 0.174, train_acc = 0.900 (3.347 sec/step)\n",
      "step 44780 \t loss = 0.088, train_acc = 1.000 (3.289 sec/step)\n",
      "step 44790 \t loss = 2.106, train_acc = 0.800 (3.355 sec/step)\n",
      "step 44800 \t loss = 0.006, train_acc = 1.000 (3.281 sec/step)\n",
      "step 44810 \t loss = 0.151, train_acc = 0.900 (3.272 sec/step)\n",
      "step 44820 \t loss = 0.001, train_acc = 1.000 (3.284 sec/step)\n",
      "step 44830 \t loss = 0.136, train_acc = 1.000 (3.307 sec/step)\n",
      "step 44840 \t loss = 0.055, train_acc = 1.000 (3.333 sec/step)\n",
      "step 44850 \t loss = 0.475, train_acc = 0.900 (3.306 sec/step)\n",
      "step 44860 \t loss = 0.007, train_acc = 1.000 (3.336 sec/step)\n",
      "step 44870 \t loss = 0.015, train_acc = 1.000 (3.349 sec/step)\n",
      "step 44880 \t loss = 0.039, train_acc = 1.000 (3.410 sec/step)\n",
      "step 44890 \t loss = 0.295, train_acc = 0.900 (3.342 sec/step)\n",
      "step 44900 \t loss = 0.201, train_acc = 0.900 (3.326 sec/step)\n",
      "step 44910 \t loss = 0.287, train_acc = 0.900 (3.324 sec/step)\n",
      "step 44920 \t loss = 0.097, train_acc = 1.000 (3.288 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44930 \t loss = 0.236, train_acc = 0.900 (3.343 sec/step)\n",
      "step 44940 \t loss = 0.014, train_acc = 1.000 (3.354 sec/step)\n",
      "step 44950 \t loss = 0.010, train_acc = 1.000 (3.366 sec/step)\n",
      "step 44960 \t loss = 0.062, train_acc = 1.000 (3.374 sec/step)\n",
      "step 44970 \t loss = 0.836, train_acc = 0.900 (3.334 sec/step)\n",
      "step 44980 \t loss = 0.001, train_acc = 1.000 (3.306 sec/step)\n",
      "step 44990 \t loss = 0.062, train_acc = 1.000 (3.343 sec/step)\n",
      "step 45000 \t loss = 0.001, train_acc = 1.000 (3.307 sec/step)\n",
      "step 45010 \t loss = 0.242, train_acc = 0.900 (3.369 sec/step)\n",
      "step 45020 \t loss = 0.069, train_acc = 1.000 (3.385 sec/step)\n",
      "step 45030 \t loss = 0.003, train_acc = 1.000 (3.426 sec/step)\n",
      "step 45040 \t loss = 0.707, train_acc = 0.900 (3.326 sec/step)\n",
      "step 45050 \t loss = 0.407, train_acc = 0.900 (3.344 sec/step)\n",
      "step 45060 \t loss = 0.205, train_acc = 0.900 (3.314 sec/step)\n",
      "step 45070 \t loss = 0.021, train_acc = 1.000 (3.302 sec/step)\n",
      "step 45080 \t loss = 0.023, train_acc = 1.000 (3.364 sec/step)\n",
      "step 45090 \t loss = 0.174, train_acc = 0.900 (3.283 sec/step)\n",
      "step 45100 \t loss = 0.351, train_acc = 0.800 (3.358 sec/step)\n",
      "step 45110 \t loss = 0.183, train_acc = 1.000 (3.325 sec/step)\n",
      "step 45120 \t loss = 0.002, train_acc = 1.000 (3.334 sec/step)\n",
      "step 45130 \t loss = 1.899, train_acc = 0.900 (3.337 sec/step)\n",
      "step 45140 \t loss = 0.226, train_acc = 0.800 (3.336 sec/step)\n",
      "step 45150 \t loss = 1.213, train_acc = 0.800 (3.299 sec/step)\n",
      "step 45160 \t loss = 0.132, train_acc = 0.900 (3.372 sec/step)\n",
      "step 45170 \t loss = 0.053, train_acc = 1.000 (3.322 sec/step)\n",
      "step 45180 \t loss = 0.071, train_acc = 1.000 (3.291 sec/step)\n",
      "step 45190 \t loss = 0.157, train_acc = 0.900 (3.327 sec/step)\n",
      "step 45200 \t loss = 0.572, train_acc = 0.900 (3.328 sec/step)\n",
      "step 45210 \t loss = 0.002, train_acc = 1.000 (3.272 sec/step)\n",
      "step 45220 \t loss = 0.001, train_acc = 1.000 (3.304 sec/step)\n",
      "step 45230 \t loss = 0.031, train_acc = 1.000 (3.316 sec/step)\n",
      "step 45240 \t loss = 0.086, train_acc = 1.000 (3.272 sec/step)\n",
      "step 45250 \t loss = 0.004, train_acc = 1.000 (3.319 sec/step)\n",
      "step 45260 \t loss = 0.029, train_acc = 1.000 (3.361 sec/step)\n",
      "step 45270 \t loss = 0.353, train_acc = 0.700 (3.381 sec/step)\n",
      "step 45280 \t loss = 0.030, train_acc = 1.000 (3.370 sec/step)\n",
      "step 45290 \t loss = 0.113, train_acc = 0.900 (3.292 sec/step)\n",
      "step 45300 \t loss = 0.163, train_acc = 0.900 (3.305 sec/step)\n",
      "step 45310 \t loss = 0.305, train_acc = 0.900 (3.337 sec/step)\n",
      "step 45320 \t loss = 0.000, train_acc = 1.000 (3.392 sec/step)\n",
      "step 45330 \t loss = 0.003, train_acc = 1.000 (3.321 sec/step)\n",
      "step 45340 \t loss = 0.039, train_acc = 1.000 (3.281 sec/step)\n",
      "step 45350 \t loss = 0.059, train_acc = 1.000 (3.307 sec/step)\n",
      "step 45360 \t loss = 0.185, train_acc = 0.900 (3.319 sec/step)\n",
      "step 45370 \t loss = 0.029, train_acc = 1.000 (3.282 sec/step)\n",
      "step 45380 \t loss = 0.068, train_acc = 1.000 (3.274 sec/step)\n",
      "step 45390 \t loss = 0.004, train_acc = 1.000 (3.359 sec/step)\n",
      "step 45400 \t loss = 0.001, train_acc = 1.000 (3.336 sec/step)\n",
      "step 45410 \t loss = 0.730, train_acc = 0.900 (3.311 sec/step)\n",
      "step 45420 \t loss = 0.060, train_acc = 1.000 (3.346 sec/step)\n",
      "step 45430 \t loss = 0.100, train_acc = 1.000 (3.345 sec/step)\n",
      "step 45440 \t loss = 0.269, train_acc = 0.900 (3.315 sec/step)\n",
      "step 45450 \t loss = 0.023, train_acc = 1.000 (3.415 sec/step)\n",
      "step 45460 \t loss = 0.036, train_acc = 1.000 (3.316 sec/step)\n",
      "step 45470 \t loss = 0.000, train_acc = 1.000 (3.336 sec/step)\n",
      "step 45480 \t loss = 0.010, train_acc = 1.000 (3.297 sec/step)\n",
      "step 45490 \t loss = 0.000, train_acc = 1.000 (3.351 sec/step)\n",
      "step 45500 \t loss = 0.628, train_acc = 0.800 (3.343 sec/step)\n",
      "step 45510 \t loss = 0.188, train_acc = 0.900 (3.337 sec/step)\n",
      "step 45520 \t loss = 3.747, train_acc = 0.900 (3.357 sec/step)\n",
      "step 45530 \t loss = 0.220, train_acc = 0.900 (3.300 sec/step)\n",
      "step 45540 \t loss = 0.501, train_acc = 0.900 (3.295 sec/step)\n",
      "step 45550 \t loss = 0.104, train_acc = 1.000 (3.304 sec/step)\n",
      "step 45560 \t loss = 0.297, train_acc = 0.900 (3.396 sec/step)\n",
      "step 45570 \t loss = 0.030, train_acc = 1.000 (3.325 sec/step)\n",
      "step 45580 \t loss = 0.017, train_acc = 1.000 (3.307 sec/step)\n",
      "step 45590 \t loss = 0.940, train_acc = 0.800 (3.321 sec/step)\n",
      "VALIDATION \t acc = 0.545 (3.618 sec)\n",
      "step 45600 \t loss = 0.291, train_acc = 0.900 (3.336 sec/step)\n",
      "step 45610 \t loss = 0.378, train_acc = 0.900 (3.352 sec/step)\n",
      "step 45620 \t loss = 0.119, train_acc = 1.000 (3.316 sec/step)\n",
      "step 45630 \t loss = 0.110, train_acc = 1.000 (3.282 sec/step)\n",
      "step 45640 \t loss = 0.262, train_acc = 0.800 (3.347 sec/step)\n",
      "step 45650 \t loss = 0.123, train_acc = 1.000 (3.284 sec/step)\n",
      "step 45660 \t loss = 0.003, train_acc = 1.000 (3.342 sec/step)\n",
      "step 45670 \t loss = 0.230, train_acc = 0.900 (3.325 sec/step)\n",
      "step 45680 \t loss = 0.014, train_acc = 1.000 (3.343 sec/step)\n",
      "step 45690 \t loss = 0.002, train_acc = 1.000 (3.326 sec/step)\n",
      "step 45700 \t loss = 0.362, train_acc = 0.900 (3.275 sec/step)\n",
      "step 45710 \t loss = 0.074, train_acc = 1.000 (3.335 sec/step)\n",
      "step 45720 \t loss = 0.477, train_acc = 0.800 (3.408 sec/step)\n",
      "step 45730 \t loss = 0.142, train_acc = 0.900 (3.402 sec/step)\n",
      "step 45740 \t loss = 0.512, train_acc = 0.900 (3.344 sec/step)\n",
      "step 45750 \t loss = 0.001, train_acc = 1.000 (3.320 sec/step)\n",
      "step 45760 \t loss = 0.601, train_acc = 0.800 (3.408 sec/step)\n",
      "step 45770 \t loss = 0.584, train_acc = 0.900 (3.322 sec/step)\n",
      "step 45780 \t loss = 0.798, train_acc = 0.900 (3.309 sec/step)\n",
      "step 45790 \t loss = 0.190, train_acc = 1.000 (3.307 sec/step)\n",
      "step 45800 \t loss = 0.112, train_acc = 1.000 (3.268 sec/step)\n",
      "step 45810 \t loss = 0.039, train_acc = 1.000 (3.300 sec/step)\n",
      "step 45820 \t loss = 0.020, train_acc = 1.000 (3.343 sec/step)\n",
      "step 45830 \t loss = 0.321, train_acc = 0.900 (3.318 sec/step)\n",
      "step 45840 \t loss = 0.454, train_acc = 0.800 (3.326 sec/step)\n",
      "step 45850 \t loss = 0.271, train_acc = 0.900 (3.297 sec/step)\n",
      "step 45860 \t loss = 0.078, train_acc = 1.000 (3.348 sec/step)\n",
      "step 45870 \t loss = 0.444, train_acc = 0.800 (3.393 sec/step)\n",
      "step 45880 \t loss = 0.080, train_acc = 1.000 (3.336 sec/step)\n",
      "step 45890 \t loss = 0.234, train_acc = 0.900 (3.318 sec/step)\n",
      "step 45900 \t loss = 1.558, train_acc = 0.600 (3.298 sec/step)\n",
      "step 45910 \t loss = 0.251, train_acc = 0.900 (3.365 sec/step)\n",
      "step 45920 \t loss = 0.699, train_acc = 0.900 (3.348 sec/step)\n",
      "step 45930 \t loss = 0.354, train_acc = 0.900 (3.366 sec/step)\n",
      "step 45940 \t loss = 0.363, train_acc = 0.900 (3.276 sec/step)\n",
      "step 45950 \t loss = 0.334, train_acc = 0.900 (3.342 sec/step)\n",
      "step 45960 \t loss = 0.619, train_acc = 0.800 (3.371 sec/step)\n",
      "step 45970 \t loss = 0.001, train_acc = 1.000 (3.374 sec/step)\n",
      "step 45980 \t loss = 0.013, train_acc = 1.000 (3.407 sec/step)\n",
      "step 45990 \t loss = 0.389, train_acc = 0.900 (3.303 sec/step)\n",
      "step 46000 \t loss = 0.007, train_acc = 1.000 (3.302 sec/step)\n",
      "step 46010 \t loss = 0.108, train_acc = 1.000 (3.368 sec/step)\n",
      "step 46020 \t loss = 0.205, train_acc = 0.800 (3.298 sec/step)\n",
      "step 46030 \t loss = 0.010, train_acc = 1.000 (3.378 sec/step)\n",
      "step 46040 \t loss = 0.140, train_acc = 0.900 (3.366 sec/step)\n",
      "step 46050 \t loss = 0.189, train_acc = 1.000 (3.423 sec/step)\n",
      "step 46060 \t loss = 0.227, train_acc = 0.900 (3.295 sec/step)\n",
      "step 46070 \t loss = 1.088, train_acc = 0.800 (3.303 sec/step)\n",
      "step 46080 \t loss = 0.088, train_acc = 0.900 (3.328 sec/step)\n",
      "step 46090 \t loss = 0.173, train_acc = 0.900 (3.285 sec/step)\n",
      "step 46100 \t loss = 0.567, train_acc = 0.700 (3.302 sec/step)\n",
      "step 46110 \t loss = 0.200, train_acc = 0.900 (3.350 sec/step)\n",
      "step 46120 \t loss = 0.160, train_acc = 0.900 (3.323 sec/step)\n",
      "step 46130 \t loss = 0.535, train_acc = 0.900 (3.432 sec/step)\n",
      "step 46140 \t loss = 0.005, train_acc = 1.000 (3.320 sec/step)\n",
      "step 46150 \t loss = 0.174, train_acc = 0.900 (3.360 sec/step)\n",
      "step 46160 \t loss = 0.406, train_acc = 0.800 (3.271 sec/step)\n",
      "step 46170 \t loss = 0.030, train_acc = 1.000 (3.307 sec/step)\n",
      "step 46180 \t loss = 0.193, train_acc = 1.000 (3.311 sec/step)\n",
      "step 46190 \t loss = 0.029, train_acc = 1.000 (3.332 sec/step)\n",
      "step 46200 \t loss = 0.211, train_acc = 0.900 (3.413 sec/step)\n",
      "step 46210 \t loss = 0.681, train_acc = 0.800 (3.309 sec/step)\n",
      "step 46220 \t loss = 0.194, train_acc = 0.900 (3.376 sec/step)\n",
      "step 46230 \t loss = 0.724, train_acc = 0.600 (3.353 sec/step)\n",
      "step 46240 \t loss = 0.963, train_acc = 0.900 (3.313 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46250 \t loss = 0.495, train_acc = 0.800 (3.362 sec/step)\n",
      "step 46260 \t loss = 0.208, train_acc = 0.900 (3.323 sec/step)\n",
      "step 46270 \t loss = 0.136, train_acc = 1.000 (3.284 sec/step)\n",
      "step 46280 \t loss = 0.641, train_acc = 0.900 (3.350 sec/step)\n",
      "step 46290 \t loss = 0.027, train_acc = 1.000 (3.283 sec/step)\n",
      "step 46300 \t loss = 0.014, train_acc = 1.000 (3.334 sec/step)\n",
      "step 46310 \t loss = 0.471, train_acc = 0.900 (3.345 sec/step)\n",
      "step 46320 \t loss = 0.218, train_acc = 0.900 (3.321 sec/step)\n",
      "step 46330 \t loss = 0.057, train_acc = 1.000 (3.352 sec/step)\n",
      "step 46340 \t loss = 0.061, train_acc = 1.000 (3.297 sec/step)\n",
      "step 46350 \t loss = 0.047, train_acc = 1.000 (3.370 sec/step)\n",
      "step 46360 \t loss = 0.249, train_acc = 0.800 (3.304 sec/step)\n",
      "step 46370 \t loss = 0.002, train_acc = 1.000 (3.322 sec/step)\n",
      "step 46380 \t loss = 0.063, train_acc = 1.000 (3.317 sec/step)\n",
      "step 46390 \t loss = 0.288, train_acc = 0.900 (3.342 sec/step)\n",
      "step 46400 \t loss = 0.044, train_acc = 1.000 (3.335 sec/step)\n",
      "step 46410 \t loss = 0.175, train_acc = 0.900 (3.338 sec/step)\n",
      "step 46420 \t loss = 0.034, train_acc = 1.000 (3.420 sec/step)\n",
      "step 46430 \t loss = 0.000, train_acc = 1.000 (3.327 sec/step)\n",
      "step 46440 \t loss = 0.243, train_acc = 0.900 (3.364 sec/step)\n",
      "step 46450 \t loss = 0.899, train_acc = 0.900 (3.327 sec/step)\n",
      "step 46460 \t loss = 0.401, train_acc = 0.900 (3.277 sec/step)\n",
      "step 46470 \t loss = 1.277, train_acc = 0.900 (3.305 sec/step)\n",
      "step 46480 \t loss = 0.606, train_acc = 0.900 (3.342 sec/step)\n",
      "step 46490 \t loss = 0.274, train_acc = 0.900 (3.416 sec/step)\n",
      "step 46500 \t loss = 0.368, train_acc = 0.900 (3.294 sec/step)\n",
      "step 46510 \t loss = 0.496, train_acc = 0.900 (3.322 sec/step)\n",
      "step 46520 \t loss = 0.220, train_acc = 0.900 (3.360 sec/step)\n",
      "step 46530 \t loss = 0.178, train_acc = 0.900 (3.338 sec/step)\n",
      "step 46540 \t loss = 0.618, train_acc = 0.800 (3.361 sec/step)\n",
      "step 46550 \t loss = 0.393, train_acc = 0.800 (3.326 sec/step)\n",
      "step 46560 \t loss = 0.409, train_acc = 0.900 (3.303 sec/step)\n",
      "step 46570 \t loss = 0.000, train_acc = 1.000 (3.348 sec/step)\n",
      "step 46580 \t loss = 0.240, train_acc = 0.800 (3.297 sec/step)\n",
      "step 46590 \t loss = 0.176, train_acc = 0.900 (3.311 sec/step)\n",
      "step 46600 \t loss = 0.191, train_acc = 0.900 (3.370 sec/step)\n",
      "step 46610 \t loss = 0.071, train_acc = 1.000 (3.372 sec/step)\n",
      "step 46620 \t loss = 0.008, train_acc = 1.000 (3.312 sec/step)\n",
      "step 46630 \t loss = 0.041, train_acc = 1.000 (3.326 sec/step)\n",
      "step 46640 \t loss = 0.082, train_acc = 1.000 (3.312 sec/step)\n",
      "step 46650 \t loss = 0.192, train_acc = 0.900 (3.328 sec/step)\n",
      "step 46660 \t loss = 0.039, train_acc = 1.000 (3.348 sec/step)\n",
      "step 46670 \t loss = 0.288, train_acc = 0.800 (3.408 sec/step)\n",
      "step 46680 \t loss = 0.106, train_acc = 1.000 (3.342 sec/step)\n",
      "step 46690 \t loss = 0.078, train_acc = 1.000 (3.361 sec/step)\n",
      "step 46700 \t loss = 0.027, train_acc = 1.000 (3.311 sec/step)\n",
      "step 46710 \t loss = 0.259, train_acc = 0.900 (3.331 sec/step)\n",
      "step 46720 \t loss = 0.055, train_acc = 1.000 (3.375 sec/step)\n",
      "step 46730 \t loss = 0.018, train_acc = 1.000 (3.298 sec/step)\n",
      "step 46740 \t loss = 0.446, train_acc = 0.900 (3.308 sec/step)\n",
      "step 46750 \t loss = 0.052, train_acc = 1.000 (3.367 sec/step)\n",
      "step 46760 \t loss = 0.106, train_acc = 1.000 (3.361 sec/step)\n",
      "step 46770 \t loss = 0.000, train_acc = 1.000 (3.321 sec/step)\n",
      "step 46780 \t loss = 0.015, train_acc = 1.000 (3.333 sec/step)\n",
      "step 46790 \t loss = 0.035, train_acc = 1.000 (3.357 sec/step)\n",
      "step 46800 \t loss = 1.581, train_acc = 0.900 (3.304 sec/step)\n",
      "step 46810 \t loss = 0.378, train_acc = 0.800 (3.281 sec/step)\n",
      "step 46820 \t loss = 0.004, train_acc = 1.000 (3.327 sec/step)\n",
      "step 46830 \t loss = 0.168, train_acc = 0.900 (3.358 sec/step)\n",
      "step 46840 \t loss = 1.065, train_acc = 0.900 (3.280 sec/step)\n",
      "step 46850 \t loss = 0.113, train_acc = 0.900 (3.340 sec/step)\n",
      "step 46860 \t loss = 0.235, train_acc = 0.900 (3.299 sec/step)\n",
      "step 46870 \t loss = 0.482, train_acc = 0.800 (3.308 sec/step)\n",
      "step 46880 \t loss = 0.052, train_acc = 1.000 (3.294 sec/step)\n",
      "step 46890 \t loss = 0.492, train_acc = 0.800 (3.342 sec/step)\n",
      "step 46900 \t loss = 0.003, train_acc = 1.000 (3.287 sec/step)\n",
      "step 46910 \t loss = 0.169, train_acc = 0.900 (3.346 sec/step)\n",
      "step 46920 \t loss = 0.237, train_acc = 0.900 (3.321 sec/step)\n",
      "step 46930 \t loss = 0.068, train_acc = 1.000 (3.331 sec/step)\n",
      "step 46940 \t loss = 0.002, train_acc = 1.000 (3.363 sec/step)\n",
      "step 46950 \t loss = 0.126, train_acc = 0.900 (3.368 sec/step)\n",
      "step 46960 \t loss = 0.036, train_acc = 1.000 (3.284 sec/step)\n",
      "step 46970 \t loss = 0.017, train_acc = 1.000 (3.383 sec/step)\n",
      "step 46980 \t loss = 0.001, train_acc = 1.000 (3.310 sec/step)\n",
      "step 46990 \t loss = 1.210, train_acc = 0.900 (3.285 sec/step)\n",
      "step 47000 \t loss = 0.259, train_acc = 0.900 (3.294 sec/step)\n",
      "step 47010 \t loss = 0.383, train_acc = 0.800 (3.304 sec/step)\n",
      "step 47020 \t loss = 0.109, train_acc = 1.000 (3.368 sec/step)\n",
      "step 47030 \t loss = 0.021, train_acc = 1.000 (3.273 sec/step)\n",
      "step 47040 \t loss = 0.000, train_acc = 1.000 (3.324 sec/step)\n",
      "step 47050 \t loss = 0.318, train_acc = 0.900 (3.289 sec/step)\n",
      "step 47060 \t loss = 0.001, train_acc = 1.000 (3.330 sec/step)\n",
      "step 47070 \t loss = 0.870, train_acc = 0.800 (3.284 sec/step)\n",
      "step 47080 \t loss = 0.640, train_acc = 0.800 (3.268 sec/step)\n",
      "step 47090 \t loss = 0.367, train_acc = 0.800 (3.350 sec/step)\n",
      "step 47100 \t loss = 0.380, train_acc = 0.900 (3.358 sec/step)\n",
      "step 47110 \t loss = 0.372, train_acc = 0.900 (3.293 sec/step)\n",
      "step 47120 \t loss = 0.880, train_acc = 0.800 (3.285 sec/step)\n",
      "step 47130 \t loss = 0.098, train_acc = 1.000 (3.301 sec/step)\n",
      "step 47140 \t loss = 0.259, train_acc = 0.900 (3.282 sec/step)\n",
      "step 47150 \t loss = 0.072, train_acc = 1.000 (3.291 sec/step)\n",
      "step 47160 \t loss = 0.087, train_acc = 0.900 (3.381 sec/step)\n",
      "step 47170 \t loss = 0.000, train_acc = 1.000 (3.286 sec/step)\n",
      "step 47180 \t loss = 0.014, train_acc = 1.000 (3.310 sec/step)\n",
      "step 47190 \t loss = 0.006, train_acc = 1.000 (3.322 sec/step)\n",
      "step 47200 \t loss = 0.316, train_acc = 0.900 (3.308 sec/step)\n",
      "step 47210 \t loss = 0.539, train_acc = 0.800 (3.323 sec/step)\n",
      "step 47220 \t loss = 0.019, train_acc = 1.000 (3.324 sec/step)\n",
      "step 47230 \t loss = 0.032, train_acc = 1.000 (3.352 sec/step)\n",
      "step 47240 \t loss = 0.007, train_acc = 1.000 (3.358 sec/step)\n",
      "step 47250 \t loss = 0.225, train_acc = 0.800 (3.352 sec/step)\n",
      "step 47260 \t loss = 0.004, train_acc = 1.000 (3.364 sec/step)\n",
      "step 47270 \t loss = 0.003, train_acc = 1.000 (3.349 sec/step)\n",
      "step 47280 \t loss = 0.156, train_acc = 0.900 (3.358 sec/step)\n",
      "step 47290 \t loss = 0.003, train_acc = 1.000 (3.357 sec/step)\n",
      "step 47300 \t loss = 0.254, train_acc = 0.900 (3.291 sec/step)\n",
      "step 47310 \t loss = 0.100, train_acc = 1.000 (3.304 sec/step)\n",
      "step 47320 \t loss = 0.317, train_acc = 0.900 (3.324 sec/step)\n",
      "step 47330 \t loss = 0.074, train_acc = 1.000 (3.283 sec/step)\n",
      "step 47340 \t loss = 0.050, train_acc = 1.000 (3.276 sec/step)\n",
      "step 47350 \t loss = 0.003, train_acc = 1.000 (3.342 sec/step)\n",
      "step 47360 \t loss = 0.270, train_acc = 0.900 (3.324 sec/step)\n",
      "step 47370 \t loss = 0.067, train_acc = 1.000 (3.322 sec/step)\n",
      "step 47380 \t loss = 0.369, train_acc = 0.900 (3.317 sec/step)\n",
      "step 47390 \t loss = 0.416, train_acc = 0.900 (3.353 sec/step)\n",
      "step 47400 \t loss = 0.246, train_acc = 0.900 (3.327 sec/step)\n",
      "step 47410 \t loss = 0.002, train_acc = 1.000 (3.354 sec/step)\n",
      "step 47420 \t loss = 0.017, train_acc = 1.000 (3.399 sec/step)\n",
      "step 47430 \t loss = 0.166, train_acc = 0.900 (3.347 sec/step)\n",
      "step 47440 \t loss = 0.494, train_acc = 0.900 (3.352 sec/step)\n",
      "step 47450 \t loss = 0.256, train_acc = 0.900 (3.327 sec/step)\n",
      "step 47460 \t loss = 0.084, train_acc = 1.000 (3.379 sec/step)\n",
      "step 47470 \t loss = 0.011, train_acc = 1.000 (3.424 sec/step)\n",
      "step 47480 \t loss = 0.006, train_acc = 1.000 (3.316 sec/step)\n",
      "step 47490 \t loss = 0.678, train_acc = 0.900 (3.325 sec/step)\n",
      "VALIDATION \t acc = 0.546 (3.628 sec)\n",
      "step 47500 \t loss = 0.967, train_acc = 0.800 (3.339 sec/step)\n",
      "step 47510 \t loss = 0.106, train_acc = 1.000 (3.303 sec/step)\n",
      "step 47520 \t loss = 0.051, train_acc = 1.000 (3.348 sec/step)\n",
      "step 47530 \t loss = 0.149, train_acc = 0.900 (3.296 sec/step)\n",
      "step 47540 \t loss = 0.044, train_acc = 1.000 (3.348 sec/step)\n",
      "step 47550 \t loss = 0.349, train_acc = 0.900 (3.342 sec/step)\n",
      "step 47560 \t loss = 0.277, train_acc = 0.800 (3.372 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 47570 \t loss = 0.001, train_acc = 1.000 (3.292 sec/step)\n",
      "step 47580 \t loss = 0.184, train_acc = 0.900 (3.336 sec/step)\n",
      "step 47590 \t loss = 0.002, train_acc = 1.000 (3.319 sec/step)\n",
      "step 47600 \t loss = 0.113, train_acc = 0.900 (3.301 sec/step)\n",
      "step 47610 \t loss = 0.067, train_acc = 1.000 (3.358 sec/step)\n",
      "step 47620 \t loss = 0.110, train_acc = 1.000 (3.303 sec/step)\n",
      "step 47630 \t loss = 0.063, train_acc = 1.000 (3.328 sec/step)\n",
      "step 47640 \t loss = 0.076, train_acc = 1.000 (3.360 sec/step)\n",
      "step 47650 \t loss = 0.414, train_acc = 0.800 (3.326 sec/step)\n",
      "step 47660 \t loss = 0.005, train_acc = 1.000 (3.283 sec/step)\n",
      "step 47670 \t loss = 0.040, train_acc = 1.000 (3.361 sec/step)\n",
      "step 47680 \t loss = 0.001, train_acc = 1.000 (3.323 sec/step)\n",
      "step 47690 \t loss = 0.026, train_acc = 1.000 (3.347 sec/step)\n",
      "step 47700 \t loss = 1.146, train_acc = 0.900 (3.309 sec/step)\n",
      "step 47710 \t loss = 0.771, train_acc = 0.900 (3.351 sec/step)\n",
      "step 47720 \t loss = 0.081, train_acc = 1.000 (3.361 sec/step)\n",
      "step 47730 \t loss = 0.194, train_acc = 0.900 (3.322 sec/step)\n",
      "step 47740 \t loss = 0.158, train_acc = 1.000 (3.343 sec/step)\n",
      "step 47750 \t loss = 0.294, train_acc = 0.900 (3.303 sec/step)\n",
      "step 47760 \t loss = 0.354, train_acc = 0.900 (3.342 sec/step)\n",
      "step 47770 \t loss = 0.312, train_acc = 0.800 (3.361 sec/step)\n",
      "step 47780 \t loss = 0.006, train_acc = 1.000 (3.322 sec/step)\n",
      "step 47790 \t loss = 0.101, train_acc = 1.000 (3.287 sec/step)\n",
      "step 47800 \t loss = 0.548, train_acc = 0.800 (3.315 sec/step)\n",
      "step 47810 \t loss = 0.702, train_acc = 0.800 (3.367 sec/step)\n",
      "step 47820 \t loss = 0.025, train_acc = 1.000 (3.301 sec/step)\n",
      "step 47830 \t loss = 0.198, train_acc = 0.900 (3.298 sec/step)\n",
      "step 47840 \t loss = 1.347, train_acc = 0.800 (3.313 sec/step)\n",
      "step 47850 \t loss = 0.327, train_acc = 0.800 (3.309 sec/step)\n",
      "step 47860 \t loss = 0.450, train_acc = 0.900 (3.293 sec/step)\n",
      "step 47870 \t loss = 0.045, train_acc = 1.000 (3.332 sec/step)\n",
      "step 47880 \t loss = 0.018, train_acc = 1.000 (3.334 sec/step)\n",
      "step 47890 \t loss = 0.084, train_acc = 1.000 (3.302 sec/step)\n",
      "step 47900 \t loss = 1.012, train_acc = 0.700 (3.377 sec/step)\n",
      "step 47910 \t loss = 0.088, train_acc = 1.000 (3.300 sec/step)\n",
      "step 47920 \t loss = 0.262, train_acc = 0.900 (3.334 sec/step)\n",
      "step 47930 \t loss = 0.009, train_acc = 1.000 (3.323 sec/step)\n",
      "step 47940 \t loss = 1.024, train_acc = 0.800 (3.352 sec/step)\n",
      "step 47950 \t loss = 0.361, train_acc = 0.900 (3.297 sec/step)\n",
      "step 47960 \t loss = 0.001, train_acc = 1.000 (3.316 sec/step)\n",
      "step 47970 \t loss = 0.348, train_acc = 0.900 (3.284 sec/step)\n",
      "step 47980 \t loss = 0.301, train_acc = 0.800 (3.297 sec/step)\n",
      "step 47990 \t loss = 0.226, train_acc = 0.900 (3.357 sec/step)\n",
      "step 48000 \t loss = 0.076, train_acc = 1.000 (3.304 sec/step)\n",
      "step 48010 \t loss = 1.307, train_acc = 0.900 (3.360 sec/step)\n",
      "step 48020 \t loss = 0.620, train_acc = 0.700 (3.346 sec/step)\n",
      "step 48030 \t loss = 0.632, train_acc = 0.800 (3.276 sec/step)\n",
      "step 48040 \t loss = 0.270, train_acc = 0.900 (3.371 sec/step)\n",
      "step 48050 \t loss = 0.000, train_acc = 1.000 (3.345 sec/step)\n",
      "step 48060 \t loss = 0.115, train_acc = 1.000 (3.296 sec/step)\n",
      "step 48070 \t loss = 0.043, train_acc = 1.000 (3.361 sec/step)\n",
      "step 48080 \t loss = 0.061, train_acc = 1.000 (3.325 sec/step)\n",
      "step 48090 \t loss = 0.019, train_acc = 1.000 (3.353 sec/step)\n",
      "step 48100 \t loss = 0.300, train_acc = 0.900 (3.359 sec/step)\n",
      "step 48110 \t loss = 0.095, train_acc = 1.000 (3.315 sec/step)\n",
      "step 48120 \t loss = 0.002, train_acc = 1.000 (3.343 sec/step)\n",
      "step 48130 \t loss = 0.130, train_acc = 0.900 (3.332 sec/step)\n",
      "step 48140 \t loss = 0.950, train_acc = 0.800 (3.272 sec/step)\n",
      "step 48150 \t loss = 0.381, train_acc = 0.900 (3.360 sec/step)\n",
      "step 48160 \t loss = 0.435, train_acc = 0.900 (3.353 sec/step)\n",
      "step 48170 \t loss = 0.703, train_acc = 0.900 (3.331 sec/step)\n",
      "step 48180 \t loss = 0.528, train_acc = 0.900 (3.360 sec/step)\n",
      "step 48190 \t loss = 0.113, train_acc = 0.900 (3.368 sec/step)\n",
      "step 48200 \t loss = 0.340, train_acc = 0.900 (3.360 sec/step)\n",
      "step 48210 \t loss = 0.039, train_acc = 1.000 (3.328 sec/step)\n",
      "step 48220 \t loss = 0.028, train_acc = 1.000 (3.290 sec/step)\n",
      "step 48230 \t loss = 0.012, train_acc = 1.000 (3.294 sec/step)\n",
      "step 48240 \t loss = 0.000, train_acc = 1.000 (3.332 sec/step)\n",
      "step 48250 \t loss = 0.198, train_acc = 0.900 (3.309 sec/step)\n",
      "step 48260 \t loss = 0.065, train_acc = 1.000 (3.313 sec/step)\n",
      "step 48270 \t loss = 0.673, train_acc = 0.900 (3.324 sec/step)\n",
      "step 48280 \t loss = 0.491, train_acc = 0.900 (3.301 sec/step)\n",
      "step 48290 \t loss = 0.048, train_acc = 1.000 (3.323 sec/step)\n",
      "step 48300 \t loss = 0.001, train_acc = 1.000 (3.298 sec/step)\n",
      "step 48310 \t loss = 0.031, train_acc = 1.000 (3.293 sec/step)\n",
      "step 48320 \t loss = 0.001, train_acc = 1.000 (3.312 sec/step)\n",
      "step 48330 \t loss = 0.000, train_acc = 1.000 (3.325 sec/step)\n",
      "step 48340 \t loss = 0.859, train_acc = 0.700 (3.318 sec/step)\n",
      "step 48350 \t loss = 0.032, train_acc = 1.000 (3.354 sec/step)\n",
      "step 48360 \t loss = 0.802, train_acc = 0.800 (3.330 sec/step)\n",
      "step 48370 \t loss = 0.029, train_acc = 1.000 (3.349 sec/step)\n",
      "step 48380 \t loss = 0.004, train_acc = 1.000 (3.365 sec/step)\n",
      "step 48390 \t loss = 0.891, train_acc = 0.900 (3.292 sec/step)\n",
      "step 48400 \t loss = 0.000, train_acc = 1.000 (3.349 sec/step)\n",
      "step 48410 \t loss = 0.234, train_acc = 0.900 (3.286 sec/step)\n",
      "step 48420 \t loss = 0.038, train_acc = 1.000 (3.352 sec/step)\n",
      "step 48430 \t loss = 0.027, train_acc = 1.000 (3.347 sec/step)\n",
      "step 48440 \t loss = 0.023, train_acc = 1.000 (3.289 sec/step)\n",
      "step 48450 \t loss = 0.022, train_acc = 1.000 (3.301 sec/step)\n",
      "step 48460 \t loss = 0.002, train_acc = 1.000 (3.317 sec/step)\n",
      "step 48470 \t loss = 0.902, train_acc = 0.900 (3.315 sec/step)\n",
      "step 48480 \t loss = 0.156, train_acc = 0.900 (3.322 sec/step)\n",
      "step 48490 \t loss = 0.227, train_acc = 0.800 (3.282 sec/step)\n",
      "step 48500 \t loss = 0.167, train_acc = 0.900 (3.385 sec/step)\n",
      "step 48510 \t loss = 0.318, train_acc = 0.800 (3.302 sec/step)\n",
      "step 48520 \t loss = 0.486, train_acc = 0.900 (3.277 sec/step)\n",
      "step 48530 \t loss = 0.903, train_acc = 0.800 (3.362 sec/step)\n",
      "step 48540 \t loss = 0.375, train_acc = 0.900 (3.342 sec/step)\n",
      "step 48550 \t loss = 0.285, train_acc = 0.800 (3.432 sec/step)\n",
      "step 48560 \t loss = 0.012, train_acc = 1.000 (3.326 sec/step)\n",
      "step 48570 \t loss = 0.744, train_acc = 0.800 (3.364 sec/step)\n",
      "step 48580 \t loss = 0.480, train_acc = 0.900 (3.318 sec/step)\n",
      "step 48590 \t loss = 0.369, train_acc = 0.800 (3.311 sec/step)\n",
      "step 48600 \t loss = 0.121, train_acc = 0.900 (3.332 sec/step)\n",
      "step 48610 \t loss = 0.089, train_acc = 1.000 (3.283 sec/step)\n",
      "step 48620 \t loss = 0.060, train_acc = 1.000 (3.313 sec/step)\n",
      "step 48630 \t loss = 0.177, train_acc = 0.900 (3.304 sec/step)\n",
      "step 48640 \t loss = 0.394, train_acc = 0.800 (3.335 sec/step)\n",
      "step 48650 \t loss = 0.009, train_acc = 1.000 (3.312 sec/step)\n",
      "step 48660 \t loss = 0.417, train_acc = 0.800 (3.332 sec/step)\n",
      "step 48670 \t loss = 0.561, train_acc = 0.800 (3.294 sec/step)\n",
      "step 48680 \t loss = 0.107, train_acc = 0.900 (3.315 sec/step)\n",
      "step 48690 \t loss = 0.006, train_acc = 1.000 (3.308 sec/step)\n",
      "step 48700 \t loss = 0.000, train_acc = 1.000 (3.338 sec/step)\n",
      "step 48710 \t loss = 0.042, train_acc = 1.000 (3.302 sec/step)\n",
      "step 48720 \t loss = 0.276, train_acc = 0.800 (3.395 sec/step)\n",
      "step 48730 \t loss = 0.003, train_acc = 1.000 (3.315 sec/step)\n",
      "step 48740 \t loss = 0.354, train_acc = 0.900 (3.387 sec/step)\n",
      "step 48750 \t loss = 0.028, train_acc = 1.000 (3.305 sec/step)\n",
      "step 48760 \t loss = 0.049, train_acc = 1.000 (3.400 sec/step)\n",
      "step 48770 \t loss = 0.005, train_acc = 1.000 (3.307 sec/step)\n",
      "step 48780 \t loss = 0.236, train_acc = 0.900 (3.326 sec/step)\n",
      "step 48790 \t loss = 0.199, train_acc = 0.900 (3.313 sec/step)\n",
      "step 48800 \t loss = 0.022, train_acc = 1.000 (3.355 sec/step)\n",
      "step 48810 \t loss = 0.314, train_acc = 0.900 (3.386 sec/step)\n",
      "step 48820 \t loss = 0.002, train_acc = 1.000 (3.284 sec/step)\n",
      "step 48830 \t loss = 0.340, train_acc = 0.800 (3.324 sec/step)\n",
      "step 48840 \t loss = 0.025, train_acc = 1.000 (3.297 sec/step)\n",
      "step 48850 \t loss = 1.268, train_acc = 0.800 (3.347 sec/step)\n",
      "step 48860 \t loss = 0.309, train_acc = 0.900 (3.341 sec/step)\n",
      "step 48870 \t loss = 0.475, train_acc = 0.900 (3.378 sec/step)\n",
      "step 48880 \t loss = 1.126, train_acc = 0.700 (3.363 sec/step)\n",
      "step 48890 \t loss = 1.105, train_acc = 0.800 (3.288 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48900 \t loss = 0.110, train_acc = 1.000 (3.361 sec/step)\n",
      "step 48910 \t loss = 0.224, train_acc = 0.900 (3.317 sec/step)\n",
      "step 48920 \t loss = 0.105, train_acc = 1.000 (3.349 sec/step)\n",
      "step 48930 \t loss = 0.452, train_acc = 0.800 (3.293 sec/step)\n",
      "step 48940 \t loss = 0.015, train_acc = 1.000 (3.341 sec/step)\n",
      "step 48950 \t loss = 0.672, train_acc = 0.800 (3.295 sec/step)\n",
      "step 48960 \t loss = 0.000, train_acc = 1.000 (3.309 sec/step)\n",
      "step 48970 \t loss = 0.004, train_acc = 1.000 (3.285 sec/step)\n",
      "step 48980 \t loss = 0.159, train_acc = 0.900 (3.292 sec/step)\n",
      "step 48990 \t loss = 3.243, train_acc = 0.700 (3.295 sec/step)\n",
      "step 49000 \t loss = 0.079, train_acc = 1.000 (3.344 sec/step)\n",
      "step 49010 \t loss = 0.235, train_acc = 0.900 (3.348 sec/step)\n",
      "step 49020 \t loss = 0.070, train_acc = 0.900 (3.311 sec/step)\n",
      "step 49030 \t loss = 2.552, train_acc = 0.600 (3.346 sec/step)\n",
      "step 49040 \t loss = 0.357, train_acc = 0.900 (3.402 sec/step)\n",
      "step 49050 \t loss = 0.094, train_acc = 1.000 (3.375 sec/step)\n",
      "step 49060 \t loss = 0.015, train_acc = 1.000 (3.329 sec/step)\n",
      "step 49070 \t loss = 0.000, train_acc = 1.000 (3.340 sec/step)\n",
      "step 49080 \t loss = 0.004, train_acc = 1.000 (3.317 sec/step)\n",
      "step 49090 \t loss = 0.001, train_acc = 1.000 (3.366 sec/step)\n",
      "step 49100 \t loss = 0.370, train_acc = 0.900 (3.322 sec/step)\n",
      "step 49110 \t loss = 0.084, train_acc = 1.000 (3.326 sec/step)\n",
      "step 49120 \t loss = 0.029, train_acc = 1.000 (3.268 sec/step)\n",
      "step 49130 \t loss = 0.906, train_acc = 0.700 (3.301 sec/step)\n",
      "step 49140 \t loss = 1.694, train_acc = 0.500 (3.374 sec/step)\n",
      "step 49150 \t loss = 0.166, train_acc = 0.900 (3.317 sec/step)\n",
      "step 49160 \t loss = 0.343, train_acc = 0.900 (3.322 sec/step)\n",
      "step 49170 \t loss = 0.542, train_acc = 0.700 (3.368 sec/step)\n",
      "step 49180 \t loss = 0.009, train_acc = 1.000 (3.362 sec/step)\n",
      "step 49190 \t loss = 0.008, train_acc = 1.000 (3.289 sec/step)\n",
      "step 49200 \t loss = 0.662, train_acc = 0.900 (3.292 sec/step)\n",
      "step 49210 \t loss = 0.347, train_acc = 0.900 (3.376 sec/step)\n",
      "step 49220 \t loss = 0.140, train_acc = 0.900 (3.340 sec/step)\n",
      "step 49230 \t loss = 0.181, train_acc = 0.900 (3.360 sec/step)\n",
      "step 49240 \t loss = 4.162, train_acc = 0.700 (3.323 sec/step)\n",
      "step 49250 \t loss = 0.155, train_acc = 0.900 (3.307 sec/step)\n",
      "step 49260 \t loss = 0.167, train_acc = 0.900 (3.330 sec/step)\n",
      "step 49270 \t loss = 0.306, train_acc = 0.900 (3.361 sec/step)\n",
      "step 49280 \t loss = 0.306, train_acc = 0.900 (3.344 sec/step)\n",
      "step 49290 \t loss = 0.111, train_acc = 0.900 (3.293 sec/step)\n",
      "step 49300 \t loss = 0.155, train_acc = 0.900 (3.319 sec/step)\n",
      "step 49310 \t loss = 0.141, train_acc = 0.900 (3.306 sec/step)\n",
      "step 49320 \t loss = 0.308, train_acc = 0.800 (3.376 sec/step)\n",
      "step 49330 \t loss = 1.215, train_acc = 0.600 (3.320 sec/step)\n",
      "step 49340 \t loss = 0.984, train_acc = 0.700 (3.332 sec/step)\n",
      "step 49350 \t loss = 0.090, train_acc = 0.900 (3.270 sec/step)\n",
      "step 49360 \t loss = 0.516, train_acc = 0.800 (3.331 sec/step)\n",
      "step 49370 \t loss = 0.104, train_acc = 0.900 (3.335 sec/step)\n",
      "step 49380 \t loss = 0.066, train_acc = 1.000 (3.320 sec/step)\n",
      "step 49390 \t loss = 0.104, train_acc = 0.900 (3.318 sec/step)\n",
      "VALIDATION \t acc = 0.533 (3.640 sec)\n",
      "step 49400 \t loss = 0.001, train_acc = 1.000 (3.292 sec/step)\n",
      "step 49410 \t loss = 0.152, train_acc = 0.900 (3.410 sec/step)\n",
      "step 49420 \t loss = 0.000, train_acc = 1.000 (3.353 sec/step)\n",
      "step 49430 \t loss = 0.006, train_acc = 1.000 (3.323 sec/step)\n",
      "step 49440 \t loss = 0.002, train_acc = 1.000 (3.364 sec/step)\n",
      "step 49450 \t loss = 0.345, train_acc = 0.900 (3.304 sec/step)\n",
      "step 49460 \t loss = 0.370, train_acc = 0.900 (3.322 sec/step)\n",
      "step 49470 \t loss = 0.296, train_acc = 0.900 (3.415 sec/step)\n",
      "step 49480 \t loss = 0.000, train_acc = 1.000 (3.285 sec/step)\n",
      "step 49490 \t loss = 0.039, train_acc = 1.000 (3.350 sec/step)\n",
      "step 49500 \t loss = 0.004, train_acc = 1.000 (3.296 sec/step)\n",
      "step 49510 \t loss = 0.033, train_acc = 1.000 (3.319 sec/step)\n",
      "step 49520 \t loss = 0.216, train_acc = 0.900 (3.328 sec/step)\n",
      "step 49530 \t loss = 0.152, train_acc = 0.900 (3.371 sec/step)\n",
      "step 49540 \t loss = 0.257, train_acc = 0.900 (3.313 sec/step)\n",
      "step 49550 \t loss = 0.013, train_acc = 1.000 (3.305 sec/step)\n",
      "step 49560 \t loss = 0.287, train_acc = 0.800 (3.287 sec/step)\n",
      "step 49570 \t loss = 0.026, train_acc = 1.000 (3.344 sec/step)\n",
      "step 49580 \t loss = 0.044, train_acc = 1.000 (3.307 sec/step)\n",
      "step 49590 \t loss = 0.607, train_acc = 0.900 (3.316 sec/step)\n",
      "step 49600 \t loss = 0.395, train_acc = 0.800 (3.280 sec/step)\n",
      "step 49610 \t loss = 0.161, train_acc = 1.000 (3.340 sec/step)\n",
      "step 49620 \t loss = 0.002, train_acc = 1.000 (3.297 sec/step)\n",
      "step 49630 \t loss = 0.035, train_acc = 1.000 (3.413 sec/step)\n",
      "step 49640 \t loss = 0.017, train_acc = 1.000 (3.326 sec/step)\n",
      "step 49650 \t loss = 0.585, train_acc = 0.800 (3.272 sec/step)\n",
      "step 49660 \t loss = 0.288, train_acc = 0.900 (3.302 sec/step)\n",
      "step 49670 \t loss = 0.005, train_acc = 1.000 (3.307 sec/step)\n",
      "step 49680 \t loss = 0.000, train_acc = 1.000 (3.318 sec/step)\n",
      "step 49690 \t loss = 0.026, train_acc = 1.000 (3.364 sec/step)\n",
      "step 49700 \t loss = 0.023, train_acc = 1.000 (3.312 sec/step)\n",
      "step 49710 \t loss = 1.758, train_acc = 0.900 (3.297 sec/step)\n",
      "step 49720 \t loss = 0.002, train_acc = 1.000 (3.352 sec/step)\n",
      "step 49730 \t loss = 0.006, train_acc = 1.000 (3.366 sec/step)\n",
      "step 49740 \t loss = 0.055, train_acc = 1.000 (3.335 sec/step)\n",
      "step 49750 \t loss = 0.001, train_acc = 1.000 (3.299 sec/step)\n",
      "step 49760 \t loss = 0.004, train_acc = 1.000 (3.337 sec/step)\n",
      "step 49770 \t loss = 0.142, train_acc = 0.900 (3.478 sec/step)\n",
      "step 49780 \t loss = 1.062, train_acc = 0.900 (3.293 sec/step)\n",
      "step 49790 \t loss = 0.000, train_acc = 1.000 (3.331 sec/step)\n",
      "step 49800 \t loss = 2.561, train_acc = 0.600 (3.357 sec/step)\n",
      "step 49810 \t loss = 0.148, train_acc = 0.900 (3.309 sec/step)\n",
      "step 49820 \t loss = 0.002, train_acc = 1.000 (3.328 sec/step)\n",
      "step 49830 \t loss = 0.045, train_acc = 1.000 (3.349 sec/step)\n",
      "step 49840 \t loss = 0.245, train_acc = 0.800 (3.310 sec/step)\n",
      "step 49850 \t loss = 0.797, train_acc = 0.800 (3.351 sec/step)\n",
      "step 49860 \t loss = 1.001, train_acc = 0.900 (3.278 sec/step)\n",
      "step 49870 \t loss = 0.000, train_acc = 1.000 (3.347 sec/step)\n",
      "step 49880 \t loss = 0.004, train_acc = 1.000 (3.317 sec/step)\n",
      "step 49890 \t loss = 0.052, train_acc = 1.000 (3.348 sec/step)\n",
      "step 49900 \t loss = 0.022, train_acc = 1.000 (3.369 sec/step)\n",
      "step 49910 \t loss = 0.073, train_acc = 1.000 (3.356 sec/step)\n",
      "step 49920 \t loss = 0.783, train_acc = 0.900 (3.294 sec/step)\n",
      "step 49930 \t loss = 0.299, train_acc = 1.000 (3.319 sec/step)\n",
      "step 49940 \t loss = 0.007, train_acc = 1.000 (3.312 sec/step)\n",
      "step 49950 \t loss = 0.000, train_acc = 1.000 (3.339 sec/step)\n",
      "step 49960 \t loss = 0.001, train_acc = 1.000 (3.318 sec/step)\n",
      "step 49970 \t loss = 0.022, train_acc = 1.000 (3.292 sec/step)\n",
      "step 49980 \t loss = 0.100, train_acc = 1.000 (3.323 sec/step)\n",
      "step 49990 \t loss = 0.042, train_acc = 1.000 (3.315 sec/step)\n",
      "step 50000 \t loss = 1.661, train_acc = 0.900 (3.307 sec/step)\n",
      "step 50010 \t loss = 0.034, train_acc = 1.000 (3.334 sec/step)\n",
      "step 50020 \t loss = 0.156, train_acc = 1.000 (3.299 sec/step)\n",
      "step 50030 \t loss = 0.055, train_acc = 1.000 (3.320 sec/step)\n",
      "step 50040 \t loss = 0.006, train_acc = 1.000 (3.303 sec/step)\n",
      "step 50050 \t loss = 0.203, train_acc = 0.900 (3.299 sec/step)\n",
      "step 50060 \t loss = 0.051, train_acc = 1.000 (3.337 sec/step)\n",
      "step 50070 \t loss = 0.020, train_acc = 1.000 (3.305 sec/step)\n",
      "step 50080 \t loss = 0.017, train_acc = 1.000 (3.315 sec/step)\n",
      "step 50090 \t loss = 0.069, train_acc = 1.000 (3.330 sec/step)\n",
      "step 50100 \t loss = 0.036, train_acc = 1.000 (3.341 sec/step)\n",
      "step 50110 \t loss = 0.046, train_acc = 1.000 (3.289 sec/step)\n",
      "step 50120 \t loss = 0.006, train_acc = 1.000 (3.356 sec/step)\n",
      "step 50130 \t loss = 0.258, train_acc = 0.900 (3.395 sec/step)\n",
      "step 50140 \t loss = 0.000, train_acc = 1.000 (3.322 sec/step)\n",
      "step 50150 \t loss = 0.000, train_acc = 1.000 (3.339 sec/step)\n",
      "step 50160 \t loss = 0.659, train_acc = 0.900 (3.362 sec/step)\n",
      "step 50170 \t loss = 0.003, train_acc = 1.000 (3.347 sec/step)\n",
      "step 50180 \t loss = 0.013, train_acc = 1.000 (3.375 sec/step)\n",
      "step 50190 \t loss = 0.004, train_acc = 1.000 (3.277 sec/step)\n",
      "step 50200 \t loss = 0.511, train_acc = 0.900 (3.314 sec/step)\n",
      "step 50210 \t loss = 0.000, train_acc = 1.000 (3.314 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50220 \t loss = 1.102, train_acc = 0.900 (3.308 sec/step)\n",
      "step 50230 \t loss = 0.039, train_acc = 1.000 (3.320 sec/step)\n",
      "step 50240 \t loss = 0.017, train_acc = 1.000 (3.317 sec/step)\n",
      "step 50250 \t loss = 0.000, train_acc = 1.000 (3.364 sec/step)\n",
      "step 50260 \t loss = 0.000, train_acc = 1.000 (3.369 sec/step)\n",
      "step 50270 \t loss = 0.128, train_acc = 0.900 (3.283 sec/step)\n",
      "step 50280 \t loss = 0.150, train_acc = 1.000 (3.333 sec/step)\n",
      "step 50290 \t loss = 0.002, train_acc = 1.000 (3.345 sec/step)\n",
      "step 50300 \t loss = 0.072, train_acc = 1.000 (3.382 sec/step)\n",
      "step 50310 \t loss = 0.749, train_acc = 0.800 (3.303 sec/step)\n",
      "step 50320 \t loss = 0.169, train_acc = 0.900 (3.306 sec/step)\n",
      "step 50330 \t loss = 0.016, train_acc = 1.000 (3.337 sec/step)\n",
      "step 50340 \t loss = 0.334, train_acc = 0.900 (3.332 sec/step)\n",
      "step 50350 \t loss = 0.368, train_acc = 0.800 (3.361 sec/step)\n",
      "step 50360 \t loss = 0.107, train_acc = 1.000 (3.347 sec/step)\n",
      "step 50370 \t loss = 0.031, train_acc = 1.000 (3.347 sec/step)\n",
      "step 50380 \t loss = 0.010, train_acc = 1.000 (3.332 sec/step)\n",
      "step 50390 \t loss = 0.010, train_acc = 1.000 (3.289 sec/step)\n",
      "step 50400 \t loss = 0.024, train_acc = 1.000 (3.321 sec/step)\n",
      "step 50410 \t loss = 0.186, train_acc = 0.900 (3.345 sec/step)\n",
      "step 50420 \t loss = 0.012, train_acc = 1.000 (3.282 sec/step)\n",
      "step 50430 \t loss = 1.736, train_acc = 0.800 (3.287 sec/step)\n",
      "step 50440 \t loss = 1.029, train_acc = 0.600 (3.328 sec/step)\n",
      "step 50450 \t loss = 0.052, train_acc = 1.000 (3.307 sec/step)\n",
      "step 50460 \t loss = 0.133, train_acc = 0.900 (3.383 sec/step)\n",
      "step 50470 \t loss = 0.284, train_acc = 0.900 (3.284 sec/step)\n",
      "step 50480 \t loss = 0.481, train_acc = 0.900 (3.355 sec/step)\n",
      "step 50490 \t loss = 0.632, train_acc = 0.900 (3.307 sec/step)\n",
      "step 50500 \t loss = 0.010, train_acc = 1.000 (3.289 sec/step)\n",
      "step 50510 \t loss = 0.003, train_acc = 1.000 (3.308 sec/step)\n",
      "step 50520 \t loss = 0.002, train_acc = 1.000 (3.343 sec/step)\n",
      "step 50530 \t loss = 0.008, train_acc = 1.000 (3.345 sec/step)\n",
      "step 50540 \t loss = 0.123, train_acc = 0.900 (3.309 sec/step)\n",
      "step 50550 \t loss = 0.516, train_acc = 0.900 (3.363 sec/step)\n",
      "step 50560 \t loss = 0.060, train_acc = 1.000 (3.321 sec/step)\n",
      "step 50570 \t loss = 0.004, train_acc = 1.000 (3.347 sec/step)\n",
      "step 50580 \t loss = 0.022, train_acc = 1.000 (3.341 sec/step)\n",
      "step 50590 \t loss = 0.088, train_acc = 1.000 (3.280 sec/step)\n",
      "step 50600 \t loss = 0.187, train_acc = 0.900 (3.395 sec/step)\n",
      "step 50610 \t loss = 0.096, train_acc = 0.900 (3.340 sec/step)\n",
      "step 50620 \t loss = 0.425, train_acc = 0.900 (3.328 sec/step)\n",
      "step 50630 \t loss = 0.010, train_acc = 1.000 (3.310 sec/step)\n",
      "step 50640 \t loss = 0.017, train_acc = 1.000 (3.385 sec/step)\n",
      "step 50650 \t loss = 0.180, train_acc = 0.900 (3.331 sec/step)\n",
      "step 50660 \t loss = 0.113, train_acc = 0.900 (3.333 sec/step)\n",
      "step 50670 \t loss = 0.175, train_acc = 0.900 (3.322 sec/step)\n",
      "step 50680 \t loss = 0.000, train_acc = 1.000 (3.356 sec/step)\n",
      "step 50690 \t loss = 0.006, train_acc = 1.000 (3.309 sec/step)\n",
      "step 50700 \t loss = 0.629, train_acc = 0.900 (3.330 sec/step)\n",
      "step 50710 \t loss = 0.228, train_acc = 0.900 (3.342 sec/step)\n",
      "step 50720 \t loss = 0.022, train_acc = 1.000 (3.363 sec/step)\n",
      "step 50730 \t loss = 0.150, train_acc = 0.900 (3.327 sec/step)\n",
      "step 50740 \t loss = 0.334, train_acc = 0.900 (3.301 sec/step)\n",
      "step 50750 \t loss = 0.705, train_acc = 0.900 (3.302 sec/step)\n",
      "step 50760 \t loss = 0.803, train_acc = 0.700 (3.404 sec/step)\n",
      "step 50770 \t loss = 0.000, train_acc = 1.000 (3.287 sec/step)\n",
      "step 50780 \t loss = 0.774, train_acc = 0.800 (3.346 sec/step)\n",
      "step 50790 \t loss = 0.151, train_acc = 0.900 (3.305 sec/step)\n",
      "step 50800 \t loss = 0.077, train_acc = 1.000 (3.355 sec/step)\n",
      "step 50810 \t loss = 0.048, train_acc = 1.000 (3.286 sec/step)\n",
      "step 50820 \t loss = 0.066, train_acc = 1.000 (3.326 sec/step)\n",
      "step 50830 \t loss = 0.041, train_acc = 1.000 (3.324 sec/step)\n",
      "step 50840 \t loss = 0.138, train_acc = 0.900 (3.303 sec/step)\n",
      "step 50850 \t loss = 0.010, train_acc = 1.000 (3.344 sec/step)\n",
      "step 50860 \t loss = 0.008, train_acc = 1.000 (3.306 sec/step)\n",
      "step 50870 \t loss = 0.022, train_acc = 1.000 (3.315 sec/step)\n",
      "step 50880 \t loss = 0.950, train_acc = 0.700 (3.329 sec/step)\n",
      "step 50890 \t loss = 0.014, train_acc = 1.000 (3.359 sec/step)\n",
      "step 50900 \t loss = 0.845, train_acc = 0.700 (3.348 sec/step)\n",
      "step 50910 \t loss = 0.596, train_acc = 0.900 (3.319 sec/step)\n",
      "step 50920 \t loss = 0.114, train_acc = 1.000 (3.318 sec/step)\n",
      "step 50930 \t loss = 0.071, train_acc = 1.000 (3.317 sec/step)\n",
      "step 50940 \t loss = 0.047, train_acc = 1.000 (3.378 sec/step)\n",
      "step 50950 \t loss = 1.509, train_acc = 0.800 (3.362 sec/step)\n",
      "step 50960 \t loss = 1.076, train_acc = 0.900 (3.345 sec/step)\n",
      "step 50970 \t loss = 0.082, train_acc = 1.000 (3.388 sec/step)\n",
      "step 50980 \t loss = 0.002, train_acc = 1.000 (3.331 sec/step)\n",
      "step 50990 \t loss = 0.532, train_acc = 0.900 (3.341 sec/step)\n",
      "step 51000 \t loss = 0.043, train_acc = 1.000 (3.374 sec/step)\n",
      "step 51010 \t loss = 0.367, train_acc = 0.800 (3.359 sec/step)\n",
      "step 51020 \t loss = 0.002, train_acc = 1.000 (3.286 sec/step)\n",
      "step 51030 \t loss = 0.075, train_acc = 1.000 (3.349 sec/step)\n",
      "step 51040 \t loss = 0.076, train_acc = 1.000 (3.374 sec/step)\n",
      "step 51050 \t loss = 0.073, train_acc = 1.000 (3.272 sec/step)\n",
      "step 51060 \t loss = 0.353, train_acc = 0.900 (3.306 sec/step)\n",
      "step 51070 \t loss = 0.004, train_acc = 1.000 (3.324 sec/step)\n",
      "step 51080 \t loss = 0.442, train_acc = 0.900 (3.308 sec/step)\n",
      "step 51090 \t loss = 0.556, train_acc = 0.900 (3.311 sec/step)\n",
      "step 51100 \t loss = 0.064, train_acc = 1.000 (3.356 sec/step)\n",
      "step 51110 \t loss = 0.086, train_acc = 1.000 (3.287 sec/step)\n",
      "step 51120 \t loss = 0.232, train_acc = 0.900 (3.364 sec/step)\n",
      "step 51130 \t loss = 0.569, train_acc = 0.900 (3.324 sec/step)\n",
      "step 51140 \t loss = 0.052, train_acc = 1.000 (3.381 sec/step)\n",
      "step 51150 \t loss = 0.001, train_acc = 1.000 (3.321 sec/step)\n",
      "step 51160 \t loss = 0.101, train_acc = 0.900 (3.337 sec/step)\n",
      "step 51170 \t loss = 0.000, train_acc = 1.000 (3.378 sec/step)\n",
      "step 51180 \t loss = 0.529, train_acc = 0.800 (3.342 sec/step)\n",
      "step 51190 \t loss = 0.187, train_acc = 0.900 (3.303 sec/step)\n",
      "step 51200 \t loss = 0.365, train_acc = 0.900 (3.442 sec/step)\n",
      "step 51210 \t loss = 0.002, train_acc = 1.000 (3.288 sec/step)\n",
      "step 51220 \t loss = 0.350, train_acc = 0.900 (3.336 sec/step)\n",
      "step 51230 \t loss = 0.071, train_acc = 1.000 (3.332 sec/step)\n",
      "step 51240 \t loss = 0.071, train_acc = 1.000 (3.376 sec/step)\n",
      "step 51250 \t loss = 0.004, train_acc = 1.000 (3.319 sec/step)\n",
      "step 51260 \t loss = 0.814, train_acc = 0.800 (3.363 sec/step)\n",
      "step 51270 \t loss = 0.383, train_acc = 0.900 (3.312 sec/step)\n",
      "step 51280 \t loss = 0.007, train_acc = 1.000 (3.356 sec/step)\n",
      "step 51290 \t loss = 0.002, train_acc = 1.000 (3.380 sec/step)\n",
      "VALIDATION \t acc = 0.560 (3.644 sec)\n",
      "step 51300 \t loss = 0.397, train_acc = 0.900 (3.319 sec/step)\n",
      "step 51310 \t loss = 0.023, train_acc = 1.000 (3.357 sec/step)\n",
      "step 51320 \t loss = 0.460, train_acc = 0.900 (3.361 sec/step)\n",
      "step 51330 \t loss = 0.078, train_acc = 1.000 (3.324 sec/step)\n",
      "step 51340 \t loss = 0.101, train_acc = 1.000 (3.280 sec/step)\n",
      "step 51350 \t loss = 0.804, train_acc = 0.800 (3.310 sec/step)\n",
      "step 51360 \t loss = 0.124, train_acc = 0.900 (3.324 sec/step)\n",
      "step 51370 \t loss = 0.009, train_acc = 1.000 (3.348 sec/step)\n",
      "step 51380 \t loss = 0.047, train_acc = 1.000 (3.303 sec/step)\n",
      "step 51390 \t loss = 0.085, train_acc = 0.900 (3.354 sec/step)\n",
      "step 51400 \t loss = 0.063, train_acc = 1.000 (3.277 sec/step)\n",
      "step 51410 \t loss = 1.496, train_acc = 0.900 (3.314 sec/step)\n",
      "step 51420 \t loss = 0.084, train_acc = 1.000 (3.372 sec/step)\n",
      "step 51430 \t loss = 0.003, train_acc = 1.000 (3.466 sec/step)\n",
      "step 51440 \t loss = 0.050, train_acc = 1.000 (3.349 sec/step)\n",
      "step 51450 \t loss = 2.182, train_acc = 0.700 (3.396 sec/step)\n",
      "step 51460 \t loss = 0.036, train_acc = 1.000 (3.346 sec/step)\n",
      "step 51470 \t loss = 0.007, train_acc = 1.000 (3.334 sec/step)\n",
      "step 51480 \t loss = 0.000, train_acc = 1.000 (3.356 sec/step)\n",
      "step 51490 \t loss = 0.001, train_acc = 1.000 (3.304 sec/step)\n",
      "step 51500 \t loss = 0.513, train_acc = 0.900 (3.357 sec/step)\n",
      "step 51510 \t loss = 0.074, train_acc = 1.000 (3.330 sec/step)\n",
      "step 51520 \t loss = 0.293, train_acc = 0.900 (3.356 sec/step)\n",
      "step 51530 \t loss = 0.256, train_acc = 0.900 (3.278 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 51540 \t loss = 0.140, train_acc = 1.000 (3.338 sec/step)\n",
      "step 51550 \t loss = 0.093, train_acc = 1.000 (3.279 sec/step)\n",
      "step 51560 \t loss = 0.063, train_acc = 1.000 (3.350 sec/step)\n",
      "step 51570 \t loss = 0.004, train_acc = 1.000 (3.296 sec/step)\n",
      "step 51580 \t loss = 1.831, train_acc = 0.800 (3.345 sec/step)\n",
      "step 51590 \t loss = 0.106, train_acc = 1.000 (3.323 sec/step)\n",
      "step 51600 \t loss = 0.242, train_acc = 1.000 (3.300 sec/step)\n",
      "step 51610 \t loss = 0.220, train_acc = 0.900 (3.337 sec/step)\n",
      "step 51620 \t loss = 0.000, train_acc = 1.000 (3.285 sec/step)\n",
      "step 51630 \t loss = 0.003, train_acc = 1.000 (3.313 sec/step)\n",
      "step 51640 \t loss = 0.003, train_acc = 1.000 (3.282 sec/step)\n",
      "step 51650 \t loss = 0.045, train_acc = 1.000 (3.360 sec/step)\n",
      "step 51660 \t loss = 0.083, train_acc = 1.000 (3.322 sec/step)\n",
      "step 51670 \t loss = 0.027, train_acc = 1.000 (3.316 sec/step)\n",
      "step 51680 \t loss = 0.210, train_acc = 0.900 (3.338 sec/step)\n",
      "step 51690 \t loss = 0.608, train_acc = 0.800 (3.362 sec/step)\n",
      "step 51700 \t loss = 0.283, train_acc = 0.900 (3.315 sec/step)\n",
      "step 51710 \t loss = 0.248, train_acc = 0.900 (3.300 sec/step)\n",
      "step 51720 \t loss = 0.553, train_acc = 0.800 (3.369 sec/step)\n",
      "step 51730 \t loss = 0.154, train_acc = 0.900 (3.279 sec/step)\n",
      "step 51740 \t loss = 0.515, train_acc = 0.900 (3.409 sec/step)\n",
      "step 51750 \t loss = 0.029, train_acc = 1.000 (3.384 sec/step)\n",
      "step 51760 \t loss = 2.004, train_acc = 0.800 (3.318 sec/step)\n",
      "step 51770 \t loss = 0.012, train_acc = 1.000 (3.377 sec/step)\n",
      "step 51780 \t loss = 0.191, train_acc = 0.900 (3.301 sec/step)\n",
      "step 51790 \t loss = 0.176, train_acc = 0.900 (3.321 sec/step)\n",
      "step 51800 \t loss = 0.036, train_acc = 1.000 (3.327 sec/step)\n",
      "step 51810 \t loss = 0.369, train_acc = 0.800 (3.333 sec/step)\n",
      "step 51820 \t loss = 0.166, train_acc = 0.900 (3.358 sec/step)\n",
      "step 51830 \t loss = 0.018, train_acc = 1.000 (3.294 sec/step)\n",
      "step 51840 \t loss = 0.193, train_acc = 0.900 (3.379 sec/step)\n",
      "step 51850 \t loss = 0.019, train_acc = 1.000 (3.322 sec/step)\n",
      "step 51860 \t loss = 0.167, train_acc = 0.900 (3.347 sec/step)\n",
      "step 51870 \t loss = 0.263, train_acc = 0.900 (3.368 sec/step)\n",
      "step 51880 \t loss = 0.139, train_acc = 1.000 (3.365 sec/step)\n",
      "step 51890 \t loss = 0.406, train_acc = 0.900 (3.331 sec/step)\n",
      "step 51900 \t loss = 0.662, train_acc = 0.900 (3.283 sec/step)\n",
      "step 51910 \t loss = 0.020, train_acc = 1.000 (3.348 sec/step)\n",
      "step 51920 \t loss = 0.473, train_acc = 0.800 (3.310 sec/step)\n",
      "step 51930 \t loss = 0.074, train_acc = 1.000 (3.435 sec/step)\n",
      "step 51940 \t loss = 0.177, train_acc = 1.000 (3.309 sec/step)\n",
      "step 51950 \t loss = 0.032, train_acc = 1.000 (3.418 sec/step)\n",
      "step 51960 \t loss = 0.715, train_acc = 0.800 (3.313 sec/step)\n",
      "step 51970 \t loss = 0.051, train_acc = 1.000 (3.342 sec/step)\n",
      "step 51980 \t loss = 0.089, train_acc = 1.000 (3.367 sec/step)\n",
      "step 51990 \t loss = 0.822, train_acc = 0.900 (3.362 sec/step)\n",
      "step 52000 \t loss = 0.722, train_acc = 0.900 (3.347 sec/step)\n",
      "step 52010 \t loss = 0.225, train_acc = 0.900 (3.328 sec/step)\n",
      "step 52020 \t loss = 0.043, train_acc = 1.000 (3.328 sec/step)\n",
      "step 52030 \t loss = 0.588, train_acc = 0.800 (3.344 sec/step)\n",
      "step 52040 \t loss = 0.026, train_acc = 1.000 (3.315 sec/step)\n",
      "step 52050 \t loss = 0.042, train_acc = 1.000 (3.314 sec/step)\n",
      "step 52060 \t loss = 0.207, train_acc = 0.900 (3.314 sec/step)\n",
      "step 52070 \t loss = 0.386, train_acc = 0.900 (3.266 sec/step)\n",
      "step 52080 \t loss = 0.273, train_acc = 0.900 (3.307 sec/step)\n",
      "step 52090 \t loss = 0.209, train_acc = 0.900 (3.357 sec/step)\n",
      "step 52100 \t loss = 0.114, train_acc = 0.900 (3.434 sec/step)\n",
      "step 52110 \t loss = 0.053, train_acc = 1.000 (3.291 sec/step)\n",
      "step 52120 \t loss = 0.013, train_acc = 1.000 (3.314 sec/step)\n",
      "step 52130 \t loss = 0.537, train_acc = 0.800 (3.349 sec/step)\n",
      "step 52140 \t loss = 0.007, train_acc = 1.000 (3.323 sec/step)\n",
      "step 52150 \t loss = 0.001, train_acc = 1.000 (3.358 sec/step)\n",
      "step 52160 \t loss = 0.070, train_acc = 1.000 (3.359 sec/step)\n",
      "step 52170 \t loss = 0.326, train_acc = 0.900 (3.296 sec/step)\n",
      "step 52180 \t loss = 0.027, train_acc = 1.000 (3.356 sec/step)\n",
      "step 52190 \t loss = 0.002, train_acc = 1.000 (3.347 sec/step)\n",
      "step 52200 \t loss = 0.043, train_acc = 1.000 (3.344 sec/step)\n",
      "step 52210 \t loss = 0.600, train_acc = 0.800 (3.320 sec/step)\n",
      "step 52220 \t loss = 0.031, train_acc = 1.000 (3.289 sec/step)\n",
      "step 52230 \t loss = 0.001, train_acc = 1.000 (3.314 sec/step)\n",
      "step 52240 \t loss = 0.307, train_acc = 0.900 (3.304 sec/step)\n",
      "step 52250 \t loss = 0.629, train_acc = 0.900 (3.339 sec/step)\n",
      "step 52260 \t loss = 0.008, train_acc = 1.000 (3.328 sec/step)\n",
      "step 52270 \t loss = 0.007, train_acc = 1.000 (3.303 sec/step)\n",
      "step 52280 \t loss = 0.024, train_acc = 1.000 (3.336 sec/step)\n",
      "step 52290 \t loss = 0.656, train_acc = 0.700 (3.293 sec/step)\n",
      "step 52300 \t loss = 0.013, train_acc = 1.000 (3.356 sec/step)\n",
      "step 52310 \t loss = 0.080, train_acc = 1.000 (3.332 sec/step)\n",
      "step 52320 \t loss = 0.187, train_acc = 0.900 (3.327 sec/step)\n",
      "step 52330 \t loss = 0.012, train_acc = 1.000 (3.293 sec/step)\n",
      "step 52340 \t loss = 0.044, train_acc = 1.000 (3.364 sec/step)\n",
      "step 52350 \t loss = 0.811, train_acc = 0.700 (3.340 sec/step)\n",
      "step 52360 \t loss = 0.105, train_acc = 1.000 (3.340 sec/step)\n",
      "step 52370 \t loss = 0.133, train_acc = 0.900 (3.336 sec/step)\n",
      "step 52380 \t loss = 0.084, train_acc = 1.000 (3.334 sec/step)\n",
      "step 52390 \t loss = 0.338, train_acc = 0.900 (3.309 sec/step)\n",
      "step 52400 \t loss = 0.784, train_acc = 0.900 (3.310 sec/step)\n",
      "step 52410 \t loss = 0.026, train_acc = 1.000 (3.308 sec/step)\n",
      "step 52420 \t loss = 0.792, train_acc = 0.900 (3.330 sec/step)\n",
      "step 52430 \t loss = 0.368, train_acc = 0.900 (3.370 sec/step)\n",
      "step 52440 \t loss = 2.462, train_acc = 0.700 (3.347 sec/step)\n",
      "step 52450 \t loss = 0.204, train_acc = 0.900 (3.339 sec/step)\n",
      "step 52460 \t loss = 0.327, train_acc = 0.900 (3.342 sec/step)\n",
      "step 52470 \t loss = 0.005, train_acc = 1.000 (3.307 sec/step)\n",
      "step 52480 \t loss = 0.092, train_acc = 0.900 (3.340 sec/step)\n",
      "step 52490 \t loss = 0.018, train_acc = 1.000 (3.311 sec/step)\n",
      "step 52500 \t loss = 0.037, train_acc = 1.000 (3.367 sec/step)\n",
      "step 52510 \t loss = 0.100, train_acc = 1.000 (3.347 sec/step)\n",
      "step 52520 \t loss = 0.336, train_acc = 0.800 (3.338 sec/step)\n",
      "step 52530 \t loss = 0.620, train_acc = 0.900 (3.287 sec/step)\n",
      "step 52540 \t loss = 0.003, train_acc = 1.000 (3.300 sec/step)\n",
      "step 52550 \t loss = 0.127, train_acc = 0.900 (3.327 sec/step)\n",
      "step 52560 \t loss = 0.025, train_acc = 1.000 (3.278 sec/step)\n",
      "step 52570 \t loss = 1.291, train_acc = 0.700 (3.323 sec/step)\n",
      "step 52580 \t loss = 0.003, train_acc = 1.000 (3.302 sec/step)\n",
      "step 52590 \t loss = 0.006, train_acc = 1.000 (3.303 sec/step)\n",
      "step 52600 \t loss = 0.156, train_acc = 0.900 (3.340 sec/step)\n",
      "step 52610 \t loss = 0.230, train_acc = 0.800 (3.294 sec/step)\n",
      "step 52620 \t loss = 0.007, train_acc = 1.000 (3.327 sec/step)\n",
      "step 52630 \t loss = 0.048, train_acc = 1.000 (3.325 sec/step)\n",
      "step 52640 \t loss = 0.695, train_acc = 0.800 (3.346 sec/step)\n",
      "step 52650 \t loss = 0.550, train_acc = 0.900 (3.325 sec/step)\n",
      "step 52660 \t loss = 0.257, train_acc = 0.800 (3.307 sec/step)\n",
      "step 52670 \t loss = 0.389, train_acc = 0.800 (3.330 sec/step)\n",
      "step 52680 \t loss = 0.080, train_acc = 0.900 (3.365 sec/step)\n",
      "step 52690 \t loss = 0.399, train_acc = 0.800 (3.305 sec/step)\n",
      "step 52700 \t loss = 0.007, train_acc = 1.000 (3.310 sec/step)\n",
      "step 52710 \t loss = 0.115, train_acc = 0.900 (3.342 sec/step)\n",
      "step 52720 \t loss = 0.436, train_acc = 0.800 (3.284 sec/step)\n",
      "step 52730 \t loss = 0.606, train_acc = 0.800 (3.410 sec/step)\n",
      "step 52740 \t loss = 0.248, train_acc = 0.900 (3.317 sec/step)\n",
      "step 52750 \t loss = 0.028, train_acc = 1.000 (3.306 sec/step)\n",
      "step 52760 \t loss = 0.004, train_acc = 1.000 (3.300 sec/step)\n",
      "step 52770 \t loss = 0.008, train_acc = 1.000 (3.330 sec/step)\n",
      "step 52780 \t loss = 0.919, train_acc = 0.900 (3.322 sec/step)\n",
      "step 52790 \t loss = 0.152, train_acc = 0.900 (3.316 sec/step)\n",
      "step 52800 \t loss = 0.011, train_acc = 1.000 (3.372 sec/step)\n",
      "step 52810 \t loss = 0.009, train_acc = 1.000 (3.281 sec/step)\n",
      "step 52820 \t loss = 0.434, train_acc = 0.900 (3.326 sec/step)\n",
      "step 52830 \t loss = 0.416, train_acc = 0.900 (3.342 sec/step)\n",
      "step 52840 \t loss = 0.026, train_acc = 1.000 (3.292 sec/step)\n",
      "step 52850 \t loss = 0.283, train_acc = 0.900 (3.321 sec/step)\n",
      "step 52860 \t loss = 0.120, train_acc = 0.900 (3.358 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 52870 \t loss = 0.026, train_acc = 1.000 (3.407 sec/step)\n",
      "step 52880 \t loss = 1.019, train_acc = 0.900 (3.456 sec/step)\n",
      "step 52890 \t loss = 0.009, train_acc = 1.000 (3.373 sec/step)\n",
      "step 52900 \t loss = 0.823, train_acc = 0.700 (3.311 sec/step)\n",
      "step 52910 \t loss = 0.244, train_acc = 0.800 (3.316 sec/step)\n",
      "step 52920 \t loss = 0.094, train_acc = 0.900 (3.345 sec/step)\n",
      "step 52930 \t loss = 0.301, train_acc = 0.800 (3.321 sec/step)\n",
      "step 52940 \t loss = 0.115, train_acc = 1.000 (3.345 sec/step)\n",
      "step 52950 \t loss = 0.001, train_acc = 1.000 (3.361 sec/step)\n",
      "step 52960 \t loss = 0.020, train_acc = 1.000 (3.305 sec/step)\n",
      "step 52970 \t loss = 0.132, train_acc = 0.900 (3.289 sec/step)\n",
      "step 52980 \t loss = 0.179, train_acc = 0.900 (3.277 sec/step)\n",
      "step 52990 \t loss = 0.043, train_acc = 1.000 (3.353 sec/step)\n",
      "step 53000 \t loss = 0.052, train_acc = 1.000 (3.371 sec/step)\n",
      "step 53010 \t loss = 0.355, train_acc = 0.900 (3.335 sec/step)\n",
      "step 53020 \t loss = 0.041, train_acc = 1.000 (3.330 sec/step)\n",
      "step 53030 \t loss = 0.080, train_acc = 1.000 (3.343 sec/step)\n",
      "step 53040 \t loss = 0.113, train_acc = 0.900 (3.350 sec/step)\n",
      "step 53050 \t loss = 0.009, train_acc = 1.000 (3.334 sec/step)\n",
      "step 53060 \t loss = 0.011, train_acc = 1.000 (3.331 sec/step)\n",
      "step 53070 \t loss = 0.002, train_acc = 1.000 (3.360 sec/step)\n",
      "step 53080 \t loss = 0.229, train_acc = 0.900 (3.382 sec/step)\n",
      "step 53090 \t loss = 0.233, train_acc = 0.900 (3.281 sec/step)\n",
      "step 53100 \t loss = 0.568, train_acc = 0.800 (3.314 sec/step)\n",
      "step 53110 \t loss = 0.311, train_acc = 0.800 (3.399 sec/step)\n",
      "step 53120 \t loss = 0.008, train_acc = 1.000 (3.364 sec/step)\n",
      "step 53130 \t loss = 0.043, train_acc = 1.000 (3.323 sec/step)\n",
      "step 53140 \t loss = 0.476, train_acc = 0.700 (3.349 sec/step)\n",
      "step 53150 \t loss = 0.032, train_acc = 1.000 (3.304 sec/step)\n",
      "step 53160 \t loss = 0.002, train_acc = 1.000 (3.340 sec/step)\n",
      "step 53170 \t loss = 0.022, train_acc = 1.000 (3.351 sec/step)\n",
      "step 53180 \t loss = 0.356, train_acc = 0.900 (3.278 sec/step)\n",
      "step 53190 \t loss = 0.003, train_acc = 1.000 (3.362 sec/step)\n",
      "VALIDATION \t acc = 0.530 (3.617 sec)\n",
      "step 53200 \t loss = 0.003, train_acc = 1.000 (3.308 sec/step)\n",
      "step 53210 \t loss = 0.115, train_acc = 1.000 (3.348 sec/step)\n",
      "step 53220 \t loss = 0.009, train_acc = 1.000 (3.352 sec/step)\n",
      "step 53230 \t loss = 1.210, train_acc = 0.700 (3.268 sec/step)\n",
      "step 53240 \t loss = 0.013, train_acc = 1.000 (3.315 sec/step)\n",
      "step 53250 \t loss = 0.078, train_acc = 1.000 (3.311 sec/step)\n",
      "step 53260 \t loss = 0.527, train_acc = 0.800 (3.353 sec/step)\n",
      "step 53270 \t loss = 0.032, train_acc = 1.000 (3.314 sec/step)\n",
      "step 53280 \t loss = 0.019, train_acc = 1.000 (3.428 sec/step)\n",
      "step 53290 \t loss = 0.110, train_acc = 0.900 (3.319 sec/step)\n",
      "step 53300 \t loss = 0.043, train_acc = 1.000 (3.317 sec/step)\n",
      "step 53310 \t loss = 0.042, train_acc = 1.000 (3.306 sec/step)\n",
      "step 53320 \t loss = 0.000, train_acc = 1.000 (3.324 sec/step)\n",
      "step 53330 \t loss = 0.001, train_acc = 1.000 (3.412 sec/step)\n",
      "step 53340 \t loss = 0.379, train_acc = 0.900 (3.301 sec/step)\n",
      "step 53350 \t loss = 0.034, train_acc = 1.000 (3.292 sec/step)\n",
      "step 53360 \t loss = 0.523, train_acc = 0.900 (3.286 sec/step)\n",
      "step 53370 \t loss = 0.044, train_acc = 1.000 (3.330 sec/step)\n",
      "step 53380 \t loss = 0.008, train_acc = 1.000 (3.360 sec/step)\n",
      "step 53390 \t loss = 0.000, train_acc = 1.000 (3.316 sec/step)\n",
      "step 53400 \t loss = 0.047, train_acc = 1.000 (3.351 sec/step)\n",
      "step 53410 \t loss = 0.226, train_acc = 0.900 (3.323 sec/step)\n",
      "step 53420 \t loss = 0.036, train_acc = 1.000 (3.317 sec/step)\n",
      "step 53430 \t loss = 0.221, train_acc = 0.900 (3.323 sec/step)\n",
      "step 53440 \t loss = 0.026, train_acc = 1.000 (3.369 sec/step)\n",
      "step 53450 \t loss = 0.412, train_acc = 0.900 (3.366 sec/step)\n",
      "step 53460 \t loss = 0.387, train_acc = 0.900 (3.294 sec/step)\n",
      "step 53470 \t loss = 0.069, train_acc = 1.000 (3.335 sec/step)\n",
      "step 53480 \t loss = 0.018, train_acc = 1.000 (3.419 sec/step)\n",
      "step 53490 \t loss = 0.049, train_acc = 1.000 (3.349 sec/step)\n",
      "step 53500 \t loss = 0.010, train_acc = 1.000 (3.375 sec/step)\n",
      "step 53510 \t loss = 0.311, train_acc = 0.900 (3.400 sec/step)\n",
      "step 53520 \t loss = 0.190, train_acc = 0.900 (3.353 sec/step)\n",
      "step 53530 \t loss = 0.586, train_acc = 0.800 (3.405 sec/step)\n",
      "step 53540 \t loss = 0.870, train_acc = 0.900 (3.346 sec/step)\n",
      "step 53550 \t loss = 0.322, train_acc = 0.800 (3.374 sec/step)\n",
      "step 53560 \t loss = 0.202, train_acc = 0.900 (3.331 sec/step)\n",
      "step 53570 \t loss = 0.027, train_acc = 1.000 (3.290 sec/step)\n",
      "step 53580 \t loss = 0.002, train_acc = 1.000 (3.290 sec/step)\n",
      "step 53590 \t loss = 0.081, train_acc = 0.900 (3.319 sec/step)\n",
      "step 53600 \t loss = 0.126, train_acc = 0.900 (3.333 sec/step)\n",
      "step 53610 \t loss = 0.017, train_acc = 1.000 (3.297 sec/step)\n",
      "step 53620 \t loss = 0.169, train_acc = 0.900 (3.331 sec/step)\n",
      "step 53630 \t loss = 0.017, train_acc = 1.000 (3.327 sec/step)\n",
      "step 53640 \t loss = 1.014, train_acc = 0.900 (3.331 sec/step)\n",
      "step 53650 \t loss = 0.124, train_acc = 0.900 (3.317 sec/step)\n",
      "step 53660 \t loss = 0.021, train_acc = 1.000 (3.345 sec/step)\n",
      "step 53670 \t loss = 0.000, train_acc = 1.000 (3.351 sec/step)\n",
      "step 53680 \t loss = 1.055, train_acc = 0.800 (3.346 sec/step)\n",
      "step 53690 \t loss = 0.320, train_acc = 0.900 (3.339 sec/step)\n",
      "step 53700 \t loss = 0.922, train_acc = 0.900 (3.287 sec/step)\n",
      "step 53710 \t loss = 0.491, train_acc = 0.900 (3.325 sec/step)\n",
      "step 53720 \t loss = 0.220, train_acc = 0.900 (3.322 sec/step)\n",
      "step 53730 \t loss = 0.717, train_acc = 0.700 (3.352 sec/step)\n",
      "step 53740 \t loss = 0.067, train_acc = 1.000 (3.299 sec/step)\n",
      "step 53750 \t loss = 0.000, train_acc = 1.000 (3.319 sec/step)\n",
      "step 53760 \t loss = 0.295, train_acc = 0.900 (3.402 sec/step)\n",
      "step 53770 \t loss = 0.273, train_acc = 0.900 (3.283 sec/step)\n",
      "step 53780 \t loss = 0.044, train_acc = 1.000 (3.337 sec/step)\n",
      "step 53790 \t loss = 0.002, train_acc = 1.000 (3.426 sec/step)\n",
      "step 53800 \t loss = 0.464, train_acc = 0.900 (3.293 sec/step)\n",
      "step 53810 \t loss = 0.136, train_acc = 1.000 (3.287 sec/step)\n",
      "step 53820 \t loss = 0.039, train_acc = 1.000 (3.371 sec/step)\n",
      "step 53830 \t loss = 0.008, train_acc = 1.000 (3.429 sec/step)\n",
      "step 53840 \t loss = 0.174, train_acc = 0.900 (3.346 sec/step)\n",
      "step 53850 \t loss = 0.215, train_acc = 1.000 (3.333 sec/step)\n",
      "step 53860 \t loss = 0.100, train_acc = 1.000 (3.295 sec/step)\n",
      "step 53870 \t loss = 0.008, train_acc = 1.000 (3.363 sec/step)\n",
      "step 53880 \t loss = 0.275, train_acc = 0.900 (3.374 sec/step)\n",
      "step 53890 \t loss = 0.331, train_acc = 0.900 (3.364 sec/step)\n",
      "step 53900 \t loss = 0.200, train_acc = 0.900 (3.298 sec/step)\n",
      "step 53910 \t loss = 0.121, train_acc = 0.900 (3.320 sec/step)\n",
      "step 53920 \t loss = 0.171, train_acc = 0.900 (3.345 sec/step)\n",
      "step 53930 \t loss = 1.172, train_acc = 0.600 (3.353 sec/step)\n",
      "step 53940 \t loss = 0.348, train_acc = 0.900 (3.304 sec/step)\n",
      "step 53950 \t loss = 0.013, train_acc = 1.000 (3.373 sec/step)\n",
      "step 53960 \t loss = 0.003, train_acc = 1.000 (3.363 sec/step)\n",
      "step 53970 \t loss = 0.052, train_acc = 1.000 (3.322 sec/step)\n",
      "step 53980 \t loss = 0.030, train_acc = 1.000 (3.325 sec/step)\n",
      "step 53990 \t loss = 0.147, train_acc = 0.900 (3.285 sec/step)\n",
      "step 54000 \t loss = 0.007, train_acc = 1.000 (3.353 sec/step)\n",
      "step 54010 \t loss = 0.718, train_acc = 0.600 (3.314 sec/step)\n",
      "step 54020 \t loss = 0.023, train_acc = 1.000 (3.320 sec/step)\n",
      "step 54030 \t loss = 0.001, train_acc = 1.000 (3.325 sec/step)\n",
      "step 54040 \t loss = 0.053, train_acc = 1.000 (3.297 sec/step)\n",
      "step 54050 \t loss = 0.138, train_acc = 1.000 (3.324 sec/step)\n",
      "step 54060 \t loss = 0.053, train_acc = 1.000 (3.333 sec/step)\n",
      "step 54070 \t loss = 0.073, train_acc = 0.900 (3.275 sec/step)\n",
      "step 54080 \t loss = 0.322, train_acc = 0.900 (3.335 sec/step)\n",
      "step 54090 \t loss = 0.000, train_acc = 1.000 (3.319 sec/step)\n",
      "step 54100 \t loss = 0.043, train_acc = 1.000 (3.327 sec/step)\n",
      "step 54110 \t loss = 0.003, train_acc = 1.000 (3.374 sec/step)\n",
      "step 54120 \t loss = 0.293, train_acc = 0.900 (3.292 sec/step)\n",
      "step 54130 \t loss = 0.244, train_acc = 0.900 (3.276 sec/step)\n",
      "step 54140 \t loss = 0.098, train_acc = 0.900 (3.379 sec/step)\n",
      "step 54150 \t loss = 0.002, train_acc = 1.000 (3.296 sec/step)\n",
      "step 54160 \t loss = 0.097, train_acc = 1.000 (3.346 sec/step)\n",
      "step 54170 \t loss = 0.101, train_acc = 0.900 (3.353 sec/step)\n",
      "step 54180 \t loss = 0.342, train_acc = 0.900 (3.309 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 54190 \t loss = 0.022, train_acc = 1.000 (3.305 sec/step)\n",
      "step 54200 \t loss = 0.001, train_acc = 1.000 (3.317 sec/step)\n",
      "step 54210 \t loss = 0.059, train_acc = 1.000 (3.329 sec/step)\n",
      "step 54220 \t loss = 0.680, train_acc = 0.900 (3.317 sec/step)\n",
      "step 54230 \t loss = 0.156, train_acc = 0.900 (3.351 sec/step)\n",
      "step 54240 \t loss = 0.068, train_acc = 1.000 (3.289 sec/step)\n",
      "step 54250 \t loss = 0.027, train_acc = 1.000 (3.297 sec/step)\n",
      "step 54260 \t loss = 0.002, train_acc = 1.000 (3.359 sec/step)\n",
      "step 54270 \t loss = 0.000, train_acc = 1.000 (3.479 sec/step)\n",
      "step 54280 \t loss = 0.050, train_acc = 1.000 (3.345 sec/step)\n",
      "step 54290 \t loss = 0.002, train_acc = 1.000 (3.299 sec/step)\n",
      "step 54300 \t loss = 0.337, train_acc = 0.800 (3.360 sec/step)\n",
      "step 54310 \t loss = 0.231, train_acc = 0.900 (3.324 sec/step)\n",
      "step 54320 \t loss = 0.251, train_acc = 0.900 (3.340 sec/step)\n",
      "step 54330 \t loss = 0.256, train_acc = 0.900 (3.438 sec/step)\n",
      "step 54340 \t loss = 0.073, train_acc = 1.000 (3.295 sec/step)\n",
      "step 54350 \t loss = 0.005, train_acc = 1.000 (3.332 sec/step)\n",
      "step 54360 \t loss = 0.008, train_acc = 1.000 (3.317 sec/step)\n",
      "step 54370 \t loss = 0.389, train_acc = 0.900 (3.332 sec/step)\n",
      "step 54380 \t loss = 0.029, train_acc = 1.000 (3.431 sec/step)\n",
      "step 54390 \t loss = 0.164, train_acc = 0.900 (3.368 sec/step)\n",
      "step 54400 \t loss = 0.370, train_acc = 0.700 (3.340 sec/step)\n",
      "step 54410 \t loss = 0.066, train_acc = 1.000 (3.358 sec/step)\n",
      "step 54420 \t loss = 0.789, train_acc = 0.800 (3.342 sec/step)\n",
      "step 54430 \t loss = 0.147, train_acc = 0.900 (3.387 sec/step)\n",
      "step 54440 \t loss = 0.000, train_acc = 1.000 (3.328 sec/step)\n",
      "step 54450 \t loss = 0.044, train_acc = 1.000 (3.333 sec/step)\n",
      "step 54460 \t loss = 0.049, train_acc = 1.000 (3.374 sec/step)\n",
      "step 54470 \t loss = 0.015, train_acc = 1.000 (3.312 sec/step)\n",
      "step 54480 \t loss = 0.002, train_acc = 1.000 (3.345 sec/step)\n",
      "step 54490 \t loss = 1.987, train_acc = 0.900 (3.429 sec/step)\n",
      "step 54500 \t loss = 0.024, train_acc = 1.000 (3.365 sec/step)\n",
      "step 54510 \t loss = 0.037, train_acc = 1.000 (3.384 sec/step)\n",
      "step 54520 \t loss = 0.483, train_acc = 0.800 (3.294 sec/step)\n",
      "step 54530 \t loss = 0.002, train_acc = 1.000 (3.360 sec/step)\n",
      "step 54540 \t loss = 0.096, train_acc = 0.900 (3.312 sec/step)\n",
      "step 54550 \t loss = 0.090, train_acc = 1.000 (3.293 sec/step)\n",
      "step 54560 \t loss = 0.509, train_acc = 0.800 (3.328 sec/step)\n",
      "step 54570 \t loss = 0.110, train_acc = 0.900 (3.357 sec/step)\n",
      "step 54580 \t loss = 0.174, train_acc = 1.000 (3.316 sec/step)\n",
      "step 54590 \t loss = 0.018, train_acc = 1.000 (3.348 sec/step)\n",
      "step 54600 \t loss = 0.098, train_acc = 0.900 (3.317 sec/step)\n",
      "step 54610 \t loss = 0.484, train_acc = 0.900 (3.345 sec/step)\n",
      "step 54620 \t loss = 0.014, train_acc = 1.000 (3.328 sec/step)\n",
      "step 54630 \t loss = 0.064, train_acc = 1.000 (3.312 sec/step)\n",
      "step 54640 \t loss = 0.291, train_acc = 0.800 (3.313 sec/step)\n",
      "step 54650 \t loss = 0.321, train_acc = 0.800 (3.286 sec/step)\n",
      "step 54660 \t loss = 0.026, train_acc = 1.000 (3.396 sec/step)\n",
      "step 54670 \t loss = 0.034, train_acc = 1.000 (3.382 sec/step)\n",
      "step 54680 \t loss = 0.798, train_acc = 0.900 (3.312 sec/step)\n",
      "step 54690 \t loss = 0.282, train_acc = 0.900 (3.310 sec/step)\n",
      "step 54700 \t loss = 0.001, train_acc = 1.000 (3.366 sec/step)\n",
      "step 54710 \t loss = 0.001, train_acc = 1.000 (3.310 sec/step)\n",
      "step 54720 \t loss = 0.399, train_acc = 0.900 (3.292 sec/step)\n",
      "step 54730 \t loss = 0.286, train_acc = 0.900 (3.334 sec/step)\n",
      "step 54740 \t loss = 0.006, train_acc = 1.000 (3.315 sec/step)\n",
      "step 54750 \t loss = 0.580, train_acc = 0.800 (3.368 sec/step)\n",
      "step 54760 \t loss = 0.006, train_acc = 1.000 (3.351 sec/step)\n",
      "step 54770 \t loss = 0.467, train_acc = 0.900 (3.285 sec/step)\n",
      "step 54780 \t loss = 0.002, train_acc = 1.000 (3.303 sec/step)\n",
      "step 54790 \t loss = 0.004, train_acc = 1.000 (3.340 sec/step)\n",
      "step 54800 \t loss = 0.017, train_acc = 1.000 (3.327 sec/step)\n",
      "step 54810 \t loss = 0.570, train_acc = 0.900 (3.350 sec/step)\n",
      "step 54820 \t loss = 0.078, train_acc = 1.000 (3.317 sec/step)\n",
      "step 54830 \t loss = 0.751, train_acc = 0.800 (3.313 sec/step)\n",
      "step 54840 \t loss = 0.623, train_acc = 0.800 (3.335 sec/step)\n",
      "step 54850 \t loss = 0.032, train_acc = 1.000 (3.362 sec/step)\n",
      "step 54860 \t loss = 0.481, train_acc = 0.800 (3.345 sec/step)\n",
      "step 54870 \t loss = 0.717, train_acc = 0.800 (3.378 sec/step)\n",
      "step 54880 \t loss = 0.003, train_acc = 1.000 (3.378 sec/step)\n",
      "step 54890 \t loss = 0.904, train_acc = 0.900 (3.394 sec/step)\n",
      "step 54900 \t loss = 0.317, train_acc = 0.900 (3.316 sec/step)\n",
      "step 54910 \t loss = 0.320, train_acc = 0.800 (3.333 sec/step)\n",
      "step 54920 \t loss = 0.853, train_acc = 0.800 (3.318 sec/step)\n",
      "step 54930 \t loss = 0.063, train_acc = 1.000 (3.380 sec/step)\n",
      "step 54940 \t loss = 0.001, train_acc = 1.000 (3.352 sec/step)\n",
      "step 54950 \t loss = 0.413, train_acc = 0.900 (3.351 sec/step)\n",
      "step 54960 \t loss = 0.003, train_acc = 1.000 (3.308 sec/step)\n",
      "step 54970 \t loss = 0.000, train_acc = 1.000 (3.295 sec/step)\n",
      "step 54980 \t loss = 0.033, train_acc = 1.000 (3.358 sec/step)\n",
      "step 54990 \t loss = 0.399, train_acc = 0.900 (3.431 sec/step)\n",
      "step 55000 \t loss = 0.161, train_acc = 0.900 (3.329 sec/step)\n",
      "step 55010 \t loss = 0.005, train_acc = 1.000 (3.288 sec/step)\n",
      "step 55020 \t loss = 0.113, train_acc = 0.900 (3.335 sec/step)\n",
      "step 55030 \t loss = 0.156, train_acc = 0.900 (3.334 sec/step)\n",
      "step 55040 \t loss = 0.250, train_acc = 0.800 (3.374 sec/step)\n",
      "step 55050 \t loss = 0.014, train_acc = 1.000 (3.277 sec/step)\n",
      "step 55060 \t loss = 0.378, train_acc = 0.900 (3.339 sec/step)\n",
      "step 55070 \t loss = 0.295, train_acc = 0.900 (3.304 sec/step)\n",
      "step 55080 \t loss = 0.201, train_acc = 1.000 (3.324 sec/step)\n",
      "step 55090 \t loss = 0.378, train_acc = 0.900 (3.402 sec/step)\n",
      "VALIDATION \t acc = 0.538 (3.616 sec)\n",
      "step 55100 \t loss = 0.843, train_acc = 0.800 (3.343 sec/step)\n",
      "step 55110 \t loss = 0.023, train_acc = 1.000 (3.307 sec/step)\n",
      "step 55120 \t loss = 1.256, train_acc = 0.800 (3.296 sec/step)\n",
      "step 55130 \t loss = 0.548, train_acc = 0.900 (3.348 sec/step)\n",
      "step 55140 \t loss = 0.608, train_acc = 0.900 (3.347 sec/step)\n",
      "step 55150 \t loss = 0.006, train_acc = 1.000 (3.315 sec/step)\n",
      "step 55160 \t loss = 0.000, train_acc = 1.000 (3.435 sec/step)\n",
      "step 55170 \t loss = 0.086, train_acc = 0.900 (3.378 sec/step)\n",
      "step 55180 \t loss = 0.040, train_acc = 1.000 (3.348 sec/step)\n",
      "step 55190 \t loss = 0.281, train_acc = 0.900 (3.332 sec/step)\n",
      "step 55200 \t loss = 0.031, train_acc = 1.000 (3.341 sec/step)\n",
      "step 55210 \t loss = 0.032, train_acc = 1.000 (3.293 sec/step)\n",
      "step 55220 \t loss = 0.563, train_acc = 0.700 (3.331 sec/step)\n",
      "step 55230 \t loss = 0.326, train_acc = 0.900 (3.300 sec/step)\n",
      "step 55240 \t loss = 0.004, train_acc = 1.000 (3.317 sec/step)\n",
      "step 55250 \t loss = 0.006, train_acc = 1.000 (3.331 sec/step)\n",
      "step 55260 \t loss = 0.003, train_acc = 1.000 (3.453 sec/step)\n",
      "step 55270 \t loss = 0.027, train_acc = 1.000 (3.285 sec/step)\n",
      "step 55280 \t loss = 0.339, train_acc = 0.900 (3.321 sec/step)\n",
      "step 55290 \t loss = 0.034, train_acc = 1.000 (3.281 sec/step)\n",
      "step 55300 \t loss = 0.575, train_acc = 0.800 (3.324 sec/step)\n",
      "step 55310 \t loss = 0.002, train_acc = 1.000 (3.356 sec/step)\n",
      "step 55320 \t loss = 0.042, train_acc = 1.000 (3.320 sec/step)\n",
      "step 55330 \t loss = 0.231, train_acc = 0.900 (3.355 sec/step)\n",
      "step 55340 \t loss = 0.002, train_acc = 1.000 (3.339 sec/step)\n",
      "step 55350 \t loss = 0.000, train_acc = 1.000 (3.313 sec/step)\n",
      "step 55360 \t loss = 0.006, train_acc = 1.000 (3.292 sec/step)\n",
      "step 55370 \t loss = 0.017, train_acc = 1.000 (3.364 sec/step)\n",
      "step 55380 \t loss = 0.112, train_acc = 1.000 (3.343 sec/step)\n",
      "step 55390 \t loss = 0.137, train_acc = 1.000 (3.291 sec/step)\n",
      "step 55400 \t loss = 0.000, train_acc = 1.000 (3.301 sec/step)\n",
      "step 55410 \t loss = 0.262, train_acc = 0.900 (3.324 sec/step)\n",
      "step 55420 \t loss = 0.002, train_acc = 1.000 (3.341 sec/step)\n",
      "step 55430 \t loss = 0.073, train_acc = 1.000 (3.318 sec/step)\n",
      "step 55440 \t loss = 0.029, train_acc = 1.000 (3.322 sec/step)\n",
      "step 55450 \t loss = 0.042, train_acc = 1.000 (3.338 sec/step)\n",
      "step 55460 \t loss = 0.009, train_acc = 1.000 (3.307 sec/step)\n",
      "step 55470 \t loss = 0.000, train_acc = 1.000 (3.324 sec/step)\n",
      "step 55480 \t loss = 0.001, train_acc = 1.000 (3.350 sec/step)\n",
      "step 55490 \t loss = 0.001, train_acc = 1.000 (3.344 sec/step)\n",
      "step 55500 \t loss = 0.455, train_acc = 0.900 (3.321 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 55510 \t loss = 0.406, train_acc = 0.900 (3.307 sec/step)\n",
      "step 55520 \t loss = 0.117, train_acc = 0.900 (3.347 sec/step)\n",
      "step 55530 \t loss = 0.262, train_acc = 0.900 (3.381 sec/step)\n",
      "step 55540 \t loss = 3.158, train_acc = 0.900 (3.348 sec/step)\n",
      "step 55550 \t loss = 0.019, train_acc = 1.000 (3.362 sec/step)\n",
      "step 55560 \t loss = 2.476, train_acc = 0.800 (3.368 sec/step)\n",
      "step 55570 \t loss = 0.002, train_acc = 1.000 (3.292 sec/step)\n",
      "step 55580 \t loss = 0.014, train_acc = 1.000 (3.351 sec/step)\n",
      "step 55590 \t loss = 0.112, train_acc = 1.000 (3.320 sec/step)\n",
      "step 55600 \t loss = 0.109, train_acc = 0.900 (3.418 sec/step)\n",
      "step 55610 \t loss = 0.663, train_acc = 0.900 (3.320 sec/step)\n",
      "step 55620 \t loss = 0.047, train_acc = 1.000 (3.365 sec/step)\n",
      "step 55630 \t loss = 0.347, train_acc = 0.800 (3.350 sec/step)\n",
      "step 55640 \t loss = 0.472, train_acc = 0.900 (3.316 sec/step)\n",
      "step 55650 \t loss = 0.583, train_acc = 0.800 (3.295 sec/step)\n",
      "step 55660 \t loss = 0.025, train_acc = 1.000 (3.316 sec/step)\n",
      "step 55670 \t loss = 0.000, train_acc = 1.000 (3.309 sec/step)\n",
      "step 55680 \t loss = 0.426, train_acc = 0.700 (3.333 sec/step)\n",
      "step 55690 \t loss = 0.088, train_acc = 1.000 (3.337 sec/step)\n",
      "step 55700 \t loss = 1.171, train_acc = 0.700 (3.416 sec/step)\n",
      "step 55710 \t loss = 0.018, train_acc = 1.000 (3.426 sec/step)\n",
      "step 55720 \t loss = 0.235, train_acc = 1.000 (3.295 sec/step)\n",
      "step 55730 \t loss = 0.442, train_acc = 0.900 (3.286 sec/step)\n",
      "step 55740 \t loss = 0.016, train_acc = 1.000 (3.342 sec/step)\n",
      "step 55750 \t loss = 1.202, train_acc = 0.800 (3.316 sec/step)\n",
      "step 55760 \t loss = 0.021, train_acc = 1.000 (3.318 sec/step)\n",
      "step 55770 \t loss = 0.000, train_acc = 1.000 (3.313 sec/step)\n",
      "step 55780 \t loss = 0.002, train_acc = 1.000 (3.360 sec/step)\n",
      "step 55790 \t loss = 0.027, train_acc = 1.000 (3.298 sec/step)\n",
      "step 55800 \t loss = 0.087, train_acc = 0.900 (3.329 sec/step)\n",
      "step 55810 \t loss = 0.135, train_acc = 1.000 (3.357 sec/step)\n",
      "step 55820 \t loss = 0.045, train_acc = 1.000 (3.329 sec/step)\n",
      "step 55830 \t loss = 0.068, train_acc = 1.000 (3.317 sec/step)\n",
      "step 55840 \t loss = 0.000, train_acc = 1.000 (3.335 sec/step)\n",
      "step 55850 \t loss = 0.005, train_acc = 1.000 (3.318 sec/step)\n",
      "step 55860 \t loss = 0.021, train_acc = 1.000 (3.305 sec/step)\n",
      "step 55870 \t loss = 0.088, train_acc = 1.000 (3.318 sec/step)\n",
      "step 55880 \t loss = 0.021, train_acc = 1.000 (3.327 sec/step)\n",
      "step 55890 \t loss = 0.164, train_acc = 0.900 (3.350 sec/step)\n",
      "step 55900 \t loss = 0.124, train_acc = 1.000 (3.352 sec/step)\n",
      "step 55910 \t loss = 0.049, train_acc = 1.000 (3.367 sec/step)\n",
      "step 55920 \t loss = 0.128, train_acc = 1.000 (3.369 sec/step)\n",
      "step 55930 \t loss = 0.054, train_acc = 1.000 (3.367 sec/step)\n",
      "step 55940 \t loss = 0.218, train_acc = 0.800 (3.327 sec/step)\n",
      "step 55950 \t loss = 0.094, train_acc = 1.000 (3.322 sec/step)\n",
      "step 55960 \t loss = 0.143, train_acc = 1.000 (3.328 sec/step)\n",
      "step 55970 \t loss = 0.002, train_acc = 1.000 (3.313 sec/step)\n",
      "step 55980 \t loss = 0.223, train_acc = 0.900 (3.351 sec/step)\n",
      "step 55990 \t loss = 0.156, train_acc = 0.900 (3.302 sec/step)\n",
      "step 56000 \t loss = 0.381, train_acc = 0.800 (3.325 sec/step)\n",
      "step 56010 \t loss = 0.263, train_acc = 0.900 (3.312 sec/step)\n",
      "step 56020 \t loss = 0.054, train_acc = 1.000 (3.338 sec/step)\n",
      "step 56030 \t loss = 0.000, train_acc = 1.000 (3.353 sec/step)\n",
      "step 56040 \t loss = 0.001, train_acc = 1.000 (3.465 sec/step)\n",
      "step 56050 \t loss = 0.285, train_acc = 0.900 (3.302 sec/step)\n",
      "step 56060 \t loss = 0.019, train_acc = 1.000 (3.347 sec/step)\n",
      "step 56070 \t loss = 0.033, train_acc = 1.000 (3.287 sec/step)\n",
      "step 56080 \t loss = 0.003, train_acc = 1.000 (3.298 sec/step)\n",
      "step 56090 \t loss = 0.045, train_acc = 1.000 (3.433 sec/step)\n",
      "step 56100 \t loss = 0.002, train_acc = 1.000 (3.328 sec/step)\n",
      "step 56110 \t loss = 0.120, train_acc = 0.900 (3.300 sec/step)\n",
      "step 56120 \t loss = 0.001, train_acc = 1.000 (3.330 sec/step)\n",
      "step 56130 \t loss = 0.025, train_acc = 1.000 (3.386 sec/step)\n",
      "step 56140 \t loss = 0.245, train_acc = 0.900 (3.375 sec/step)\n",
      "step 56150 \t loss = 0.102, train_acc = 0.900 (3.354 sec/step)\n",
      "step 56160 \t loss = 0.069, train_acc = 1.000 (3.342 sec/step)\n",
      "step 56170 \t loss = 0.138, train_acc = 1.000 (3.408 sec/step)\n",
      "step 56180 \t loss = 0.445, train_acc = 0.800 (3.372 sec/step)\n",
      "step 56190 \t loss = 0.095, train_acc = 1.000 (3.370 sec/step)\n",
      "step 56200 \t loss = 0.003, train_acc = 1.000 (3.399 sec/step)\n",
      "step 56210 \t loss = 0.303, train_acc = 0.900 (3.337 sec/step)\n",
      "step 56220 \t loss = 0.019, train_acc = 1.000 (3.278 sec/step)\n",
      "step 56230 \t loss = 0.153, train_acc = 1.000 (3.350 sec/step)\n",
      "step 56240 \t loss = 0.677, train_acc = 0.800 (3.300 sec/step)\n",
      "step 56250 \t loss = 0.012, train_acc = 1.000 (3.316 sec/step)\n",
      "step 56260 \t loss = 0.006, train_acc = 1.000 (3.381 sec/step)\n",
      "step 56270 \t loss = 0.487, train_acc = 0.900 (3.305 sec/step)\n",
      "step 56280 \t loss = 0.016, train_acc = 1.000 (3.323 sec/step)\n",
      "step 56290 \t loss = 0.397, train_acc = 0.800 (3.274 sec/step)\n",
      "step 56300 \t loss = 0.110, train_acc = 0.900 (3.344 sec/step)\n",
      "step 56310 \t loss = 0.893, train_acc = 0.900 (3.295 sec/step)\n",
      "step 56320 \t loss = 0.034, train_acc = 1.000 (3.278 sec/step)\n",
      "step 56330 \t loss = 0.026, train_acc = 1.000 (3.339 sec/step)\n",
      "step 56340 \t loss = 0.036, train_acc = 1.000 (3.320 sec/step)\n",
      "step 56350 \t loss = 0.329, train_acc = 0.900 (3.352 sec/step)\n",
      "step 56360 \t loss = 0.091, train_acc = 1.000 (3.336 sec/step)\n",
      "step 56370 \t loss = 0.048, train_acc = 1.000 (3.321 sec/step)\n",
      "step 56380 \t loss = 0.232, train_acc = 0.900 (3.422 sec/step)\n",
      "step 56390 \t loss = 0.005, train_acc = 1.000 (3.396 sec/step)\n",
      "step 56400 \t loss = 0.067, train_acc = 1.000 (3.307 sec/step)\n",
      "step 56410 \t loss = 1.117, train_acc = 0.800 (3.364 sec/step)\n",
      "step 56420 \t loss = 0.064, train_acc = 1.000 (3.395 sec/step)\n",
      "step 56430 \t loss = 0.578, train_acc = 0.900 (3.314 sec/step)\n",
      "step 56440 \t loss = 0.008, train_acc = 1.000 (3.321 sec/step)\n",
      "step 56450 \t loss = 0.025, train_acc = 1.000 (3.287 sec/step)\n",
      "step 56460 \t loss = 0.201, train_acc = 0.900 (3.366 sec/step)\n",
      "step 56470 \t loss = 0.045, train_acc = 1.000 (3.367 sec/step)\n",
      "step 56480 \t loss = 0.017, train_acc = 1.000 (3.351 sec/step)\n",
      "step 56490 \t loss = 0.209, train_acc = 0.900 (3.363 sec/step)\n",
      "step 56500 \t loss = 0.043, train_acc = 1.000 (3.369 sec/step)\n",
      "step 56510 \t loss = 0.019, train_acc = 1.000 (3.304 sec/step)\n",
      "step 56520 \t loss = 0.754, train_acc = 0.800 (3.365 sec/step)\n",
      "step 56530 \t loss = 0.083, train_acc = 1.000 (3.346 sec/step)\n",
      "step 56540 \t loss = 0.103, train_acc = 1.000 (3.430 sec/step)\n",
      "step 56550 \t loss = 0.264, train_acc = 0.900 (3.356 sec/step)\n",
      "step 56560 \t loss = 0.544, train_acc = 0.900 (3.339 sec/step)\n",
      "step 56570 \t loss = 0.195, train_acc = 0.800 (3.342 sec/step)\n",
      "step 56580 \t loss = 0.553, train_acc = 0.800 (3.313 sec/step)\n",
      "step 56590 \t loss = 0.239, train_acc = 0.900 (3.362 sec/step)\n",
      "step 56600 \t loss = 0.371, train_acc = 0.800 (3.305 sec/step)\n",
      "step 56610 \t loss = 0.072, train_acc = 1.000 (3.320 sec/step)\n",
      "step 56620 \t loss = 0.091, train_acc = 1.000 (3.303 sec/step)\n",
      "step 56630 \t loss = 0.019, train_acc = 1.000 (3.305 sec/step)\n",
      "step 56640 \t loss = 0.129, train_acc = 0.900 (3.370 sec/step)\n",
      "step 56650 \t loss = 0.149, train_acc = 0.900 (3.333 sec/step)\n",
      "step 56660 \t loss = 0.097, train_acc = 0.900 (3.275 sec/step)\n",
      "step 56670 \t loss = 0.001, train_acc = 1.000 (3.325 sec/step)\n",
      "step 56680 \t loss = 0.023, train_acc = 1.000 (3.317 sec/step)\n",
      "step 56690 \t loss = 0.029, train_acc = 1.000 (3.336 sec/step)\n",
      "step 56700 \t loss = 0.166, train_acc = 0.900 (3.383 sec/step)\n",
      "step 56710 \t loss = 2.615, train_acc = 0.900 (3.312 sec/step)\n",
      "step 56720 \t loss = 0.040, train_acc = 1.000 (3.349 sec/step)\n",
      "step 56730 \t loss = 0.483, train_acc = 0.900 (3.329 sec/step)\n",
      "step 56740 \t loss = 0.014, train_acc = 1.000 (3.352 sec/step)\n",
      "step 56750 \t loss = 1.337, train_acc = 0.800 (3.435 sec/step)\n",
      "step 56760 \t loss = 0.093, train_acc = 1.000 (3.317 sec/step)\n",
      "step 56770 \t loss = 0.006, train_acc = 1.000 (3.345 sec/step)\n",
      "step 56780 \t loss = 0.152, train_acc = 0.900 (3.292 sec/step)\n",
      "step 56790 \t loss = 0.720, train_acc = 0.900 (3.329 sec/step)\n",
      "step 56800 \t loss = 0.015, train_acc = 1.000 (3.355 sec/step)\n",
      "step 56810 \t loss = 0.027, train_acc = 1.000 (3.354 sec/step)\n",
      "step 56820 \t loss = 0.085, train_acc = 1.000 (3.422 sec/step)\n",
      "step 56830 \t loss = 0.247, train_acc = 0.900 (3.406 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 56840 \t loss = 1.283, train_acc = 0.800 (3.293 sec/step)\n",
      "step 56850 \t loss = 0.020, train_acc = 1.000 (3.333 sec/step)\n",
      "step 56860 \t loss = 0.054, train_acc = 1.000 (3.316 sec/step)\n",
      "step 56870 \t loss = 0.011, train_acc = 1.000 (3.336 sec/step)\n",
      "step 56880 \t loss = 0.127, train_acc = 0.900 (3.350 sec/step)\n",
      "step 56890 \t loss = 0.001, train_acc = 1.000 (3.299 sec/step)\n",
      "step 56900 \t loss = 0.035, train_acc = 1.000 (3.315 sec/step)\n",
      "step 56910 \t loss = 0.112, train_acc = 0.900 (3.307 sec/step)\n",
      "step 56920 \t loss = 0.002, train_acc = 1.000 (3.315 sec/step)\n",
      "step 56930 \t loss = 0.018, train_acc = 1.000 (3.324 sec/step)\n",
      "step 56940 \t loss = 0.072, train_acc = 1.000 (3.387 sec/step)\n",
      "step 56950 \t loss = 0.078, train_acc = 1.000 (3.365 sec/step)\n",
      "step 56960 \t loss = 0.156, train_acc = 0.900 (3.399 sec/step)\n",
      "step 56970 \t loss = 0.000, train_acc = 1.000 (3.390 sec/step)\n",
      "step 56980 \t loss = 0.001, train_acc = 1.000 (3.379 sec/step)\n",
      "step 56990 \t loss = 0.104, train_acc = 0.900 (3.360 sec/step)\n",
      "VALIDATION \t acc = 0.515 (3.616 sec)\n",
      "step 57000 \t loss = 0.114, train_acc = 1.000 (3.286 sec/step)\n",
      "step 57010 \t loss = 0.029, train_acc = 1.000 (3.302 sec/step)\n",
      "step 57020 \t loss = 0.031, train_acc = 1.000 (3.330 sec/step)\n",
      "step 57030 \t loss = 0.386, train_acc = 0.900 (3.316 sec/step)\n",
      "step 57040 \t loss = 0.117, train_acc = 1.000 (3.381 sec/step)\n",
      "step 57050 \t loss = 0.037, train_acc = 1.000 (3.453 sec/step)\n",
      "step 57060 \t loss = 0.048, train_acc = 1.000 (3.345 sec/step)\n",
      "step 57070 \t loss = 0.001, train_acc = 1.000 (3.314 sec/step)\n",
      "step 57080 \t loss = 0.000, train_acc = 1.000 (3.328 sec/step)\n",
      "step 57090 \t loss = 0.000, train_acc = 1.000 (3.372 sec/step)\n",
      "step 57100 \t loss = 0.049, train_acc = 1.000 (3.357 sec/step)\n",
      "step 57110 \t loss = 0.000, train_acc = 1.000 (3.324 sec/step)\n",
      "step 57120 \t loss = 0.307, train_acc = 0.900 (3.387 sec/step)\n",
      "step 57130 \t loss = 0.133, train_acc = 0.900 (3.355 sec/step)\n",
      "step 57140 \t loss = 0.364, train_acc = 0.800 (3.350 sec/step)\n",
      "step 57150 \t loss = 0.514, train_acc = 0.900 (3.362 sec/step)\n",
      "step 57160 \t loss = 0.191, train_acc = 0.900 (3.284 sec/step)\n",
      "step 57170 \t loss = 0.068, train_acc = 1.000 (3.302 sec/step)\n",
      "step 57180 \t loss = 0.232, train_acc = 0.900 (3.329 sec/step)\n",
      "step 57190 \t loss = 0.078, train_acc = 1.000 (3.389 sec/step)\n",
      "step 57200 \t loss = 1.412, train_acc = 0.900 (3.327 sec/step)\n",
      "step 57210 \t loss = 0.020, train_acc = 1.000 (3.315 sec/step)\n",
      "step 57220 \t loss = 2.202, train_acc = 0.800 (3.369 sec/step)\n",
      "step 57230 \t loss = 0.056, train_acc = 1.000 (3.350 sec/step)\n",
      "step 57240 \t loss = 0.292, train_acc = 0.900 (3.360 sec/step)\n",
      "step 57250 \t loss = 0.462, train_acc = 0.900 (3.335 sec/step)\n",
      "step 57260 \t loss = 0.014, train_acc = 1.000 (3.320 sec/step)\n",
      "step 57270 \t loss = 0.083, train_acc = 1.000 (3.349 sec/step)\n",
      "step 57280 \t loss = 0.001, train_acc = 1.000 (3.307 sec/step)\n",
      "step 57290 \t loss = 0.036, train_acc = 1.000 (3.323 sec/step)\n",
      "step 57300 \t loss = 0.073, train_acc = 1.000 (3.416 sec/step)\n",
      "step 57310 \t loss = 0.011, train_acc = 1.000 (3.297 sec/step)\n",
      "step 57320 \t loss = 2.913, train_acc = 0.600 (3.317 sec/step)\n",
      "step 57330 \t loss = 0.253, train_acc = 0.900 (3.330 sec/step)\n",
      "step 57340 \t loss = 0.900, train_acc = 0.800 (3.334 sec/step)\n",
      "step 57350 \t loss = 0.293, train_acc = 0.900 (3.371 sec/step)\n",
      "step 57360 \t loss = 1.017, train_acc = 0.700 (3.321 sec/step)\n",
      "step 57370 \t loss = 0.026, train_acc = 1.000 (3.366 sec/step)\n",
      "step 57380 \t loss = 0.013, train_acc = 1.000 (3.385 sec/step)\n",
      "step 57390 \t loss = 0.005, train_acc = 1.000 (3.357 sec/step)\n",
      "step 57400 \t loss = 0.889, train_acc = 0.900 (3.314 sec/step)\n",
      "step 57410 \t loss = 0.228, train_acc = 0.900 (3.361 sec/step)\n",
      "step 57420 \t loss = 0.157, train_acc = 0.900 (3.345 sec/step)\n",
      "step 57430 \t loss = 0.382, train_acc = 0.900 (3.357 sec/step)\n",
      "step 57440 \t loss = 0.434, train_acc = 0.900 (3.367 sec/step)\n",
      "step 57450 \t loss = 0.091, train_acc = 0.900 (3.313 sec/step)\n",
      "step 57460 \t loss = 0.014, train_acc = 1.000 (3.351 sec/step)\n",
      "step 57470 \t loss = 0.320, train_acc = 0.900 (3.289 sec/step)\n",
      "step 57480 \t loss = 0.054, train_acc = 1.000 (3.305 sec/step)\n",
      "step 57490 \t loss = 0.292, train_acc = 0.900 (3.293 sec/step)\n",
      "step 57500 \t loss = 0.006, train_acc = 1.000 (3.332 sec/step)\n",
      "step 57510 \t loss = 0.123, train_acc = 0.900 (3.375 sec/step)\n",
      "step 57520 \t loss = 0.089, train_acc = 1.000 (3.332 sec/step)\n",
      "step 57530 \t loss = 0.189, train_acc = 0.900 (3.362 sec/step)\n",
      "step 57540 \t loss = 0.066, train_acc = 1.000 (3.327 sec/step)\n",
      "step 57550 \t loss = 0.070, train_acc = 1.000 (3.343 sec/step)\n",
      "step 57560 \t loss = 0.115, train_acc = 1.000 (3.295 sec/step)\n",
      "step 57570 \t loss = 0.240, train_acc = 0.900 (3.344 sec/step)\n",
      "step 57580 \t loss = 0.592, train_acc = 0.900 (3.394 sec/step)\n",
      "step 57590 \t loss = 0.610, train_acc = 0.800 (3.367 sec/step)\n",
      "step 57600 \t loss = 0.055, train_acc = 1.000 (3.375 sec/step)\n",
      "step 57610 \t loss = 0.554, train_acc = 0.900 (3.334 sec/step)\n",
      "step 57620 \t loss = 0.190, train_acc = 0.900 (3.325 sec/step)\n",
      "step 57630 \t loss = 0.023, train_acc = 1.000 (3.443 sec/step)\n",
      "step 57640 \t loss = 0.926, train_acc = 0.900 (3.284 sec/step)\n",
      "step 57650 \t loss = 0.114, train_acc = 0.900 (3.371 sec/step)\n",
      "step 57660 \t loss = 0.052, train_acc = 1.000 (3.349 sec/step)\n",
      "step 57670 \t loss = 0.424, train_acc = 0.900 (3.404 sec/step)\n",
      "step 57680 \t loss = 0.172, train_acc = 0.900 (3.327 sec/step)\n",
      "step 57690 \t loss = 0.056, train_acc = 1.000 (3.303 sec/step)\n",
      "step 57700 \t loss = 0.387, train_acc = 0.900 (3.383 sec/step)\n",
      "step 57710 \t loss = 0.001, train_acc = 1.000 (3.310 sec/step)\n",
      "step 57720 \t loss = 0.387, train_acc = 0.800 (3.328 sec/step)\n",
      "step 57730 \t loss = 0.086, train_acc = 1.000 (3.354 sec/step)\n",
      "step 57740 \t loss = 0.033, train_acc = 1.000 (3.325 sec/step)\n",
      "step 57750 \t loss = 0.001, train_acc = 1.000 (3.321 sec/step)\n",
      "step 57760 \t loss = 0.874, train_acc = 0.900 (3.353 sec/step)\n",
      "step 57770 \t loss = 0.448, train_acc = 0.900 (3.328 sec/step)\n",
      "step 57780 \t loss = 0.035, train_acc = 1.000 (3.343 sec/step)\n",
      "step 57790 \t loss = 0.009, train_acc = 1.000 (3.386 sec/step)\n",
      "step 57800 \t loss = 0.249, train_acc = 0.800 (3.335 sec/step)\n",
      "step 57810 \t loss = 0.077, train_acc = 1.000 (3.333 sec/step)\n",
      "step 57820 \t loss = 0.095, train_acc = 0.900 (3.414 sec/step)\n",
      "step 57830 \t loss = 0.003, train_acc = 1.000 (3.318 sec/step)\n",
      "step 57840 \t loss = 0.014, train_acc = 1.000 (3.352 sec/step)\n",
      "step 57850 \t loss = 0.134, train_acc = 0.900 (3.366 sec/step)\n",
      "step 57860 \t loss = 0.465, train_acc = 0.900 (3.354 sec/step)\n",
      "step 57870 \t loss = 0.080, train_acc = 1.000 (3.348 sec/step)\n",
      "step 57880 \t loss = 0.102, train_acc = 0.900 (3.307 sec/step)\n",
      "step 57890 \t loss = 0.219, train_acc = 0.900 (3.391 sec/step)\n",
      "step 57900 \t loss = 0.629, train_acc = 0.800 (3.378 sec/step)\n",
      "step 57910 \t loss = 0.271, train_acc = 0.900 (3.355 sec/step)\n",
      "step 57920 \t loss = 0.095, train_acc = 1.000 (3.289 sec/step)\n",
      "step 57930 \t loss = 0.213, train_acc = 0.900 (3.292 sec/step)\n",
      "step 57940 \t loss = 22.855, train_acc = 0.900 (3.337 sec/step)\n",
      "step 57950 \t loss = 0.772, train_acc = 0.800 (3.319 sec/step)\n",
      "step 57960 \t loss = 0.513, train_acc = 0.800 (3.291 sec/step)\n",
      "step 57970 \t loss = 0.111, train_acc = 0.900 (3.356 sec/step)\n",
      "step 57980 \t loss = 0.019, train_acc = 1.000 (3.335 sec/step)\n",
      "step 57990 \t loss = 0.440, train_acc = 0.900 (3.304 sec/step)\n",
      "step 58000 \t loss = 1.077, train_acc = 0.700 (3.342 sec/step)\n",
      "step 58010 \t loss = 0.011, train_acc = 1.000 (3.340 sec/step)\n",
      "step 58020 \t loss = 0.011, train_acc = 1.000 (3.377 sec/step)\n",
      "step 58030 \t loss = 0.208, train_acc = 0.900 (3.290 sec/step)\n",
      "step 58040 \t loss = 0.014, train_acc = 1.000 (3.335 sec/step)\n",
      "step 58050 \t loss = 0.003, train_acc = 1.000 (3.467 sec/step)\n",
      "step 58060 \t loss = 0.096, train_acc = 0.900 (3.341 sec/step)\n",
      "step 58070 \t loss = 0.178, train_acc = 0.900 (3.326 sec/step)\n",
      "step 58080 \t loss = 0.061, train_acc = 1.000 (3.335 sec/step)\n",
      "step 58090 \t loss = 0.436, train_acc = 0.900 (3.358 sec/step)\n",
      "step 58100 \t loss = 0.068, train_acc = 1.000 (3.321 sec/step)\n",
      "step 58110 \t loss = 0.558, train_acc = 0.800 (3.364 sec/step)\n",
      "step 58120 \t loss = 0.003, train_acc = 1.000 (3.292 sec/step)\n",
      "step 58130 \t loss = 0.092, train_acc = 0.900 (3.341 sec/step)\n",
      "step 58140 \t loss = 0.066, train_acc = 1.000 (3.286 sec/step)\n",
      "step 58150 \t loss = 0.733, train_acc = 0.700 (3.333 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 58160 \t loss = 0.161, train_acc = 0.900 (3.319 sec/step)\n",
      "step 58170 \t loss = 0.191, train_acc = 1.000 (3.317 sec/step)\n",
      "step 58180 \t loss = 0.135, train_acc = 0.900 (3.342 sec/step)\n",
      "step 58190 \t loss = 0.210, train_acc = 0.900 (3.386 sec/step)\n",
      "step 58200 \t loss = 0.001, train_acc = 1.000 (3.292 sec/step)\n",
      "step 58210 \t loss = 0.000, train_acc = 1.000 (3.319 sec/step)\n",
      "step 58220 \t loss = 0.002, train_acc = 1.000 (3.299 sec/step)\n",
      "step 58230 \t loss = 0.015, train_acc = 1.000 (3.335 sec/step)\n",
      "step 58240 \t loss = 0.022, train_acc = 1.000 (3.370 sec/step)\n",
      "step 58250 \t loss = 0.002, train_acc = 1.000 (3.314 sec/step)\n",
      "step 58260 \t loss = 0.073, train_acc = 0.900 (3.294 sec/step)\n",
      "step 58270 \t loss = 0.002, train_acc = 1.000 (3.294 sec/step)\n",
      "step 58280 \t loss = 0.068, train_acc = 1.000 (3.335 sec/step)\n",
      "step 58290 \t loss = 0.002, train_acc = 1.000 (3.400 sec/step)\n",
      "step 58300 \t loss = 0.096, train_acc = 0.900 (3.365 sec/step)\n",
      "step 58310 \t loss = 0.287, train_acc = 0.900 (3.355 sec/step)\n",
      "step 58320 \t loss = 0.136, train_acc = 1.000 (3.319 sec/step)\n",
      "step 58330 \t loss = 0.296, train_acc = 0.800 (3.373 sec/step)\n",
      "step 58340 \t loss = 0.470, train_acc = 0.900 (3.319 sec/step)\n",
      "step 58350 \t loss = 0.010, train_acc = 1.000 (3.336 sec/step)\n",
      "step 58360 \t loss = 0.013, train_acc = 1.000 (3.339 sec/step)\n",
      "step 58370 \t loss = 0.127, train_acc = 0.900 (3.338 sec/step)\n",
      "step 58380 \t loss = 0.160, train_acc = 1.000 (3.339 sec/step)\n",
      "step 58390 \t loss = 0.254, train_acc = 0.900 (3.367 sec/step)\n",
      "step 58400 \t loss = 1.397, train_acc = 0.900 (3.330 sec/step)\n",
      "step 58410 \t loss = 0.011, train_acc = 1.000 (3.347 sec/step)\n",
      "step 58420 \t loss = 0.007, train_acc = 1.000 (3.311 sec/step)\n",
      "step 58430 \t loss = 0.020, train_acc = 1.000 (3.400 sec/step)\n",
      "step 58440 \t loss = 0.002, train_acc = 1.000 (3.432 sec/step)\n",
      "step 58450 \t loss = 0.056, train_acc = 1.000 (3.341 sec/step)\n",
      "step 58460 \t loss = 0.018, train_acc = 1.000 (3.332 sec/step)\n",
      "step 58470 \t loss = 0.022, train_acc = 1.000 (3.368 sec/step)\n",
      "step 58480 \t loss = 0.022, train_acc = 1.000 (3.421 sec/step)\n",
      "step 58490 \t loss = 0.006, train_acc = 1.000 (3.370 sec/step)\n",
      "step 58500 \t loss = 3.795, train_acc = 0.800 (3.322 sec/step)\n",
      "step 58510 \t loss = 0.948, train_acc = 0.800 (3.364 sec/step)\n",
      "step 58520 \t loss = 0.470, train_acc = 0.800 (3.387 sec/step)\n",
      "step 58530 \t loss = 0.174, train_acc = 0.900 (3.376 sec/step)\n",
      "step 58540 \t loss = 0.457, train_acc = 0.900 (3.352 sec/step)\n",
      "step 58550 \t loss = 0.808, train_acc = 0.900 (3.377 sec/step)\n",
      "step 58560 \t loss = 0.127, train_acc = 0.900 (3.289 sec/step)\n",
      "step 58570 \t loss = 0.026, train_acc = 1.000 (3.327 sec/step)\n",
      "step 58580 \t loss = 0.051, train_acc = 1.000 (3.386 sec/step)\n",
      "step 58590 \t loss = 0.084, train_acc = 1.000 (3.330 sec/step)\n",
      "step 58600 \t loss = 0.326, train_acc = 0.900 (3.320 sec/step)\n",
      "step 58610 \t loss = 0.617, train_acc = 0.900 (3.503 sec/step)\n",
      "step 58620 \t loss = 0.004, train_acc = 1.000 (3.327 sec/step)\n",
      "step 58630 \t loss = 0.001, train_acc = 1.000 (3.319 sec/step)\n",
      "step 58640 \t loss = 0.211, train_acc = 0.900 (3.329 sec/step)\n",
      "step 58650 \t loss = 0.182, train_acc = 0.900 (3.381 sec/step)\n",
      "step 58660 \t loss = 0.079, train_acc = 1.000 (3.347 sec/step)\n",
      "step 58670 \t loss = 0.000, train_acc = 1.000 (3.349 sec/step)\n",
      "step 58680 \t loss = 0.436, train_acc = 0.800 (3.312 sec/step)\n",
      "step 58690 \t loss = 0.000, train_acc = 1.000 (3.349 sec/step)\n",
      "step 58700 \t loss = 1.377, train_acc = 0.800 (3.350 sec/step)\n",
      "step 58710 \t loss = 0.002, train_acc = 1.000 (3.363 sec/step)\n",
      "step 58720 \t loss = 0.138, train_acc = 0.900 (3.370 sec/step)\n",
      "step 58730 \t loss = 0.292, train_acc = 0.900 (3.340 sec/step)\n",
      "step 58740 \t loss = 0.002, train_acc = 1.000 (3.362 sec/step)\n",
      "step 58750 \t loss = 0.092, train_acc = 1.000 (3.333 sec/step)\n",
      "step 58760 \t loss = 0.005, train_acc = 1.000 (3.327 sec/step)\n",
      "step 58770 \t loss = 0.003, train_acc = 1.000 (3.328 sec/step)\n",
      "step 58780 \t loss = 0.301, train_acc = 0.900 (3.370 sec/step)\n",
      "step 58790 \t loss = 0.002, train_acc = 1.000 (3.364 sec/step)\n",
      "step 58800 \t loss = 0.021, train_acc = 1.000 (3.306 sec/step)\n",
      "step 58810 \t loss = 0.000, train_acc = 1.000 (3.380 sec/step)\n",
      "step 58820 \t loss = 0.005, train_acc = 1.000 (3.366 sec/step)\n",
      "step 58830 \t loss = 0.000, train_acc = 1.000 (3.356 sec/step)\n",
      "step 58840 \t loss = 0.977, train_acc = 0.700 (3.272 sec/step)\n",
      "step 58850 \t loss = 0.168, train_acc = 1.000 (3.330 sec/step)\n",
      "step 58860 \t loss = 0.101, train_acc = 1.000 (3.320 sec/step)\n",
      "step 58870 \t loss = 0.194, train_acc = 0.900 (3.315 sec/step)\n",
      "step 58880 \t loss = 0.076, train_acc = 1.000 (3.370 sec/step)\n",
      "step 58890 \t loss = 0.077, train_acc = 0.900 (3.281 sec/step)\n",
      "VALIDATION \t acc = 0.548 (3.602 sec)\n",
      "step 58900 \t loss = 0.004, train_acc = 1.000 (3.302 sec/step)\n",
      "step 58910 \t loss = 0.606, train_acc = 0.700 (3.317 sec/step)\n",
      "step 58920 \t loss = 0.319, train_acc = 0.900 (3.324 sec/step)\n",
      "step 58930 \t loss = 0.016, train_acc = 1.000 (3.350 sec/step)\n",
      "step 58940 \t loss = 0.114, train_acc = 0.900 (3.363 sec/step)\n",
      "step 58950 \t loss = 0.001, train_acc = 1.000 (3.301 sec/step)\n",
      "step 58960 \t loss = 0.766, train_acc = 0.800 (3.343 sec/step)\n",
      "step 58970 \t loss = 0.516, train_acc = 0.900 (3.323 sec/step)\n",
      "step 58980 \t loss = 0.417, train_acc = 0.900 (3.299 sec/step)\n",
      "step 58990 \t loss = 0.016, train_acc = 1.000 (3.346 sec/step)\n",
      "step 59000 \t loss = 0.163, train_acc = 0.900 (3.337 sec/step)\n",
      "step 59010 \t loss = 0.002, train_acc = 1.000 (3.375 sec/step)\n",
      "step 59020 \t loss = 0.075, train_acc = 1.000 (3.348 sec/step)\n",
      "step 59030 \t loss = 0.025, train_acc = 1.000 (3.357 sec/step)\n",
      "step 59040 \t loss = 0.048, train_acc = 1.000 (3.294 sec/step)\n",
      "step 59050 \t loss = 0.111, train_acc = 1.000 (3.375 sec/step)\n",
      "step 59060 \t loss = 0.317, train_acc = 0.900 (3.344 sec/step)\n",
      "step 59070 \t loss = 0.008, train_acc = 1.000 (3.380 sec/step)\n",
      "step 59080 \t loss = 0.056, train_acc = 1.000 (3.346 sec/step)\n",
      "step 59090 \t loss = 0.344, train_acc = 0.900 (3.319 sec/step)\n",
      "step 59100 \t loss = 0.010, train_acc = 1.000 (3.320 sec/step)\n",
      "step 59110 \t loss = 0.106, train_acc = 1.000 (3.354 sec/step)\n",
      "step 59120 \t loss = 0.153, train_acc = 0.900 (3.328 sec/step)\n",
      "step 59130 \t loss = 0.029, train_acc = 1.000 (3.323 sec/step)\n",
      "step 59140 \t loss = 0.001, train_acc = 1.000 (3.360 sec/step)\n",
      "step 59150 \t loss = 0.062, train_acc = 1.000 (3.378 sec/step)\n",
      "step 59160 \t loss = 0.141, train_acc = 0.900 (3.325 sec/step)\n",
      "step 59170 \t loss = 0.141, train_acc = 1.000 (3.387 sec/step)\n",
      "step 59180 \t loss = 0.128, train_acc = 1.000 (3.389 sec/step)\n",
      "step 59190 \t loss = 0.008, train_acc = 1.000 (3.317 sec/step)\n",
      "step 59200 \t loss = 0.001, train_acc = 1.000 (3.316 sec/step)\n",
      "step 59210 \t loss = 1.259, train_acc = 0.700 (3.345 sec/step)\n",
      "step 59220 \t loss = 0.086, train_acc = 1.000 (3.360 sec/step)\n",
      "step 59230 \t loss = 0.003, train_acc = 1.000 (3.333 sec/step)\n",
      "step 59240 \t loss = 0.027, train_acc = 1.000 (3.328 sec/step)\n",
      "step 59250 \t loss = 0.071, train_acc = 1.000 (3.335 sec/step)\n",
      "step 59260 \t loss = 0.021, train_acc = 1.000 (3.386 sec/step)\n",
      "step 59270 \t loss = 0.035, train_acc = 1.000 (3.396 sec/step)\n",
      "step 59280 \t loss = 0.003, train_acc = 1.000 (3.381 sec/step)\n",
      "step 59290 \t loss = 0.000, train_acc = 1.000 (3.312 sec/step)\n",
      "step 59300 \t loss = 0.077, train_acc = 0.900 (3.364 sec/step)\n",
      "step 59310 \t loss = 0.098, train_acc = 0.900 (3.300 sec/step)\n",
      "step 59320 \t loss = 1.005, train_acc = 0.800 (3.365 sec/step)\n",
      "step 59330 \t loss = 0.281, train_acc = 0.900 (3.391 sec/step)\n",
      "step 59340 \t loss = 0.064, train_acc = 1.000 (3.342 sec/step)\n",
      "step 59350 \t loss = 0.827, train_acc = 0.900 (3.322 sec/step)\n",
      "step 59360 \t loss = 0.000, train_acc = 1.000 (3.363 sec/step)\n",
      "step 59370 \t loss = 0.011, train_acc = 1.000 (3.365 sec/step)\n",
      "step 59380 \t loss = 0.754, train_acc = 0.900 (3.359 sec/step)\n",
      "step 59390 \t loss = 0.075, train_acc = 1.000 (3.297 sec/step)\n",
      "step 59400 \t loss = 0.001, train_acc = 1.000 (3.317 sec/step)\n",
      "step 59410 \t loss = 0.138, train_acc = 0.900 (3.374 sec/step)\n",
      "step 59420 \t loss = 0.122, train_acc = 1.000 (3.345 sec/step)\n",
      "step 59430 \t loss = 0.012, train_acc = 1.000 (3.335 sec/step)\n",
      "step 59440 \t loss = 0.633, train_acc = 0.900 (3.407 sec/step)\n",
      "step 59450 \t loss = 0.002, train_acc = 1.000 (3.395 sec/step)\n",
      "step 59460 \t loss = 0.378, train_acc = 0.900 (3.333 sec/step)\n",
      "step 59470 \t loss = 0.011, train_acc = 1.000 (3.376 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 59480 \t loss = 0.156, train_acc = 0.900 (3.312 sec/step)\n",
      "step 59490 \t loss = 1.326, train_acc = 0.700 (3.318 sec/step)\n",
      "step 59500 \t loss = 1.687, train_acc = 0.700 (3.318 sec/step)\n",
      "step 59510 \t loss = 0.005, train_acc = 1.000 (3.329 sec/step)\n",
      "step 59520 \t loss = 0.565, train_acc = 0.800 (3.474 sec/step)\n",
      "step 59530 \t loss = 0.001, train_acc = 1.000 (3.359 sec/step)\n",
      "step 59540 \t loss = 0.005, train_acc = 1.000 (3.355 sec/step)\n",
      "step 59550 \t loss = 1.581, train_acc = 0.900 (3.353 sec/step)\n",
      "step 59560 \t loss = 0.395, train_acc = 0.900 (3.316 sec/step)\n",
      "step 59570 \t loss = 0.271, train_acc = 0.900 (3.329 sec/step)\n",
      "step 59580 \t loss = 0.434, train_acc = 0.800 (3.310 sec/step)\n",
      "step 59590 \t loss = 0.044, train_acc = 1.000 (3.407 sec/step)\n",
      "step 59600 \t loss = 0.416, train_acc = 0.800 (3.330 sec/step)\n",
      "step 59610 \t loss = 0.027, train_acc = 1.000 (3.301 sec/step)\n",
      "step 59620 \t loss = 0.346, train_acc = 0.800 (3.352 sec/step)\n",
      "step 59630 \t loss = 0.438, train_acc = 0.700 (3.320 sec/step)\n",
      "step 59640 \t loss = 0.011, train_acc = 1.000 (3.365 sec/step)\n",
      "step 59650 \t loss = 0.558, train_acc = 0.900 (3.397 sec/step)\n",
      "step 59660 \t loss = 0.044, train_acc = 1.000 (3.397 sec/step)\n",
      "step 59670 \t loss = 0.008, train_acc = 1.000 (3.351 sec/step)\n",
      "step 59680 \t loss = 0.003, train_acc = 1.000 (3.327 sec/step)\n",
      "step 59690 \t loss = 0.028, train_acc = 1.000 (3.338 sec/step)\n",
      "step 59700 \t loss = 0.004, train_acc = 1.000 (3.356 sec/step)\n",
      "step 59710 \t loss = 0.090, train_acc = 1.000 (3.317 sec/step)\n",
      "step 59720 \t loss = 0.953, train_acc = 0.700 (3.341 sec/step)\n",
      "step 59730 \t loss = 0.251, train_acc = 0.900 (3.333 sec/step)\n",
      "step 59740 \t loss = 0.049, train_acc = 1.000 (3.298 sec/step)\n",
      "step 59750 \t loss = 0.419, train_acc = 0.800 (3.335 sec/step)\n",
      "step 59760 \t loss = 0.392, train_acc = 0.800 (3.364 sec/step)\n",
      "step 59770 \t loss = 0.652, train_acc = 0.800 (3.380 sec/step)\n",
      "step 59780 \t loss = 0.172, train_acc = 0.900 (3.335 sec/step)\n",
      "step 59790 \t loss = 0.087, train_acc = 0.900 (3.328 sec/step)\n",
      "step 59800 \t loss = 0.041, train_acc = 1.000 (3.327 sec/step)\n",
      "step 59810 \t loss = 0.085, train_acc = 1.000 (3.322 sec/step)\n",
      "step 59820 \t loss = 0.004, train_acc = 1.000 (3.387 sec/step)\n",
      "step 59830 \t loss = 0.040, train_acc = 1.000 (3.391 sec/step)\n",
      "step 59840 \t loss = 0.475, train_acc = 0.900 (3.314 sec/step)\n",
      "step 59850 \t loss = 0.062, train_acc = 1.000 (3.311 sec/step)\n",
      "step 59860 \t loss = 0.389, train_acc = 0.900 (3.347 sec/step)\n",
      "step 59870 \t loss = 0.037, train_acc = 1.000 (3.285 sec/step)\n",
      "step 59880 \t loss = 0.103, train_acc = 1.000 (3.362 sec/step)\n",
      "step 59890 \t loss = 0.357, train_acc = 0.800 (3.349 sec/step)\n",
      "step 59900 \t loss = 0.003, train_acc = 1.000 (3.459 sec/step)\n",
      "step 59910 \t loss = 0.001, train_acc = 1.000 (3.358 sec/step)\n",
      "step 59920 \t loss = 0.338, train_acc = 0.900 (3.341 sec/step)\n",
      "step 59930 \t loss = 0.134, train_acc = 0.900 (3.353 sec/step)\n",
      "step 59940 \t loss = 0.012, train_acc = 1.000 (3.352 sec/step)\n",
      "step 59950 \t loss = 0.373, train_acc = 0.900 (3.321 sec/step)\n",
      "step 59960 \t loss = 0.228, train_acc = 0.900 (3.332 sec/step)\n",
      "step 59970 \t loss = 0.359, train_acc = 0.900 (3.306 sec/step)\n",
      "step 59980 \t loss = 0.003, train_acc = 1.000 (3.390 sec/step)\n",
      "step 59990 \t loss = 0.098, train_acc = 0.900 (3.383 sec/step)\n",
      "step 60000 \t loss = 0.022, train_acc = 1.000 (3.365 sec/step)\n",
      "step 60010 \t loss = 0.004, train_acc = 1.000 (3.310 sec/step)\n",
      "step 60020 \t loss = 0.000, train_acc = 1.000 (3.333 sec/step)\n",
      "step 60030 \t loss = 0.352, train_acc = 0.900 (3.347 sec/step)\n",
      "step 60040 \t loss = 0.022, train_acc = 1.000 (3.388 sec/step)\n",
      "step 60050 \t loss = 0.156, train_acc = 0.900 (3.377 sec/step)\n",
      "step 60060 \t loss = 0.027, train_acc = 1.000 (3.297 sec/step)\n",
      "step 60070 \t loss = 0.406, train_acc = 0.900 (3.307 sec/step)\n",
      "step 60080 \t loss = 0.012, train_acc = 1.000 (3.328 sec/step)\n",
      "step 60090 \t loss = 0.415, train_acc = 0.800 (3.340 sec/step)\n",
      "step 60100 \t loss = 0.022, train_acc = 1.000 (3.321 sec/step)\n",
      "step 60110 \t loss = 0.028, train_acc = 1.000 (3.399 sec/step)\n",
      "step 60120 \t loss = 0.002, train_acc = 1.000 (3.317 sec/step)\n",
      "step 60130 \t loss = 0.000, train_acc = 1.000 (3.321 sec/step)\n",
      "step 60140 \t loss = 0.000, train_acc = 1.000 (3.396 sec/step)\n",
      "step 60150 \t loss = 0.026, train_acc = 1.000 (3.304 sec/step)\n",
      "step 60160 \t loss = 0.015, train_acc = 1.000 (3.353 sec/step)\n",
      "step 60170 \t loss = 0.446, train_acc = 0.900 (3.379 sec/step)\n",
      "step 60180 \t loss = 0.187, train_acc = 0.900 (3.320 sec/step)\n",
      "step 60190 \t loss = 0.000, train_acc = 1.000 (3.305 sec/step)\n",
      "step 60200 \t loss = 0.072, train_acc = 1.000 (3.346 sec/step)\n",
      "step 60210 \t loss = 0.184, train_acc = 0.900 (3.326 sec/step)\n",
      "step 60220 \t loss = 0.012, train_acc = 1.000 (3.417 sec/step)\n",
      "step 60230 \t loss = 0.011, train_acc = 1.000 (3.325 sec/step)\n",
      "step 60240 \t loss = 0.126, train_acc = 0.900 (3.323 sec/step)\n",
      "step 60250 \t loss = 0.901, train_acc = 0.800 (3.306 sec/step)\n",
      "step 60260 \t loss = 0.022, train_acc = 1.000 (3.420 sec/step)\n",
      "step 60270 \t loss = 0.235, train_acc = 0.900 (3.286 sec/step)\n",
      "step 60280 \t loss = 0.019, train_acc = 1.000 (3.302 sec/step)\n",
      "step 60290 \t loss = 0.172, train_acc = 0.900 (3.290 sec/step)\n",
      "step 60300 \t loss = 0.525, train_acc = 0.900 (3.287 sec/step)\n",
      "step 60310 \t loss = 0.702, train_acc = 0.900 (3.280 sec/step)\n",
      "step 60320 \t loss = 0.004, train_acc = 1.000 (3.413 sec/step)\n",
      "step 60330 \t loss = 0.002, train_acc = 1.000 (3.358 sec/step)\n",
      "step 60340 \t loss = 0.530, train_acc = 0.800 (3.372 sec/step)\n",
      "step 60350 \t loss = 0.011, train_acc = 1.000 (3.327 sec/step)\n",
      "step 60360 \t loss = 0.062, train_acc = 1.000 (3.329 sec/step)\n",
      "step 60370 \t loss = 0.017, train_acc = 1.000 (3.433 sec/step)\n",
      "step 60380 \t loss = 0.806, train_acc = 0.900 (3.303 sec/step)\n",
      "step 60390 \t loss = 0.216, train_acc = 0.900 (3.308 sec/step)\n",
      "step 60400 \t loss = 0.057, train_acc = 1.000 (3.383 sec/step)\n",
      "step 60410 \t loss = 0.037, train_acc = 1.000 (3.288 sec/step)\n",
      "step 60420 \t loss = 0.048, train_acc = 1.000 (3.365 sec/step)\n",
      "step 60430 \t loss = 0.015, train_acc = 1.000 (3.316 sec/step)\n",
      "step 60440 \t loss = 0.568, train_acc = 0.900 (3.305 sec/step)\n",
      "step 60450 \t loss = 0.438, train_acc = 0.900 (3.367 sec/step)\n",
      "step 60460 \t loss = 0.021, train_acc = 1.000 (3.364 sec/step)\n",
      "step 60470 \t loss = 0.003, train_acc = 1.000 (3.359 sec/step)\n",
      "step 60480 \t loss = 0.001, train_acc = 1.000 (3.344 sec/step)\n",
      "step 60490 \t loss = 0.152, train_acc = 0.800 (3.306 sec/step)\n",
      "step 60500 \t loss = 0.991, train_acc = 0.700 (3.368 sec/step)\n",
      "step 60510 \t loss = 0.145, train_acc = 1.000 (3.325 sec/step)\n",
      "step 60520 \t loss = 0.013, train_acc = 1.000 (3.328 sec/step)\n",
      "step 60530 \t loss = 0.023, train_acc = 1.000 (3.299 sec/step)\n",
      "step 60540 \t loss = 0.004, train_acc = 1.000 (3.384 sec/step)\n",
      "step 60550 \t loss = 0.288, train_acc = 0.900 (3.439 sec/step)\n",
      "step 60560 \t loss = 0.088, train_acc = 1.000 (3.324 sec/step)\n",
      "step 60570 \t loss = 0.027, train_acc = 1.000 (3.321 sec/step)\n",
      "step 60580 \t loss = 0.018, train_acc = 1.000 (3.327 sec/step)\n",
      "step 60590 \t loss = 0.001, train_acc = 1.000 (3.390 sec/step)\n",
      "step 60600 \t loss = 0.000, train_acc = 1.000 (3.307 sec/step)\n",
      "step 60610 \t loss = 0.218, train_acc = 0.900 (3.286 sec/step)\n",
      "step 60620 \t loss = 0.088, train_acc = 0.900 (3.314 sec/step)\n",
      "step 60630 \t loss = 0.155, train_acc = 0.900 (3.318 sec/step)\n",
      "step 60640 \t loss = 0.036, train_acc = 1.000 (3.290 sec/step)\n",
      "step 60650 \t loss = 0.023, train_acc = 1.000 (3.325 sec/step)\n",
      "step 60660 \t loss = 0.172, train_acc = 1.000 (3.342 sec/step)\n",
      "step 60670 \t loss = 0.002, train_acc = 1.000 (3.359 sec/step)\n",
      "step 60680 \t loss = 0.709, train_acc = 0.900 (3.315 sec/step)\n",
      "step 60690 \t loss = 0.080, train_acc = 1.000 (3.295 sec/step)\n",
      "step 60700 \t loss = 0.019, train_acc = 1.000 (3.330 sec/step)\n",
      "step 60710 \t loss = 0.037, train_acc = 1.000 (3.365 sec/step)\n",
      "step 60720 \t loss = 0.274, train_acc = 0.900 (3.420 sec/step)\n",
      "step 60730 \t loss = 0.001, train_acc = 1.000 (3.325 sec/step)\n",
      "step 60740 \t loss = 0.213, train_acc = 0.900 (3.338 sec/step)\n",
      "step 60750 \t loss = 0.228, train_acc = 0.900 (3.367 sec/step)\n",
      "step 60760 \t loss = 0.002, train_acc = 1.000 (3.321 sec/step)\n",
      "step 60770 \t loss = 0.489, train_acc = 0.800 (3.323 sec/step)\n",
      "step 60780 \t loss = 0.003, train_acc = 1.000 (3.436 sec/step)\n",
      "step 60790 \t loss = 0.037, train_acc = 1.000 (3.333 sec/step)\n",
      "VALIDATION \t acc = 0.536 (3.648 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60800 \t loss = 0.478, train_acc = 0.900 (3.355 sec/step)\n",
      "step 60810 \t loss = 0.040, train_acc = 1.000 (3.366 sec/step)\n",
      "step 60820 \t loss = 0.227, train_acc = 0.900 (3.282 sec/step)\n",
      "step 60830 \t loss = 0.129, train_acc = 1.000 (3.345 sec/step)\n",
      "step 60840 \t loss = 0.008, train_acc = 1.000 (3.309 sec/step)\n",
      "step 60850 \t loss = 0.290, train_acc = 0.900 (3.334 sec/step)\n",
      "step 60860 \t loss = 0.051, train_acc = 1.000 (3.346 sec/step)\n",
      "step 60870 \t loss = 0.276, train_acc = 0.800 (3.360 sec/step)\n",
      "step 60880 \t loss = 0.320, train_acc = 0.800 (3.305 sec/step)\n",
      "step 60890 \t loss = 0.720, train_acc = 0.800 (3.324 sec/step)\n",
      "step 60900 \t loss = 0.092, train_acc = 1.000 (3.362 sec/step)\n",
      "step 60910 \t loss = 0.001, train_acc = 1.000 (3.394 sec/step)\n",
      "step 60920 \t loss = 0.000, train_acc = 1.000 (3.362 sec/step)\n",
      "step 60930 \t loss = 0.022, train_acc = 1.000 (3.361 sec/step)\n",
      "step 60940 \t loss = 0.004, train_acc = 1.000 (3.291 sec/step)\n",
      "step 60950 \t loss = 0.025, train_acc = 1.000 (3.393 sec/step)\n",
      "step 60960 \t loss = 0.391, train_acc = 0.900 (3.365 sec/step)\n",
      "step 60970 \t loss = 0.202, train_acc = 0.900 (3.287 sec/step)\n",
      "step 60980 \t loss = 0.023, train_acc = 1.000 (3.365 sec/step)\n",
      "step 60990 \t loss = 0.000, train_acc = 1.000 (3.335 sec/step)\n",
      "step 61000 \t loss = 0.673, train_acc = 0.700 (3.359 sec/step)\n",
      "step 61010 \t loss = 0.014, train_acc = 1.000 (3.345 sec/step)\n",
      "step 61020 \t loss = 1.154, train_acc = 0.800 (3.381 sec/step)\n",
      "step 61030 \t loss = 0.173, train_acc = 0.900 (3.306 sec/step)\n",
      "step 61040 \t loss = 0.278, train_acc = 0.900 (3.370 sec/step)\n",
      "step 61050 \t loss = 0.022, train_acc = 1.000 (3.346 sec/step)\n",
      "step 61060 \t loss = 0.001, train_acc = 1.000 (3.332 sec/step)\n",
      "step 61070 \t loss = 0.017, train_acc = 1.000 (3.282 sec/step)\n",
      "step 61080 \t loss = 0.397, train_acc = 0.900 (3.377 sec/step)\n",
      "step 61090 \t loss = 0.204, train_acc = 0.900 (3.314 sec/step)\n",
      "step 61100 \t loss = 0.108, train_acc = 1.000 (3.302 sec/step)\n",
      "step 61110 \t loss = 0.016, train_acc = 1.000 (3.368 sec/step)\n",
      "step 61120 \t loss = 0.948, train_acc = 0.900 (3.309 sec/step)\n",
      "step 61130 \t loss = 0.337, train_acc = 0.900 (3.339 sec/step)\n",
      "step 61140 \t loss = 0.120, train_acc = 0.900 (3.365 sec/step)\n",
      "step 61150 \t loss = 0.255, train_acc = 0.900 (3.345 sec/step)\n",
      "step 61160 \t loss = 0.006, train_acc = 1.000 (3.317 sec/step)\n",
      "step 61170 \t loss = 0.011, train_acc = 1.000 (3.309 sec/step)\n",
      "step 61180 \t loss = 0.000, train_acc = 1.000 (3.311 sec/step)\n",
      "step 61190 \t loss = 0.000, train_acc = 1.000 (3.440 sec/step)\n",
      "step 61200 \t loss = 0.049, train_acc = 1.000 (3.320 sec/step)\n",
      "step 61210 \t loss = 0.629, train_acc = 0.900 (3.323 sec/step)\n",
      "step 61220 \t loss = 0.188, train_acc = 0.900 (3.329 sec/step)\n",
      "step 61230 \t loss = 0.007, train_acc = 1.000 (3.370 sec/step)\n",
      "step 61240 \t loss = 0.568, train_acc = 0.900 (3.409 sec/step)\n",
      "step 61250 \t loss = 0.300, train_acc = 0.900 (3.337 sec/step)\n",
      "step 61260 \t loss = 0.406, train_acc = 0.900 (3.373 sec/step)\n",
      "step 61270 \t loss = 0.195, train_acc = 0.900 (3.318 sec/step)\n",
      "step 61280 \t loss = 0.017, train_acc = 1.000 (3.321 sec/step)\n",
      "step 61290 \t loss = 0.071, train_acc = 1.000 (3.371 sec/step)\n",
      "step 61300 \t loss = 0.507, train_acc = 0.900 (3.296 sec/step)\n",
      "step 61310 \t loss = 0.001, train_acc = 1.000 (3.334 sec/step)\n",
      "step 61320 \t loss = 0.035, train_acc = 1.000 (3.385 sec/step)\n",
      "step 61330 \t loss = 0.375, train_acc = 0.900 (3.297 sec/step)\n",
      "step 61340 \t loss = 0.421, train_acc = 0.900 (3.326 sec/step)\n",
      "step 61350 \t loss = 0.011, train_acc = 1.000 (3.342 sec/step)\n",
      "step 61360 \t loss = 0.041, train_acc = 1.000 (3.324 sec/step)\n",
      "step 61370 \t loss = 0.036, train_acc = 1.000 (3.322 sec/step)\n",
      "step 61380 \t loss = 0.072, train_acc = 1.000 (3.323 sec/step)\n",
      "step 61390 \t loss = 0.001, train_acc = 1.000 (3.329 sec/step)\n",
      "step 61400 \t loss = 0.026, train_acc = 1.000 (3.333 sec/step)\n",
      "step 61410 \t loss = 0.459, train_acc = 0.900 (3.307 sec/step)\n",
      "step 61420 \t loss = 0.125, train_acc = 1.000 (3.359 sec/step)\n",
      "step 61430 \t loss = 3.224, train_acc = 0.400 (3.398 sec/step)\n",
      "step 61440 \t loss = 0.107, train_acc = 1.000 (3.299 sec/step)\n",
      "step 61450 \t loss = 0.395, train_acc = 0.900 (3.302 sec/step)\n",
      "step 61460 \t loss = 0.060, train_acc = 1.000 (3.372 sec/step)\n",
      "step 61470 \t loss = 0.330, train_acc = 0.900 (3.311 sec/step)\n",
      "step 61480 \t loss = 0.315, train_acc = 0.900 (3.351 sec/step)\n",
      "step 61490 \t loss = 0.415, train_acc = 0.700 (3.367 sec/step)\n",
      "step 61500 \t loss = 0.526, train_acc = 0.700 (3.289 sec/step)\n",
      "step 61510 \t loss = 0.185, train_acc = 0.900 (3.336 sec/step)\n",
      "step 61520 \t loss = 0.001, train_acc = 1.000 (3.359 sec/step)\n",
      "step 61530 \t loss = 0.397, train_acc = 0.900 (3.350 sec/step)\n",
      "step 61540 \t loss = 0.430, train_acc = 0.900 (3.293 sec/step)\n",
      "step 61550 \t loss = 0.177, train_acc = 0.900 (3.380 sec/step)\n",
      "step 61560 \t loss = 0.365, train_acc = 0.800 (3.373 sec/step)\n",
      "step 61570 \t loss = 0.304, train_acc = 0.900 (3.362 sec/step)\n",
      "step 61580 \t loss = 0.010, train_acc = 1.000 (3.413 sec/step)\n",
      "step 61590 \t loss = 0.106, train_acc = 1.000 (3.360 sec/step)\n",
      "step 61600 \t loss = 0.326, train_acc = 0.900 (3.368 sec/step)\n",
      "step 61610 \t loss = 0.583, train_acc = 0.900 (3.354 sec/step)\n",
      "step 61620 \t loss = 0.040, train_acc = 1.000 (3.341 sec/step)\n",
      "step 61630 \t loss = 0.163, train_acc = 1.000 (3.326 sec/step)\n",
      "step 61640 \t loss = 0.207, train_acc = 0.900 (3.314 sec/step)\n",
      "step 61650 \t loss = 0.157, train_acc = 1.000 (3.313 sec/step)\n",
      "step 61660 \t loss = 0.090, train_acc = 1.000 (3.294 sec/step)\n",
      "step 61670 \t loss = 0.038, train_acc = 1.000 (3.396 sec/step)\n",
      "step 61680 \t loss = 0.095, train_acc = 0.900 (3.395 sec/step)\n",
      "step 61690 \t loss = 0.006, train_acc = 1.000 (3.378 sec/step)\n",
      "step 61700 \t loss = 0.046, train_acc = 1.000 (3.325 sec/step)\n",
      "step 61710 \t loss = 0.016, train_acc = 1.000 (3.356 sec/step)\n",
      "step 61720 \t loss = 0.009, train_acc = 1.000 (3.350 sec/step)\n",
      "step 61730 \t loss = 0.046, train_acc = 1.000 (3.367 sec/step)\n",
      "step 61740 \t loss = 0.160, train_acc = 0.900 (3.361 sec/step)\n",
      "step 61750 \t loss = 0.534, train_acc = 0.900 (3.307 sec/step)\n",
      "step 61760 \t loss = 0.003, train_acc = 1.000 (3.331 sec/step)\n",
      "step 61770 \t loss = 0.048, train_acc = 1.000 (3.308 sec/step)\n",
      "step 61780 \t loss = 0.011, train_acc = 1.000 (3.402 sec/step)\n",
      "step 61790 \t loss = 0.054, train_acc = 1.000 (3.345 sec/step)\n",
      "step 61800 \t loss = 0.761, train_acc = 0.900 (3.303 sec/step)\n",
      "step 61810 \t loss = 0.438, train_acc = 0.900 (3.395 sec/step)\n",
      "step 61820 \t loss = 0.019, train_acc = 1.000 (3.337 sec/step)\n",
      "step 61830 \t loss = 0.007, train_acc = 1.000 (3.297 sec/step)\n",
      "step 61840 \t loss = 0.455, train_acc = 0.800 (3.318 sec/step)\n",
      "step 61850 \t loss = 0.645, train_acc = 0.800 (3.383 sec/step)\n",
      "step 61860 \t loss = 0.276, train_acc = 0.900 (3.361 sec/step)\n",
      "step 61870 \t loss = 0.000, train_acc = 1.000 (3.387 sec/step)\n",
      "step 61880 \t loss = 0.375, train_acc = 0.900 (3.327 sec/step)\n",
      "step 61890 \t loss = 0.014, train_acc = 1.000 (3.374 sec/step)\n",
      "step 61900 \t loss = 0.001, train_acc = 1.000 (3.326 sec/step)\n",
      "step 61910 \t loss = 0.009, train_acc = 1.000 (3.321 sec/step)\n",
      "step 61920 \t loss = 0.297, train_acc = 0.900 (3.400 sec/step)\n",
      "step 61930 \t loss = 0.029, train_acc = 1.000 (3.295 sec/step)\n",
      "step 61940 \t loss = 0.282, train_acc = 0.900 (3.339 sec/step)\n",
      "step 61950 \t loss = 1.076, train_acc = 0.700 (3.329 sec/step)\n",
      "step 61960 \t loss = 1.149, train_acc = 0.900 (3.328 sec/step)\n",
      "step 61970 \t loss = 0.060, train_acc = 1.000 (3.379 sec/step)\n",
      "step 61980 \t loss = 0.037, train_acc = 1.000 (3.352 sec/step)\n",
      "step 61990 \t loss = 0.126, train_acc = 0.900 (3.341 sec/step)\n",
      "step 62000 \t loss = 0.405, train_acc = 0.900 (3.313 sec/step)\n",
      "step 62010 \t loss = 0.518, train_acc = 0.900 (3.351 sec/step)\n",
      "step 62020 \t loss = 0.001, train_acc = 1.000 (3.282 sec/step)\n",
      "step 62030 \t loss = 0.013, train_acc = 1.000 (3.349 sec/step)\n",
      "step 62040 \t loss = 0.225, train_acc = 1.000 (3.401 sec/step)\n",
      "step 62050 \t loss = 0.002, train_acc = 1.000 (3.300 sec/step)\n",
      "step 62060 \t loss = 0.147, train_acc = 0.900 (3.351 sec/step)\n",
      "step 62070 \t loss = 0.121, train_acc = 0.900 (3.299 sec/step)\n",
      "step 62080 \t loss = 0.787, train_acc = 0.900 (3.348 sec/step)\n",
      "step 62090 \t loss = 0.017, train_acc = 1.000 (3.371 sec/step)\n",
      "step 62100 \t loss = 0.000, train_acc = 1.000 (3.348 sec/step)\n",
      "step 62110 \t loss = 0.011, train_acc = 1.000 (3.364 sec/step)\n",
      "step 62120 \t loss = 0.002, train_acc = 1.000 (3.370 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 62130 \t loss = 0.103, train_acc = 0.900 (3.368 sec/step)\n",
      "step 62140 \t loss = 0.057, train_acc = 1.000 (3.363 sec/step)\n",
      "step 62150 \t loss = 0.023, train_acc = 1.000 (3.325 sec/step)\n",
      "step 62160 \t loss = 0.105, train_acc = 1.000 (3.339 sec/step)\n",
      "step 62170 \t loss = 0.009, train_acc = 1.000 (3.371 sec/step)\n",
      "step 62180 \t loss = 0.025, train_acc = 1.000 (3.329 sec/step)\n",
      "step 62190 \t loss = 0.134, train_acc = 0.900 (3.331 sec/step)\n",
      "step 62200 \t loss = 0.460, train_acc = 0.800 (3.305 sec/step)\n",
      "step 62210 \t loss = 0.117, train_acc = 0.900 (3.327 sec/step)\n",
      "step 62220 \t loss = 0.010, train_acc = 1.000 (3.368 sec/step)\n",
      "step 62230 \t loss = 0.108, train_acc = 1.000 (3.337 sec/step)\n",
      "step 62240 \t loss = 0.004, train_acc = 1.000 (3.302 sec/step)\n",
      "step 62250 \t loss = 0.000, train_acc = 1.000 (3.433 sec/step)\n",
      "step 62260 \t loss = 0.196, train_acc = 0.900 (3.303 sec/step)\n",
      "step 62270 \t loss = 0.001, train_acc = 1.000 (3.400 sec/step)\n",
      "step 62280 \t loss = 0.124, train_acc = 1.000 (3.387 sec/step)\n",
      "step 62290 \t loss = 0.482, train_acc = 0.800 (3.392 sec/step)\n",
      "step 62300 \t loss = 0.004, train_acc = 1.000 (3.296 sec/step)\n",
      "step 62310 \t loss = 0.012, train_acc = 1.000 (3.292 sec/step)\n",
      "step 62320 \t loss = 2.936, train_acc = 0.700 (3.322 sec/step)\n",
      "step 62330 \t loss = 0.108, train_acc = 0.900 (3.318 sec/step)\n",
      "step 62340 \t loss = 0.099, train_acc = 1.000 (3.330 sec/step)\n",
      "step 62350 \t loss = 0.502, train_acc = 0.800 (3.374 sec/step)\n",
      "step 62360 \t loss = 0.261, train_acc = 0.900 (3.394 sec/step)\n",
      "step 62370 \t loss = 1.421, train_acc = 0.800 (3.298 sec/step)\n",
      "step 62380 \t loss = 0.008, train_acc = 1.000 (3.335 sec/step)\n",
      "step 62390 \t loss = 0.107, train_acc = 1.000 (3.481 sec/step)\n",
      "step 62400 \t loss = 0.012, train_acc = 1.000 (3.401 sec/step)\n",
      "step 62410 \t loss = 0.119, train_acc = 1.000 (3.361 sec/step)\n",
      "step 62420 \t loss = 0.032, train_acc = 1.000 (3.367 sec/step)\n",
      "step 62430 \t loss = 0.275, train_acc = 0.900 (3.348 sec/step)\n",
      "step 62440 \t loss = 0.783, train_acc = 0.800 (3.344 sec/step)\n",
      "step 62450 \t loss = 0.259, train_acc = 0.900 (3.429 sec/step)\n",
      "step 62460 \t loss = 0.010, train_acc = 1.000 (3.329 sec/step)\n",
      "step 62470 \t loss = 0.171, train_acc = 0.900 (3.353 sec/step)\n",
      "step 62480 \t loss = 0.065, train_acc = 1.000 (3.352 sec/step)\n",
      "step 62490 \t loss = 0.238, train_acc = 0.900 (3.335 sec/step)\n",
      "step 62500 \t loss = 0.033, train_acc = 1.000 (3.451 sec/step)\n",
      "step 62510 \t loss = 0.110, train_acc = 0.900 (3.322 sec/step)\n",
      "step 62520 \t loss = 0.075, train_acc = 1.000 (3.374 sec/step)\n",
      "step 62530 \t loss = 0.386, train_acc = 0.900 (3.329 sec/step)\n",
      "step 62540 \t loss = 0.048, train_acc = 1.000 (3.344 sec/step)\n",
      "step 62550 \t loss = 0.107, train_acc = 0.900 (3.386 sec/step)\n",
      "step 62560 \t loss = 0.104, train_acc = 1.000 (3.336 sec/step)\n",
      "step 62570 \t loss = 0.005, train_acc = 1.000 (3.307 sec/step)\n",
      "step 62580 \t loss = 0.240, train_acc = 0.800 (3.304 sec/step)\n",
      "step 62590 \t loss = 0.010, train_acc = 1.000 (3.319 sec/step)\n",
      "step 62600 \t loss = 0.114, train_acc = 1.000 (3.375 sec/step)\n",
      "step 62610 \t loss = 0.019, train_acc = 1.000 (3.332 sec/step)\n",
      "step 62620 \t loss = 1.106, train_acc = 0.800 (3.363 sec/step)\n",
      "step 62630 \t loss = 0.047, train_acc = 1.000 (3.383 sec/step)\n",
      "step 62640 \t loss = 0.154, train_acc = 1.000 (3.370 sec/step)\n",
      "step 62650 \t loss = 0.009, train_acc = 1.000 (3.316 sec/step)\n",
      "step 62660 \t loss = 0.217, train_acc = 0.900 (3.337 sec/step)\n",
      "step 62670 \t loss = 0.013, train_acc = 1.000 (3.318 sec/step)\n",
      "step 62680 \t loss = 0.004, train_acc = 1.000 (3.333 sec/step)\n",
      "step 62690 \t loss = 1.417, train_acc = 0.500 (3.293 sec/step)\n",
      "VALIDATION \t acc = 0.532 (3.630 sec)\n",
      "step 62700 \t loss = 0.341, train_acc = 0.900 (3.294 sec/step)\n",
      "step 62710 \t loss = 0.173, train_acc = 0.900 (3.383 sec/step)\n",
      "step 62720 \t loss = 0.000, train_acc = 1.000 (3.322 sec/step)\n",
      "step 62730 \t loss = 0.027, train_acc = 1.000 (3.329 sec/step)\n",
      "step 62740 \t loss = 0.027, train_acc = 1.000 (3.327 sec/step)\n",
      "step 62750 \t loss = 0.108, train_acc = 1.000 (3.326 sec/step)\n",
      "step 62760 \t loss = 0.013, train_acc = 1.000 (3.481 sec/step)\n",
      "step 62770 \t loss = 57.153, train_acc = 0.800 (3.299 sec/step)\n",
      "step 62780 \t loss = 0.101, train_acc = 1.000 (3.380 sec/step)\n",
      "step 62790 \t loss = 1.384, train_acc = 0.900 (3.343 sec/step)\n",
      "step 62800 \t loss = 0.322, train_acc = 0.900 (3.345 sec/step)\n",
      "step 62810 \t loss = 0.143, train_acc = 0.900 (3.339 sec/step)\n",
      "step 62820 \t loss = 0.038, train_acc = 1.000 (3.321 sec/step)\n",
      "step 62830 \t loss = 0.087, train_acc = 0.900 (3.352 sec/step)\n",
      "step 62840 \t loss = 0.997, train_acc = 0.700 (3.330 sec/step)\n",
      "step 62850 \t loss = 0.882, train_acc = 0.900 (3.301 sec/step)\n",
      "step 62860 \t loss = 0.360, train_acc = 0.900 (3.385 sec/step)\n",
      "step 62870 \t loss = 0.017, train_acc = 1.000 (3.327 sec/step)\n",
      "step 62880 \t loss = 1.133, train_acc = 0.900 (3.363 sec/step)\n",
      "step 62890 \t loss = 0.996, train_acc = 0.800 (3.344 sec/step)\n",
      "step 62900 \t loss = 1.042, train_acc = 0.800 (3.332 sec/step)\n",
      "step 62910 \t loss = 0.048, train_acc = 1.000 (3.315 sec/step)\n",
      "step 62920 \t loss = 0.058, train_acc = 1.000 (3.353 sec/step)\n",
      "step 62930 \t loss = 0.210, train_acc = 0.900 (3.339 sec/step)\n",
      "step 62940 \t loss = 0.376, train_acc = 0.900 (3.350 sec/step)\n",
      "step 62950 \t loss = 0.331, train_acc = 0.900 (3.301 sec/step)\n",
      "step 62960 \t loss = 0.002, train_acc = 1.000 (3.429 sec/step)\n",
      "step 62970 \t loss = 0.000, train_acc = 1.000 (3.363 sec/step)\n",
      "step 62980 \t loss = 0.083, train_acc = 1.000 (3.354 sec/step)\n",
      "step 62990 \t loss = 0.002, train_acc = 1.000 (3.387 sec/step)\n",
      "step 63000 \t loss = 0.001, train_acc = 1.000 (3.358 sec/step)\n",
      "step 63010 \t loss = 1.813, train_acc = 0.800 (3.343 sec/step)\n",
      "step 63020 \t loss = 0.385, train_acc = 0.900 (3.304 sec/step)\n",
      "step 63030 \t loss = 0.019, train_acc = 1.000 (3.369 sec/step)\n",
      "step 63040 \t loss = 0.083, train_acc = 1.000 (3.309 sec/step)\n",
      "step 63050 \t loss = 0.028, train_acc = 1.000 (3.326 sec/step)\n",
      "step 63060 \t loss = 0.080, train_acc = 1.000 (3.305 sec/step)\n",
      "step 63070 \t loss = 0.341, train_acc = 0.900 (3.298 sec/step)\n",
      "step 63080 \t loss = 0.002, train_acc = 1.000 (3.396 sec/step)\n",
      "step 63090 \t loss = 0.282, train_acc = 0.900 (3.308 sec/step)\n",
      "step 63100 \t loss = 1.305, train_acc = 0.800 (3.322 sec/step)\n",
      "step 63110 \t loss = 0.446, train_acc = 0.900 (3.369 sec/step)\n",
      "step 63120 \t loss = 0.002, train_acc = 1.000 (3.319 sec/step)\n",
      "step 63130 \t loss = 0.158, train_acc = 1.000 (3.332 sec/step)\n",
      "step 63140 \t loss = 0.497, train_acc = 0.900 (3.328 sec/step)\n",
      "step 63150 \t loss = 0.004, train_acc = 1.000 (3.358 sec/step)\n",
      "step 63160 \t loss = 0.003, train_acc = 1.000 (3.381 sec/step)\n",
      "step 63170 \t loss = 0.006, train_acc = 1.000 (3.388 sec/step)\n",
      "step 63180 \t loss = 0.171, train_acc = 0.900 (3.341 sec/step)\n",
      "step 63190 \t loss = 0.062, train_acc = 1.000 (3.331 sec/step)\n",
      "step 63200 \t loss = 0.568, train_acc = 0.800 (3.379 sec/step)\n",
      "step 63210 \t loss = 0.001, train_acc = 1.000 (3.351 sec/step)\n",
      "step 63220 \t loss = 0.047, train_acc = 1.000 (3.354 sec/step)\n",
      "step 63230 \t loss = 0.356, train_acc = 0.900 (3.334 sec/step)\n",
      "step 63240 \t loss = 0.013, train_acc = 1.000 (3.377 sec/step)\n",
      "step 63250 \t loss = 0.009, train_acc = 1.000 (3.296 sec/step)\n",
      "step 63260 \t loss = 0.001, train_acc = 1.000 (3.321 sec/step)\n",
      "step 63270 \t loss = 0.083, train_acc = 0.900 (3.344 sec/step)\n",
      "step 63280 \t loss = 0.022, train_acc = 1.000 (3.305 sec/step)\n",
      "step 63290 \t loss = 0.050, train_acc = 1.000 (3.301 sec/step)\n",
      "step 63300 \t loss = 0.289, train_acc = 0.900 (3.333 sec/step)\n",
      "step 63310 \t loss = 0.042, train_acc = 1.000 (3.361 sec/step)\n",
      "step 63320 \t loss = 0.004, train_acc = 1.000 (3.339 sec/step)\n",
      "step 63330 \t loss = 0.293, train_acc = 0.900 (3.326 sec/step)\n",
      "step 63340 \t loss = 0.040, train_acc = 1.000 (3.352 sec/step)\n",
      "step 63350 \t loss = 1.088, train_acc = 0.900 (3.352 sec/step)\n",
      "step 63360 \t loss = 1.159, train_acc = 0.800 (3.368 sec/step)\n",
      "step 63370 \t loss = 1.595, train_acc = 0.800 (3.305 sec/step)\n",
      "step 63380 \t loss = 0.000, train_acc = 1.000 (3.408 sec/step)\n",
      "step 63390 \t loss = 0.481, train_acc = 0.800 (3.427 sec/step)\n",
      "step 63400 \t loss = 0.873, train_acc = 0.900 (3.309 sec/step)\n",
      "step 63410 \t loss = 0.389, train_acc = 0.800 (3.318 sec/step)\n",
      "step 63420 \t loss = 0.003, train_acc = 1.000 (3.392 sec/step)\n",
      "step 63430 \t loss = 0.373, train_acc = 0.900 (3.344 sec/step)\n",
      "step 63440 \t loss = 0.005, train_acc = 1.000 (3.361 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 63450 \t loss = 0.077, train_acc = 1.000 (3.317 sec/step)\n",
      "step 63460 \t loss = 0.041, train_acc = 1.000 (3.337 sec/step)\n",
      "step 63470 \t loss = 0.434, train_acc = 0.900 (3.341 sec/step)\n",
      "step 63480 \t loss = 0.794, train_acc = 0.600 (3.368 sec/step)\n",
      "step 63490 \t loss = 0.162, train_acc = 0.900 (3.337 sec/step)\n",
      "step 63500 \t loss = 0.737, train_acc = 0.900 (3.302 sec/step)\n",
      "step 63510 \t loss = 0.177, train_acc = 1.000 (3.366 sec/step)\n",
      "step 63520 \t loss = 0.114, train_acc = 0.900 (3.312 sec/step)\n",
      "step 63530 \t loss = 0.006, train_acc = 1.000 (3.339 sec/step)\n",
      "step 63540 \t loss = 0.018, train_acc = 1.000 (3.316 sec/step)\n",
      "step 63550 \t loss = 0.067, train_acc = 1.000 (3.336 sec/step)\n",
      "step 63560 \t loss = 0.043, train_acc = 1.000 (3.408 sec/step)\n",
      "step 63570 \t loss = 0.113, train_acc = 0.900 (3.393 sec/step)\n",
      "step 63580 \t loss = 0.053, train_acc = 1.000 (3.314 sec/step)\n",
      "step 63590 \t loss = 0.190, train_acc = 0.900 (3.395 sec/step)\n",
      "step 63600 \t loss = 0.074, train_acc = 1.000 (3.470 sec/step)\n",
      "step 63610 \t loss = 0.408, train_acc = 0.800 (3.346 sec/step)\n",
      "step 63620 \t loss = 0.106, train_acc = 1.000 (3.391 sec/step)\n",
      "step 63630 \t loss = 0.061, train_acc = 1.000 (3.362 sec/step)\n",
      "step 63640 \t loss = 0.651, train_acc = 0.900 (3.356 sec/step)\n",
      "step 63650 \t loss = 0.605, train_acc = 0.900 (3.346 sec/step)\n",
      "step 63660 \t loss = 0.002, train_acc = 1.000 (3.344 sec/step)\n",
      "step 63670 \t loss = 0.224, train_acc = 0.900 (3.368 sec/step)\n",
      "step 63680 \t loss = 0.009, train_acc = 1.000 (3.406 sec/step)\n",
      "step 63690 \t loss = 0.176, train_acc = 0.900 (3.374 sec/step)\n",
      "step 63700 \t loss = 0.093, train_acc = 1.000 (3.397 sec/step)\n",
      "step 63710 \t loss = 0.518, train_acc = 0.800 (3.336 sec/step)\n",
      "step 63720 \t loss = 0.058, train_acc = 1.000 (3.325 sec/step)\n",
      "step 63730 \t loss = 0.067, train_acc = 1.000 (3.315 sec/step)\n",
      "step 63740 \t loss = 0.028, train_acc = 1.000 (3.312 sec/step)\n",
      "step 63750 \t loss = 0.001, train_acc = 1.000 (3.372 sec/step)\n",
      "step 63760 \t loss = 0.002, train_acc = 1.000 (3.305 sec/step)\n",
      "step 63770 \t loss = 1.677, train_acc = 0.900 (3.306 sec/step)\n",
      "step 63780 \t loss = 0.316, train_acc = 0.900 (3.325 sec/step)\n",
      "step 63790 \t loss = 0.123, train_acc = 0.900 (3.331 sec/step)\n",
      "step 63800 \t loss = 0.108, train_acc = 1.000 (3.336 sec/step)\n",
      "step 63810 \t loss = 0.024, train_acc = 1.000 (3.347 sec/step)\n",
      "step 63820 \t loss = 0.111, train_acc = 1.000 (3.307 sec/step)\n",
      "step 63830 \t loss = 0.055, train_acc = 1.000 (3.386 sec/step)\n",
      "step 63840 \t loss = 0.941, train_acc = 0.900 (3.341 sec/step)\n",
      "step 63850 \t loss = 0.017, train_acc = 1.000 (3.327 sec/step)\n",
      "step 63860 \t loss = 0.046, train_acc = 1.000 (3.383 sec/step)\n",
      "step 63870 \t loss = 0.010, train_acc = 1.000 (3.302 sec/step)\n",
      "step 63880 \t loss = 0.006, train_acc = 1.000 (3.297 sec/step)\n",
      "step 63890 \t loss = 0.023, train_acc = 1.000 (3.375 sec/step)\n",
      "step 63900 \t loss = 0.788, train_acc = 0.800 (3.329 sec/step)\n",
      "step 63910 \t loss = 0.594, train_acc = 0.900 (3.325 sec/step)\n",
      "step 63920 \t loss = 0.336, train_acc = 0.900 (3.327 sec/step)\n",
      "step 63930 \t loss = 0.113, train_acc = 0.900 (3.337 sec/step)\n",
      "step 63940 \t loss = 0.008, train_acc = 1.000 (3.364 sec/step)\n",
      "step 63950 \t loss = 0.134, train_acc = 1.000 (3.525 sec/step)\n",
      "step 63960 \t loss = 0.103, train_acc = 1.000 (3.320 sec/step)\n",
      "step 63970 \t loss = 0.561, train_acc = 0.800 (3.296 sec/step)\n",
      "step 63980 \t loss = 0.208, train_acc = 0.800 (3.333 sec/step)\n",
      "step 63990 \t loss = 0.000, train_acc = 1.000 (3.366 sec/step)\n",
      "step 64000 \t loss = 0.152, train_acc = 0.900 (3.348 sec/step)\n",
      "step 64010 \t loss = 0.436, train_acc = 0.800 (3.362 sec/step)\n",
      "step 64020 \t loss = 0.539, train_acc = 0.800 (3.331 sec/step)\n",
      "step 64030 \t loss = 0.085, train_acc = 1.000 (3.486 sec/step)\n",
      "step 64040 \t loss = 0.006, train_acc = 1.000 (3.377 sec/step)\n",
      "step 64050 \t loss = 0.141, train_acc = 1.000 (3.371 sec/step)\n",
      "step 64060 \t loss = 0.013, train_acc = 1.000 (3.365 sec/step)\n",
      "step 64070 \t loss = 0.174, train_acc = 0.900 (3.375 sec/step)\n",
      "step 64080 \t loss = 0.024, train_acc = 1.000 (3.378 sec/step)\n",
      "step 64090 \t loss = 0.882, train_acc = 0.700 (3.292 sec/step)\n",
      "step 64100 \t loss = 0.037, train_acc = 1.000 (3.374 sec/step)\n",
      "step 64110 \t loss = 0.007, train_acc = 1.000 (3.303 sec/step)\n",
      "step 64120 \t loss = 0.046, train_acc = 1.000 (3.314 sec/step)\n",
      "step 64130 \t loss = 0.636, train_acc = 0.900 (3.345 sec/step)\n",
      "step 64140 \t loss = 0.003, train_acc = 1.000 (3.331 sec/step)\n",
      "step 64150 \t loss = 0.007, train_acc = 1.000 (3.339 sec/step)\n",
      "step 64160 \t loss = 0.012, train_acc = 1.000 (3.346 sec/step)\n",
      "step 64170 \t loss = 0.395, train_acc = 0.800 (3.357 sec/step)\n",
      "step 64180 \t loss = 0.231, train_acc = 1.000 (3.305 sec/step)\n",
      "step 64190 \t loss = 0.008, train_acc = 1.000 (3.336 sec/step)\n",
      "step 64200 \t loss = 0.305, train_acc = 0.900 (3.315 sec/step)\n",
      "step 64210 \t loss = 0.303, train_acc = 0.900 (3.311 sec/step)\n",
      "step 64220 \t loss = 0.324, train_acc = 0.900 (3.367 sec/step)\n",
      "step 64230 \t loss = 0.072, train_acc = 1.000 (3.381 sec/step)\n",
      "step 64240 \t loss = 0.160, train_acc = 0.900 (3.376 sec/step)\n",
      "step 64250 \t loss = 0.002, train_acc = 1.000 (3.381 sec/step)\n",
      "step 64260 \t loss = 0.008, train_acc = 1.000 (3.372 sec/step)\n",
      "step 64270 \t loss = 0.128, train_acc = 0.900 (3.358 sec/step)\n",
      "step 64280 \t loss = 0.010, train_acc = 1.000 (3.352 sec/step)\n",
      "step 64290 \t loss = 0.370, train_acc = 0.900 (3.320 sec/step)\n",
      "step 64300 \t loss = 0.012, train_acc = 1.000 (3.407 sec/step)\n",
      "step 64310 \t loss = 0.412, train_acc = 0.800 (3.320 sec/step)\n",
      "step 64320 \t loss = 0.010, train_acc = 1.000 (3.319 sec/step)\n",
      "step 64330 \t loss = 0.461, train_acc = 0.800 (3.331 sec/step)\n",
      "step 64340 \t loss = 0.429, train_acc = 0.800 (3.324 sec/step)\n",
      "step 64350 \t loss = 0.015, train_acc = 1.000 (3.363 sec/step)\n",
      "step 64360 \t loss = 0.242, train_acc = 0.800 (3.315 sec/step)\n",
      "step 64370 \t loss = 0.279, train_acc = 0.900 (3.354 sec/step)\n",
      "step 64380 \t loss = 0.228, train_acc = 0.900 (3.384 sec/step)\n",
      "step 64390 \t loss = 0.005, train_acc = 1.000 (3.409 sec/step)\n",
      "step 64400 \t loss = 0.054, train_acc = 1.000 (3.370 sec/step)\n",
      "step 64410 \t loss = 0.090, train_acc = 0.900 (3.357 sec/step)\n",
      "step 64420 \t loss = 0.029, train_acc = 1.000 (3.367 sec/step)\n",
      "step 64430 \t loss = 0.144, train_acc = 0.900 (3.324 sec/step)\n",
      "step 64440 \t loss = 0.246, train_acc = 0.800 (3.387 sec/step)\n",
      "step 64450 \t loss = 0.033, train_acc = 1.000 (3.295 sec/step)\n",
      "step 64460 \t loss = 0.024, train_acc = 1.000 (3.341 sec/step)\n",
      "step 64470 \t loss = 0.001, train_acc = 1.000 (3.385 sec/step)\n",
      "step 64480 \t loss = 0.013, train_acc = 1.000 (3.299 sec/step)\n",
      "step 64490 \t loss = 0.000, train_acc = 1.000 (3.385 sec/step)\n",
      "step 64500 \t loss = 0.001, train_acc = 1.000 (3.346 sec/step)\n",
      "step 64510 \t loss = 0.026, train_acc = 1.000 (3.332 sec/step)\n",
      "step 64520 \t loss = 0.910, train_acc = 0.800 (3.309 sec/step)\n",
      "step 64530 \t loss = 1.037, train_acc = 0.700 (3.321 sec/step)\n",
      "step 64540 \t loss = 0.187, train_acc = 1.000 (3.360 sec/step)\n",
      "step 64550 \t loss = 0.020, train_acc = 1.000 (3.387 sec/step)\n",
      "step 64560 \t loss = 0.045, train_acc = 1.000 (3.391 sec/step)\n",
      "step 64570 \t loss = 0.248, train_acc = 0.900 (3.305 sec/step)\n",
      "step 64580 \t loss = 0.357, train_acc = 0.900 (3.398 sec/step)\n",
      "step 64590 \t loss = 0.008, train_acc = 1.000 (3.384 sec/step)\n",
      "VALIDATION \t acc = 0.565 (3.652 sec)\n",
      "New Best Accuracy 0.565 > Old Best 0.563.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 64600 \t loss = 1.461, train_acc = 0.800 (3.366 sec/step)\n",
      "step 64610 \t loss = 0.018, train_acc = 1.000 (3.394 sec/step)\n",
      "step 64620 \t loss = 0.458, train_acc = 0.800 (3.351 sec/step)\n",
      "step 64630 \t loss = 0.754, train_acc = 0.900 (3.353 sec/step)\n",
      "step 64640 \t loss = 0.007, train_acc = 1.000 (3.329 sec/step)\n",
      "step 64650 \t loss = 0.247, train_acc = 0.900 (3.343 sec/step)\n",
      "step 64660 \t loss = 0.001, train_acc = 1.000 (3.308 sec/step)\n",
      "step 64670 \t loss = 0.060, train_acc = 1.000 (3.351 sec/step)\n",
      "step 64680 \t loss = 0.201, train_acc = 0.900 (3.376 sec/step)\n",
      "step 64690 \t loss = 0.532, train_acc = 0.900 (3.286 sec/step)\n",
      "step 64700 \t loss = 0.003, train_acc = 1.000 (3.373 sec/step)\n",
      "step 64710 \t loss = 0.000, train_acc = 1.000 (3.360 sec/step)\n",
      "step 64720 \t loss = 2.202, train_acc = 0.900 (3.358 sec/step)\n",
      "step 64730 \t loss = 0.201, train_acc = 0.900 (3.308 sec/step)\n",
      "step 64740 \t loss = 0.030, train_acc = 1.000 (3.293 sec/step)\n",
      "step 64750 \t loss = 0.633, train_acc = 0.900 (3.370 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 64760 \t loss = 0.627, train_acc = 0.900 (3.348 sec/step)\n",
      "step 64770 \t loss = 0.113, train_acc = 1.000 (3.380 sec/step)\n",
      "step 64780 \t loss = 0.077, train_acc = 1.000 (3.343 sec/step)\n",
      "step 64790 \t loss = 0.037, train_acc = 1.000 (3.307 sec/step)\n",
      "step 64800 \t loss = 0.141, train_acc = 1.000 (3.328 sec/step)\n",
      "step 64810 \t loss = 0.030, train_acc = 1.000 (3.292 sec/step)\n",
      "step 64820 \t loss = 0.031, train_acc = 1.000 (3.328 sec/step)\n",
      "step 64830 \t loss = 0.010, train_acc = 1.000 (3.301 sec/step)\n",
      "step 64840 \t loss = 0.422, train_acc = 0.900 (3.350 sec/step)\n",
      "step 64850 \t loss = 0.712, train_acc = 0.800 (3.366 sec/step)\n",
      "step 64860 \t loss = 0.008, train_acc = 1.000 (3.368 sec/step)\n",
      "step 64870 \t loss = 0.007, train_acc = 1.000 (3.321 sec/step)\n",
      "step 64880 \t loss = 0.000, train_acc = 1.000 (3.351 sec/step)\n",
      "step 64890 \t loss = 0.400, train_acc = 0.900 (3.326 sec/step)\n",
      "step 64900 \t loss = 0.100, train_acc = 0.900 (3.305 sec/step)\n",
      "step 64910 \t loss = 0.214, train_acc = 0.900 (3.353 sec/step)\n",
      "step 64920 \t loss = 0.101, train_acc = 0.900 (3.356 sec/step)\n",
      "step 64930 \t loss = 0.019, train_acc = 1.000 (3.376 sec/step)\n",
      "step 64940 \t loss = 0.077, train_acc = 1.000 (3.325 sec/step)\n",
      "step 64950 \t loss = 0.354, train_acc = 0.900 (3.354 sec/step)\n",
      "step 64960 \t loss = 0.534, train_acc = 0.800 (3.418 sec/step)\n",
      "step 64970 \t loss = 0.348, train_acc = 0.900 (3.354 sec/step)\n",
      "step 64980 \t loss = 0.640, train_acc = 0.900 (3.342 sec/step)\n",
      "step 64990 \t loss = 0.570, train_acc = 0.900 (3.333 sec/step)\n",
      "step 65000 \t loss = 0.061, train_acc = 1.000 (3.302 sec/step)\n",
      "step 65010 \t loss = 0.590, train_acc = 0.900 (3.316 sec/step)\n",
      "step 65020 \t loss = 0.254, train_acc = 0.900 (3.359 sec/step)\n",
      "step 65030 \t loss = 0.083, train_acc = 1.000 (3.377 sec/step)\n",
      "step 65040 \t loss = 0.330, train_acc = 0.900 (3.339 sec/step)\n",
      "step 65050 \t loss = 0.107, train_acc = 0.900 (3.299 sec/step)\n",
      "step 65060 \t loss = 0.007, train_acc = 1.000 (3.392 sec/step)\n",
      "step 65070 \t loss = 0.003, train_acc = 1.000 (3.313 sec/step)\n",
      "step 65080 \t loss = 0.003, train_acc = 1.000 (3.304 sec/step)\n",
      "step 65090 \t loss = 0.396, train_acc = 0.800 (3.325 sec/step)\n",
      "step 65100 \t loss = 0.014, train_acc = 1.000 (3.324 sec/step)\n",
      "step 65110 \t loss = 0.134, train_acc = 0.900 (3.318 sec/step)\n",
      "step 65120 \t loss = 0.113, train_acc = 0.900 (3.315 sec/step)\n",
      "step 65130 \t loss = 0.323, train_acc = 0.900 (3.334 sec/step)\n",
      "step 65140 \t loss = 0.021, train_acc = 1.000 (3.356 sec/step)\n",
      "step 65150 \t loss = 0.000, train_acc = 1.000 (3.311 sec/step)\n",
      "step 65160 \t loss = 0.000, train_acc = 1.000 (3.321 sec/step)\n",
      "step 65170 \t loss = 0.014, train_acc = 1.000 (3.316 sec/step)\n",
      "step 65180 \t loss = 0.374, train_acc = 0.900 (3.367 sec/step)\n",
      "step 65190 \t loss = 0.003, train_acc = 1.000 (3.339 sec/step)\n",
      "step 65200 \t loss = 0.057, train_acc = 1.000 (3.400 sec/step)\n",
      "step 65210 \t loss = 0.145, train_acc = 0.900 (3.295 sec/step)\n",
      "step 65220 \t loss = 0.188, train_acc = 1.000 (3.325 sec/step)\n",
      "step 65230 \t loss = 0.245, train_acc = 0.900 (3.314 sec/step)\n",
      "step 65240 \t loss = 0.054, train_acc = 1.000 (3.315 sec/step)\n",
      "step 65250 \t loss = 0.003, train_acc = 1.000 (3.369 sec/step)\n",
      "step 65260 \t loss = 1.461, train_acc = 0.700 (3.331 sec/step)\n",
      "step 65270 \t loss = 0.029, train_acc = 1.000 (3.367 sec/step)\n",
      "step 65280 \t loss = 0.885, train_acc = 0.900 (3.384 sec/step)\n",
      "step 65290 \t loss = 0.038, train_acc = 1.000 (3.333 sec/step)\n",
      "step 65300 \t loss = 0.003, train_acc = 1.000 (3.327 sec/step)\n",
      "step 65310 \t loss = 0.097, train_acc = 0.900 (3.418 sec/step)\n",
      "step 65320 \t loss = 1.101, train_acc = 0.700 (3.329 sec/step)\n",
      "step 65330 \t loss = 0.004, train_acc = 1.000 (3.360 sec/step)\n",
      "step 65340 \t loss = 0.016, train_acc = 1.000 (3.374 sec/step)\n",
      "step 65350 \t loss = 0.003, train_acc = 1.000 (3.374 sec/step)\n",
      "step 65360 \t loss = 0.231, train_acc = 0.900 (3.376 sec/step)\n",
      "step 65370 \t loss = 0.338, train_acc = 0.800 (3.338 sec/step)\n",
      "step 65380 \t loss = 0.006, train_acc = 1.000 (3.357 sec/step)\n",
      "step 65390 \t loss = 0.024, train_acc = 1.000 (3.363 sec/step)\n",
      "step 65400 \t loss = 0.235, train_acc = 0.900 (3.327 sec/step)\n",
      "step 65410 \t loss = 0.000, train_acc = 1.000 (3.363 sec/step)\n",
      "step 65420 \t loss = 0.896, train_acc = 0.900 (3.326 sec/step)\n",
      "step 65430 \t loss = 0.140, train_acc = 0.900 (3.334 sec/step)\n",
      "step 65440 \t loss = 0.002, train_acc = 1.000 (3.368 sec/step)\n",
      "step 65450 \t loss = 0.325, train_acc = 0.900 (3.316 sec/step)\n",
      "step 65460 \t loss = 0.003, train_acc = 1.000 (3.350 sec/step)\n",
      "step 65470 \t loss = 0.133, train_acc = 0.900 (3.350 sec/step)\n",
      "step 65480 \t loss = 0.003, train_acc = 1.000 (3.377 sec/step)\n",
      "step 65490 \t loss = 0.517, train_acc = 0.800 (3.310 sec/step)\n",
      "step 65500 \t loss = 0.002, train_acc = 1.000 (3.331 sec/step)\n",
      "step 65510 \t loss = 0.024, train_acc = 1.000 (3.316 sec/step)\n",
      "step 65520 \t loss = 0.119, train_acc = 0.900 (3.303 sec/step)\n",
      "step 65530 \t loss = 0.322, train_acc = 0.900 (3.321 sec/step)\n",
      "step 65540 \t loss = 0.288, train_acc = 0.900 (3.285 sec/step)\n",
      "step 65550 \t loss = 0.418, train_acc = 0.900 (3.314 sec/step)\n",
      "step 65560 \t loss = 0.000, train_acc = 1.000 (3.287 sec/step)\n",
      "step 65570 \t loss = 0.004, train_acc = 1.000 (3.354 sec/step)\n",
      "step 65580 \t loss = 0.064, train_acc = 1.000 (3.323 sec/step)\n",
      "step 65590 \t loss = 0.036, train_acc = 1.000 (3.315 sec/step)\n",
      "step 65600 \t loss = 0.734, train_acc = 0.900 (3.325 sec/step)\n",
      "step 65610 \t loss = 0.094, train_acc = 1.000 (3.335 sec/step)\n",
      "step 65620 \t loss = 0.007, train_acc = 1.000 (3.381 sec/step)\n",
      "step 65630 \t loss = 0.193, train_acc = 0.900 (3.316 sec/step)\n",
      "step 65640 \t loss = 0.013, train_acc = 1.000 (3.362 sec/step)\n",
      "step 65650 \t loss = 0.599, train_acc = 0.800 (3.319 sec/step)\n",
      "step 65660 \t loss = 0.397, train_acc = 0.900 (3.386 sec/step)\n",
      "step 65670 \t loss = 0.057, train_acc = 1.000 (3.366 sec/step)\n",
      "step 65680 \t loss = 0.008, train_acc = 1.000 (3.309 sec/step)\n",
      "step 65690 \t loss = 3.145, train_acc = 0.900 (3.349 sec/step)\n",
      "step 65700 \t loss = 0.059, train_acc = 1.000 (3.310 sec/step)\n",
      "step 65710 \t loss = 0.024, train_acc = 1.000 (3.396 sec/step)\n",
      "step 65720 \t loss = 0.011, train_acc = 1.000 (3.366 sec/step)\n",
      "step 65730 \t loss = 0.072, train_acc = 1.000 (3.304 sec/step)\n",
      "step 65740 \t loss = 0.885, train_acc = 0.800 (3.329 sec/step)\n",
      "step 65750 \t loss = 0.323, train_acc = 0.900 (3.302 sec/step)\n",
      "step 65760 \t loss = 0.453, train_acc = 0.900 (3.317 sec/step)\n",
      "step 65770 \t loss = 0.018, train_acc = 1.000 (3.313 sec/step)\n",
      "step 65780 \t loss = 0.032, train_acc = 1.000 (3.350 sec/step)\n",
      "step 65790 \t loss = 0.786, train_acc = 0.900 (3.348 sec/step)\n",
      "step 65800 \t loss = 0.032, train_acc = 1.000 (3.350 sec/step)\n",
      "step 65810 \t loss = 0.022, train_acc = 1.000 (3.395 sec/step)\n",
      "step 65820 \t loss = 0.019, train_acc = 1.000 (3.348 sec/step)\n",
      "step 65830 \t loss = 0.001, train_acc = 1.000 (3.367 sec/step)\n",
      "step 65840 \t loss = 0.238, train_acc = 0.900 (3.303 sec/step)\n",
      "step 65850 \t loss = 0.159, train_acc = 0.900 (3.471 sec/step)\n",
      "step 65860 \t loss = 0.129, train_acc = 1.000 (3.299 sec/step)\n",
      "step 65870 \t loss = 0.357, train_acc = 0.800 (3.338 sec/step)\n",
      "step 65880 \t loss = 0.002, train_acc = 1.000 (3.288 sec/step)\n",
      "step 65890 \t loss = 0.039, train_acc = 1.000 (3.369 sec/step)\n",
      "step 65900 \t loss = 0.000, train_acc = 1.000 (3.316 sec/step)\n",
      "step 65910 \t loss = 0.032, train_acc = 1.000 (3.354 sec/step)\n",
      "step 65920 \t loss = 0.017, train_acc = 1.000 (3.316 sec/step)\n",
      "step 65930 \t loss = 0.304, train_acc = 0.900 (3.300 sec/step)\n",
      "step 65940 \t loss = 0.225, train_acc = 0.900 (3.307 sec/step)\n",
      "step 65950 \t loss = 0.011, train_acc = 1.000 (3.325 sec/step)\n",
      "step 65960 \t loss = 0.410, train_acc = 0.800 (3.380 sec/step)\n",
      "step 65970 \t loss = 0.001, train_acc = 1.000 (3.319 sec/step)\n",
      "step 65980 \t loss = 0.497, train_acc = 0.800 (3.320 sec/step)\n",
      "step 65990 \t loss = 0.770, train_acc = 0.800 (3.321 sec/step)\n",
      "step 66000 \t loss = 0.002, train_acc = 1.000 (3.352 sec/step)\n",
      "step 66010 \t loss = 1.430, train_acc = 0.900 (3.299 sec/step)\n",
      "step 66020 \t loss = 0.492, train_acc = 0.900 (3.360 sec/step)\n",
      "step 66030 \t loss = 0.058, train_acc = 1.000 (3.346 sec/step)\n",
      "step 66040 \t loss = 0.062, train_acc = 1.000 (3.304 sec/step)\n",
      "step 66050 \t loss = 0.145, train_acc = 0.900 (3.353 sec/step)\n",
      "step 66060 \t loss = 0.007, train_acc = 1.000 (3.305 sec/step)\n",
      "step 66070 \t loss = 0.970, train_acc = 0.900 (3.364 sec/step)\n",
      "step 66080 \t loss = 0.092, train_acc = 1.000 (3.314 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 66090 \t loss = 0.003, train_acc = 1.000 (3.338 sec/step)\n",
      "step 66100 \t loss = 0.000, train_acc = 1.000 (3.345 sec/step)\n",
      "step 66110 \t loss = 0.024, train_acc = 1.000 (3.351 sec/step)\n",
      "step 66120 \t loss = 0.089, train_acc = 1.000 (3.344 sec/step)\n",
      "step 66130 \t loss = 0.410, train_acc = 0.900 (3.363 sec/step)\n",
      "step 66140 \t loss = 0.055, train_acc = 1.000 (3.309 sec/step)\n",
      "step 66150 \t loss = 2.566, train_acc = 0.800 (3.354 sec/step)\n",
      "step 66160 \t loss = 0.003, train_acc = 1.000 (3.328 sec/step)\n",
      "step 66170 \t loss = 0.016, train_acc = 1.000 (3.376 sec/step)\n",
      "step 66180 \t loss = 0.210, train_acc = 0.900 (3.300 sec/step)\n",
      "step 66190 \t loss = 0.021, train_acc = 1.000 (3.385 sec/step)\n",
      "step 66200 \t loss = 1.411, train_acc = 0.800 (3.391 sec/step)\n",
      "step 66210 \t loss = 0.083, train_acc = 1.000 (3.369 sec/step)\n",
      "step 66220 \t loss = 0.001, train_acc = 1.000 (3.443 sec/step)\n",
      "step 66230 \t loss = 0.021, train_acc = 1.000 (3.316 sec/step)\n",
      "step 66240 \t loss = 0.109, train_acc = 0.900 (3.326 sec/step)\n",
      "step 66250 \t loss = 0.071, train_acc = 1.000 (3.309 sec/step)\n",
      "step 66260 \t loss = 0.107, train_acc = 1.000 (3.320 sec/step)\n",
      "step 66270 \t loss = 2.036, train_acc = 0.700 (3.337 sec/step)\n",
      "step 66280 \t loss = 0.055, train_acc = 1.000 (3.355 sec/step)\n",
      "step 66290 \t loss = 0.032, train_acc = 1.000 (3.373 sec/step)\n",
      "step 66300 \t loss = 0.000, train_acc = 1.000 (3.336 sec/step)\n",
      "step 66310 \t loss = 0.000, train_acc = 1.000 (3.320 sec/step)\n",
      "step 66320 \t loss = 0.808, train_acc = 0.800 (3.340 sec/step)\n",
      "step 66330 \t loss = 0.002, train_acc = 1.000 (3.387 sec/step)\n",
      "step 66340 \t loss = 0.104, train_acc = 1.000 (3.370 sec/step)\n",
      "step 66350 \t loss = 0.288, train_acc = 0.900 (3.321 sec/step)\n",
      "step 66360 \t loss = 0.326, train_acc = 0.900 (3.315 sec/step)\n",
      "step 66370 \t loss = 0.375, train_acc = 0.900 (3.309 sec/step)\n",
      "step 66380 \t loss = 0.108, train_acc = 1.000 (3.346 sec/step)\n",
      "step 66390 \t loss = 0.126, train_acc = 1.000 (3.347 sec/step)\n",
      "step 66400 \t loss = 0.024, train_acc = 1.000 (3.323 sec/step)\n",
      "step 66410 \t loss = 0.024, train_acc = 1.000 (3.339 sec/step)\n",
      "step 66420 \t loss = 0.001, train_acc = 1.000 (3.382 sec/step)\n",
      "step 66430 \t loss = 0.027, train_acc = 1.000 (3.349 sec/step)\n",
      "step 66440 \t loss = 0.032, train_acc = 1.000 (3.411 sec/step)\n",
      "step 66450 \t loss = 1.278, train_acc = 0.900 (3.335 sec/step)\n",
      "step 66460 \t loss = 0.264, train_acc = 0.900 (3.368 sec/step)\n",
      "step 66470 \t loss = 0.008, train_acc = 1.000 (3.322 sec/step)\n",
      "step 66480 \t loss = 0.453, train_acc = 0.900 (3.339 sec/step)\n",
      "step 66490 \t loss = 0.259, train_acc = 0.900 (3.305 sec/step)\n",
      "VALIDATION \t acc = 0.549 (3.668 sec)\n",
      "step 66500 \t loss = 0.153, train_acc = 0.900 (3.321 sec/step)\n",
      "step 66510 \t loss = 0.005, train_acc = 1.000 (3.325 sec/step)\n",
      "step 66520 \t loss = 0.061, train_acc = 1.000 (3.333 sec/step)\n",
      "step 66530 \t loss = 0.149, train_acc = 0.900 (3.313 sec/step)\n",
      "step 66540 \t loss = 0.026, train_acc = 1.000 (3.392 sec/step)\n",
      "step 66550 \t loss = 0.180, train_acc = 0.900 (3.356 sec/step)\n",
      "step 66560 \t loss = 0.547, train_acc = 0.800 (3.412 sec/step)\n",
      "step 66570 \t loss = 0.042, train_acc = 1.000 (3.382 sec/step)\n",
      "step 66580 \t loss = 0.001, train_acc = 1.000 (3.328 sec/step)\n",
      "step 66590 \t loss = 0.103, train_acc = 1.000 (3.339 sec/step)\n",
      "step 66600 \t loss = 0.103, train_acc = 0.900 (3.335 sec/step)\n",
      "step 66610 \t loss = 0.570, train_acc = 0.900 (3.391 sec/step)\n",
      "step 66620 \t loss = 0.334, train_acc = 0.900 (3.346 sec/step)\n",
      "step 66630 \t loss = 0.014, train_acc = 1.000 (3.356 sec/step)\n",
      "step 66640 \t loss = 0.188, train_acc = 0.900 (3.325 sec/step)\n",
      "step 66650 \t loss = 0.100, train_acc = 1.000 (3.307 sec/step)\n",
      "step 66660 \t loss = 0.102, train_acc = 1.000 (3.306 sec/step)\n",
      "step 66670 \t loss = 0.076, train_acc = 1.000 (3.363 sec/step)\n",
      "step 66680 \t loss = 0.011, train_acc = 1.000 (3.352 sec/step)\n",
      "step 66690 \t loss = 0.004, train_acc = 1.000 (3.378 sec/step)\n",
      "step 66700 \t loss = 0.050, train_acc = 1.000 (3.341 sec/step)\n",
      "step 66710 \t loss = 0.387, train_acc = 0.900 (3.353 sec/step)\n",
      "step 66720 \t loss = 0.018, train_acc = 1.000 (3.386 sec/step)\n",
      "step 66730 \t loss = 0.281, train_acc = 0.900 (3.314 sec/step)\n",
      "step 66740 \t loss = 0.462, train_acc = 0.800 (3.315 sec/step)\n",
      "step 66750 \t loss = 0.002, train_acc = 1.000 (3.297 sec/step)\n",
      "step 66760 \t loss = 0.006, train_acc = 1.000 (3.322 sec/step)\n",
      "step 66770 \t loss = 0.097, train_acc = 0.900 (3.341 sec/step)\n",
      "step 66780 \t loss = 0.000, train_acc = 1.000 (3.382 sec/step)\n",
      "step 66790 \t loss = 0.000, train_acc = 1.000 (3.339 sec/step)\n",
      "step 66800 \t loss = 0.202, train_acc = 0.900 (3.345 sec/step)\n",
      "step 66810 \t loss = 0.395, train_acc = 0.900 (3.383 sec/step)\n",
      "step 66820 \t loss = 0.070, train_acc = 1.000 (3.431 sec/step)\n",
      "step 66830 \t loss = 0.030, train_acc = 1.000 (3.319 sec/step)\n",
      "step 66840 \t loss = 0.048, train_acc = 1.000 (3.303 sec/step)\n",
      "step 66850 \t loss = 0.572, train_acc = 0.900 (3.342 sec/step)\n",
      "step 66860 \t loss = 0.575, train_acc = 0.900 (3.334 sec/step)\n",
      "step 66870 \t loss = 0.028, train_acc = 1.000 (3.327 sec/step)\n",
      "step 66880 \t loss = 0.040, train_acc = 1.000 (3.329 sec/step)\n",
      "step 66890 \t loss = 0.001, train_acc = 1.000 (3.298 sec/step)\n",
      "step 66900 \t loss = 0.017, train_acc = 1.000 (3.388 sec/step)\n",
      "step 66910 \t loss = 0.003, train_acc = 1.000 (3.351 sec/step)\n",
      "step 66920 \t loss = 1.072, train_acc = 0.900 (3.377 sec/step)\n",
      "step 66930 \t loss = 0.037, train_acc = 1.000 (3.364 sec/step)\n",
      "step 66940 \t loss = 0.005, train_acc = 1.000 (3.314 sec/step)\n",
      "step 66950 \t loss = 0.282, train_acc = 0.800 (3.331 sec/step)\n",
      "step 66960 \t loss = 0.362, train_acc = 0.900 (3.382 sec/step)\n",
      "step 66970 \t loss = 0.000, train_acc = 1.000 (3.339 sec/step)\n",
      "step 66980 \t loss = 0.002, train_acc = 1.000 (3.366 sec/step)\n",
      "step 66990 \t loss = 1.038, train_acc = 0.900 (3.337 sec/step)\n",
      "step 67000 \t loss = 0.161, train_acc = 0.900 (3.395 sec/step)\n",
      "step 67010 \t loss = 0.020, train_acc = 1.000 (3.371 sec/step)\n",
      "step 67020 \t loss = 0.000, train_acc = 1.000 (3.334 sec/step)\n",
      "step 67030 \t loss = 0.233, train_acc = 0.900 (3.363 sec/step)\n",
      "step 67040 \t loss = 1.429, train_acc = 0.900 (3.348 sec/step)\n",
      "step 67050 \t loss = 0.024, train_acc = 1.000 (3.365 sec/step)\n",
      "step 67060 \t loss = 0.000, train_acc = 1.000 (3.364 sec/step)\n",
      "step 67070 \t loss = 0.621, train_acc = 0.900 (3.340 sec/step)\n",
      "step 67080 \t loss = 0.365, train_acc = 0.900 (3.356 sec/step)\n",
      "step 67090 \t loss = 0.055, train_acc = 1.000 (3.365 sec/step)\n",
      "step 67100 \t loss = 0.030, train_acc = 1.000 (3.327 sec/step)\n",
      "step 67110 \t loss = 0.010, train_acc = 1.000 (3.365 sec/step)\n",
      "step 67120 \t loss = 0.018, train_acc = 1.000 (3.340 sec/step)\n",
      "step 67130 \t loss = 0.019, train_acc = 1.000 (3.348 sec/step)\n",
      "step 67140 \t loss = 0.045, train_acc = 1.000 (3.335 sec/step)\n",
      "step 67150 \t loss = 0.010, train_acc = 1.000 (3.353 sec/step)\n",
      "step 67160 \t loss = 0.110, train_acc = 0.900 (3.367 sec/step)\n",
      "step 67170 \t loss = 0.010, train_acc = 1.000 (3.296 sec/step)\n",
      "step 67180 \t loss = 0.024, train_acc = 1.000 (3.286 sec/step)\n",
      "step 67190 \t loss = 0.011, train_acc = 1.000 (3.373 sec/step)\n",
      "step 67200 \t loss = 0.147, train_acc = 0.900 (3.374 sec/step)\n",
      "step 67210 \t loss = 0.048, train_acc = 1.000 (3.347 sec/step)\n",
      "step 67220 \t loss = 0.012, train_acc = 1.000 (3.379 sec/step)\n",
      "step 67230 \t loss = 0.008, train_acc = 1.000 (3.367 sec/step)\n",
      "step 67240 \t loss = 0.737, train_acc = 0.900 (3.285 sec/step)\n",
      "step 67250 \t loss = 0.019, train_acc = 1.000 (3.310 sec/step)\n",
      "step 67260 \t loss = 0.767, train_acc = 0.900 (3.438 sec/step)\n",
      "step 67270 \t loss = 0.008, train_acc = 1.000 (3.378 sec/step)\n",
      "step 67280 \t loss = 0.003, train_acc = 1.000 (3.366 sec/step)\n",
      "step 67290 \t loss = 0.206, train_acc = 0.900 (3.387 sec/step)\n",
      "step 67300 \t loss = 0.168, train_acc = 0.900 (3.401 sec/step)\n",
      "step 67310 \t loss = 0.039, train_acc = 1.000 (3.346 sec/step)\n",
      "step 67320 \t loss = 0.000, train_acc = 1.000 (3.381 sec/step)\n",
      "step 67330 \t loss = 0.014, train_acc = 1.000 (3.325 sec/step)\n",
      "step 67340 \t loss = 0.002, train_acc = 1.000 (3.336 sec/step)\n",
      "step 67350 \t loss = 0.027, train_acc = 1.000 (3.343 sec/step)\n",
      "step 67360 \t loss = 0.027, train_acc = 1.000 (3.341 sec/step)\n",
      "step 67370 \t loss = 0.360, train_acc = 0.900 (3.400 sec/step)\n",
      "step 67380 \t loss = 0.008, train_acc = 1.000 (3.347 sec/step)\n",
      "step 67390 \t loss = 0.006, train_acc = 1.000 (3.354 sec/step)\n",
      "step 67400 \t loss = 0.441, train_acc = 0.900 (3.331 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 67410 \t loss = 0.297, train_acc = 0.900 (3.358 sec/step)\n",
      "step 67420 \t loss = 0.046, train_acc = 1.000 (3.365 sec/step)\n",
      "step 67430 \t loss = 0.008, train_acc = 1.000 (3.364 sec/step)\n",
      "step 67440 \t loss = 0.003, train_acc = 1.000 (3.347 sec/step)\n",
      "step 67450 \t loss = 0.079, train_acc = 1.000 (3.389 sec/step)\n",
      "step 67460 \t loss = 0.008, train_acc = 1.000 (3.307 sec/step)\n",
      "step 67470 \t loss = 0.002, train_acc = 1.000 (3.363 sec/step)\n",
      "step 67480 \t loss = 0.289, train_acc = 0.900 (3.353 sec/step)\n",
      "step 67490 \t loss = 0.232, train_acc = 0.900 (3.378 sec/step)\n",
      "step 67500 \t loss = 0.000, train_acc = 1.000 (3.374 sec/step)\n",
      "step 67510 \t loss = 0.031, train_acc = 1.000 (3.329 sec/step)\n",
      "step 67520 \t loss = 0.748, train_acc = 0.800 (3.336 sec/step)\n",
      "step 67530 \t loss = 0.019, train_acc = 1.000 (3.296 sec/step)\n",
      "step 67540 \t loss = 1.572, train_acc = 0.900 (3.338 sec/step)\n",
      "step 67550 \t loss = 0.001, train_acc = 1.000 (3.290 sec/step)\n",
      "step 67560 \t loss = 0.093, train_acc = 1.000 (3.351 sec/step)\n",
      "step 67570 \t loss = 0.023, train_acc = 1.000 (3.299 sec/step)\n",
      "step 67580 \t loss = 0.011, train_acc = 1.000 (3.332 sec/step)\n",
      "step 67590 \t loss = 0.006, train_acc = 1.000 (3.331 sec/step)\n",
      "step 67600 \t loss = 0.037, train_acc = 1.000 (3.325 sec/step)\n",
      "step 67610 \t loss = 0.410, train_acc = 0.900 (3.375 sec/step)\n",
      "step 67620 \t loss = 0.004, train_acc = 1.000 (3.373 sec/step)\n",
      "step 67630 \t loss = 0.047, train_acc = 1.000 (3.327 sec/step)\n",
      "step 67640 \t loss = 0.048, train_acc = 1.000 (3.322 sec/step)\n",
      "step 67650 \t loss = 0.001, train_acc = 1.000 (3.287 sec/step)\n",
      "step 67660 \t loss = 0.057, train_acc = 1.000 (3.324 sec/step)\n",
      "step 67670 \t loss = 0.337, train_acc = 0.900 (3.333 sec/step)\n",
      "step 67680 \t loss = 0.035, train_acc = 1.000 (3.339 sec/step)\n",
      "step 67690 \t loss = 0.145, train_acc = 0.900 (3.390 sec/step)\n",
      "step 67700 \t loss = 1.018, train_acc = 0.800 (3.372 sec/step)\n",
      "step 67710 \t loss = 0.040, train_acc = 1.000 (3.387 sec/step)\n",
      "step 67720 \t loss = 0.895, train_acc = 0.900 (3.385 sec/step)\n",
      "step 67730 \t loss = 0.268, train_acc = 0.900 (3.426 sec/step)\n",
      "step 67740 \t loss = 0.258, train_acc = 0.900 (3.343 sec/step)\n",
      "step 67750 \t loss = 0.067, train_acc = 1.000 (3.393 sec/step)\n",
      "step 67760 \t loss = 0.071, train_acc = 1.000 (3.348 sec/step)\n",
      "step 67770 \t loss = 0.196, train_acc = 0.900 (3.326 sec/step)\n",
      "step 67780 \t loss = 0.382, train_acc = 0.900 (3.390 sec/step)\n",
      "step 67790 \t loss = 0.257, train_acc = 0.900 (3.317 sec/step)\n",
      "step 67800 \t loss = 0.816, train_acc = 0.900 (3.340 sec/step)\n",
      "step 67810 \t loss = 0.141, train_acc = 0.900 (3.342 sec/step)\n",
      "step 67820 \t loss = 0.237, train_acc = 0.900 (3.343 sec/step)\n",
      "step 67830 \t loss = 0.013, train_acc = 1.000 (3.331 sec/step)\n",
      "step 67840 \t loss = 0.080, train_acc = 0.900 (3.375 sec/step)\n",
      "step 67850 \t loss = 0.133, train_acc = 0.900 (3.328 sec/step)\n",
      "step 67860 \t loss = 0.322, train_acc = 0.800 (3.362 sec/step)\n",
      "step 67870 \t loss = 0.028, train_acc = 1.000 (3.304 sec/step)\n",
      "step 67880 \t loss = 0.019, train_acc = 1.000 (3.361 sec/step)\n",
      "step 67890 \t loss = 0.010, train_acc = 1.000 (3.360 sec/step)\n",
      "step 67900 \t loss = 0.091, train_acc = 1.000 (3.336 sec/step)\n",
      "step 67910 \t loss = 0.010, train_acc = 1.000 (3.331 sec/step)\n",
      "step 67920 \t loss = 0.075, train_acc = 1.000 (3.339 sec/step)\n",
      "step 67930 \t loss = 0.028, train_acc = 1.000 (3.327 sec/step)\n",
      "step 67940 \t loss = 0.006, train_acc = 1.000 (3.371 sec/step)\n",
      "step 67950 \t loss = 0.386, train_acc = 0.900 (3.295 sec/step)\n",
      "step 67960 \t loss = 0.002, train_acc = 1.000 (3.328 sec/step)\n",
      "step 67970 \t loss = 0.559, train_acc = 0.900 (3.329 sec/step)\n",
      "step 67980 \t loss = 0.225, train_acc = 1.000 (3.366 sec/step)\n",
      "step 67990 \t loss = 0.327, train_acc = 0.800 (3.352 sec/step)\n",
      "step 68000 \t loss = 0.246, train_acc = 0.900 (3.339 sec/step)\n",
      "step 68010 \t loss = 0.036, train_acc = 1.000 (3.345 sec/step)\n",
      "step 68020 \t loss = 0.023, train_acc = 1.000 (3.307 sec/step)\n",
      "step 68030 \t loss = 1.235, train_acc = 0.600 (3.335 sec/step)\n",
      "step 68040 \t loss = 0.008, train_acc = 1.000 (3.307 sec/step)\n",
      "step 68050 \t loss = 0.155, train_acc = 1.000 (3.359 sec/step)\n",
      "step 68060 \t loss = 0.257, train_acc = 0.900 (3.327 sec/step)\n",
      "step 68070 \t loss = 0.003, train_acc = 1.000 (3.302 sec/step)\n",
      "step 68080 \t loss = 0.017, train_acc = 1.000 (3.339 sec/step)\n",
      "step 68090 \t loss = 0.000, train_acc = 1.000 (3.347 sec/step)\n",
      "step 68100 \t loss = 0.002, train_acc = 1.000 (3.462 sec/step)\n",
      "step 68110 \t loss = 0.077, train_acc = 1.000 (3.343 sec/step)\n",
      "step 68120 \t loss = 0.071, train_acc = 1.000 (3.382 sec/step)\n",
      "step 68130 \t loss = 0.207, train_acc = 0.900 (3.355 sec/step)\n",
      "step 68140 \t loss = 0.837, train_acc = 0.900 (3.310 sec/step)\n",
      "step 68150 \t loss = 0.010, train_acc = 1.000 (3.402 sec/step)\n",
      "step 68160 \t loss = 1.068, train_acc = 0.800 (3.362 sec/step)\n",
      "step 68170 \t loss = 0.157, train_acc = 1.000 (3.331 sec/step)\n",
      "step 68180 \t loss = 0.000, train_acc = 1.000 (3.419 sec/step)\n",
      "step 68190 \t loss = 0.407, train_acc = 0.800 (3.323 sec/step)\n",
      "step 68200 \t loss = 0.129, train_acc = 1.000 (3.360 sec/step)\n",
      "step 68210 \t loss = 0.117, train_acc = 0.900 (3.322 sec/step)\n",
      "step 68220 \t loss = 0.063, train_acc = 1.000 (3.326 sec/step)\n",
      "step 68230 \t loss = 0.006, train_acc = 1.000 (3.330 sec/step)\n",
      "step 68240 \t loss = 0.250, train_acc = 0.900 (3.352 sec/step)\n",
      "step 68250 \t loss = 0.259, train_acc = 0.900 (3.365 sec/step)\n",
      "step 68260 \t loss = 0.044, train_acc = 1.000 (3.393 sec/step)\n",
      "step 68270 \t loss = 0.000, train_acc = 1.000 (3.318 sec/step)\n",
      "step 68280 \t loss = 0.096, train_acc = 0.900 (3.363 sec/step)\n",
      "step 68290 \t loss = 0.313, train_acc = 0.900 (3.378 sec/step)\n",
      "step 68300 \t loss = 0.047, train_acc = 1.000 (3.317 sec/step)\n",
      "step 68310 \t loss = 0.542, train_acc = 0.800 (3.302 sec/step)\n",
      "step 68320 \t loss = 0.663, train_acc = 0.800 (3.316 sec/step)\n",
      "step 68330 \t loss = 0.212, train_acc = 0.900 (3.345 sec/step)\n",
      "step 68340 \t loss = 0.768, train_acc = 0.900 (3.383 sec/step)\n",
      "step 68350 \t loss = 0.009, train_acc = 1.000 (3.308 sec/step)\n",
      "step 68360 \t loss = 0.002, train_acc = 1.000 (3.375 sec/step)\n",
      "step 68370 \t loss = 0.014, train_acc = 1.000 (3.468 sec/step)\n",
      "step 68380 \t loss = 0.000, train_acc = 1.000 (3.296 sec/step)\n",
      "step 68390 \t loss = 0.141, train_acc = 0.900 (3.335 sec/step)\n",
      "VALIDATION \t acc = 0.535 (3.631 sec)\n",
      "step 68400 \t loss = 0.004, train_acc = 1.000 (3.368 sec/step)\n",
      "step 68410 \t loss = 0.045, train_acc = 1.000 (3.346 sec/step)\n",
      "step 68420 \t loss = 0.022, train_acc = 1.000 (3.330 sec/step)\n",
      "step 68430 \t loss = 0.007, train_acc = 1.000 (3.420 sec/step)\n",
      "step 68440 \t loss = 0.039, train_acc = 1.000 (3.304 sec/step)\n",
      "step 68450 \t loss = 0.002, train_acc = 1.000 (3.335 sec/step)\n",
      "step 68460 \t loss = 0.013, train_acc = 1.000 (3.328 sec/step)\n",
      "step 68470 \t loss = 0.019, train_acc = 1.000 (3.376 sec/step)\n",
      "step 68480 \t loss = 0.001, train_acc = 1.000 (3.347 sec/step)\n",
      "step 68490 \t loss = 0.000, train_acc = 1.000 (3.331 sec/step)\n",
      "step 68500 \t loss = 0.082, train_acc = 0.900 (3.359 sec/step)\n",
      "step 68510 \t loss = 2.563, train_acc = 0.800 (3.309 sec/step)\n",
      "step 68520 \t loss = 0.533, train_acc = 0.800 (3.376 sec/step)\n",
      "step 68530 \t loss = 0.000, train_acc = 1.000 (3.355 sec/step)\n",
      "step 68540 \t loss = 0.043, train_acc = 1.000 (3.361 sec/step)\n",
      "step 68550 \t loss = 0.003, train_acc = 1.000 (3.335 sec/step)\n",
      "step 68560 \t loss = 0.006, train_acc = 1.000 (3.406 sec/step)\n",
      "step 68570 \t loss = 0.001, train_acc = 1.000 (3.322 sec/step)\n",
      "step 68580 \t loss = 0.125, train_acc = 0.900 (3.331 sec/step)\n",
      "step 68590 \t loss = 0.379, train_acc = 0.900 (3.345 sec/step)\n",
      "step 68600 \t loss = 0.158, train_acc = 0.900 (3.353 sec/step)\n",
      "step 68610 \t loss = 0.146, train_acc = 1.000 (3.432 sec/step)\n",
      "step 68620 \t loss = 0.013, train_acc = 1.000 (3.322 sec/step)\n",
      "step 68630 \t loss = 0.006, train_acc = 1.000 (3.367 sec/step)\n",
      "step 68640 \t loss = 0.487, train_acc = 0.800 (3.328 sec/step)\n",
      "step 68650 \t loss = 0.216, train_acc = 0.900 (3.347 sec/step)\n",
      "step 68660 \t loss = 0.810, train_acc = 0.600 (3.355 sec/step)\n",
      "step 68670 \t loss = 1.631, train_acc = 0.600 (3.342 sec/step)\n",
      "step 68680 \t loss = 0.062, train_acc = 1.000 (3.345 sec/step)\n",
      "step 68690 \t loss = 1.012, train_acc = 0.600 (3.324 sec/step)\n",
      "step 68700 \t loss = 0.832, train_acc = 0.800 (3.326 sec/step)\n",
      "step 68710 \t loss = 0.406, train_acc = 0.900 (3.307 sec/step)\n",
      "step 68720 \t loss = 0.037, train_acc = 1.000 (3.346 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 68730 \t loss = 0.056, train_acc = 1.000 (3.317 sec/step)\n",
      "step 68740 \t loss = 0.012, train_acc = 1.000 (3.396 sec/step)\n",
      "step 68750 \t loss = 0.003, train_acc = 1.000 (3.323 sec/step)\n",
      "step 68760 \t loss = 0.104, train_acc = 0.900 (3.320 sec/step)\n",
      "step 68770 \t loss = 0.352, train_acc = 0.900 (3.341 sec/step)\n",
      "step 68780 \t loss = 1.068, train_acc = 0.800 (3.358 sec/step)\n",
      "step 68790 \t loss = 0.004, train_acc = 1.000 (3.338 sec/step)\n",
      "step 68800 \t loss = 1.441, train_acc = 0.600 (3.328 sec/step)\n",
      "step 68810 \t loss = 0.009, train_acc = 1.000 (3.385 sec/step)\n",
      "step 68820 \t loss = 0.799, train_acc = 0.900 (3.487 sec/step)\n",
      "step 68830 \t loss = 0.011, train_acc = 1.000 (3.329 sec/step)\n",
      "step 68840 \t loss = 1.080, train_acc = 0.800 (3.364 sec/step)\n",
      "step 68850 \t loss = 0.604, train_acc = 0.700 (3.374 sec/step)\n",
      "step 68860 \t loss = 0.089, train_acc = 1.000 (3.351 sec/step)\n",
      "step 68870 \t loss = 0.001, train_acc = 1.000 (3.329 sec/step)\n",
      "step 68880 \t loss = 0.084, train_acc = 1.000 (3.384 sec/step)\n",
      "step 68890 \t loss = 0.026, train_acc = 1.000 (3.354 sec/step)\n",
      "step 68900 \t loss = 0.005, train_acc = 1.000 (3.362 sec/step)\n",
      "step 68910 \t loss = 0.000, train_acc = 1.000 (3.364 sec/step)\n",
      "step 68920 \t loss = 0.386, train_acc = 0.900 (3.358 sec/step)\n",
      "step 68930 \t loss = 0.539, train_acc = 0.700 (3.375 sec/step)\n",
      "step 68940 \t loss = 1.127, train_acc = 0.700 (3.311 sec/step)\n",
      "step 68950 \t loss = 0.002, train_acc = 1.000 (3.307 sec/step)\n",
      "step 68960 \t loss = 0.321, train_acc = 0.800 (3.346 sec/step)\n",
      "step 68970 \t loss = 0.631, train_acc = 0.800 (3.355 sec/step)\n",
      "step 68980 \t loss = 0.357, train_acc = 0.900 (3.325 sec/step)\n",
      "step 68990 \t loss = 0.330, train_acc = 0.900 (3.291 sec/step)\n",
      "step 69000 \t loss = 0.136, train_acc = 0.900 (3.411 sec/step)\n",
      "step 69010 \t loss = 0.017, train_acc = 1.000 (3.310 sec/step)\n",
      "step 69020 \t loss = 0.012, train_acc = 1.000 (3.313 sec/step)\n",
      "step 69030 \t loss = 0.489, train_acc = 0.800 (3.335 sec/step)\n",
      "step 69040 \t loss = 0.109, train_acc = 1.000 (3.345 sec/step)\n",
      "step 69050 \t loss = 0.916, train_acc = 0.800 (3.349 sec/step)\n",
      "step 69060 \t loss = 0.025, train_acc = 1.000 (3.362 sec/step)\n",
      "step 69070 \t loss = 0.188, train_acc = 0.900 (3.380 sec/step)\n",
      "step 69080 \t loss = 0.087, train_acc = 1.000 (3.381 sec/step)\n",
      "step 69090 \t loss = 0.061, train_acc = 1.000 (3.335 sec/step)\n",
      "step 69100 \t loss = 0.077, train_acc = 1.000 (3.351 sec/step)\n",
      "step 69110 \t loss = 0.004, train_acc = 1.000 (3.306 sec/step)\n",
      "step 69120 \t loss = 0.073, train_acc = 1.000 (3.334 sec/step)\n",
      "step 69130 \t loss = 0.001, train_acc = 1.000 (3.332 sec/step)\n",
      "step 69140 \t loss = 0.006, train_acc = 1.000 (3.328 sec/step)\n",
      "step 69150 \t loss = 0.076, train_acc = 1.000 (3.352 sec/step)\n",
      "step 69160 \t loss = 0.002, train_acc = 1.000 (3.341 sec/step)\n",
      "step 69170 \t loss = 0.056, train_acc = 1.000 (3.379 sec/step)\n",
      "step 69180 \t loss = 0.337, train_acc = 0.900 (3.366 sec/step)\n",
      "step 69190 \t loss = 0.065, train_acc = 1.000 (3.382 sec/step)\n",
      "step 69200 \t loss = 0.240, train_acc = 0.900 (3.322 sec/step)\n",
      "step 69210 \t loss = 0.004, train_acc = 1.000 (3.370 sec/step)\n",
      "step 69220 \t loss = 0.120, train_acc = 1.000 (3.306 sec/step)\n",
      "step 69230 \t loss = 0.087, train_acc = 1.000 (3.357 sec/step)\n",
      "step 69240 \t loss = 0.311, train_acc = 0.900 (3.404 sec/step)\n",
      "step 69250 \t loss = 0.008, train_acc = 1.000 (3.351 sec/step)\n",
      "step 69260 \t loss = 0.087, train_acc = 0.900 (3.416 sec/step)\n",
      "step 69270 \t loss = 0.166, train_acc = 0.900 (3.366 sec/step)\n",
      "step 69280 \t loss = 0.264, train_acc = 0.900 (3.329 sec/step)\n",
      "step 69290 \t loss = 0.009, train_acc = 1.000 (3.370 sec/step)\n",
      "step 69300 \t loss = 0.037, train_acc = 1.000 (3.351 sec/step)\n",
      "step 69310 \t loss = 0.012, train_acc = 1.000 (3.336 sec/step)\n",
      "step 69320 \t loss = 0.341, train_acc = 0.900 (3.297 sec/step)\n",
      "step 69330 \t loss = 0.034, train_acc = 1.000 (3.334 sec/step)\n",
      "step 69340 \t loss = 0.000, train_acc = 1.000 (3.348 sec/step)\n",
      "step 69350 \t loss = 0.561, train_acc = 0.900 (3.318 sec/step)\n",
      "step 69360 \t loss = 0.057, train_acc = 1.000 (3.472 sec/step)\n",
      "step 69370 \t loss = 0.068, train_acc = 1.000 (3.294 sec/step)\n",
      "step 69380 \t loss = 0.003, train_acc = 1.000 (3.323 sec/step)\n",
      "step 69390 \t loss = 0.043, train_acc = 1.000 (3.380 sec/step)\n",
      "step 69400 \t loss = 0.000, train_acc = 1.000 (3.338 sec/step)\n",
      "step 69410 \t loss = 0.856, train_acc = 0.800 (3.380 sec/step)\n",
      "step 69420 \t loss = 0.002, train_acc = 1.000 (3.329 sec/step)\n",
      "step 69430 \t loss = 0.036, train_acc = 1.000 (3.350 sec/step)\n",
      "step 69440 \t loss = 0.095, train_acc = 1.000 (3.331 sec/step)\n",
      "step 69450 \t loss = 0.000, train_acc = 1.000 (3.369 sec/step)\n",
      "step 69460 \t loss = 0.095, train_acc = 1.000 (3.298 sec/step)\n",
      "step 69470 \t loss = 0.013, train_acc = 1.000 (3.377 sec/step)\n",
      "step 69480 \t loss = 0.216, train_acc = 1.000 (3.343 sec/step)\n",
      "step 69490 \t loss = 0.009, train_acc = 1.000 (3.290 sec/step)\n",
      "step 69500 \t loss = 0.007, train_acc = 1.000 (3.324 sec/step)\n",
      "step 69510 \t loss = 0.000, train_acc = 1.000 (3.393 sec/step)\n",
      "step 69520 \t loss = 0.171, train_acc = 0.900 (3.340 sec/step)\n",
      "step 69530 \t loss = 0.007, train_acc = 1.000 (3.399 sec/step)\n",
      "step 69540 \t loss = 0.335, train_acc = 0.900 (3.335 sec/step)\n",
      "step 69550 \t loss = 0.003, train_acc = 1.000 (3.383 sec/step)\n",
      "step 69560 \t loss = 0.062, train_acc = 1.000 (3.407 sec/step)\n",
      "step 69570 \t loss = 1.152, train_acc = 0.800 (3.299 sec/step)\n",
      "step 69580 \t loss = 0.001, train_acc = 1.000 (3.333 sec/step)\n",
      "step 69590 \t loss = 0.453, train_acc = 0.900 (3.323 sec/step)\n",
      "step 69600 \t loss = 0.001, train_acc = 1.000 (3.353 sec/step)\n",
      "step 69610 \t loss = 0.050, train_acc = 1.000 (3.336 sec/step)\n",
      "step 69620 \t loss = 0.008, train_acc = 1.000 (3.372 sec/step)\n",
      "step 69630 \t loss = 0.003, train_acc = 1.000 (3.377 sec/step)\n",
      "step 69640 \t loss = 0.137, train_acc = 0.900 (3.382 sec/step)\n",
      "step 69650 \t loss = 0.041, train_acc = 1.000 (3.318 sec/step)\n",
      "step 69660 \t loss = 0.234, train_acc = 0.900 (3.308 sec/step)\n",
      "step 69670 \t loss = 0.137, train_acc = 1.000 (3.356 sec/step)\n",
      "step 69680 \t loss = 0.095, train_acc = 1.000 (3.425 sec/step)\n",
      "step 69690 \t loss = 0.003, train_acc = 1.000 (3.365 sec/step)\n",
      "step 69700 \t loss = 0.025, train_acc = 1.000 (3.332 sec/step)\n",
      "step 69710 \t loss = 0.013, train_acc = 1.000 (3.356 sec/step)\n",
      "step 69720 \t loss = 0.031, train_acc = 1.000 (3.403 sec/step)\n",
      "step 69730 \t loss = 0.467, train_acc = 0.800 (3.370 sec/step)\n",
      "step 69740 \t loss = 0.003, train_acc = 1.000 (3.347 sec/step)\n",
      "step 69750 \t loss = 0.666, train_acc = 0.900 (3.334 sec/step)\n",
      "step 69760 \t loss = 0.042, train_acc = 1.000 (3.322 sec/step)\n",
      "step 69770 \t loss = 1.016, train_acc = 0.900 (3.358 sec/step)\n",
      "step 69780 \t loss = 0.095, train_acc = 1.000 (3.302 sec/step)\n",
      "step 69790 \t loss = 0.057, train_acc = 1.000 (3.325 sec/step)\n",
      "step 69800 \t loss = 0.797, train_acc = 0.700 (3.362 sec/step)\n",
      "step 69810 \t loss = 0.239, train_acc = 0.900 (3.343 sec/step)\n",
      "step 69820 \t loss = 0.107, train_acc = 0.900 (3.290 sec/step)\n",
      "step 69830 \t loss = 0.448, train_acc = 0.900 (3.348 sec/step)\n",
      "step 69840 \t loss = 0.176, train_acc = 0.900 (3.361 sec/step)\n",
      "step 69850 \t loss = 0.045, train_acc = 1.000 (3.371 sec/step)\n",
      "step 69860 \t loss = 0.771, train_acc = 0.900 (3.369 sec/step)\n",
      "step 69870 \t loss = 0.376, train_acc = 0.900 (3.325 sec/step)\n",
      "step 69880 \t loss = 0.083, train_acc = 1.000 (3.391 sec/step)\n",
      "step 69890 \t loss = 0.007, train_acc = 1.000 (3.314 sec/step)\n",
      "step 69900 \t loss = 0.722, train_acc = 0.800 (3.378 sec/step)\n",
      "step 69910 \t loss = 0.846, train_acc = 0.900 (3.354 sec/step)\n",
      "step 69920 \t loss = 0.007, train_acc = 1.000 (3.317 sec/step)\n",
      "step 69930 \t loss = 0.004, train_acc = 1.000 (3.335 sec/step)\n",
      "step 69940 \t loss = 0.249, train_acc = 0.900 (3.316 sec/step)\n",
      "step 69950 \t loss = 0.066, train_acc = 1.000 (3.333 sec/step)\n",
      "step 69960 \t loss = 0.000, train_acc = 1.000 (3.314 sec/step)\n",
      "step 69970 \t loss = 0.360, train_acc = 0.900 (3.353 sec/step)\n",
      "step 69980 \t loss = 0.173, train_acc = 0.900 (3.366 sec/step)\n",
      "step 69990 \t loss = 0.726, train_acc = 0.900 (3.298 sec/step)\n",
      "step 70000 \t loss = 0.007, train_acc = 1.000 (3.339 sec/step)\n",
      "step 70010 \t loss = 0.334, train_acc = 0.900 (3.407 sec/step)\n",
      "step 70020 \t loss = 0.000, train_acc = 1.000 (3.400 sec/step)\n",
      "step 70030 \t loss = 0.296, train_acc = 0.900 (3.351 sec/step)\n",
      "step 70040 \t loss = 0.480, train_acc = 0.900 (3.333 sec/step)\n",
      "step 70050 \t loss = 0.202, train_acc = 0.900 (3.328 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 70060 \t loss = 0.613, train_acc = 0.800 (3.320 sec/step)\n",
      "step 70070 \t loss = 0.003, train_acc = 1.000 (3.361 sec/step)\n",
      "step 70080 \t loss = 0.045, train_acc = 1.000 (3.416 sec/step)\n",
      "step 70090 \t loss = 0.066, train_acc = 1.000 (3.303 sec/step)\n",
      "step 70100 \t loss = 0.004, train_acc = 1.000 (3.367 sec/step)\n",
      "step 70110 \t loss = 0.107, train_acc = 0.900 (3.341 sec/step)\n",
      "step 70120 \t loss = 0.055, train_acc = 1.000 (3.347 sec/step)\n",
      "step 70130 \t loss = 0.652, train_acc = 0.900 (3.364 sec/step)\n",
      "step 70140 \t loss = 1.502, train_acc = 0.800 (3.333 sec/step)\n",
      "step 70150 \t loss = 0.071, train_acc = 1.000 (3.316 sec/step)\n",
      "step 70160 \t loss = 0.019, train_acc = 1.000 (3.303 sec/step)\n",
      "step 70170 \t loss = 0.108, train_acc = 0.900 (3.338 sec/step)\n",
      "step 70180 \t loss = 0.000, train_acc = 1.000 (3.342 sec/step)\n",
      "step 70190 \t loss = 0.513, train_acc = 0.900 (3.314 sec/step)\n",
      "step 70200 \t loss = 0.048, train_acc = 1.000 (3.288 sec/step)\n",
      "step 70210 \t loss = 0.052, train_acc = 1.000 (3.366 sec/step)\n",
      "step 70220 \t loss = 0.025, train_acc = 1.000 (3.355 sec/step)\n",
      "step 70230 \t loss = 0.078, train_acc = 1.000 (3.406 sec/step)\n",
      "step 70240 \t loss = 0.254, train_acc = 0.800 (3.318 sec/step)\n",
      "step 70250 \t loss = 0.000, train_acc = 1.000 (3.295 sec/step)\n",
      "step 70260 \t loss = 1.741, train_acc = 0.900 (3.324 sec/step)\n",
      "step 70270 \t loss = 0.033, train_acc = 1.000 (3.377 sec/step)\n",
      "step 70280 \t loss = 1.482, train_acc = 0.800 (3.357 sec/step)\n",
      "step 70290 \t loss = 0.578, train_acc = 0.800 (3.295 sec/step)\n",
      "VALIDATION \t acc = 0.508 (3.602 sec)\n",
      "step 70300 \t loss = 0.260, train_acc = 0.900 (3.337 sec/step)\n",
      "step 70310 \t loss = 0.279, train_acc = 0.900 (3.340 sec/step)\n",
      "step 70320 \t loss = 0.211, train_acc = 0.900 (3.328 sec/step)\n",
      "step 70330 \t loss = 1.099, train_acc = 0.600 (3.376 sec/step)\n",
      "step 70340 \t loss = 0.008, train_acc = 1.000 (3.343 sec/step)\n",
      "step 70350 \t loss = 0.314, train_acc = 0.900 (3.369 sec/step)\n",
      "step 70360 \t loss = 0.001, train_acc = 1.000 (3.367 sec/step)\n",
      "step 70370 \t loss = 0.003, train_acc = 1.000 (3.395 sec/step)\n",
      "step 70380 \t loss = 0.002, train_acc = 1.000 (3.394 sec/step)\n",
      "step 70390 \t loss = 0.132, train_acc = 0.900 (3.358 sec/step)\n",
      "step 70400 \t loss = 0.000, train_acc = 1.000 (3.337 sec/step)\n",
      "step 70410 \t loss = 0.000, train_acc = 1.000 (3.356 sec/step)\n",
      "step 70420 \t loss = 0.010, train_acc = 1.000 (3.330 sec/step)\n",
      "step 70430 \t loss = 0.000, train_acc = 1.000 (3.408 sec/step)\n",
      "step 70440 \t loss = 0.004, train_acc = 1.000 (3.388 sec/step)\n",
      "step 70450 \t loss = 0.322, train_acc = 0.900 (3.446 sec/step)\n",
      "step 70460 \t loss = 0.068, train_acc = 1.000 (3.335 sec/step)\n",
      "step 70470 \t loss = 0.600, train_acc = 0.900 (3.304 sec/step)\n",
      "step 70480 \t loss = 0.876, train_acc = 0.800 (3.307 sec/step)\n",
      "step 70490 \t loss = 0.291, train_acc = 0.900 (3.335 sec/step)\n",
      "step 70500 \t loss = 0.559, train_acc = 0.800 (3.321 sec/step)\n",
      "step 70510 \t loss = 0.087, train_acc = 1.000 (3.348 sec/step)\n",
      "step 70520 \t loss = 0.535, train_acc = 0.800 (3.352 sec/step)\n",
      "step 70530 \t loss = 0.182, train_acc = 0.900 (3.325 sec/step)\n",
      "step 70540 \t loss = 0.040, train_acc = 1.000 (3.407 sec/step)\n",
      "step 70550 \t loss = 0.180, train_acc = 0.900 (3.382 sec/step)\n",
      "step 70560 \t loss = 0.223, train_acc = 1.000 (3.325 sec/step)\n",
      "step 70570 \t loss = 0.104, train_acc = 0.900 (3.417 sec/step)\n",
      "step 70580 \t loss = 0.053, train_acc = 1.000 (3.336 sec/step)\n",
      "step 70590 \t loss = 0.969, train_acc = 0.800 (3.324 sec/step)\n",
      "step 70600 \t loss = 0.055, train_acc = 1.000 (3.358 sec/step)\n",
      "step 70610 \t loss = 0.113, train_acc = 1.000 (3.405 sec/step)\n",
      "step 70620 \t loss = 0.010, train_acc = 1.000 (3.453 sec/step)\n",
      "step 70630 \t loss = 1.448, train_acc = 0.900 (3.388 sec/step)\n",
      "step 70640 \t loss = 0.108, train_acc = 1.000 (3.355 sec/step)\n",
      "step 70650 \t loss = 0.049, train_acc = 1.000 (3.366 sec/step)\n",
      "step 70660 \t loss = 0.315, train_acc = 0.900 (3.401 sec/step)\n",
      "step 70670 \t loss = 0.078, train_acc = 0.900 (3.359 sec/step)\n",
      "step 70680 \t loss = 0.015, train_acc = 1.000 (3.322 sec/step)\n",
      "step 70690 \t loss = 0.000, train_acc = 1.000 (3.352 sec/step)\n",
      "step 70700 \t loss = 1.544, train_acc = 0.800 (3.376 sec/step)\n",
      "step 70710 \t loss = 0.112, train_acc = 1.000 (3.351 sec/step)\n",
      "step 70720 \t loss = 0.305, train_acc = 0.900 (3.355 sec/step)\n",
      "step 70730 \t loss = 0.538, train_acc = 0.800 (3.394 sec/step)\n",
      "step 70740 \t loss = 0.136, train_acc = 1.000 (3.340 sec/step)\n",
      "step 70750 \t loss = 0.025, train_acc = 1.000 (3.308 sec/step)\n",
      "step 70760 \t loss = 0.365, train_acc = 0.800 (3.304 sec/step)\n",
      "step 70770 \t loss = 0.206, train_acc = 0.900 (3.299 sec/step)\n",
      "step 70780 \t loss = 0.003, train_acc = 1.000 (3.375 sec/step)\n",
      "step 70790 \t loss = 0.474, train_acc = 0.900 (3.310 sec/step)\n",
      "step 70800 \t loss = 0.020, train_acc = 1.000 (3.346 sec/step)\n",
      "step 70810 \t loss = 0.080, train_acc = 1.000 (3.349 sec/step)\n",
      "step 70820 \t loss = 0.143, train_acc = 0.900 (3.366 sec/step)\n",
      "step 70830 \t loss = 0.097, train_acc = 1.000 (3.335 sec/step)\n",
      "step 70840 \t loss = 0.066, train_acc = 1.000 (3.325 sec/step)\n",
      "step 70850 \t loss = 0.009, train_acc = 1.000 (3.369 sec/step)\n",
      "step 70860 \t loss = 0.013, train_acc = 1.000 (3.367 sec/step)\n",
      "step 70870 \t loss = 0.001, train_acc = 1.000 (3.381 sec/step)\n",
      "step 70880 \t loss = 0.147, train_acc = 0.900 (3.372 sec/step)\n",
      "step 70890 \t loss = 0.220, train_acc = 0.900 (3.344 sec/step)\n",
      "step 70900 \t loss = 0.660, train_acc = 0.900 (3.360 sec/step)\n",
      "step 70910 \t loss = 0.162, train_acc = 0.900 (3.332 sec/step)\n",
      "step 70920 \t loss = 0.055, train_acc = 1.000 (3.377 sec/step)\n",
      "step 70930 \t loss = 2.714, train_acc = 0.800 (3.373 sec/step)\n",
      "step 70940 \t loss = 0.084, train_acc = 1.000 (3.357 sec/step)\n",
      "step 70950 \t loss = 1.315, train_acc = 0.800 (3.325 sec/step)\n",
      "step 70960 \t loss = 0.446, train_acc = 0.900 (3.316 sec/step)\n",
      "step 70970 \t loss = 0.932, train_acc = 0.900 (3.302 sec/step)\n",
      "step 70980 \t loss = 0.014, train_acc = 1.000 (3.354 sec/step)\n",
      "step 70990 \t loss = 0.293, train_acc = 0.900 (3.320 sec/step)\n",
      "step 71000 \t loss = 0.279, train_acc = 1.000 (3.334 sec/step)\n",
      "step 71010 \t loss = 0.483, train_acc = 0.900 (3.335 sec/step)\n",
      "step 71020 \t loss = 0.384, train_acc = 0.900 (3.366 sec/step)\n",
      "step 71030 \t loss = 0.387, train_acc = 0.900 (3.391 sec/step)\n",
      "step 71040 \t loss = 0.008, train_acc = 1.000 (3.370 sec/step)\n",
      "step 71050 \t loss = 0.104, train_acc = 1.000 (3.299 sec/step)\n",
      "step 71060 \t loss = 0.111, train_acc = 0.900 (3.391 sec/step)\n",
      "step 71070 \t loss = 0.000, train_acc = 1.000 (3.344 sec/step)\n",
      "step 71080 \t loss = 0.893, train_acc = 0.900 (3.336 sec/step)\n",
      "step 71090 \t loss = 0.001, train_acc = 1.000 (3.365 sec/step)\n",
      "step 71100 \t loss = 0.004, train_acc = 1.000 (3.361 sec/step)\n",
      "step 71110 \t loss = 0.306, train_acc = 0.900 (3.339 sec/step)\n",
      "step 71120 \t loss = 0.139, train_acc = 0.900 (3.350 sec/step)\n",
      "step 71130 \t loss = 0.313, train_acc = 0.800 (3.372 sec/step)\n",
      "step 71140 \t loss = 0.362, train_acc = 0.900 (3.332 sec/step)\n",
      "step 71150 \t loss = 0.338, train_acc = 1.000 (3.403 sec/step)\n",
      "step 71160 \t loss = 0.200, train_acc = 0.900 (3.340 sec/step)\n",
      "step 71170 \t loss = 0.076, train_acc = 1.000 (3.387 sec/step)\n",
      "step 71180 \t loss = 0.061, train_acc = 1.000 (3.362 sec/step)\n",
      "step 71190 \t loss = 0.057, train_acc = 1.000 (3.401 sec/step)\n",
      "step 71200 \t loss = 0.248, train_acc = 0.900 (3.317 sec/step)\n",
      "step 71210 \t loss = 0.005, train_acc = 1.000 (3.325 sec/step)\n",
      "step 71220 \t loss = 0.000, train_acc = 1.000 (3.320 sec/step)\n",
      "step 71230 \t loss = 0.008, train_acc = 1.000 (3.368 sec/step)\n",
      "step 71240 \t loss = 0.164, train_acc = 0.900 (3.345 sec/step)\n",
      "step 71250 \t loss = 0.009, train_acc = 1.000 (3.324 sec/step)\n",
      "step 71260 \t loss = 0.384, train_acc = 0.900 (3.326 sec/step)\n",
      "step 71270 \t loss = 0.064, train_acc = 1.000 (3.333 sec/step)\n",
      "step 71280 \t loss = 0.000, train_acc = 1.000 (3.395 sec/step)\n",
      "step 71290 \t loss = 0.042, train_acc = 1.000 (3.320 sec/step)\n",
      "step 71300 \t loss = 0.078, train_acc = 1.000 (3.321 sec/step)\n",
      "step 71310 \t loss = 0.289, train_acc = 0.900 (3.324 sec/step)\n",
      "step 71320 \t loss = 0.839, train_acc = 0.900 (3.337 sec/step)\n",
      "step 71330 \t loss = 0.002, train_acc = 1.000 (3.411 sec/step)\n",
      "step 71340 \t loss = 0.145, train_acc = 0.900 (3.371 sec/step)\n",
      "step 71350 \t loss = 0.120, train_acc = 0.900 (3.309 sec/step)\n",
      "step 71360 \t loss = 0.362, train_acc = 0.800 (3.358 sec/step)\n",
      "step 71370 \t loss = 0.003, train_acc = 1.000 (3.338 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 71380 \t loss = 0.006, train_acc = 1.000 (3.311 sec/step)\n",
      "step 71390 \t loss = 0.010, train_acc = 1.000 (3.362 sec/step)\n",
      "step 71400 \t loss = 1.456, train_acc = 0.800 (3.330 sec/step)\n",
      "step 71410 \t loss = 0.003, train_acc = 1.000 (3.376 sec/step)\n",
      "step 71420 \t loss = 0.000, train_acc = 1.000 (3.316 sec/step)\n",
      "step 71430 \t loss = 0.511, train_acc = 0.800 (3.321 sec/step)\n",
      "step 71440 \t loss = 0.001, train_acc = 1.000 (3.335 sec/step)\n",
      "step 71450 \t loss = 0.949, train_acc = 0.900 (3.404 sec/step)\n",
      "step 71460 \t loss = 0.002, train_acc = 1.000 (3.321 sec/step)\n",
      "step 71470 \t loss = 0.273, train_acc = 0.900 (3.499 sec/step)\n",
      "step 71480 \t loss = 0.000, train_acc = 1.000 (3.366 sec/step)\n",
      "step 71490 \t loss = 0.022, train_acc = 1.000 (3.379 sec/step)\n",
      "step 71500 \t loss = 0.704, train_acc = 0.800 (3.359 sec/step)\n",
      "step 71510 \t loss = 0.032, train_acc = 1.000 (3.323 sec/step)\n",
      "step 71520 \t loss = 0.040, train_acc = 1.000 (3.369 sec/step)\n",
      "step 71530 \t loss = 0.042, train_acc = 1.000 (3.334 sec/step)\n",
      "step 71540 \t loss = 1.366, train_acc = 0.900 (3.359 sec/step)\n",
      "step 71550 \t loss = 0.266, train_acc = 0.900 (3.334 sec/step)\n",
      "step 71560 \t loss = 1.424, train_acc = 0.800 (3.371 sec/step)\n",
      "step 71570 \t loss = 0.029, train_acc = 1.000 (3.353 sec/step)\n",
      "step 71580 \t loss = 0.164, train_acc = 0.900 (3.293 sec/step)\n",
      "step 71590 \t loss = 0.104, train_acc = 0.900 (3.390 sec/step)\n",
      "step 71600 \t loss = 0.003, train_acc = 1.000 (3.361 sec/step)\n",
      "step 71610 \t loss = 0.281, train_acc = 0.800 (3.298 sec/step)\n",
      "step 71620 \t loss = 0.537, train_acc = 0.700 (3.369 sec/step)\n",
      "step 71630 \t loss = 0.167, train_acc = 0.900 (3.346 sec/step)\n",
      "step 71640 \t loss = 0.045, train_acc = 1.000 (3.374 sec/step)\n",
      "step 71650 \t loss = 1.603, train_acc = 0.800 (3.383 sec/step)\n",
      "step 71660 \t loss = 0.002, train_acc = 1.000 (3.362 sec/step)\n",
      "step 71670 \t loss = 0.005, train_acc = 1.000 (3.319 sec/step)\n",
      "step 71680 \t loss = 0.015, train_acc = 1.000 (3.397 sec/step)\n",
      "step 71690 \t loss = 0.081, train_acc = 0.900 (3.383 sec/step)\n",
      "step 71700 \t loss = 0.001, train_acc = 1.000 (3.320 sec/step)\n",
      "step 71710 \t loss = 0.207, train_acc = 0.900 (3.377 sec/step)\n",
      "step 71720 \t loss = 0.236, train_acc = 0.900 (3.366 sec/step)\n",
      "step 71730 \t loss = 0.001, train_acc = 1.000 (3.305 sec/step)\n",
      "step 71740 \t loss = 0.256, train_acc = 0.900 (3.315 sec/step)\n",
      "step 71750 \t loss = 0.048, train_acc = 1.000 (3.374 sec/step)\n",
      "step 71760 \t loss = 0.256, train_acc = 0.900 (3.350 sec/step)\n",
      "step 71770 \t loss = 0.167, train_acc = 0.900 (3.367 sec/step)\n",
      "step 71780 \t loss = 0.198, train_acc = 0.900 (3.333 sec/step)\n",
      "step 71790 \t loss = 0.063, train_acc = 1.000 (3.341 sec/step)\n",
      "step 71800 \t loss = 0.010, train_acc = 1.000 (3.347 sec/step)\n",
      "step 71810 \t loss = 1.281, train_acc = 0.800 (3.302 sec/step)\n",
      "step 71820 \t loss = 0.360, train_acc = 0.900 (3.334 sec/step)\n",
      "step 71830 \t loss = 0.009, train_acc = 1.000 (3.302 sec/step)\n",
      "step 71840 \t loss = 0.299, train_acc = 0.900 (3.360 sec/step)\n",
      "step 71850 \t loss = 0.088, train_acc = 1.000 (3.356 sec/step)\n",
      "step 71860 \t loss = 0.015, train_acc = 1.000 (3.341 sec/step)\n",
      "step 71870 \t loss = 2.245, train_acc = 0.900 (3.340 sec/step)\n",
      "step 71880 \t loss = 0.053, train_acc = 1.000 (3.334 sec/step)\n",
      "step 71890 \t loss = 0.066, train_acc = 1.000 (3.331 sec/step)\n",
      "step 71900 \t loss = 0.845, train_acc = 0.900 (3.416 sec/step)\n",
      "step 71910 \t loss = 0.259, train_acc = 0.900 (3.312 sec/step)\n",
      "step 71920 \t loss = 0.060, train_acc = 1.000 (3.344 sec/step)\n",
      "step 71930 \t loss = 1.144, train_acc = 0.800 (3.314 sec/step)\n",
      "step 71940 \t loss = 0.041, train_acc = 1.000 (3.354 sec/step)\n",
      "step 71950 \t loss = 0.005, train_acc = 1.000 (3.368 sec/step)\n",
      "step 71960 \t loss = 0.524, train_acc = 0.900 (3.319 sec/step)\n",
      "step 71970 \t loss = 0.001, train_acc = 1.000 (3.377 sec/step)\n",
      "step 71980 \t loss = 0.020, train_acc = 1.000 (3.365 sec/step)\n",
      "step 71990 \t loss = 0.252, train_acc = 0.800 (3.334 sec/step)\n",
      "step 72000 \t loss = 0.051, train_acc = 1.000 (3.379 sec/step)\n",
      "step 72010 \t loss = 0.416, train_acc = 0.800 (3.378 sec/step)\n",
      "step 72020 \t loss = 0.003, train_acc = 1.000 (3.299 sec/step)\n",
      "step 72030 \t loss = 0.136, train_acc = 0.900 (3.319 sec/step)\n",
      "step 72040 \t loss = 0.076, train_acc = 1.000 (3.341 sec/step)\n",
      "step 72050 \t loss = 0.004, train_acc = 1.000 (3.403 sec/step)\n",
      "step 72060 \t loss = 0.003, train_acc = 1.000 (3.356 sec/step)\n",
      "step 72070 \t loss = 0.016, train_acc = 1.000 (3.370 sec/step)\n",
      "step 72080 \t loss = 0.154, train_acc = 0.900 (3.402 sec/step)\n",
      "step 72090 \t loss = 0.366, train_acc = 0.900 (3.364 sec/step)\n",
      "step 72100 \t loss = 0.226, train_acc = 0.900 (3.306 sec/step)\n",
      "step 72110 \t loss = 0.001, train_acc = 1.000 (3.334 sec/step)\n",
      "step 72120 \t loss = 0.410, train_acc = 0.900 (3.474 sec/step)\n",
      "step 72130 \t loss = 0.020, train_acc = 1.000 (3.333 sec/step)\n",
      "step 72140 \t loss = 0.004, train_acc = 1.000 (3.367 sec/step)\n",
      "step 72150 \t loss = 0.026, train_acc = 1.000 (3.304 sec/step)\n",
      "step 72160 \t loss = 0.020, train_acc = 1.000 (3.394 sec/step)\n",
      "step 72170 \t loss = 0.041, train_acc = 1.000 (3.333 sec/step)\n",
      "step 72180 \t loss = 0.014, train_acc = 1.000 (3.349 sec/step)\n",
      "step 72190 \t loss = 0.119, train_acc = 0.900 (3.308 sec/step)\n",
      "VALIDATION \t acc = 0.537 (3.616 sec)\n",
      "step 72200 \t loss = 0.045, train_acc = 1.000 (3.335 sec/step)\n",
      "step 72210 \t loss = 0.088, train_acc = 1.000 (3.391 sec/step)\n",
      "step 72220 \t loss = 0.050, train_acc = 1.000 (3.359 sec/step)\n",
      "step 72230 \t loss = 0.001, train_acc = 1.000 (3.330 sec/step)\n",
      "step 72240 \t loss = 0.000, train_acc = 1.000 (3.313 sec/step)\n",
      "step 72250 \t loss = 0.031, train_acc = 1.000 (3.332 sec/step)\n",
      "step 72260 \t loss = 0.010, train_acc = 1.000 (3.354 sec/step)\n",
      "step 72270 \t loss = 0.002, train_acc = 1.000 (3.350 sec/step)\n",
      "step 72280 \t loss = 0.061, train_acc = 1.000 (3.318 sec/step)\n",
      "step 72290 \t loss = 0.095, train_acc = 1.000 (3.362 sec/step)\n",
      "step 72300 \t loss = 0.006, train_acc = 1.000 (3.294 sec/step)\n",
      "step 72310 \t loss = 0.034, train_acc = 1.000 (3.331 sec/step)\n",
      "step 72320 \t loss = 0.601, train_acc = 0.900 (3.347 sec/step)\n",
      "step 72330 \t loss = 0.532, train_acc = 0.800 (3.331 sec/step)\n",
      "step 72340 \t loss = 0.002, train_acc = 1.000 (3.310 sec/step)\n",
      "step 72350 \t loss = 0.290, train_acc = 0.900 (3.311 sec/step)\n",
      "step 72360 \t loss = 0.041, train_acc = 1.000 (3.341 sec/step)\n",
      "step 72370 \t loss = 0.297, train_acc = 0.900 (3.393 sec/step)\n",
      "step 72380 \t loss = 0.503, train_acc = 0.900 (3.374 sec/step)\n",
      "step 72390 \t loss = 0.057, train_acc = 1.000 (3.424 sec/step)\n",
      "step 72400 \t loss = 0.377, train_acc = 0.800 (3.333 sec/step)\n",
      "step 72410 \t loss = 0.155, train_acc = 0.900 (3.402 sec/step)\n",
      "step 72420 \t loss = 0.075, train_acc = 1.000 (3.287 sec/step)\n",
      "step 72430 \t loss = 0.000, train_acc = 1.000 (3.411 sec/step)\n",
      "step 72440 \t loss = 0.000, train_acc = 1.000 (3.367 sec/step)\n",
      "step 72450 \t loss = 0.300, train_acc = 0.900 (3.389 sec/step)\n",
      "step 72460 \t loss = 0.997, train_acc = 0.700 (3.375 sec/step)\n",
      "step 72470 \t loss = 0.298, train_acc = 0.900 (3.339 sec/step)\n",
      "step 72480 \t loss = 0.004, train_acc = 1.000 (3.296 sec/step)\n",
      "step 72490 \t loss = 0.011, train_acc = 1.000 (3.323 sec/step)\n",
      "step 72500 \t loss = 0.020, train_acc = 1.000 (3.399 sec/step)\n",
      "step 72510 \t loss = 0.019, train_acc = 1.000 (3.409 sec/step)\n",
      "step 72520 \t loss = 0.106, train_acc = 1.000 (3.389 sec/step)\n",
      "step 72530 \t loss = 0.003, train_acc = 1.000 (3.335 sec/step)\n",
      "step 72540 \t loss = 0.000, train_acc = 1.000 (3.343 sec/step)\n",
      "step 72550 \t loss = 0.000, train_acc = 1.000 (3.309 sec/step)\n",
      "step 72560 \t loss = 0.043, train_acc = 1.000 (3.370 sec/step)\n",
      "step 72570 \t loss = 0.456, train_acc = 0.900 (3.382 sec/step)\n",
      "step 72580 \t loss = 0.464, train_acc = 0.900 (3.313 sec/step)\n",
      "step 72590 \t loss = 0.016, train_acc = 1.000 (3.347 sec/step)\n",
      "step 72600 \t loss = 0.135, train_acc = 0.900 (3.394 sec/step)\n",
      "step 72610 \t loss = 0.038, train_acc = 1.000 (3.369 sec/step)\n",
      "step 72620 \t loss = 0.230, train_acc = 0.900 (3.325 sec/step)\n",
      "step 72630 \t loss = 0.573, train_acc = 0.900 (3.315 sec/step)\n",
      "step 72640 \t loss = 0.072, train_acc = 1.000 (3.349 sec/step)\n",
      "step 72650 \t loss = 0.000, train_acc = 1.000 (3.389 sec/step)\n",
      "step 72660 \t loss = 0.051, train_acc = 1.000 (3.342 sec/step)\n",
      "step 72670 \t loss = 0.032, train_acc = 1.000 (3.357 sec/step)\n",
      "step 72680 \t loss = 0.111, train_acc = 0.900 (3.306 sec/step)\n",
      "step 72690 \t loss = 0.131, train_acc = 0.900 (3.414 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 72700 \t loss = 0.001, train_acc = 1.000 (3.366 sec/step)\n",
      "step 72710 \t loss = 0.004, train_acc = 1.000 (3.362 sec/step)\n",
      "step 72720 \t loss = 0.148, train_acc = 0.900 (3.391 sec/step)\n",
      "step 72730 \t loss = 0.026, train_acc = 1.000 (3.330 sec/step)\n",
      "step 72740 \t loss = 0.126, train_acc = 0.900 (3.298 sec/step)\n",
      "step 72750 \t loss = 0.015, train_acc = 1.000 (3.393 sec/step)\n",
      "step 72760 \t loss = 0.279, train_acc = 0.900 (3.393 sec/step)\n",
      "step 72770 \t loss = 0.021, train_acc = 1.000 (3.351 sec/step)\n",
      "step 72780 \t loss = 0.438, train_acc = 0.900 (3.377 sec/step)\n",
      "step 72790 \t loss = 0.494, train_acc = 0.800 (3.338 sec/step)\n",
      "step 72800 \t loss = 0.405, train_acc = 0.900 (3.380 sec/step)\n",
      "step 72810 \t loss = 0.004, train_acc = 1.000 (3.350 sec/step)\n",
      "step 72820 \t loss = 0.000, train_acc = 1.000 (3.394 sec/step)\n",
      "step 72830 \t loss = 0.546, train_acc = 0.900 (3.375 sec/step)\n",
      "step 72840 \t loss = 0.059, train_acc = 1.000 (3.353 sec/step)\n",
      "step 72850 \t loss = 0.451, train_acc = 0.900 (3.383 sec/step)\n",
      "step 72860 \t loss = 0.088, train_acc = 0.900 (3.338 sec/step)\n",
      "step 72870 \t loss = 0.263, train_acc = 1.000 (3.346 sec/step)\n",
      "step 72880 \t loss = 0.487, train_acc = 0.900 (3.304 sec/step)\n",
      "step 72890 \t loss = 0.253, train_acc = 0.900 (3.380 sec/step)\n",
      "step 72900 \t loss = 0.004, train_acc = 1.000 (3.330 sec/step)\n",
      "step 72910 \t loss = 0.032, train_acc = 1.000 (3.374 sec/step)\n",
      "step 72920 \t loss = 0.136, train_acc = 1.000 (3.333 sec/step)\n",
      "step 72930 \t loss = 0.015, train_acc = 1.000 (3.358 sec/step)\n",
      "step 72940 \t loss = 0.001, train_acc = 1.000 (3.317 sec/step)\n",
      "step 72950 \t loss = 0.066, train_acc = 1.000 (3.345 sec/step)\n",
      "step 72960 \t loss = 0.852, train_acc = 0.800 (3.390 sec/step)\n",
      "step 72970 \t loss = 0.017, train_acc = 1.000 (3.335 sec/step)\n",
      "step 72980 \t loss = 0.267, train_acc = 0.900 (3.375 sec/step)\n",
      "step 72990 \t loss = 0.003, train_acc = 1.000 (3.371 sec/step)\n",
      "step 73000 \t loss = 0.056, train_acc = 1.000 (3.316 sec/step)\n",
      "step 73010 \t loss = 0.797, train_acc = 0.900 (3.328 sec/step)\n",
      "step 73020 \t loss = 0.095, train_acc = 1.000 (3.363 sec/step)\n",
      "step 73030 \t loss = 0.145, train_acc = 0.900 (3.367 sec/step)\n",
      "step 73040 \t loss = 2.310, train_acc = 0.800 (3.309 sec/step)\n",
      "step 73050 \t loss = 0.415, train_acc = 0.800 (3.369 sec/step)\n",
      "step 73060 \t loss = 0.085, train_acc = 1.000 (3.294 sec/step)\n",
      "step 73070 \t loss = 0.027, train_acc = 1.000 (3.325 sec/step)\n",
      "step 73080 \t loss = 0.017, train_acc = 1.000 (3.401 sec/step)\n",
      "step 73090 \t loss = 0.097, train_acc = 1.000 (3.291 sec/step)\n",
      "step 73100 \t loss = 0.193, train_acc = 0.900 (3.361 sec/step)\n",
      "step 73110 \t loss = 0.079, train_acc = 1.000 (3.338 sec/step)\n",
      "step 73120 \t loss = 0.023, train_acc = 1.000 (3.362 sec/step)\n",
      "step 73130 \t loss = 0.225, train_acc = 0.900 (3.342 sec/step)\n",
      "step 73140 \t loss = 0.004, train_acc = 1.000 (3.330 sec/step)\n",
      "step 73150 \t loss = 0.000, train_acc = 1.000 (3.346 sec/step)\n",
      "step 73160 \t loss = 0.001, train_acc = 1.000 (3.311 sec/step)\n",
      "step 73170 \t loss = 0.476, train_acc = 0.800 (3.327 sec/step)\n",
      "step 73180 \t loss = 0.396, train_acc = 0.900 (3.364 sec/step)\n",
      "step 73190 \t loss = 0.845, train_acc = 0.900 (3.368 sec/step)\n",
      "step 73200 \t loss = 0.053, train_acc = 1.000 (3.365 sec/step)\n",
      "step 73210 \t loss = 0.131, train_acc = 0.900 (3.366 sec/step)\n",
      "step 73220 \t loss = 0.001, train_acc = 1.000 (3.320 sec/step)\n",
      "step 73230 \t loss = 0.003, train_acc = 1.000 (3.367 sec/step)\n",
      "step 73240 \t loss = 0.102, train_acc = 1.000 (3.337 sec/step)\n",
      "step 73250 \t loss = 0.119, train_acc = 0.900 (3.313 sec/step)\n",
      "step 73260 \t loss = 0.370, train_acc = 0.800 (3.308 sec/step)\n",
      "step 73270 \t loss = 0.126, train_acc = 0.900 (3.330 sec/step)\n",
      "step 73280 \t loss = 1.347, train_acc = 0.800 (3.324 sec/step)\n",
      "step 73290 \t loss = 0.105, train_acc = 0.900 (3.366 sec/step)\n",
      "step 73300 \t loss = 0.043, train_acc = 1.000 (3.365 sec/step)\n",
      "step 73310 \t loss = 0.469, train_acc = 0.900 (3.316 sec/step)\n",
      "step 73320 \t loss = 0.130, train_acc = 0.900 (3.313 sec/step)\n",
      "step 73330 \t loss = 0.024, train_acc = 1.000 (3.339 sec/step)\n",
      "step 73340 \t loss = 0.153, train_acc = 0.900 (3.322 sec/step)\n",
      "step 73350 \t loss = 0.081, train_acc = 0.900 (3.344 sec/step)\n",
      "step 73360 \t loss = 0.268, train_acc = 0.900 (3.307 sec/step)\n",
      "step 73370 \t loss = 0.122, train_acc = 0.900 (3.360 sec/step)\n",
      "step 73380 \t loss = 0.022, train_acc = 1.000 (3.467 sec/step)\n",
      "step 73390 \t loss = 0.002, train_acc = 1.000 (3.331 sec/step)\n",
      "step 73400 \t loss = 1.210, train_acc = 0.900 (3.358 sec/step)\n",
      "step 73410 \t loss = 0.438, train_acc = 0.900 (3.331 sec/step)\n",
      "step 73420 \t loss = 0.381, train_acc = 0.900 (3.381 sec/step)\n",
      "step 73430 \t loss = 0.068, train_acc = 1.000 (3.386 sec/step)\n",
      "step 73440 \t loss = 0.082, train_acc = 0.900 (3.322 sec/step)\n",
      "step 73450 \t loss = 0.198, train_acc = 0.900 (3.339 sec/step)\n",
      "step 73460 \t loss = 0.000, train_acc = 1.000 (3.365 sec/step)\n",
      "step 73470 \t loss = 0.505, train_acc = 0.800 (3.378 sec/step)\n",
      "step 73480 \t loss = 0.129, train_acc = 1.000 (3.302 sec/step)\n",
      "step 73490 \t loss = 1.487, train_acc = 0.700 (3.301 sec/step)\n",
      "step 73500 \t loss = 0.944, train_acc = 0.800 (3.356 sec/step)\n",
      "step 73510 \t loss = 0.113, train_acc = 1.000 (3.364 sec/step)\n",
      "step 73520 \t loss = 0.001, train_acc = 1.000 (3.322 sec/step)\n",
      "step 73530 \t loss = 0.110, train_acc = 1.000 (3.353 sec/step)\n",
      "step 73540 \t loss = 0.281, train_acc = 0.900 (3.341 sec/step)\n",
      "step 73550 \t loss = 0.681, train_acc = 0.800 (3.308 sec/step)\n",
      "step 73560 \t loss = 0.016, train_acc = 1.000 (3.333 sec/step)\n",
      "step 73570 \t loss = 0.145, train_acc = 0.900 (3.361 sec/step)\n",
      "step 73580 \t loss = 0.168, train_acc = 0.900 (3.288 sec/step)\n",
      "step 73590 \t loss = 0.834, train_acc = 0.700 (3.345 sec/step)\n",
      "step 73600 \t loss = 0.021, train_acc = 1.000 (3.309 sec/step)\n",
      "step 73610 \t loss = 0.530, train_acc = 0.900 (3.314 sec/step)\n",
      "step 73620 \t loss = 0.189, train_acc = 0.900 (3.378 sec/step)\n",
      "step 73630 \t loss = 0.017, train_acc = 1.000 (3.334 sec/step)\n",
      "step 73640 \t loss = 0.009, train_acc = 1.000 (3.354 sec/step)\n",
      "step 73650 \t loss = 0.003, train_acc = 1.000 (3.303 sec/step)\n",
      "step 73660 \t loss = 0.005, train_acc = 1.000 (3.338 sec/step)\n",
      "step 73670 \t loss = 0.533, train_acc = 0.900 (3.382 sec/step)\n",
      "step 73680 \t loss = 0.409, train_acc = 0.800 (3.327 sec/step)\n",
      "step 73690 \t loss = 0.000, train_acc = 1.000 (3.317 sec/step)\n",
      "step 73700 \t loss = 0.010, train_acc = 1.000 (3.359 sec/step)\n",
      "step 73710 \t loss = 0.010, train_acc = 1.000 (3.361 sec/step)\n",
      "step 73720 \t loss = 0.053, train_acc = 1.000 (3.370 sec/step)\n",
      "step 73730 \t loss = 0.073, train_acc = 1.000 (3.392 sec/step)\n",
      "step 73740 \t loss = 0.069, train_acc = 1.000 (3.349 sec/step)\n",
      "step 73750 \t loss = 0.072, train_acc = 1.000 (3.356 sec/step)\n",
      "step 73760 \t loss = 0.011, train_acc = 1.000 (3.365 sec/step)\n",
      "step 73770 \t loss = 0.169, train_acc = 0.900 (3.329 sec/step)\n",
      "step 73780 \t loss = 0.049, train_acc = 1.000 (3.319 sec/step)\n",
      "step 73790 \t loss = 0.003, train_acc = 1.000 (3.365 sec/step)\n",
      "step 73800 \t loss = 0.040, train_acc = 1.000 (3.279 sec/step)\n",
      "step 73810 \t loss = 0.002, train_acc = 1.000 (3.352 sec/step)\n",
      "step 73820 \t loss = 0.000, train_acc = 1.000 (3.357 sec/step)\n",
      "step 73830 \t loss = 0.086, train_acc = 1.000 (3.346 sec/step)\n",
      "step 73840 \t loss = 1.437, train_acc = 0.900 (3.369 sec/step)\n",
      "step 73850 \t loss = 0.612, train_acc = 0.800 (3.285 sec/step)\n",
      "step 73860 \t loss = 0.553, train_acc = 0.800 (3.297 sec/step)\n",
      "step 73870 \t loss = 0.000, train_acc = 1.000 (3.374 sec/step)\n",
      "step 73880 \t loss = 0.000, train_acc = 1.000 (3.326 sec/step)\n",
      "step 73890 \t loss = 0.004, train_acc = 1.000 (3.365 sec/step)\n",
      "step 73900 \t loss = 0.348, train_acc = 0.900 (3.375 sec/step)\n",
      "step 73910 \t loss = 0.000, train_acc = 1.000 (3.406 sec/step)\n",
      "step 73920 \t loss = 0.009, train_acc = 1.000 (3.324 sec/step)\n",
      "step 73930 \t loss = 0.153, train_acc = 0.900 (3.315 sec/step)\n",
      "step 73940 \t loss = 0.006, train_acc = 1.000 (3.376 sec/step)\n",
      "step 73950 \t loss = 0.279, train_acc = 0.900 (3.356 sec/step)\n",
      "step 73960 \t loss = 0.042, train_acc = 1.000 (3.359 sec/step)\n",
      "step 73970 \t loss = 0.000, train_acc = 1.000 (3.478 sec/step)\n",
      "step 73980 \t loss = 0.568, train_acc = 0.900 (3.320 sec/step)\n",
      "step 73990 \t loss = 0.036, train_acc = 1.000 (3.320 sec/step)\n",
      "step 74000 \t loss = 0.001, train_acc = 1.000 (3.383 sec/step)\n",
      "step 74010 \t loss = 0.009, train_acc = 1.000 (3.365 sec/step)\n",
      "step 74020 \t loss = 0.033, train_acc = 1.000 (3.318 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 74030 \t loss = 0.001, train_acc = 1.000 (3.337 sec/step)\n",
      "step 74040 \t loss = 0.169, train_acc = 0.900 (3.365 sec/step)\n",
      "step 74050 \t loss = 0.521, train_acc = 0.900 (3.323 sec/step)\n",
      "step 74060 \t loss = 0.034, train_acc = 1.000 (3.389 sec/step)\n",
      "step 74070 \t loss = 0.036, train_acc = 1.000 (3.370 sec/step)\n",
      "step 74080 \t loss = 0.230, train_acc = 0.900 (3.337 sec/step)\n",
      "step 74090 \t loss = 0.594, train_acc = 0.800 (3.366 sec/step)\n",
      "VALIDATION \t acc = 0.567 (3.636 sec)\n",
      "New Best Accuracy 0.567 > Old Best 0.565.  Saving...\n",
      "The checkpoint has been created.\n",
      "step 74100 \t loss = 0.001, train_acc = 1.000 (3.373 sec/step)\n",
      "step 74110 \t loss = 0.001, train_acc = 1.000 (3.382 sec/step)\n",
      "step 74120 \t loss = 0.001, train_acc = 1.000 (3.396 sec/step)\n",
      "step 74130 \t loss = 0.585, train_acc = 0.800 (3.354 sec/step)\n",
      "step 74140 \t loss = 0.004, train_acc = 1.000 (3.389 sec/step)\n",
      "step 74150 \t loss = 0.239, train_acc = 0.800 (3.380 sec/step)\n",
      "step 74160 \t loss = 0.272, train_acc = 0.900 (3.352 sec/step)\n",
      "step 74170 \t loss = 0.051, train_acc = 1.000 (3.303 sec/step)\n",
      "step 74180 \t loss = 0.000, train_acc = 1.000 (3.327 sec/step)\n",
      "step 74190 \t loss = 0.358, train_acc = 0.900 (3.315 sec/step)\n",
      "step 74200 \t loss = 0.014, train_acc = 1.000 (3.346 sec/step)\n",
      "step 74210 \t loss = 0.026, train_acc = 1.000 (3.318 sec/step)\n",
      "step 74220 \t loss = 0.898, train_acc = 0.900 (3.348 sec/step)\n",
      "step 74230 \t loss = 0.163, train_acc = 0.900 (3.374 sec/step)\n",
      "step 74240 \t loss = 0.040, train_acc = 1.000 (3.348 sec/step)\n",
      "step 74250 \t loss = 0.204, train_acc = 0.900 (3.369 sec/step)\n",
      "step 74260 \t loss = 0.044, train_acc = 1.000 (3.378 sec/step)\n",
      "step 74270 \t loss = 0.004, train_acc = 1.000 (3.299 sec/step)\n",
      "step 74280 \t loss = 0.010, train_acc = 1.000 (3.343 sec/step)\n",
      "step 74290 \t loss = 0.558, train_acc = 0.900 (3.384 sec/step)\n",
      "step 74300 \t loss = 0.354, train_acc = 0.900 (3.363 sec/step)\n",
      "step 74310 \t loss = 0.055, train_acc = 1.000 (3.387 sec/step)\n",
      "step 74320 \t loss = 0.000, train_acc = 1.000 (3.342 sec/step)\n",
      "step 74330 \t loss = 0.001, train_acc = 1.000 (3.388 sec/step)\n",
      "step 74340 \t loss = 0.072, train_acc = 1.000 (3.351 sec/step)\n",
      "step 74350 \t loss = 0.007, train_acc = 1.000 (3.303 sec/step)\n",
      "step 74360 \t loss = 0.151, train_acc = 1.000 (3.338 sec/step)\n",
      "step 74370 \t loss = 0.064, train_acc = 1.000 (3.359 sec/step)\n",
      "step 74380 \t loss = 0.067, train_acc = 1.000 (3.370 sec/step)\n",
      "step 74390 \t loss = 1.199, train_acc = 0.600 (3.294 sec/step)\n",
      "step 74400 \t loss = 1.026, train_acc = 0.700 (3.335 sec/step)\n",
      "step 74410 \t loss = 0.694, train_acc = 0.800 (3.325 sec/step)\n",
      "step 74420 \t loss = 0.676, train_acc = 0.700 (3.406 sec/step)\n",
      "step 74430 \t loss = 1.819, train_acc = 0.700 (3.343 sec/step)\n",
      "step 74440 \t loss = 2.009, train_acc = 0.700 (3.384 sec/step)\n",
      "step 74450 \t loss = 0.003, train_acc = 1.000 (3.327 sec/step)\n",
      "step 74460 \t loss = 0.164, train_acc = 0.900 (3.351 sec/step)\n",
      "step 74470 \t loss = 0.005, train_acc = 1.000 (3.332 sec/step)\n",
      "step 74480 \t loss = 0.038, train_acc = 1.000 (3.312 sec/step)\n",
      "step 74490 \t loss = 0.304, train_acc = 0.900 (3.403 sec/step)\n",
      "step 74500 \t loss = 0.228, train_acc = 0.900 (3.333 sec/step)\n",
      "step 74510 \t loss = 0.203, train_acc = 0.900 (3.341 sec/step)\n",
      "step 74520 \t loss = 0.035, train_acc = 1.000 (3.316 sec/step)\n",
      "step 74530 \t loss = 0.009, train_acc = 1.000 (3.328 sec/step)\n",
      "step 74540 \t loss = 0.504, train_acc = 0.900 (3.335 sec/step)\n",
      "step 74550 \t loss = 0.658, train_acc = 0.800 (3.375 sec/step)\n",
      "step 74560 \t loss = 0.130, train_acc = 0.900 (3.367 sec/step)\n",
      "step 74570 \t loss = 0.531, train_acc = 0.900 (3.313 sec/step)\n",
      "step 74580 \t loss = 0.356, train_acc = 0.900 (3.314 sec/step)\n",
      "step 74590 \t loss = 0.018, train_acc = 1.000 (3.302 sec/step)\n",
      "step 74600 \t loss = 0.007, train_acc = 1.000 (3.367 sec/step)\n",
      "step 74610 \t loss = 0.121, train_acc = 0.900 (3.383 sec/step)\n",
      "step 74620 \t loss = 0.089, train_acc = 1.000 (3.403 sec/step)\n",
      "step 74630 \t loss = 0.421, train_acc = 0.900 (3.323 sec/step)\n",
      "step 74640 \t loss = 0.279, train_acc = 0.800 (3.314 sec/step)\n",
      "step 74650 \t loss = 0.232, train_acc = 0.900 (3.342 sec/step)\n",
      "step 74660 \t loss = 0.000, train_acc = 1.000 (3.393 sec/step)\n",
      "step 74670 \t loss = 0.076, train_acc = 0.900 (3.360 sec/step)\n",
      "step 74680 \t loss = 0.388, train_acc = 0.900 (3.360 sec/step)\n",
      "step 74690 \t loss = 0.006, train_acc = 1.000 (3.395 sec/step)\n",
      "step 74700 \t loss = 0.043, train_acc = 1.000 (3.314 sec/step)\n",
      "step 74710 \t loss = 0.306, train_acc = 0.900 (3.347 sec/step)\n",
      "step 74720 \t loss = 0.014, train_acc = 1.000 (3.293 sec/step)\n",
      "step 74730 \t loss = 0.253, train_acc = 0.900 (3.327 sec/step)\n",
      "step 74740 \t loss = 0.022, train_acc = 1.000 (3.353 sec/step)\n",
      "step 74750 \t loss = 0.415, train_acc = 0.900 (3.396 sec/step)\n",
      "step 74760 \t loss = 0.000, train_acc = 1.000 (3.396 sec/step)\n",
      "step 74770 \t loss = 0.403, train_acc = 0.900 (3.352 sec/step)\n",
      "step 74780 \t loss = 0.001, train_acc = 1.000 (3.308 sec/step)\n",
      "step 74790 \t loss = 1.747, train_acc = 0.900 (3.347 sec/step)\n",
      "step 74800 \t loss = 0.021, train_acc = 1.000 (3.334 sec/step)\n",
      "step 74810 \t loss = 0.294, train_acc = 0.900 (3.357 sec/step)\n",
      "step 74820 \t loss = 0.001, train_acc = 1.000 (3.315 sec/step)\n",
      "step 74830 \t loss = 0.952, train_acc = 0.900 (3.368 sec/step)\n",
      "step 74840 \t loss = 0.000, train_acc = 1.000 (3.351 sec/step)\n",
      "step 74850 \t loss = 0.091, train_acc = 1.000 (3.379 sec/step)\n",
      "step 74860 \t loss = 0.016, train_acc = 1.000 (3.343 sec/step)\n",
      "step 74870 \t loss = 0.001, train_acc = 1.000 (3.392 sec/step)\n",
      "step 74880 \t loss = 0.055, train_acc = 1.000 (3.375 sec/step)\n",
      "step 74890 \t loss = 0.000, train_acc = 1.000 (3.443 sec/step)\n",
      "step 74900 \t loss = 0.652, train_acc = 0.800 (3.318 sec/step)\n",
      "step 74910 \t loss = 0.221, train_acc = 0.900 (3.295 sec/step)\n",
      "step 74920 \t loss = 0.078, train_acc = 1.000 (3.314 sec/step)\n",
      "step 74930 \t loss = 0.006, train_acc = 1.000 (3.349 sec/step)\n",
      "step 74940 \t loss = 0.229, train_acc = 0.900 (3.375 sec/step)\n",
      "step 74950 \t loss = 0.000, train_acc = 1.000 (3.361 sec/step)\n",
      "step 74960 \t loss = 0.007, train_acc = 1.000 (3.388 sec/step)\n",
      "step 74970 \t loss = 0.023, train_acc = 1.000 (3.293 sec/step)\n",
      "step 74980 \t loss = 0.000, train_acc = 1.000 (3.370 sec/step)\n",
      "step 74990 \t loss = 0.010, train_acc = 1.000 (3.375 sec/step)\n",
      "step 75000 \t loss = 0.086, train_acc = 0.900 (3.343 sec/step)\n",
      "step 75010 \t loss = 0.005, train_acc = 1.000 (3.325 sec/step)\n",
      "step 75020 \t loss = 0.006, train_acc = 1.000 (3.364 sec/step)\n",
      "step 75030 \t loss = 0.009, train_acc = 1.000 (3.295 sec/step)\n",
      "step 75040 \t loss = 0.884, train_acc = 0.800 (3.351 sec/step)\n",
      "step 75050 \t loss = 0.092, train_acc = 0.900 (3.324 sec/step)\n",
      "step 75060 \t loss = 0.001, train_acc = 1.000 (3.456 sec/step)\n",
      "step 75070 \t loss = 0.007, train_acc = 1.000 (3.367 sec/step)\n",
      "step 75080 \t loss = 0.544, train_acc = 0.900 (3.386 sec/step)\n",
      "step 75090 \t loss = 0.435, train_acc = 0.700 (3.349 sec/step)\n",
      "step 75100 \t loss = 0.027, train_acc = 1.000 (3.340 sec/step)\n",
      "step 75110 \t loss = 0.376, train_acc = 0.800 (3.369 sec/step)\n",
      "step 75120 \t loss = 0.012, train_acc = 1.000 (3.334 sec/step)\n",
      "step 75130 \t loss = 0.002, train_acc = 1.000 (3.343 sec/step)\n",
      "step 75140 \t loss = 0.131, train_acc = 0.900 (3.350 sec/step)\n",
      "step 75150 \t loss = 0.049, train_acc = 1.000 (3.350 sec/step)\n",
      "step 75160 \t loss = 0.858, train_acc = 0.900 (3.371 sec/step)\n",
      "step 75170 \t loss = 0.157, train_acc = 0.900 (3.389 sec/step)\n",
      "step 75180 \t loss = 0.303, train_acc = 0.900 (3.373 sec/step)\n",
      "step 75190 \t loss = 0.030, train_acc = 1.000 (3.351 sec/step)\n",
      "step 75200 \t loss = 0.147, train_acc = 0.900 (3.348 sec/step)\n",
      "step 75210 \t loss = 0.001, train_acc = 1.000 (3.354 sec/step)\n",
      "step 75220 \t loss = 0.001, train_acc = 1.000 (3.399 sec/step)\n",
      "step 75230 \t loss = 0.564, train_acc = 0.800 (3.377 sec/step)\n",
      "step 75240 \t loss = 0.134, train_acc = 0.900 (3.386 sec/step)\n",
      "step 75250 \t loss = 0.003, train_acc = 1.000 (3.319 sec/step)\n",
      "step 75260 \t loss = 0.000, train_acc = 1.000 (3.349 sec/step)\n",
      "step 75270 \t loss = 0.172, train_acc = 0.900 (3.417 sec/step)\n",
      "step 75280 \t loss = 0.052, train_acc = 1.000 (3.368 sec/step)\n",
      "step 75290 \t loss = 0.004, train_acc = 1.000 (3.397 sec/step)\n",
      "step 75300 \t loss = 0.003, train_acc = 1.000 (3.422 sec/step)\n",
      "step 75310 \t loss = 0.035, train_acc = 1.000 (3.327 sec/step)\n",
      "step 75320 \t loss = 0.003, train_acc = 1.000 (3.359 sec/step)\n",
      "step 75330 \t loss = 0.450, train_acc = 0.900 (3.330 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 75340 \t loss = 0.018, train_acc = 1.000 (3.300 sec/step)\n",
      "step 75350 \t loss = 0.055, train_acc = 1.000 (3.395 sec/step)\n",
      "step 75360 \t loss = 0.058, train_acc = 1.000 (3.298 sec/step)\n",
      "step 75370 \t loss = 0.200, train_acc = 0.900 (3.343 sec/step)\n",
      "step 75380 \t loss = 0.089, train_acc = 1.000 (3.362 sec/step)\n",
      "step 75390 \t loss = 0.004, train_acc = 1.000 (3.335 sec/step)\n",
      "step 75400 \t loss = 0.069, train_acc = 1.000 (3.298 sec/step)\n",
      "step 75410 \t loss = 0.000, train_acc = 1.000 (3.367 sec/step)\n",
      "step 75420 \t loss = 0.017, train_acc = 1.000 (3.328 sec/step)\n",
      "step 75430 \t loss = 0.231, train_acc = 0.900 (3.333 sec/step)\n",
      "step 75440 \t loss = 0.161, train_acc = 0.900 (3.338 sec/step)\n",
      "step 75450 \t loss = 0.173, train_acc = 0.900 (3.352 sec/step)\n",
      "step 75460 \t loss = 0.157, train_acc = 0.900 (3.353 sec/step)\n",
      "step 75470 \t loss = 0.003, train_acc = 1.000 (3.369 sec/step)\n",
      "step 75480 \t loss = 0.021, train_acc = 1.000 (3.364 sec/step)\n",
      "step 75490 \t loss = 0.002, train_acc = 1.000 (3.320 sec/step)\n",
      "step 75500 \t loss = 0.100, train_acc = 0.900 (3.358 sec/step)\n",
      "step 75510 \t loss = 0.000, train_acc = 1.000 (3.404 sec/step)\n",
      "step 75520 \t loss = 0.330, train_acc = 0.900 (3.352 sec/step)\n",
      "step 75530 \t loss = 0.033, train_acc = 1.000 (3.364 sec/step)\n",
      "step 75540 \t loss = 0.036, train_acc = 1.000 (3.314 sec/step)\n",
      "step 75550 \t loss = 0.744, train_acc = 0.800 (3.322 sec/step)\n",
      "step 75560 \t loss = 0.296, train_acc = 0.900 (3.348 sec/step)\n",
      "step 75570 \t loss = 0.034, train_acc = 1.000 (3.306 sec/step)\n",
      "step 75580 \t loss = 0.023, train_acc = 1.000 (3.359 sec/step)\n",
      "step 75590 \t loss = 0.012, train_acc = 1.000 (3.359 sec/step)\n",
      "step 75600 \t loss = 0.047, train_acc = 1.000 (3.345 sec/step)\n",
      "step 75610 \t loss = 1.568, train_acc = 0.700 (3.381 sec/step)\n",
      "step 75620 \t loss = 0.199, train_acc = 0.900 (3.371 sec/step)\n",
      "step 75630 \t loss = 0.038, train_acc = 1.000 (3.335 sec/step)\n",
      "step 75640 \t loss = 0.025, train_acc = 1.000 (3.358 sec/step)\n",
      "step 75650 \t loss = 0.116, train_acc = 0.900 (3.370 sec/step)\n",
      "step 75660 \t loss = 0.940, train_acc = 0.900 (3.320 sec/step)\n",
      "step 75670 \t loss = 0.533, train_acc = 0.800 (3.338 sec/step)\n",
      "step 75680 \t loss = 0.527, train_acc = 0.800 (3.317 sec/step)\n",
      "step 75690 \t loss = 0.001, train_acc = 1.000 (3.328 sec/step)\n",
      "step 75700 \t loss = 0.037, train_acc = 1.000 (3.358 sec/step)\n",
      "step 75710 \t loss = 0.033, train_acc = 1.000 (3.345 sec/step)\n",
      "step 75720 \t loss = 0.233, train_acc = 0.800 (3.410 sec/step)\n",
      "step 75730 \t loss = 0.543, train_acc = 0.800 (3.333 sec/step)\n",
      "step 75740 \t loss = 0.567, train_acc = 0.800 (3.318 sec/step)\n",
      "step 75750 \t loss = 0.828, train_acc = 0.800 (3.300 sec/step)\n",
      "step 75760 \t loss = 0.714, train_acc = 0.800 (3.328 sec/step)\n",
      "step 75770 \t loss = 0.986, train_acc = 0.800 (3.321 sec/step)\n",
      "step 75780 \t loss = 0.271, train_acc = 0.800 (3.439 sec/step)\n",
      "step 75790 \t loss = 1.535, train_acc = 0.900 (3.353 sec/step)\n",
      "step 75800 \t loss = 0.000, train_acc = 1.000 (3.358 sec/step)\n",
      "step 75810 \t loss = 0.136, train_acc = 1.000 (3.322 sec/step)\n",
      "step 75820 \t loss = 0.938, train_acc = 0.700 (3.377 sec/step)\n",
      "step 75830 \t loss = 0.235, train_acc = 1.000 (3.348 sec/step)\n",
      "step 75840 \t loss = 0.014, train_acc = 1.000 (3.358 sec/step)\n",
      "step 75850 \t loss = 0.828, train_acc = 0.800 (3.344 sec/step)\n",
      "step 75860 \t loss = 0.030, train_acc = 1.000 (3.334 sec/step)\n",
      "step 75870 \t loss = 0.022, train_acc = 1.000 (3.332 sec/step)\n",
      "step 75880 \t loss = 0.142, train_acc = 1.000 (3.346 sec/step)\n",
      "step 75890 \t loss = 0.000, train_acc = 1.000 (3.407 sec/step)\n",
      "step 75900 \t loss = 0.542, train_acc = 0.800 (3.308 sec/step)\n",
      "step 75910 \t loss = 0.156, train_acc = 0.900 (3.308 sec/step)\n",
      "step 75920 \t loss = 0.298, train_acc = 0.800 (3.343 sec/step)\n",
      "step 75930 \t loss = 0.027, train_acc = 1.000 (3.346 sec/step)\n",
      "step 75940 \t loss = 0.078, train_acc = 1.000 (3.293 sec/step)\n",
      "step 75950 \t loss = 0.004, train_acc = 1.000 (3.389 sec/step)\n",
      "step 75960 \t loss = 0.102, train_acc = 0.900 (3.326 sec/step)\n",
      "step 75970 \t loss = 0.004, train_acc = 1.000 (3.340 sec/step)\n",
      "step 75980 \t loss = 0.004, train_acc = 1.000 (3.389 sec/step)\n",
      "step 75990 \t loss = 0.172, train_acc = 0.900 (3.398 sec/step)\n",
      "VALIDATION \t acc = 0.562 (3.647 sec)\n",
      "step 76000 \t loss = 0.075, train_acc = 1.000 (3.342 sec/step)\n",
      "step 76010 \t loss = 0.004, train_acc = 1.000 (3.335 sec/step)\n",
      "step 76020 \t loss = 0.001, train_acc = 1.000 (3.385 sec/step)\n",
      "step 76030 \t loss = 0.002, train_acc = 1.000 (3.337 sec/step)\n",
      "step 76040 \t loss = 0.001, train_acc = 1.000 (3.375 sec/step)\n",
      "step 76050 \t loss = 0.425, train_acc = 0.900 (3.365 sec/step)\n",
      "step 76060 \t loss = 0.007, train_acc = 1.000 (3.309 sec/step)\n",
      "step 76070 \t loss = 0.087, train_acc = 1.000 (3.293 sec/step)\n",
      "step 76080 \t loss = 0.590, train_acc = 0.800 (3.420 sec/step)\n",
      "step 76090 \t loss = 0.006, train_acc = 1.000 (3.305 sec/step)\n",
      "step 76100 \t loss = 0.024, train_acc = 1.000 (3.372 sec/step)\n",
      "step 76110 \t loss = 0.220, train_acc = 0.900 (3.344 sec/step)\n",
      "step 76120 \t loss = 0.113, train_acc = 1.000 (3.330 sec/step)\n",
      "step 76130 \t loss = 0.006, train_acc = 1.000 (3.351 sec/step)\n",
      "step 76140 \t loss = 0.001, train_acc = 1.000 (3.449 sec/step)\n",
      "step 76150 \t loss = 0.006, train_acc = 1.000 (3.316 sec/step)\n",
      "step 76160 \t loss = 0.052, train_acc = 1.000 (3.319 sec/step)\n",
      "step 76170 \t loss = 5.901, train_acc = 0.800 (3.321 sec/step)\n",
      "step 76180 \t loss = 0.341, train_acc = 0.900 (3.359 sec/step)\n",
      "step 76190 \t loss = 0.181, train_acc = 1.000 (3.304 sec/step)\n",
      "step 76200 \t loss = 0.143, train_acc = 1.000 (3.367 sec/step)\n",
      "step 76210 \t loss = 0.864, train_acc = 0.800 (3.339 sec/step)\n",
      "step 76220 \t loss = 0.176, train_acc = 0.900 (3.345 sec/step)\n",
      "step 76230 \t loss = 0.002, train_acc = 1.000 (3.331 sec/step)\n",
      "step 76240 \t loss = 1.145, train_acc = 0.800 (3.312 sec/step)\n",
      "step 76250 \t loss = 0.466, train_acc = 0.900 (3.355 sec/step)\n",
      "step 76260 \t loss = 0.028, train_acc = 1.000 (3.351 sec/step)\n",
      "step 76270 \t loss = 0.219, train_acc = 0.900 (3.344 sec/step)\n",
      "step 76280 \t loss = 0.105, train_acc = 1.000 (3.336 sec/step)\n",
      "step 76290 \t loss = 0.003, train_acc = 1.000 (3.297 sec/step)\n",
      "step 76300 \t loss = 0.000, train_acc = 1.000 (3.394 sec/step)\n",
      "step 76310 \t loss = 0.237, train_acc = 0.900 (3.319 sec/step)\n",
      "step 76320 \t loss = 0.770, train_acc = 0.900 (3.361 sec/step)\n",
      "step 76330 \t loss = 0.045, train_acc = 1.000 (3.317 sec/step)\n",
      "step 76340 \t loss = 0.004, train_acc = 1.000 (3.308 sec/step)\n",
      "step 76350 \t loss = 0.001, train_acc = 1.000 (3.382 sec/step)\n",
      "step 76360 \t loss = 0.062, train_acc = 1.000 (3.385 sec/step)\n",
      "step 76370 \t loss = 0.000, train_acc = 1.000 (3.321 sec/step)\n",
      "step 76380 \t loss = 0.297, train_acc = 0.900 (3.327 sec/step)\n",
      "step 76390 \t loss = 0.002, train_acc = 1.000 (3.323 sec/step)\n",
      "step 76400 \t loss = 0.195, train_acc = 0.900 (3.302 sec/step)\n",
      "step 76410 \t loss = 0.998, train_acc = 0.700 (3.432 sec/step)\n",
      "step 76420 \t loss = 0.000, train_acc = 1.000 (3.305 sec/step)\n",
      "step 76430 \t loss = 0.107, train_acc = 0.900 (3.311 sec/step)\n",
      "step 76440 \t loss = 0.013, train_acc = 1.000 (3.306 sec/step)\n",
      "step 76450 \t loss = 0.023, train_acc = 1.000 (3.332 sec/step)\n",
      "step 76460 \t loss = 0.108, train_acc = 0.900 (3.353 sec/step)\n",
      "step 76470 \t loss = 0.522, train_acc = 0.900 (3.355 sec/step)\n",
      "step 76480 \t loss = 0.525, train_acc = 0.900 (3.298 sec/step)\n",
      "step 76490 \t loss = 0.502, train_acc = 0.900 (3.330 sec/step)\n",
      "step 76500 \t loss = 0.388, train_acc = 0.700 (3.383 sec/step)\n",
      "step 76510 \t loss = 0.002, train_acc = 1.000 (3.321 sec/step)\n",
      "step 76520 \t loss = 0.001, train_acc = 1.000 (3.323 sec/step)\n",
      "step 76530 \t loss = 0.504, train_acc = 0.800 (3.313 sec/step)\n",
      "step 76540 \t loss = 0.303, train_acc = 0.900 (3.384 sec/step)\n",
      "step 76550 \t loss = 0.142, train_acc = 0.900 (3.344 sec/step)\n",
      "step 76560 \t loss = 0.535, train_acc = 0.900 (3.381 sec/step)\n",
      "step 76570 \t loss = 0.079, train_acc = 1.000 (3.351 sec/step)\n",
      "step 76580 \t loss = 0.036, train_acc = 1.000 (3.370 sec/step)\n",
      "step 76590 \t loss = 0.036, train_acc = 1.000 (3.382 sec/step)\n",
      "step 76600 \t loss = 0.019, train_acc = 1.000 (3.381 sec/step)\n",
      "step 76610 \t loss = 0.024, train_acc = 1.000 (3.346 sec/step)\n",
      "step 76620 \t loss = 0.047, train_acc = 1.000 (3.371 sec/step)\n",
      "step 76630 \t loss = 0.790, train_acc = 0.800 (3.364 sec/step)\n",
      "step 76640 \t loss = 0.014, train_acc = 1.000 (3.348 sec/step)\n",
      "step 76650 \t loss = 0.004, train_acc = 1.000 (3.377 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 76660 \t loss = 0.051, train_acc = 1.000 (3.365 sec/step)\n",
      "step 76670 \t loss = 0.374, train_acc = 0.900 (3.412 sec/step)\n",
      "step 76680 \t loss = 0.080, train_acc = 1.000 (3.370 sec/step)\n",
      "step 76690 \t loss = 0.118, train_acc = 0.900 (3.345 sec/step)\n",
      "step 76700 \t loss = 0.418, train_acc = 0.900 (3.337 sec/step)\n",
      "step 76710 \t loss = 0.061, train_acc = 1.000 (3.338 sec/step)\n",
      "step 76720 \t loss = 0.453, train_acc = 0.900 (3.403 sec/step)\n",
      "step 76730 \t loss = 0.037, train_acc = 1.000 (3.397 sec/step)\n",
      "step 76740 \t loss = 0.023, train_acc = 1.000 (3.351 sec/step)\n",
      "step 76750 \t loss = 0.020, train_acc = 1.000 (3.334 sec/step)\n",
      "step 76760 \t loss = 0.296, train_acc = 0.900 (3.328 sec/step)\n",
      "step 76770 \t loss = 0.184, train_acc = 0.900 (3.339 sec/step)\n",
      "step 76780 \t loss = 0.128, train_acc = 0.900 (3.394 sec/step)\n",
      "step 76790 \t loss = 0.256, train_acc = 0.900 (3.321 sec/step)\n",
      "step 76800 \t loss = 0.584, train_acc = 0.800 (3.329 sec/step)\n",
      "step 76810 \t loss = 0.126, train_acc = 0.900 (3.349 sec/step)\n",
      "step 76820 \t loss = 0.042, train_acc = 1.000 (3.340 sec/step)\n",
      "step 76830 \t loss = 0.001, train_acc = 1.000 (3.360 sec/step)\n",
      "step 76840 \t loss = 0.047, train_acc = 1.000 (3.347 sec/step)\n",
      "step 76850 \t loss = 0.131, train_acc = 1.000 (3.336 sec/step)\n",
      "step 76860 \t loss = 0.320, train_acc = 0.900 (3.364 sec/step)\n",
      "step 76870 \t loss = 0.309, train_acc = 0.900 (3.313 sec/step)\n",
      "step 76880 \t loss = 0.001, train_acc = 1.000 (3.327 sec/step)\n",
      "step 76890 \t loss = 0.006, train_acc = 1.000 (3.308 sec/step)\n",
      "step 76900 \t loss = 0.011, train_acc = 1.000 (3.355 sec/step)\n",
      "step 76910 \t loss = 0.854, train_acc = 0.700 (3.368 sec/step)\n",
      "step 76920 \t loss = 0.089, train_acc = 0.900 (3.352 sec/step)\n",
      "step 76930 \t loss = 0.004, train_acc = 1.000 (3.303 sec/step)\n",
      "step 76940 \t loss = 0.075, train_acc = 1.000 (3.411 sec/step)\n",
      "step 76950 \t loss = 0.022, train_acc = 1.000 (3.360 sec/step)\n",
      "step 76960 \t loss = 0.044, train_acc = 1.000 (3.361 sec/step)\n",
      "step 76970 \t loss = 0.014, train_acc = 1.000 (3.326 sec/step)\n",
      "step 76980 \t loss = 2.429, train_acc = 0.800 (3.318 sec/step)\n",
      "step 76990 \t loss = 0.016, train_acc = 1.000 (3.309 sec/step)\n",
      "step 77000 \t loss = 0.108, train_acc = 0.900 (3.369 sec/step)\n",
      "step 77010 \t loss = 0.157, train_acc = 1.000 (3.342 sec/step)\n",
      "step 77020 \t loss = 0.036, train_acc = 1.000 (3.415 sec/step)\n",
      "step 77030 \t loss = 0.039, train_acc = 1.000 (3.376 sec/step)\n",
      "step 77040 \t loss = 0.247, train_acc = 0.900 (3.296 sec/step)\n",
      "step 77050 \t loss = 2.511, train_acc = 0.900 (3.344 sec/step)\n",
      "step 77060 \t loss = 0.417, train_acc = 0.800 (3.336 sec/step)\n",
      "step 77070 \t loss = 0.502, train_acc = 0.900 (3.386 sec/step)\n",
      "step 77080 \t loss = 1.226, train_acc = 0.800 (3.344 sec/step)\n",
      "step 77090 \t loss = 0.987, train_acc = 0.800 (3.324 sec/step)\n",
      "step 77100 \t loss = 0.244, train_acc = 0.900 (3.340 sec/step)\n",
      "step 77110 \t loss = 0.011, train_acc = 1.000 (3.344 sec/step)\n",
      "step 77120 \t loss = 0.030, train_acc = 1.000 (3.342 sec/step)\n",
      "step 77130 \t loss = 0.146, train_acc = 0.900 (3.358 sec/step)\n",
      "step 77140 \t loss = 0.100, train_acc = 0.900 (3.360 sec/step)\n",
      "step 77150 \t loss = 0.026, train_acc = 1.000 (3.375 sec/step)\n",
      "step 77160 \t loss = 0.113, train_acc = 1.000 (3.329 sec/step)\n",
      "step 77170 \t loss = 0.006, train_acc = 1.000 (3.341 sec/step)\n",
      "step 77180 \t loss = 0.056, train_acc = 1.000 (3.366 sec/step)\n",
      "step 77190 \t loss = 0.170, train_acc = 0.900 (3.347 sec/step)\n",
      "step 77200 \t loss = 0.004, train_acc = 1.000 (3.338 sec/step)\n",
      "step 77210 \t loss = 0.010, train_acc = 1.000 (3.346 sec/step)\n",
      "step 77220 \t loss = 0.015, train_acc = 1.000 (3.375 sec/step)\n",
      "step 77230 \t loss = 0.244, train_acc = 0.900 (3.323 sec/step)\n",
      "step 77240 \t loss = 0.077, train_acc = 0.900 (3.370 sec/step)\n",
      "step 77250 \t loss = 0.000, train_acc = 1.000 (3.383 sec/step)\n",
      "step 77260 \t loss = 0.246, train_acc = 0.900 (3.438 sec/step)\n",
      "step 77270 \t loss = 0.371, train_acc = 0.900 (3.393 sec/step)\n",
      "step 77280 \t loss = 0.003, train_acc = 1.000 (3.364 sec/step)\n",
      "step 77290 \t loss = 0.057, train_acc = 1.000 (3.357 sec/step)\n",
      "step 77300 \t loss = 0.000, train_acc = 1.000 (3.353 sec/step)\n",
      "step 77310 \t loss = 0.000, train_acc = 1.000 (3.382 sec/step)\n",
      "step 77320 \t loss = 0.021, train_acc = 1.000 (3.351 sec/step)\n",
      "step 77330 \t loss = 0.000, train_acc = 1.000 (3.438 sec/step)\n",
      "step 77340 \t loss = 0.132, train_acc = 0.900 (3.365 sec/step)\n",
      "step 77350 \t loss = 0.437, train_acc = 0.900 (3.310 sec/step)\n",
      "step 77360 \t loss = 0.181, train_acc = 0.900 (3.383 sec/step)\n",
      "step 77370 \t loss = 0.368, train_acc = 0.900 (3.323 sec/step)\n",
      "step 77380 \t loss = 0.035, train_acc = 1.000 (3.378 sec/step)\n",
      "step 77390 \t loss = 0.133, train_acc = 0.900 (3.306 sec/step)\n",
      "step 77400 \t loss = 0.219, train_acc = 0.900 (3.375 sec/step)\n",
      "step 77410 \t loss = 0.112, train_acc = 0.900 (3.321 sec/step)\n",
      "step 77420 \t loss = 0.028, train_acc = 1.000 (3.340 sec/step)\n",
      "step 77430 \t loss = 0.000, train_acc = 1.000 (3.328 sec/step)\n",
      "step 77440 \t loss = 0.237, train_acc = 0.900 (3.361 sec/step)\n",
      "step 77450 \t loss = 0.197, train_acc = 0.900 (3.306 sec/step)\n",
      "step 77460 \t loss = 0.053, train_acc = 1.000 (3.357 sec/step)\n",
      "step 77470 \t loss = 0.311, train_acc = 0.800 (3.359 sec/step)\n",
      "step 77480 \t loss = 0.857, train_acc = 0.900 (3.337 sec/step)\n",
      "step 77490 \t loss = 0.526, train_acc = 0.900 (3.325 sec/step)\n",
      "step 77500 \t loss = 0.089, train_acc = 1.000 (3.454 sec/step)\n",
      "step 77510 \t loss = 0.017, train_acc = 1.000 (3.441 sec/step)\n",
      "step 77520 \t loss = 0.000, train_acc = 1.000 (3.450 sec/step)\n",
      "step 77530 \t loss = 0.776, train_acc = 0.900 (3.315 sec/step)\n",
      "step 77540 \t loss = 0.015, train_acc = 1.000 (3.334 sec/step)\n",
      "step 77550 \t loss = 0.100, train_acc = 1.000 (3.394 sec/step)\n",
      "step 77560 \t loss = 0.626, train_acc = 0.800 (3.319 sec/step)\n",
      "step 77570 \t loss = 0.001, train_acc = 1.000 (3.355 sec/step)\n",
      "step 77580 \t loss = 0.004, train_acc = 1.000 (3.329 sec/step)\n",
      "step 77590 \t loss = 0.065, train_acc = 1.000 (3.332 sec/step)\n",
      "step 77600 \t loss = 0.005, train_acc = 1.000 (3.318 sec/step)\n",
      "step 77610 \t loss = 0.001, train_acc = 1.000 (3.432 sec/step)\n",
      "step 77620 \t loss = 0.080, train_acc = 0.900 (3.331 sec/step)\n",
      "step 77630 \t loss = 0.096, train_acc = 0.900 (3.338 sec/step)\n",
      "step 77640 \t loss = 0.002, train_acc = 1.000 (3.406 sec/step)\n",
      "step 77650 \t loss = 0.089, train_acc = 0.900 (3.342 sec/step)\n",
      "step 77660 \t loss = 0.897, train_acc = 0.800 (3.363 sec/step)\n",
      "step 77670 \t loss = 0.240, train_acc = 0.900 (3.370 sec/step)\n",
      "step 77680 \t loss = 0.024, train_acc = 1.000 (3.350 sec/step)\n",
      "step 77690 \t loss = 0.322, train_acc = 0.900 (3.350 sec/step)\n",
      "step 77700 \t loss = 0.081, train_acc = 0.900 (3.399 sec/step)\n",
      "step 77710 \t loss = 0.093, train_acc = 1.000 (3.332 sec/step)\n",
      "step 77720 \t loss = 0.069, train_acc = 1.000 (3.373 sec/step)\n",
      "step 77730 \t loss = 0.091, train_acc = 1.000 (3.361 sec/step)\n",
      "step 77740 \t loss = 0.006, train_acc = 1.000 (3.469 sec/step)\n",
      "step 77750 \t loss = 0.097, train_acc = 1.000 (3.350 sec/step)\n",
      "step 77760 \t loss = 0.266, train_acc = 0.900 (3.344 sec/step)\n",
      "step 77770 \t loss = 0.661, train_acc = 0.900 (3.353 sec/step)\n",
      "step 77780 \t loss = 0.394, train_acc = 0.900 (3.378 sec/step)\n",
      "step 77790 \t loss = 0.117, train_acc = 0.900 (3.333 sec/step)\n",
      "step 77800 \t loss = 1.358, train_acc = 0.800 (3.313 sec/step)\n",
      "step 77810 \t loss = 0.462, train_acc = 0.900 (3.353 sec/step)\n",
      "step 77820 \t loss = 0.029, train_acc = 1.000 (3.364 sec/step)\n",
      "step 77830 \t loss = 0.719, train_acc = 0.800 (3.398 sec/step)\n",
      "step 77840 \t loss = 0.091, train_acc = 0.900 (3.350 sec/step)\n",
      "step 77850 \t loss = 0.655, train_acc = 0.900 (3.360 sec/step)\n",
      "step 77860 \t loss = 0.008, train_acc = 1.000 (3.337 sec/step)\n",
      "step 77870 \t loss = 0.091, train_acc = 0.900 (3.398 sec/step)\n",
      "step 77880 \t loss = 0.017, train_acc = 1.000 (3.352 sec/step)\n",
      "step 77890 \t loss = 1.218, train_acc = 0.900 (3.315 sec/step)\n",
      "VALIDATION \t acc = 0.527 (3.627 sec)\n",
      "step 77900 \t loss = 0.098, train_acc = 1.000 (3.411 sec/step)\n",
      "step 77910 \t loss = 0.025, train_acc = 1.000 (3.305 sec/step)\n",
      "step 77920 \t loss = 0.220, train_acc = 0.900 (3.330 sec/step)\n",
      "step 77930 \t loss = 0.153, train_acc = 0.900 (3.402 sec/step)\n",
      "step 77940 \t loss = 0.007, train_acc = 1.000 (3.370 sec/step)\n",
      "step 77950 \t loss = 0.159, train_acc = 0.900 (3.338 sec/step)\n",
      "step 77960 \t loss = 0.085, train_acc = 0.900 (3.418 sec/step)\n",
      "step 77970 \t loss = 0.003, train_acc = 1.000 (3.326 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 77980 \t loss = 0.185, train_acc = 0.800 (3.333 sec/step)\n",
      "step 77990 \t loss = 0.003, train_acc = 1.000 (3.324 sec/step)\n",
      "step 78000 \t loss = 0.040, train_acc = 1.000 (3.356 sec/step)\n",
      "step 78010 \t loss = 0.008, train_acc = 1.000 (3.340 sec/step)\n",
      "step 78020 \t loss = 0.928, train_acc = 0.800 (3.354 sec/step)\n",
      "step 78030 \t loss = 0.003, train_acc = 1.000 (3.350 sec/step)\n",
      "step 78040 \t loss = 0.012, train_acc = 1.000 (3.371 sec/step)\n",
      "step 78050 \t loss = 0.347, train_acc = 0.900 (3.372 sec/step)\n",
      "step 78060 \t loss = 0.939, train_acc = 0.900 (3.406 sec/step)\n",
      "step 78070 \t loss = 0.034, train_acc = 1.000 (3.375 sec/step)\n",
      "step 78080 \t loss = 0.038, train_acc = 1.000 (3.330 sec/step)\n",
      "step 78090 \t loss = 0.104, train_acc = 1.000 (3.332 sec/step)\n",
      "step 78100 \t loss = 0.145, train_acc = 1.000 (3.381 sec/step)\n",
      "step 78110 \t loss = 0.104, train_acc = 1.000 (3.387 sec/step)\n",
      "step 78120 \t loss = 0.161, train_acc = 0.900 (3.439 sec/step)\n",
      "step 78130 \t loss = 0.000, train_acc = 1.000 (3.333 sec/step)\n",
      "step 78140 \t loss = 0.134, train_acc = 0.900 (3.305 sec/step)\n",
      "step 78150 \t loss = 0.067, train_acc = 1.000 (3.303 sec/step)\n",
      "step 78160 \t loss = 0.048, train_acc = 1.000 (3.375 sec/step)\n",
      "step 78170 \t loss = 2.449, train_acc = 0.700 (3.345 sec/step)\n",
      "step 78180 \t loss = 0.220, train_acc = 0.900 (3.331 sec/step)\n",
      "step 78190 \t loss = 0.247, train_acc = 0.900 (3.375 sec/step)\n",
      "step 78200 \t loss = 0.026, train_acc = 1.000 (3.326 sec/step)\n",
      "step 78210 \t loss = 2.128, train_acc = 0.900 (3.342 sec/step)\n",
      "step 78220 \t loss = 0.041, train_acc = 1.000 (3.340 sec/step)\n",
      "step 78230 \t loss = 0.041, train_acc = 1.000 (3.320 sec/step)\n",
      "step 78240 \t loss = 0.004, train_acc = 1.000 (3.332 sec/step)\n",
      "step 78250 \t loss = 0.002, train_acc = 1.000 (3.303 sec/step)\n",
      "step 78260 \t loss = 0.001, train_acc = 1.000 (3.347 sec/step)\n",
      "step 78270 \t loss = 0.037, train_acc = 1.000 (3.307 sec/step)\n",
      "step 78280 \t loss = 0.003, train_acc = 1.000 (3.387 sec/step)\n",
      "step 78290 \t loss = 0.013, train_acc = 1.000 (3.388 sec/step)\n",
      "step 78300 \t loss = 0.008, train_acc = 1.000 (3.380 sec/step)\n",
      "step 78310 \t loss = 0.008, train_acc = 1.000 (3.347 sec/step)\n",
      "step 78320 \t loss = 0.001, train_acc = 1.000 (3.324 sec/step)\n",
      "step 78330 \t loss = 0.328, train_acc = 0.900 (3.348 sec/step)\n",
      "step 78340 \t loss = 0.527, train_acc = 0.800 (3.379 sec/step)\n",
      "step 78350 \t loss = 0.003, train_acc = 1.000 (3.376 sec/step)\n",
      "step 78360 \t loss = 0.043, train_acc = 1.000 (3.345 sec/step)\n",
      "step 78370 \t loss = 0.037, train_acc = 1.000 (3.368 sec/step)\n",
      "step 78380 \t loss = 0.301, train_acc = 0.900 (3.362 sec/step)\n",
      "step 78390 \t loss = 0.029, train_acc = 1.000 (3.341 sec/step)\n",
      "step 78400 \t loss = 0.033, train_acc = 1.000 (3.342 sec/step)\n",
      "step 78410 \t loss = 0.015, train_acc = 1.000 (3.385 sec/step)\n",
      "step 78420 \t loss = 0.410, train_acc = 0.900 (3.326 sec/step)\n",
      "step 78430 \t loss = 1.462, train_acc = 0.600 (3.398 sec/step)\n",
      "step 78440 \t loss = 0.388, train_acc = 0.900 (3.313 sec/step)\n",
      "step 78450 \t loss = 0.285, train_acc = 0.900 (3.362 sec/step)\n",
      "step 78460 \t loss = 0.068, train_acc = 1.000 (3.371 sec/step)\n",
      "step 78470 \t loss = 0.391, train_acc = 0.900 (3.298 sec/step)\n",
      "step 78480 \t loss = 0.172, train_acc = 0.900 (3.342 sec/step)\n",
      "step 78490 \t loss = 0.007, train_acc = 1.000 (3.341 sec/step)\n",
      "step 78500 \t loss = 0.082, train_acc = 1.000 (3.307 sec/step)\n",
      "step 78510 \t loss = 0.329, train_acc = 0.900 (3.382 sec/step)\n",
      "step 78520 \t loss = 0.001, train_acc = 1.000 (3.346 sec/step)\n",
      "step 78530 \t loss = 0.500, train_acc = 0.900 (3.374 sec/step)\n",
      "step 78540 \t loss = 0.500, train_acc = 0.800 (3.412 sec/step)\n",
      "step 78550 \t loss = 0.178, train_acc = 0.900 (3.337 sec/step)\n",
      "step 78560 \t loss = 0.000, train_acc = 1.000 (3.331 sec/step)\n",
      "step 78570 \t loss = 0.005, train_acc = 1.000 (3.384 sec/step)\n",
      "step 78580 \t loss = 0.087, train_acc = 0.900 (3.338 sec/step)\n",
      "step 78590 \t loss = 0.001, train_acc = 1.000 (3.344 sec/step)\n",
      "step 78600 \t loss = 0.123, train_acc = 0.900 (3.353 sec/step)\n",
      "step 78610 \t loss = 0.167, train_acc = 0.900 (3.368 sec/step)\n",
      "step 78620 \t loss = 0.373, train_acc = 0.900 (3.383 sec/step)\n",
      "step 78630 \t loss = 0.173, train_acc = 0.900 (3.384 sec/step)\n",
      "step 78640 \t loss = 0.010, train_acc = 1.000 (3.353 sec/step)\n",
      "step 78650 \t loss = 0.000, train_acc = 1.000 (3.362 sec/step)\n",
      "step 78660 \t loss = 0.190, train_acc = 0.900 (3.363 sec/step)\n",
      "step 78670 \t loss = 0.033, train_acc = 1.000 (3.334 sec/step)\n",
      "step 78680 \t loss = 0.070, train_acc = 1.000 (3.305 sec/step)\n",
      "step 78690 \t loss = 0.053, train_acc = 1.000 (3.358 sec/step)\n",
      "step 78700 \t loss = 0.066, train_acc = 1.000 (3.360 sec/step)\n",
      "step 78710 \t loss = 0.000, train_acc = 1.000 (3.382 sec/step)\n",
      "step 78720 \t loss = 0.006, train_acc = 1.000 (3.352 sec/step)\n",
      "step 78730 \t loss = 0.007, train_acc = 1.000 (3.297 sec/step)\n",
      "step 78740 \t loss = 0.105, train_acc = 1.000 (3.332 sec/step)\n",
      "step 78750 \t loss = 0.249, train_acc = 0.900 (3.351 sec/step)\n",
      "step 78760 \t loss = 0.016, train_acc = 1.000 (3.363 sec/step)\n",
      "step 78770 \t loss = 1.158, train_acc = 0.900 (3.340 sec/step)\n",
      "step 78780 \t loss = 0.528, train_acc = 0.900 (3.332 sec/step)\n",
      "step 78790 \t loss = 0.000, train_acc = 1.000 (3.357 sec/step)\n",
      "step 78800 \t loss = 0.020, train_acc = 1.000 (3.329 sec/step)\n",
      "step 78810 \t loss = 0.174, train_acc = 0.900 (3.344 sec/step)\n",
      "step 78820 \t loss = 0.084, train_acc = 1.000 (3.339 sec/step)\n",
      "step 78830 \t loss = 0.018, train_acc = 1.000 (3.337 sec/step)\n",
      "step 78840 \t loss = 0.004, train_acc = 1.000 (3.345 sec/step)\n",
      "step 78850 \t loss = 0.000, train_acc = 1.000 (3.371 sec/step)\n",
      "step 78860 \t loss = 0.032, train_acc = 1.000 (3.304 sec/step)\n",
      "step 78870 \t loss = 0.002, train_acc = 1.000 (3.353 sec/step)\n",
      "step 78880 \t loss = 0.001, train_acc = 1.000 (3.318 sec/step)\n",
      "step 78890 \t loss = 0.112, train_acc = 0.900 (3.298 sec/step)\n",
      "step 78900 \t loss = 0.000, train_acc = 1.000 (3.316 sec/step)\n",
      "step 78910 \t loss = 0.030, train_acc = 1.000 (3.337 sec/step)\n",
      "step 78920 \t loss = 0.085, train_acc = 0.900 (3.378 sec/step)\n",
      "step 78930 \t loss = 0.010, train_acc = 1.000 (3.342 sec/step)\n",
      "step 78940 \t loss = 0.236, train_acc = 0.900 (3.337 sec/step)\n",
      "step 78950 \t loss = 0.239, train_acc = 0.900 (3.370 sec/step)\n",
      "step 78960 \t loss = 0.166, train_acc = 0.900 (3.303 sec/step)\n",
      "step 78970 \t loss = 0.003, train_acc = 1.000 (3.307 sec/step)\n",
      "step 78980 \t loss = 0.000, train_acc = 1.000 (3.332 sec/step)\n",
      "step 78990 \t loss = 0.428, train_acc = 0.900 (3.332 sec/step)\n",
      "step 79000 \t loss = 0.753, train_acc = 0.900 (3.300 sec/step)\n",
      "step 79010 \t loss = 0.001, train_acc = 1.000 (3.363 sec/step)\n",
      "step 79020 \t loss = 0.000, train_acc = 1.000 (3.301 sec/step)\n",
      "step 79030 \t loss = 0.028, train_acc = 1.000 (3.402 sec/step)\n",
      "step 79040 \t loss = 1.720, train_acc = 0.800 (3.352 sec/step)\n",
      "step 79050 \t loss = 0.519, train_acc = 0.800 (3.321 sec/step)\n",
      "step 79060 \t loss = 0.031, train_acc = 1.000 (3.334 sec/step)\n",
      "step 79070 \t loss = 0.251, train_acc = 0.900 (3.395 sec/step)\n",
      "step 79080 \t loss = 0.011, train_acc = 1.000 (3.326 sec/step)\n",
      "step 79090 \t loss = 0.009, train_acc = 1.000 (3.343 sec/step)\n",
      "step 79100 \t loss = 0.312, train_acc = 0.800 (3.353 sec/step)\n",
      "step 79110 \t loss = 0.336, train_acc = 0.900 (3.347 sec/step)\n",
      "step 79120 \t loss = 0.653, train_acc = 0.900 (3.404 sec/step)\n",
      "step 79130 \t loss = 0.002, train_acc = 1.000 (3.341 sec/step)\n",
      "step 79140 \t loss = 0.348, train_acc = 0.800 (3.327 sec/step)\n",
      "step 79150 \t loss = 0.901, train_acc = 0.700 (3.331 sec/step)\n",
      "step 79160 \t loss = 0.001, train_acc = 1.000 (3.327 sec/step)\n",
      "step 79170 \t loss = 0.019, train_acc = 1.000 (3.359 sec/step)\n",
      "step 79180 \t loss = 0.017, train_acc = 1.000 (3.340 sec/step)\n",
      "step 79190 \t loss = 0.824, train_acc = 0.900 (3.389 sec/step)\n",
      "step 79200 \t loss = 0.000, train_acc = 1.000 (3.360 sec/step)\n",
      "step 79210 \t loss = 0.565, train_acc = 0.800 (3.370 sec/step)\n",
      "step 79220 \t loss = 0.022, train_acc = 1.000 (3.385 sec/step)\n",
      "step 79230 \t loss = 0.006, train_acc = 1.000 (3.341 sec/step)\n",
      "step 79240 \t loss = 0.365, train_acc = 0.900 (3.382 sec/step)\n",
      "step 79250 \t loss = 0.071, train_acc = 1.000 (3.328 sec/step)\n",
      "step 79260 \t loss = 0.129, train_acc = 0.900 (3.380 sec/step)\n",
      "step 79270 \t loss = 0.224, train_acc = 0.800 (3.340 sec/step)\n",
      "step 79280 \t loss = 0.170, train_acc = 0.900 (3.319 sec/step)\n",
      "step 79290 \t loss = 0.248, train_acc = 0.900 (3.403 sec/step)\n",
      "step 79300 \t loss = 0.035, train_acc = 1.000 (3.354 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 79310 \t loss = 0.000, train_acc = 1.000 (3.353 sec/step)\n",
      "step 79320 \t loss = 0.278, train_acc = 0.900 (3.348 sec/step)\n",
      "step 79330 \t loss = 0.024, train_acc = 1.000 (3.378 sec/step)\n",
      "step 79340 \t loss = 0.183, train_acc = 1.000 (3.396 sec/step)\n",
      "step 79350 \t loss = 0.029, train_acc = 1.000 (3.339 sec/step)\n",
      "step 79360 \t loss = 0.000, train_acc = 1.000 (3.410 sec/step)\n",
      "step 79370 \t loss = 0.042, train_acc = 1.000 (3.330 sec/step)\n",
      "step 79380 \t loss = 0.101, train_acc = 1.000 (3.321 sec/step)\n",
      "step 79390 \t loss = 0.453, train_acc = 0.900 (3.390 sec/step)\n",
      "step 79400 \t loss = 0.061, train_acc = 1.000 (3.311 sec/step)\n",
      "step 79410 \t loss = 0.702, train_acc = 0.900 (3.319 sec/step)\n",
      "step 79420 \t loss = 0.052, train_acc = 1.000 (3.380 sec/step)\n",
      "step 79430 \t loss = 0.746, train_acc = 0.700 (3.314 sec/step)\n",
      "step 79440 \t loss = 0.032, train_acc = 1.000 (3.379 sec/step)\n",
      "step 79450 \t loss = 0.256, train_acc = 0.900 (3.332 sec/step)\n",
      "step 79460 \t loss = 0.027, train_acc = 1.000 (3.310 sec/step)\n",
      "step 79470 \t loss = 0.001, train_acc = 1.000 (3.362 sec/step)\n",
      "step 79480 \t loss = 0.333, train_acc = 0.900 (3.402 sec/step)\n",
      "step 79490 \t loss = 0.052, train_acc = 1.000 (3.419 sec/step)\n",
      "step 79500 \t loss = 0.051, train_acc = 1.000 (3.378 sec/step)\n",
      "step 79510 \t loss = 0.262, train_acc = 0.900 (3.362 sec/step)\n",
      "step 79520 \t loss = 0.000, train_acc = 1.000 (3.359 sec/step)\n",
      "step 79530 \t loss = 0.313, train_acc = 0.900 (3.370 sec/step)\n",
      "step 79540 \t loss = 0.578, train_acc = 0.900 (3.410 sec/step)\n",
      "step 79550 \t loss = 0.013, train_acc = 1.000 (3.340 sec/step)\n",
      "step 79560 \t loss = 0.110, train_acc = 1.000 (3.303 sec/step)\n",
      "step 79570 \t loss = 0.352, train_acc = 0.900 (3.339 sec/step)\n",
      "step 79580 \t loss = 0.263, train_acc = 0.900 (3.367 sec/step)\n",
      "step 79590 \t loss = 0.767, train_acc = 0.800 (3.362 sec/step)\n",
      "step 79600 \t loss = 0.236, train_acc = 0.900 (3.380 sec/step)\n",
      "step 79610 \t loss = 0.006, train_acc = 1.000 (3.330 sec/step)\n",
      "step 79620 \t loss = 0.023, train_acc = 1.000 (3.358 sec/step)\n",
      "step 79630 \t loss = 0.278, train_acc = 0.800 (3.362 sec/step)\n",
      "step 79640 \t loss = 0.011, train_acc = 1.000 (3.388 sec/step)\n",
      "step 79650 \t loss = 0.001, train_acc = 1.000 (3.390 sec/step)\n",
      "step 79660 \t loss = 0.011, train_acc = 1.000 (3.330 sec/step)\n",
      "step 79670 \t loss = 0.000, train_acc = 1.000 (3.349 sec/step)\n",
      "step 79680 \t loss = 0.002, train_acc = 1.000 (3.371 sec/step)\n",
      "step 79690 \t loss = 0.001, train_acc = 1.000 (3.444 sec/step)\n",
      "step 79700 \t loss = 2.495, train_acc = 0.900 (3.356 sec/step)\n",
      "step 79710 \t loss = 0.014, train_acc = 1.000 (3.349 sec/step)\n",
      "step 79720 \t loss = 0.455, train_acc = 0.900 (3.370 sec/step)\n",
      "step 79730 \t loss = 0.045, train_acc = 1.000 (3.357 sec/step)\n",
      "step 79740 \t loss = 0.004, train_acc = 1.000 (3.455 sec/step)\n",
      "step 79750 \t loss = 0.003, train_acc = 1.000 (3.306 sec/step)\n",
      "step 79760 \t loss = 0.087, train_acc = 1.000 (3.363 sec/step)\n",
      "step 79770 \t loss = 0.800, train_acc = 0.700 (3.365 sec/step)\n",
      "step 79780 \t loss = 0.298, train_acc = 0.900 (3.315 sec/step)\n",
      "step 79790 \t loss = 1.122, train_acc = 0.800 (3.328 sec/step)\n",
      "VALIDATION \t acc = 0.540 (3.629 sec)\n",
      "step 79800 \t loss = 0.225, train_acc = 0.900 (3.332 sec/step)\n",
      "step 79810 \t loss = 0.669, train_acc = 0.900 (3.331 sec/step)\n",
      "step 79820 \t loss = 0.010, train_acc = 1.000 (3.332 sec/step)\n",
      "step 79830 \t loss = 0.468, train_acc = 0.900 (3.377 sec/step)\n",
      "step 79840 \t loss = 0.014, train_acc = 1.000 (3.392 sec/step)\n",
      "step 79850 \t loss = 0.356, train_acc = 0.900 (3.354 sec/step)\n",
      "step 79860 \t loss = 0.285, train_acc = 0.900 (3.312 sec/step)\n",
      "step 79870 \t loss = 0.019, train_acc = 1.000 (3.303 sec/step)\n",
      "step 79880 \t loss = 0.007, train_acc = 1.000 (3.362 sec/step)\n",
      "step 79890 \t loss = 0.001, train_acc = 1.000 (3.409 sec/step)\n",
      "step 79900 \t loss = 0.378, train_acc = 0.900 (3.321 sec/step)\n",
      "step 79910 \t loss = 0.000, train_acc = 1.000 (3.399 sec/step)\n",
      "step 79920 \t loss = 0.019, train_acc = 1.000 (3.381 sec/step)\n",
      "step 79930 \t loss = 0.155, train_acc = 1.000 (3.376 sec/step)\n",
      "step 79940 \t loss = 0.137, train_acc = 0.900 (3.363 sec/step)\n",
      "step 79950 \t loss = 0.484, train_acc = 0.900 (3.344 sec/step)\n",
      "step 79960 \t loss = 0.253, train_acc = 0.900 (3.349 sec/step)\n",
      "step 79970 \t loss = 0.022, train_acc = 1.000 (3.371 sec/step)\n",
      "step 79980 \t loss = 0.000, train_acc = 1.000 (3.370 sec/step)\n",
      "step 79990 \t loss = 0.351, train_acc = 0.800 (3.378 sec/step)\n",
      "step 80000 \t loss = 0.513, train_acc = 0.700 (3.392 sec/step)\n",
      "step 80010 \t loss = 0.002, train_acc = 1.000 (3.346 sec/step)\n",
      "step 80020 \t loss = 0.338, train_acc = 0.800 (3.389 sec/step)\n",
      "step 80030 \t loss = 0.000, train_acc = 1.000 (3.344 sec/step)\n",
      "step 80040 \t loss = 0.003, train_acc = 1.000 (3.488 sec/step)\n",
      "step 80050 \t loss = 0.114, train_acc = 0.900 (3.314 sec/step)\n",
      "step 80060 \t loss = 0.001, train_acc = 1.000 (3.357 sec/step)\n",
      "step 80070 \t loss = 0.000, train_acc = 1.000 (3.330 sec/step)\n",
      "step 80080 \t loss = 0.337, train_acc = 0.800 (3.345 sec/step)\n",
      "step 80090 \t loss = 0.105, train_acc = 0.900 (3.389 sec/step)\n",
      "step 80100 \t loss = 0.132, train_acc = 0.900 (3.391 sec/step)\n",
      "step 80110 \t loss = 0.007, train_acc = 1.000 (3.318 sec/step)\n",
      "step 80120 \t loss = 1.010, train_acc = 0.800 (3.364 sec/step)\n",
      "step 80130 \t loss = 0.436, train_acc = 0.900 (3.343 sec/step)\n",
      "step 80140 \t loss = 0.898, train_acc = 0.700 (3.400 sec/step)\n",
      "step 80150 \t loss = 0.003, train_acc = 1.000 (3.349 sec/step)\n",
      "step 80160 \t loss = 2.037, train_acc = 0.800 (3.351 sec/step)\n",
      "step 80170 \t loss = 0.067, train_acc = 1.000 (3.341 sec/step)\n",
      "step 80180 \t loss = 0.001, train_acc = 1.000 (3.378 sec/step)\n",
      "step 80190 \t loss = 0.145, train_acc = 0.900 (3.309 sec/step)\n",
      "step 80200 \t loss = 0.297, train_acc = 0.800 (3.337 sec/step)\n",
      "step 80210 \t loss = 0.552, train_acc = 0.900 (3.396 sec/step)\n",
      "step 80220 \t loss = 0.024, train_acc = 1.000 (3.369 sec/step)\n",
      "step 80230 \t loss = 0.350, train_acc = 0.800 (3.367 sec/step)\n",
      "step 80240 \t loss = 0.031, train_acc = 1.000 (3.317 sec/step)\n",
      "step 80250 \t loss = 0.834, train_acc = 0.800 (3.366 sec/step)\n",
      "step 80260 \t loss = 0.006, train_acc = 1.000 (3.368 sec/step)\n",
      "step 80270 \t loss = 0.397, train_acc = 0.800 (3.371 sec/step)\n",
      "step 80280 \t loss = 0.359, train_acc = 0.900 (3.341 sec/step)\n",
      "step 80290 \t loss = 0.010, train_acc = 1.000 (3.390 sec/step)\n",
      "step 80300 \t loss = 0.662, train_acc = 0.800 (3.302 sec/step)\n",
      "step 80310 \t loss = 0.014, train_acc = 1.000 (3.349 sec/step)\n",
      "step 80320 \t loss = 0.012, train_acc = 1.000 (3.341 sec/step)\n",
      "step 80330 \t loss = 0.356, train_acc = 0.900 (3.318 sec/step)\n",
      "step 80340 \t loss = 0.544, train_acc = 0.900 (3.397 sec/step)\n",
      "step 80350 \t loss = 0.510, train_acc = 0.800 (3.367 sec/step)\n",
      "step 80360 \t loss = 0.424, train_acc = 0.900 (3.313 sec/step)\n",
      "step 80370 \t loss = 0.305, train_acc = 0.900 (3.425 sec/step)\n",
      "step 80380 \t loss = 0.081, train_acc = 0.900 (3.423 sec/step)\n",
      "step 80390 \t loss = 0.201, train_acc = 0.900 (3.329 sec/step)\n",
      "step 80400 \t loss = 0.005, train_acc = 1.000 (3.312 sec/step)\n",
      "step 80410 \t loss = 0.010, train_acc = 1.000 (3.397 sec/step)\n",
      "step 80420 \t loss = 0.039, train_acc = 1.000 (3.377 sec/step)\n",
      "step 80430 \t loss = 0.245, train_acc = 0.900 (3.342 sec/step)\n",
      "step 80440 \t loss = 0.016, train_acc = 1.000 (3.387 sec/step)\n",
      "step 80450 \t loss = 0.003, train_acc = 1.000 (3.361 sec/step)\n",
      "step 80460 \t loss = 0.001, train_acc = 1.000 (3.345 sec/step)\n",
      "step 80470 \t loss = 0.364, train_acc = 0.900 (3.357 sec/step)\n",
      "step 80480 \t loss = 0.002, train_acc = 1.000 (3.349 sec/step)\n",
      "step 80490 \t loss = 0.018, train_acc = 1.000 (3.372 sec/step)\n",
      "step 80500 \t loss = 0.034, train_acc = 1.000 (3.365 sec/step)\n",
      "step 80510 \t loss = 0.035, train_acc = 1.000 (3.449 sec/step)\n",
      "step 80520 \t loss = 0.187, train_acc = 0.900 (3.415 sec/step)\n",
      "step 80530 \t loss = 0.116, train_acc = 1.000 (3.353 sec/step)\n",
      "step 80540 \t loss = 0.003, train_acc = 1.000 (3.307 sec/step)\n",
      "step 80550 \t loss = 0.032, train_acc = 1.000 (3.390 sec/step)\n",
      "step 80560 \t loss = 0.057, train_acc = 1.000 (3.322 sec/step)\n",
      "step 80570 \t loss = 0.063, train_acc = 1.000 (3.319 sec/step)\n",
      "step 80580 \t loss = 0.037, train_acc = 1.000 (3.356 sec/step)\n",
      "step 80590 \t loss = 0.005, train_acc = 1.000 (3.322 sec/step)\n",
      "step 80600 \t loss = 0.000, train_acc = 1.000 (3.307 sec/step)\n",
      "step 80610 \t loss = 0.379, train_acc = 0.900 (3.417 sec/step)\n",
      "step 80620 \t loss = 0.002, train_acc = 1.000 (3.341 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 80630 \t loss = 0.119, train_acc = 0.900 (3.388 sec/step)\n",
      "step 80640 \t loss = 1.182, train_acc = 0.800 (3.372 sec/step)\n",
      "step 80650 \t loss = 0.670, train_acc = 0.900 (3.364 sec/step)\n",
      "step 80660 \t loss = 0.045, train_acc = 1.000 (3.353 sec/step)\n",
      "step 80670 \t loss = 0.063, train_acc = 1.000 (3.394 sec/step)\n",
      "step 80680 \t loss = 0.012, train_acc = 1.000 (3.385 sec/step)\n",
      "step 80690 \t loss = 0.009, train_acc = 1.000 (3.333 sec/step)\n",
      "step 80700 \t loss = 0.611, train_acc = 0.800 (3.350 sec/step)\n",
      "step 80710 \t loss = 0.002, train_acc = 1.000 (3.364 sec/step)\n",
      "step 80720 \t loss = 0.080, train_acc = 1.000 (3.372 sec/step)\n",
      "step 80730 \t loss = 0.440, train_acc = 0.900 (3.318 sec/step)\n",
      "step 80740 \t loss = 0.372, train_acc = 0.800 (3.393 sec/step)\n",
      "step 80750 \t loss = 0.172, train_acc = 0.900 (3.378 sec/step)\n",
      "step 80760 \t loss = 0.001, train_acc = 1.000 (3.336 sec/step)\n",
      "step 80770 \t loss = 0.002, train_acc = 1.000 (3.322 sec/step)\n",
      "step 80780 \t loss = 0.005, train_acc = 1.000 (3.387 sec/step)\n",
      "step 80790 \t loss = 1.402, train_acc = 0.800 (3.332 sec/step)\n",
      "step 80800 \t loss = 0.025, train_acc = 1.000 (3.355 sec/step)\n",
      "step 80810 \t loss = 0.230, train_acc = 0.900 (3.308 sec/step)\n",
      "step 80820 \t loss = 0.369, train_acc = 0.900 (3.329 sec/step)\n",
      "step 80830 \t loss = 0.330, train_acc = 0.900 (3.318 sec/step)\n",
      "step 80840 \t loss = 0.003, train_acc = 1.000 (3.369 sec/step)\n",
      "step 80850 \t loss = 0.121, train_acc = 0.900 (3.314 sec/step)\n",
      "step 80860 \t loss = 0.210, train_acc = 0.900 (3.325 sec/step)\n",
      "step 80870 \t loss = 0.566, train_acc = 0.800 (3.321 sec/step)\n",
      "step 80880 \t loss = 0.110, train_acc = 1.000 (3.318 sec/step)\n",
      "step 80890 \t loss = 0.394, train_acc = 0.800 (3.375 sec/step)\n",
      "step 80900 \t loss = 0.111, train_acc = 0.900 (3.387 sec/step)\n",
      "step 80910 \t loss = 0.004, train_acc = 1.000 (3.313 sec/step)\n",
      "step 80920 \t loss = 0.106, train_acc = 1.000 (3.381 sec/step)\n",
      "step 80930 \t loss = 0.032, train_acc = 1.000 (3.315 sec/step)\n",
      "step 80940 \t loss = 0.228, train_acc = 0.900 (3.371 sec/step)\n",
      "step 80950 \t loss = 0.046, train_acc = 1.000 (3.360 sec/step)\n",
      "step 80960 \t loss = 0.044, train_acc = 1.000 (3.300 sec/step)\n",
      "step 80970 \t loss = 0.364, train_acc = 0.900 (3.348 sec/step)\n",
      "step 80980 \t loss = 0.138, train_acc = 1.000 (3.396 sec/step)\n",
      "step 80990 \t loss = 0.002, train_acc = 1.000 (3.385 sec/step)\n",
      "step 81000 \t loss = 0.224, train_acc = 0.900 (3.323 sec/step)\n",
      "step 81010 \t loss = 0.209, train_acc = 0.900 (3.370 sec/step)\n",
      "step 81020 \t loss = 0.019, train_acc = 1.000 (3.325 sec/step)\n",
      "step 81030 \t loss = 0.042, train_acc = 1.000 (3.381 sec/step)\n",
      "step 81040 \t loss = 0.706, train_acc = 0.800 (3.359 sec/step)\n",
      "step 81050 \t loss = 0.002, train_acc = 1.000 (3.362 sec/step)\n",
      "step 81060 \t loss = 0.004, train_acc = 1.000 (3.362 sec/step)\n",
      "step 81070 \t loss = 0.004, train_acc = 1.000 (3.344 sec/step)\n",
      "step 81080 \t loss = 0.001, train_acc = 1.000 (3.329 sec/step)\n",
      "step 81090 \t loss = 0.387, train_acc = 0.900 (3.374 sec/step)\n",
      "step 81100 \t loss = 0.000, train_acc = 1.000 (3.366 sec/step)\n",
      "step 81110 \t loss = 0.243, train_acc = 0.900 (3.366 sec/step)\n",
      "step 81120 \t loss = 0.425, train_acc = 0.900 (3.366 sec/step)\n",
      "step 81130 \t loss = 0.001, train_acc = 1.000 (3.347 sec/step)\n",
      "step 81140 \t loss = 0.589, train_acc = 0.900 (3.387 sec/step)\n",
      "step 81150 \t loss = 0.015, train_acc = 1.000 (3.406 sec/step)\n",
      "step 81160 \t loss = 0.022, train_acc = 1.000 (3.324 sec/step)\n",
      "step 81170 \t loss = 0.013, train_acc = 1.000 (3.398 sec/step)\n",
      "step 81180 \t loss = 0.002, train_acc = 1.000 (3.368 sec/step)\n",
      "step 81190 \t loss = 0.384, train_acc = 0.800 (3.406 sec/step)\n",
      "step 81200 \t loss = 0.005, train_acc = 1.000 (3.315 sec/step)\n",
      "step 81210 \t loss = 0.301, train_acc = 0.900 (3.356 sec/step)\n",
      "step 81220 \t loss = 0.677, train_acc = 0.800 (3.358 sec/step)\n",
      "step 81230 \t loss = 0.079, train_acc = 1.000 (3.315 sec/step)\n",
      "step 81240 \t loss = 0.074, train_acc = 0.900 (3.368 sec/step)\n",
      "step 81250 \t loss = 0.431, train_acc = 0.700 (3.396 sec/step)\n",
      "step 81260 \t loss = 0.203, train_acc = 0.800 (3.345 sec/step)\n",
      "step 81270 \t loss = 0.126, train_acc = 0.900 (3.377 sec/step)\n",
      "step 81280 \t loss = 0.001, train_acc = 1.000 (3.322 sec/step)\n",
      "step 81290 \t loss = 0.064, train_acc = 1.000 (3.353 sec/step)\n",
      "step 81300 \t loss = 0.079, train_acc = 1.000 (3.345 sec/step)\n",
      "step 81310 \t loss = 0.135, train_acc = 0.900 (3.320 sec/step)\n",
      "step 81320 \t loss = 0.063, train_acc = 1.000 (3.313 sec/step)\n",
      "step 81330 \t loss = 0.000, train_acc = 1.000 (3.368 sec/step)\n",
      "step 81340 \t loss = 0.009, train_acc = 1.000 (3.376 sec/step)\n",
      "step 81350 \t loss = 0.000, train_acc = 1.000 (3.355 sec/step)\n",
      "step 81360 \t loss = 1.780, train_acc = 0.900 (3.365 sec/step)\n",
      "step 81370 \t loss = 0.022, train_acc = 1.000 (3.364 sec/step)\n",
      "step 81380 \t loss = 0.184, train_acc = 0.900 (3.378 sec/step)\n",
      "step 81390 \t loss = 0.000, train_acc = 1.000 (3.382 sec/step)\n",
      "step 81400 \t loss = 1.196, train_acc = 0.600 (3.322 sec/step)\n",
      "step 81410 \t loss = 0.753, train_acc = 0.900 (3.317 sec/step)\n",
      "step 81420 \t loss = 0.746, train_acc = 0.800 (3.367 sec/step)\n",
      "step 81430 \t loss = 0.325, train_acc = 0.900 (3.339 sec/step)\n",
      "step 81440 \t loss = 0.126, train_acc = 1.000 (3.321 sec/step)\n",
      "step 81450 \t loss = 0.730, train_acc = 0.800 (3.402 sec/step)\n",
      "step 81460 \t loss = 0.226, train_acc = 0.900 (3.342 sec/step)\n",
      "step 81470 \t loss = 0.012, train_acc = 1.000 (3.310 sec/step)\n",
      "step 81480 \t loss = 0.000, train_acc = 1.000 (3.382 sec/step)\n",
      "step 81490 \t loss = 0.006, train_acc = 1.000 (3.370 sec/step)\n",
      "step 81500 \t loss = 0.016, train_acc = 1.000 (3.359 sec/step)\n",
      "step 81510 \t loss = 0.014, train_acc = 1.000 (3.379 sec/step)\n",
      "step 81520 \t loss = 0.017, train_acc = 1.000 (3.365 sec/step)\n",
      "step 81530 \t loss = 0.267, train_acc = 0.900 (3.367 sec/step)\n",
      "step 81540 \t loss = 0.271, train_acc = 0.900 (3.375 sec/step)\n",
      "step 81550 \t loss = 0.242, train_acc = 0.900 (3.338 sec/step)\n",
      "step 81560 \t loss = 0.058, train_acc = 1.000 (3.346 sec/step)\n",
      "step 81570 \t loss = 0.000, train_acc = 1.000 (3.357 sec/step)\n",
      "step 81580 \t loss = 0.024, train_acc = 1.000 (3.338 sec/step)\n",
      "step 81590 \t loss = 0.003, train_acc = 1.000 (3.306 sec/step)\n",
      "step 81600 \t loss = 0.047, train_acc = 1.000 (3.377 sec/step)\n",
      "step 81610 \t loss = 0.601, train_acc = 0.900 (3.317 sec/step)\n",
      "step 81620 \t loss = 0.000, train_acc = 1.000 (3.330 sec/step)\n",
      "step 81630 \t loss = 0.219, train_acc = 0.900 (3.303 sec/step)\n",
      "step 81640 \t loss = 1.199, train_acc = 0.900 (3.373 sec/step)\n",
      "step 81650 \t loss = 0.001, train_acc = 1.000 (3.334 sec/step)\n",
      "step 81660 \t loss = 0.001, train_acc = 1.000 (3.404 sec/step)\n",
      "step 81670 \t loss = 0.049, train_acc = 1.000 (3.358 sec/step)\n",
      "step 81680 \t loss = 0.002, train_acc = 1.000 (3.399 sec/step)\n",
      "step 81690 \t loss = 0.116, train_acc = 1.000 (3.396 sec/step)\n",
      "VALIDATION \t acc = 0.538 (3.642 sec)\n",
      "step 81700 \t loss = 0.424, train_acc = 0.900 (3.376 sec/step)\n",
      "step 81710 \t loss = 0.060, train_acc = 1.000 (3.292 sec/step)\n",
      "step 81720 \t loss = 0.127, train_acc = 0.900 (3.323 sec/step)\n",
      "step 81730 \t loss = 0.405, train_acc = 0.900 (3.399 sec/step)\n",
      "step 81740 \t loss = 1.225, train_acc = 0.800 (3.481 sec/step)\n",
      "step 81750 \t loss = 0.022, train_acc = 1.000 (3.410 sec/step)\n",
      "step 81760 \t loss = 0.482, train_acc = 0.800 (3.303 sec/step)\n",
      "step 81770 \t loss = 0.498, train_acc = 0.800 (3.312 sec/step)\n",
      "step 81780 \t loss = 0.321, train_acc = 0.900 (3.332 sec/step)\n",
      "step 81790 \t loss = 0.146, train_acc = 0.900 (3.329 sec/step)\n",
      "step 81800 \t loss = 0.064, train_acc = 1.000 (3.303 sec/step)\n",
      "step 81810 \t loss = 0.000, train_acc = 1.000 (3.324 sec/step)\n",
      "step 81820 \t loss = 0.003, train_acc = 1.000 (3.319 sec/step)\n",
      "step 81830 \t loss = 0.006, train_acc = 1.000 (3.294 sec/step)\n",
      "step 81840 \t loss = 0.962, train_acc = 0.700 (3.340 sec/step)\n",
      "step 81850 \t loss = 0.443, train_acc = 0.800 (3.387 sec/step)\n",
      "step 81860 \t loss = 0.218, train_acc = 0.900 (3.350 sec/step)\n",
      "step 81870 \t loss = 0.307, train_acc = 0.900 (3.391 sec/step)\n",
      "step 81880 \t loss = 0.949, train_acc = 0.800 (3.329 sec/step)\n",
      "step 81890 \t loss = 0.019, train_acc = 1.000 (3.336 sec/step)\n",
      "step 81900 \t loss = 0.307, train_acc = 0.800 (3.321 sec/step)\n",
      "step 81910 \t loss = 0.226, train_acc = 0.900 (3.462 sec/step)\n",
      "step 81920 \t loss = 0.092, train_acc = 1.000 (3.371 sec/step)\n",
      "step 81930 \t loss = 0.078, train_acc = 0.900 (3.324 sec/step)\n",
      "step 81940 \t loss = 0.033, train_acc = 1.000 (3.344 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 81950 \t loss = 0.044, train_acc = 1.000 (3.334 sec/step)\n",
      "step 81960 \t loss = 0.065, train_acc = 1.000 (3.442 sec/step)\n",
      "step 81970 \t loss = 0.954, train_acc = 0.900 (3.315 sec/step)\n",
      "step 81980 \t loss = 0.001, train_acc = 1.000 (3.343 sec/step)\n",
      "step 81990 \t loss = 0.055, train_acc = 1.000 (3.388 sec/step)\n",
      "step 82000 \t loss = 0.021, train_acc = 1.000 (3.349 sec/step)\n",
      "step 82010 \t loss = 0.051, train_acc = 1.000 (3.368 sec/step)\n",
      "step 82020 \t loss = 0.062, train_acc = 1.000 (3.303 sec/step)\n",
      "step 82030 \t loss = 0.503, train_acc = 0.900 (3.383 sec/step)\n",
      "step 82040 \t loss = 1.443, train_acc = 0.600 (3.304 sec/step)\n",
      "step 82050 \t loss = 0.134, train_acc = 0.900 (3.343 sec/step)\n",
      "step 82060 \t loss = 0.087, train_acc = 0.900 (3.336 sec/step)\n",
      "step 82070 \t loss = 0.140, train_acc = 0.900 (3.372 sec/step)\n",
      "step 82080 \t loss = 0.073, train_acc = 1.000 (3.333 sec/step)\n",
      "step 82090 \t loss = 0.000, train_acc = 1.000 (3.382 sec/step)\n",
      "step 82100 \t loss = 0.022, train_acc = 1.000 (3.344 sec/step)\n",
      "step 82110 \t loss = 0.298, train_acc = 0.900 (3.394 sec/step)\n",
      "step 82120 \t loss = 0.364, train_acc = 0.900 (3.376 sec/step)\n",
      "step 82130 \t loss = 0.255, train_acc = 0.900 (3.365 sec/step)\n",
      "step 82140 \t loss = 0.200, train_acc = 0.900 (3.353 sec/step)\n",
      "step 82150 \t loss = 0.460, train_acc = 0.700 (3.359 sec/step)\n",
      "step 82160 \t loss = 0.025, train_acc = 1.000 (3.358 sec/step)\n",
      "step 82170 \t loss = 0.019, train_acc = 1.000 (3.370 sec/step)\n",
      "step 82180 \t loss = 0.000, train_acc = 1.000 (3.355 sec/step)\n",
      "step 82190 \t loss = 0.255, train_acc = 0.900 (3.339 sec/step)\n",
      "step 82200 \t loss = 0.275, train_acc = 0.800 (3.332 sec/step)\n",
      "step 82210 \t loss = 0.108, train_acc = 1.000 (3.348 sec/step)\n",
      "step 82220 \t loss = 0.122, train_acc = 1.000 (3.371 sec/step)\n",
      "step 82230 \t loss = 0.012, train_acc = 1.000 (3.374 sec/step)\n",
      "step 82240 \t loss = 0.003, train_acc = 1.000 (3.344 sec/step)\n",
      "step 82250 \t loss = 0.015, train_acc = 1.000 (3.390 sec/step)\n",
      "step 82260 \t loss = 0.240, train_acc = 0.900 (3.395 sec/step)\n",
      "step 82270 \t loss = 0.334, train_acc = 0.900 (3.362 sec/step)\n",
      "step 82280 \t loss = 0.520, train_acc = 0.900 (3.351 sec/step)\n",
      "step 82290 \t loss = 0.015, train_acc = 1.000 (3.325 sec/step)\n",
      "step 82300 \t loss = 0.019, train_acc = 1.000 (3.339 sec/step)\n",
      "step 82310 \t loss = 0.181, train_acc = 0.900 (3.350 sec/step)\n",
      "step 82320 \t loss = 0.046, train_acc = 1.000 (3.357 sec/step)\n",
      "step 82330 \t loss = 0.067, train_acc = 1.000 (3.371 sec/step)\n",
      "step 82340 \t loss = 0.005, train_acc = 1.000 (3.351 sec/step)\n",
      "step 82350 \t loss = 0.371, train_acc = 0.800 (3.302 sec/step)\n",
      "step 82360 \t loss = 0.320, train_acc = 0.900 (3.328 sec/step)\n",
      "step 82370 \t loss = 0.007, train_acc = 1.000 (3.398 sec/step)\n",
      "step 82380 \t loss = 0.302, train_acc = 0.900 (3.372 sec/step)\n",
      "step 82390 \t loss = 0.201, train_acc = 0.900 (3.311 sec/step)\n",
      "step 82400 \t loss = 0.892, train_acc = 0.900 (3.377 sec/step)\n",
      "step 82410 \t loss = 1.543, train_acc = 0.700 (3.293 sec/step)\n",
      "step 82420 \t loss = 0.112, train_acc = 1.000 (3.388 sec/step)\n",
      "step 82430 \t loss = 0.122, train_acc = 0.900 (3.319 sec/step)\n",
      "step 82440 \t loss = 0.322, train_acc = 0.900 (3.368 sec/step)\n",
      "step 82450 \t loss = 0.014, train_acc = 1.000 (3.368 sec/step)\n",
      "step 82460 \t loss = 0.007, train_acc = 1.000 (3.460 sec/step)\n",
      "step 82470 \t loss = 0.200, train_acc = 0.900 (3.367 sec/step)\n",
      "step 82480 \t loss = 0.543, train_acc = 0.900 (3.371 sec/step)\n",
      "step 82490 \t loss = 0.325, train_acc = 0.900 (3.308 sec/step)\n",
      "step 82500 \t loss = 0.065, train_acc = 1.000 (3.357 sec/step)\n",
      "step 82510 \t loss = 0.049, train_acc = 1.000 (3.304 sec/step)\n",
      "step 82520 \t loss = 0.023, train_acc = 1.000 (3.352 sec/step)\n",
      "step 82530 \t loss = 0.002, train_acc = 1.000 (3.334 sec/step)\n",
      "step 82540 \t loss = 0.015, train_acc = 1.000 (3.430 sec/step)\n",
      "step 82550 \t loss = 0.000, train_acc = 1.000 (3.324 sec/step)\n",
      "step 82560 \t loss = 0.006, train_acc = 1.000 (3.391 sec/step)\n",
      "step 82570 \t loss = 1.362, train_acc = 0.800 (3.353 sec/step)\n",
      "step 82580 \t loss = 0.207, train_acc = 0.900 (3.384 sec/step)\n",
      "step 82590 \t loss = 0.258, train_acc = 0.900 (3.395 sec/step)\n",
      "step 82600 \t loss = 0.441, train_acc = 0.900 (3.455 sec/step)\n",
      "step 82610 \t loss = 0.172, train_acc = 0.900 (3.365 sec/step)\n",
      "step 82620 \t loss = 0.000, train_acc = 1.000 (3.373 sec/step)\n",
      "step 82630 \t loss = 0.570, train_acc = 0.900 (3.383 sec/step)\n",
      "step 82640 \t loss = 0.343, train_acc = 0.900 (3.370 sec/step)\n",
      "step 82650 \t loss = 0.000, train_acc = 1.000 (3.351 sec/step)\n",
      "step 82660 \t loss = 0.188, train_acc = 0.900 (3.462 sec/step)\n",
      "step 82670 \t loss = 0.007, train_acc = 1.000 (3.341 sec/step)\n",
      "step 82680 \t loss = 0.063, train_acc = 1.000 (3.329 sec/step)\n",
      "step 82690 \t loss = 0.009, train_acc = 1.000 (3.358 sec/step)\n",
      "step 82700 \t loss = 0.006, train_acc = 1.000 (3.360 sec/step)\n",
      "step 82710 \t loss = 0.682, train_acc = 0.800 (3.375 sec/step)\n",
      "step 82720 \t loss = 0.067, train_acc = 1.000 (3.336 sec/step)\n",
      "step 82730 \t loss = 0.684, train_acc = 0.800 (3.380 sec/step)\n",
      "step 82740 \t loss = 0.017, train_acc = 1.000 (3.362 sec/step)\n",
      "step 82750 \t loss = 0.844, train_acc = 0.800 (3.311 sec/step)\n",
      "step 82760 \t loss = 0.251, train_acc = 0.900 (3.379 sec/step)\n",
      "step 82770 \t loss = 0.041, train_acc = 1.000 (3.373 sec/step)\n",
      "step 82780 \t loss = 0.012, train_acc = 1.000 (3.329 sec/step)\n",
      "step 82790 \t loss = 1.963, train_acc = 0.800 (3.393 sec/step)\n",
      "step 82800 \t loss = 0.268, train_acc = 0.900 (3.335 sec/step)\n",
      "step 82810 \t loss = 0.352, train_acc = 0.900 (3.347 sec/step)\n",
      "step 82820 \t loss = 0.004, train_acc = 1.000 (3.386 sec/step)\n",
      "step 82830 \t loss = 0.141, train_acc = 0.900 (3.367 sec/step)\n",
      "step 82840 \t loss = 0.119, train_acc = 0.900 (3.324 sec/step)\n",
      "step 82850 \t loss = 0.028, train_acc = 1.000 (3.329 sec/step)\n",
      "step 82860 \t loss = 0.249, train_acc = 0.900 (3.326 sec/step)\n",
      "step 82870 \t loss = 0.140, train_acc = 1.000 (3.310 sec/step)\n",
      "step 82880 \t loss = 0.076, train_acc = 1.000 (3.354 sec/step)\n",
      "step 82890 \t loss = 0.025, train_acc = 1.000 (3.377 sec/step)\n",
      "step 82900 \t loss = 0.000, train_acc = 1.000 (3.400 sec/step)\n",
      "step 82910 \t loss = 0.001, train_acc = 1.000 (3.360 sec/step)\n",
      "step 82920 \t loss = 1.432, train_acc = 0.700 (3.374 sec/step)\n",
      "step 82930 \t loss = 1.172, train_acc = 0.900 (3.331 sec/step)\n",
      "step 82940 \t loss = 0.024, train_acc = 1.000 (3.348 sec/step)\n",
      "step 82950 \t loss = 0.630, train_acc = 0.900 (3.346 sec/step)\n",
      "step 82960 \t loss = 0.316, train_acc = 0.900 (3.309 sec/step)\n",
      "step 82970 \t loss = 0.195, train_acc = 0.900 (3.424 sec/step)\n",
      "step 82980 \t loss = 0.004, train_acc = 1.000 (3.375 sec/step)\n",
      "step 82990 \t loss = 0.000, train_acc = 1.000 (3.430 sec/step)\n",
      "step 83000 \t loss = 0.177, train_acc = 0.900 (3.471 sec/step)\n",
      "step 83010 \t loss = 0.469, train_acc = 1.000 (3.381 sec/step)\n",
      "step 83020 \t loss = 0.413, train_acc = 0.900 (3.403 sec/step)\n",
      "step 83030 \t loss = 0.064, train_acc = 1.000 (3.314 sec/step)\n",
      "step 83040 \t loss = 0.392, train_acc = 0.900 (3.384 sec/step)\n",
      "step 83050 \t loss = 1.652, train_acc = 0.800 (3.388 sec/step)\n",
      "step 83060 \t loss = 0.026, train_acc = 1.000 (3.343 sec/step)\n",
      "step 83070 \t loss = 0.364, train_acc = 0.900 (3.334 sec/step)\n",
      "step 83080 \t loss = 0.113, train_acc = 0.900 (3.364 sec/step)\n",
      "step 83090 \t loss = 0.012, train_acc = 1.000 (3.343 sec/step)\n",
      "step 83100 \t loss = 0.052, train_acc = 1.000 (3.324 sec/step)\n",
      "step 83110 \t loss = 0.001, train_acc = 1.000 (3.380 sec/step)\n",
      "step 83120 \t loss = 0.064, train_acc = 1.000 (3.380 sec/step)\n",
      "step 83130 \t loss = 0.012, train_acc = 1.000 (3.345 sec/step)\n",
      "step 83140 \t loss = 0.040, train_acc = 1.000 (3.330 sec/step)\n",
      "step 83150 \t loss = 0.023, train_acc = 1.000 (3.368 sec/step)\n",
      "step 83160 \t loss = 0.077, train_acc = 1.000 (3.375 sec/step)\n",
      "step 83170 \t loss = 0.009, train_acc = 1.000 (3.345 sec/step)\n",
      "step 83180 \t loss = 0.029, train_acc = 1.000 (3.344 sec/step)\n",
      "step 83190 \t loss = 0.094, train_acc = 0.900 (3.450 sec/step)\n",
      "step 83200 \t loss = 0.857, train_acc = 0.900 (3.316 sec/step)\n",
      "step 83210 \t loss = 0.179, train_acc = 0.900 (3.446 sec/step)\n",
      "step 83220 \t loss = 0.151, train_acc = 0.900 (3.350 sec/step)\n",
      "step 83230 \t loss = 0.000, train_acc = 1.000 (3.374 sec/step)\n",
      "step 83240 \t loss = 0.115, train_acc = 0.900 (3.341 sec/step)\n",
      "step 83250 \t loss = 0.215, train_acc = 0.900 (3.341 sec/step)\n",
      "step 83260 \t loss = 0.301, train_acc = 0.900 (3.392 sec/step)\n",
      "step 83270 \t loss = 0.079, train_acc = 1.000 (3.312 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 83280 \t loss = 0.008, train_acc = 1.000 (3.355 sec/step)\n",
      "step 83290 \t loss = 0.022, train_acc = 1.000 (3.382 sec/step)\n",
      "step 83300 \t loss = 0.002, train_acc = 1.000 (3.353 sec/step)\n",
      "step 83310 \t loss = 0.024, train_acc = 1.000 (3.368 sec/step)\n",
      "step 83320 \t loss = 0.002, train_acc = 1.000 (3.308 sec/step)\n",
      "step 83330 \t loss = 0.055, train_acc = 1.000 (3.387 sec/step)\n",
      "step 83340 \t loss = 0.320, train_acc = 0.900 (3.364 sec/step)\n",
      "step 83350 \t loss = 0.167, train_acc = 0.900 (3.433 sec/step)\n",
      "step 83360 \t loss = 0.269, train_acc = 0.900 (3.353 sec/step)\n",
      "step 83370 \t loss = 0.000, train_acc = 1.000 (3.361 sec/step)\n",
      "step 83380 \t loss = 0.450, train_acc = 0.800 (3.397 sec/step)\n",
      "step 83390 \t loss = 0.000, train_acc = 1.000 (3.346 sec/step)\n",
      "step 83400 \t loss = 0.398, train_acc = 0.900 (3.388 sec/step)\n",
      "step 83410 \t loss = 0.000, train_acc = 1.000 (3.345 sec/step)\n",
      "step 83420 \t loss = 0.029, train_acc = 1.000 (3.306 sec/step)\n",
      "step 83430 \t loss = 0.021, train_acc = 1.000 (3.328 sec/step)\n",
      "step 83440 \t loss = 0.171, train_acc = 0.900 (3.346 sec/step)\n",
      "step 83450 \t loss = 0.153, train_acc = 0.900 (3.365 sec/step)\n",
      "step 83460 \t loss = 0.007, train_acc = 1.000 (3.360 sec/step)\n",
      "step 83470 \t loss = 0.037, train_acc = 1.000 (3.328 sec/step)\n",
      "step 83480 \t loss = 0.020, train_acc = 1.000 (3.413 sec/step)\n",
      "step 83490 \t loss = 0.271, train_acc = 0.900 (3.374 sec/step)\n",
      "step 83500 \t loss = 0.298, train_acc = 0.900 (3.328 sec/step)\n",
      "step 83510 \t loss = 0.013, train_acc = 1.000 (3.366 sec/step)\n",
      "step 83520 \t loss = 0.005, train_acc = 1.000 (3.308 sec/step)\n",
      "step 83530 \t loss = 0.069, train_acc = 1.000 (3.301 sec/step)\n",
      "step 83540 \t loss = 0.442, train_acc = 0.900 (3.432 sec/step)\n",
      "step 83550 \t loss = 0.027, train_acc = 1.000 (3.335 sec/step)\n",
      "step 83560 \t loss = 0.907, train_acc = 0.700 (3.372 sec/step)\n",
      "step 83570 \t loss = 0.778, train_acc = 0.800 (3.399 sec/step)\n",
      "step 83580 \t loss = 0.207, train_acc = 0.900 (3.380 sec/step)\n",
      "step 83590 \t loss = 0.036, train_acc = 1.000 (3.353 sec/step)\n",
      "VALIDATION \t acc = 0.529 (3.609 sec)\n",
      "step 83600 \t loss = 0.496, train_acc = 0.900 (3.394 sec/step)\n",
      "step 83610 \t loss = 0.010, train_acc = 1.000 (3.321 sec/step)\n",
      "step 83620 \t loss = 0.342, train_acc = 0.900 (3.418 sec/step)\n",
      "step 83630 \t loss = 0.076, train_acc = 1.000 (3.399 sec/step)\n",
      "step 83640 \t loss = 0.027, train_acc = 1.000 (3.394 sec/step)\n",
      "step 83650 \t loss = 0.314, train_acc = 0.800 (3.335 sec/step)\n",
      "step 83660 \t loss = 0.000, train_acc = 1.000 (3.376 sec/step)\n",
      "step 83670 \t loss = 0.003, train_acc = 1.000 (3.342 sec/step)\n",
      "step 83680 \t loss = 0.002, train_acc = 1.000 (3.411 sec/step)\n",
      "step 83690 \t loss = 0.016, train_acc = 1.000 (3.345 sec/step)\n",
      "step 83700 \t loss = 0.227, train_acc = 0.900 (3.420 sec/step)\n",
      "step 83710 \t loss = 0.001, train_acc = 1.000 (3.362 sec/step)\n",
      "step 83720 \t loss = 0.553, train_acc = 0.900 (3.390 sec/step)\n",
      "step 83730 \t loss = 0.037, train_acc = 1.000 (3.312 sec/step)\n",
      "step 83740 \t loss = 0.001, train_acc = 1.000 (3.376 sec/step)\n",
      "step 83750 \t loss = 0.146, train_acc = 0.900 (3.332 sec/step)\n",
      "step 83760 \t loss = 0.219, train_acc = 1.000 (3.382 sec/step)\n",
      "step 83770 \t loss = 0.007, train_acc = 1.000 (3.381 sec/step)\n",
      "step 83780 \t loss = 0.002, train_acc = 1.000 (3.340 sec/step)\n",
      "step 83790 \t loss = 0.000, train_acc = 1.000 (3.376 sec/step)\n",
      "step 83800 \t loss = 0.094, train_acc = 1.000 (3.374 sec/step)\n",
      "step 83810 \t loss = 0.034, train_acc = 1.000 (3.388 sec/step)\n",
      "step 83820 \t loss = 0.009, train_acc = 1.000 (3.402 sec/step)\n",
      "step 83830 \t loss = 0.014, train_acc = 1.000 (3.408 sec/step)\n",
      "step 83840 \t loss = 0.037, train_acc = 1.000 (3.338 sec/step)\n",
      "step 83850 \t loss = 0.207, train_acc = 1.000 (3.385 sec/step)\n",
      "step 83860 \t loss = 0.015, train_acc = 1.000 (3.383 sec/step)\n",
      "step 83870 \t loss = 0.000, train_acc = 1.000 (3.364 sec/step)\n",
      "step 83880 \t loss = 0.606, train_acc = 0.800 (3.348 sec/step)\n",
      "step 83890 \t loss = 0.319, train_acc = 0.900 (3.379 sec/step)\n",
      "step 83900 \t loss = 0.029, train_acc = 1.000 (3.312 sec/step)\n",
      "step 83910 \t loss = 0.064, train_acc = 1.000 (3.365 sec/step)\n",
      "step 83920 \t loss = 0.015, train_acc = 1.000 (3.377 sec/step)\n",
      "step 83930 \t loss = 0.014, train_acc = 1.000 (3.375 sec/step)\n",
      "step 83940 \t loss = 0.013, train_acc = 1.000 (3.325 sec/step)\n",
      "step 83950 \t loss = 0.001, train_acc = 1.000 (3.371 sec/step)\n",
      "step 83960 \t loss = 0.161, train_acc = 0.900 (3.338 sec/step)\n",
      "step 83970 \t loss = 0.035, train_acc = 1.000 (3.352 sec/step)\n",
      "step 83980 \t loss = 0.158, train_acc = 0.900 (3.371 sec/step)\n",
      "step 83990 \t loss = 0.206, train_acc = 0.900 (3.379 sec/step)\n",
      "step 84000 \t loss = 0.963, train_acc = 0.600 (3.341 sec/step)\n",
      "step 84010 \t loss = 0.022, train_acc = 1.000 (3.308 sec/step)\n",
      "step 84020 \t loss = 0.123, train_acc = 1.000 (3.315 sec/step)\n",
      "step 84030 \t loss = 0.084, train_acc = 1.000 (3.320 sec/step)\n",
      "step 84040 \t loss = 0.215, train_acc = 0.900 (3.319 sec/step)\n",
      "step 84050 \t loss = 0.141, train_acc = 0.900 (3.353 sec/step)\n",
      "step 84060 \t loss = 0.045, train_acc = 1.000 (3.338 sec/step)\n",
      "step 84070 \t loss = 0.000, train_acc = 1.000 (3.319 sec/step)\n",
      "step 84080 \t loss = 0.826, train_acc = 0.900 (3.370 sec/step)\n",
      "step 84090 \t loss = 0.042, train_acc = 1.000 (3.379 sec/step)\n",
      "step 84100 \t loss = 0.106, train_acc = 1.000 (3.368 sec/step)\n",
      "step 84110 \t loss = 0.028, train_acc = 1.000 (3.337 sec/step)\n",
      "step 84120 \t loss = 0.849, train_acc = 0.600 (3.340 sec/step)\n",
      "step 84130 \t loss = 0.356, train_acc = 0.900 (3.368 sec/step)\n",
      "step 84140 \t loss = 0.121, train_acc = 0.900 (3.387 sec/step)\n",
      "step 84150 \t loss = 0.100, train_acc = 0.900 (3.349 sec/step)\n",
      "step 84160 \t loss = 0.002, train_acc = 1.000 (3.340 sec/step)\n",
      "step 84170 \t loss = 0.000, train_acc = 1.000 (3.354 sec/step)\n",
      "step 84180 \t loss = 0.002, train_acc = 1.000 (3.378 sec/step)\n",
      "step 84190 \t loss = 0.890, train_acc = 0.800 (3.349 sec/step)\n",
      "step 84200 \t loss = 0.113, train_acc = 1.000 (3.308 sec/step)\n",
      "step 84210 \t loss = 0.000, train_acc = 1.000 (3.326 sec/step)\n",
      "step 84220 \t loss = 1.380, train_acc = 0.700 (3.400 sec/step)\n",
      "step 84230 \t loss = 1.040, train_acc = 0.800 (3.330 sec/step)\n",
      "step 84240 \t loss = 0.138, train_acc = 1.000 (3.321 sec/step)\n",
      "step 84250 \t loss = 0.598, train_acc = 0.900 (3.358 sec/step)\n",
      "step 84260 \t loss = 0.030, train_acc = 1.000 (3.308 sec/step)\n",
      "step 84270 \t loss = 0.202, train_acc = 0.900 (3.328 sec/step)\n",
      "step 84280 \t loss = 0.000, train_acc = 1.000 (3.323 sec/step)\n",
      "step 84290 \t loss = 0.245, train_acc = 0.900 (3.344 sec/step)\n",
      "step 84300 \t loss = 0.017, train_acc = 1.000 (3.317 sec/step)\n",
      "step 84310 \t loss = 0.061, train_acc = 1.000 (3.347 sec/step)\n",
      "step 84320 \t loss = 0.474, train_acc = 0.900 (3.374 sec/step)\n",
      "step 84330 \t loss = 0.431, train_acc = 0.900 (3.334 sec/step)\n",
      "step 84340 \t loss = 0.018, train_acc = 1.000 (3.335 sec/step)\n",
      "step 84350 \t loss = 0.021, train_acc = 1.000 (3.399 sec/step)\n",
      "step 84360 \t loss = 0.147, train_acc = 0.900 (3.357 sec/step)\n",
      "step 84370 \t loss = 0.104, train_acc = 0.900 (3.388 sec/step)\n",
      "step 84380 \t loss = 0.271, train_acc = 0.900 (3.316 sec/step)\n",
      "step 84390 \t loss = 0.001, train_acc = 1.000 (3.330 sec/step)\n",
      "step 84400 \t loss = 0.003, train_acc = 1.000 (3.369 sec/step)\n",
      "step 84410 \t loss = 0.297, train_acc = 0.900 (3.399 sec/step)\n",
      "step 84420 \t loss = 0.050, train_acc = 1.000 (3.311 sec/step)\n",
      "step 84430 \t loss = 0.282, train_acc = 0.900 (3.338 sec/step)\n",
      "step 84440 \t loss = 0.002, train_acc = 1.000 (3.360 sec/step)\n",
      "step 84450 \t loss = 0.007, train_acc = 1.000 (3.363 sec/step)\n",
      "step 84460 \t loss = 1.746, train_acc = 0.900 (3.338 sec/step)\n",
      "step 84470 \t loss = 0.858, train_acc = 0.900 (3.349 sec/step)\n",
      "step 84480 \t loss = 0.133, train_acc = 1.000 (3.352 sec/step)\n",
      "step 84490 \t loss = 0.008, train_acc = 1.000 (3.352 sec/step)\n",
      "step 84500 \t loss = 0.119, train_acc = 0.900 (3.360 sec/step)\n",
      "step 84510 \t loss = 0.036, train_acc = 1.000 (3.332 sec/step)\n",
      "step 84520 \t loss = 0.602, train_acc = 0.900 (3.379 sec/step)\n",
      "step 84530 \t loss = 0.000, train_acc = 1.000 (3.335 sec/step)\n",
      "step 84540 \t loss = 0.011, train_acc = 1.000 (3.310 sec/step)\n",
      "step 84550 \t loss = 0.062, train_acc = 1.000 (3.361 sec/step)\n",
      "step 84560 \t loss = 0.631, train_acc = 0.900 (3.353 sec/step)\n",
      "step 84570 \t loss = 0.938, train_acc = 0.800 (3.347 sec/step)\n",
      "step 84580 \t loss = 0.550, train_acc = 0.900 (3.409 sec/step)\n",
      "step 84590 \t loss = 0.145, train_acc = 0.900 (3.399 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 84600 \t loss = 0.036, train_acc = 1.000 (3.366 sec/step)\n",
      "step 84610 \t loss = 0.078, train_acc = 1.000 (3.315 sec/step)\n",
      "step 84620 \t loss = 0.055, train_acc = 1.000 (3.349 sec/step)\n",
      "step 84630 \t loss = 0.073, train_acc = 1.000 (3.374 sec/step)\n",
      "step 84640 \t loss = 0.339, train_acc = 0.900 (3.402 sec/step)\n",
      "step 84650 \t loss = 0.031, train_acc = 1.000 (3.390 sec/step)\n",
      "step 84660 \t loss = 0.503, train_acc = 0.900 (3.330 sec/step)\n",
      "step 84670 \t loss = 0.103, train_acc = 0.900 (3.392 sec/step)\n",
      "step 84680 \t loss = 0.101, train_acc = 0.900 (3.399 sec/step)\n",
      "step 84690 \t loss = 0.705, train_acc = 0.800 (3.339 sec/step)\n",
      "step 84700 \t loss = 0.013, train_acc = 1.000 (3.342 sec/step)\n",
      "step 84710 \t loss = 0.069, train_acc = 1.000 (3.340 sec/step)\n",
      "step 84720 \t loss = 0.041, train_acc = 1.000 (3.371 sec/step)\n",
      "step 84730 \t loss = 0.219, train_acc = 0.900 (3.344 sec/step)\n",
      "step 84740 \t loss = 0.102, train_acc = 0.900 (3.393 sec/step)\n",
      "step 84750 \t loss = 1.308, train_acc = 0.800 (3.425 sec/step)\n",
      "step 84760 \t loss = 0.177, train_acc = 0.900 (3.324 sec/step)\n",
      "step 84770 \t loss = 0.294, train_acc = 0.900 (3.317 sec/step)\n",
      "step 84780 \t loss = 0.027, train_acc = 1.000 (3.348 sec/step)\n",
      "step 84790 \t loss = 0.317, train_acc = 0.900 (3.297 sec/step)\n",
      "step 84800 \t loss = 0.266, train_acc = 0.900 (3.310 sec/step)\n",
      "step 84810 \t loss = 0.027, train_acc = 1.000 (3.376 sec/step)\n",
      "step 84820 \t loss = 0.000, train_acc = 1.000 (3.348 sec/step)\n",
      "step 84830 \t loss = 0.000, train_acc = 1.000 (3.334 sec/step)\n",
      "step 84840 \t loss = 0.000, train_acc = 1.000 (3.478 sec/step)\n",
      "step 84850 \t loss = 0.349, train_acc = 0.900 (3.364 sec/step)\n",
      "step 84860 \t loss = 0.638, train_acc = 0.800 (3.370 sec/step)\n",
      "step 84870 \t loss = 0.853, train_acc = 0.800 (3.361 sec/step)\n",
      "step 84880 \t loss = 0.029, train_acc = 1.000 (3.384 sec/step)\n",
      "step 84890 \t loss = 0.051, train_acc = 1.000 (3.364 sec/step)\n",
      "step 84900 \t loss = 0.000, train_acc = 1.000 (3.336 sec/step)\n",
      "step 84910 \t loss = 0.004, train_acc = 1.000 (3.331 sec/step)\n",
      "step 84920 \t loss = 1.200, train_acc = 0.800 (3.353 sec/step)\n",
      "step 84930 \t loss = 0.629, train_acc = 0.900 (3.380 sec/step)\n",
      "step 84940 \t loss = 1.038, train_acc = 0.900 (3.331 sec/step)\n",
      "step 84950 \t loss = 0.380, train_acc = 0.900 (3.368 sec/step)\n",
      "step 84960 \t loss = 0.213, train_acc = 0.900 (3.334 sec/step)\n",
      "step 84970 \t loss = 0.035, train_acc = 1.000 (3.411 sec/step)\n",
      "step 84980 \t loss = 0.675, train_acc = 0.800 (3.312 sec/step)\n",
      "step 84990 \t loss = 0.642, train_acc = 0.900 (3.314 sec/step)\n",
      "step 85000 \t loss = 0.068, train_acc = 1.000 (3.346 sec/step)\n",
      "step 85010 \t loss = 0.000, train_acc = 1.000 (3.410 sec/step)\n",
      "step 85020 \t loss = 0.083, train_acc = 0.900 (3.342 sec/step)\n",
      "step 85030 \t loss = 0.151, train_acc = 1.000 (3.378 sec/step)\n",
      "step 85040 \t loss = 0.079, train_acc = 1.000 (3.371 sec/step)\n",
      "step 85050 \t loss = 1.184, train_acc = 0.900 (3.353 sec/step)\n",
      "step 85060 \t loss = 0.005, train_acc = 1.000 (3.350 sec/step)\n",
      "step 85070 \t loss = 0.352, train_acc = 0.900 (3.399 sec/step)\n",
      "step 85080 \t loss = 0.066, train_acc = 1.000 (3.369 sec/step)\n",
      "step 85090 \t loss = 0.078, train_acc = 1.000 (3.321 sec/step)\n",
      "step 85100 \t loss = 0.074, train_acc = 1.000 (3.339 sec/step)\n",
      "step 85110 \t loss = 0.180, train_acc = 0.900 (3.355 sec/step)\n",
      "step 85120 \t loss = 0.086, train_acc = 0.900 (3.360 sec/step)\n",
      "step 85130 \t loss = 0.001, train_acc = 1.000 (3.367 sec/step)\n",
      "step 85140 \t loss = 0.393, train_acc = 0.800 (3.380 sec/step)\n",
      "step 85150 \t loss = 0.073, train_acc = 1.000 (3.362 sec/step)\n",
      "step 85160 \t loss = 0.000, train_acc = 1.000 (3.372 sec/step)\n",
      "step 85170 \t loss = 0.141, train_acc = 1.000 (3.341 sec/step)\n",
      "step 85180 \t loss = 0.001, train_acc = 1.000 (3.361 sec/step)\n",
      "step 85190 \t loss = 0.013, train_acc = 1.000 (3.382 sec/step)\n",
      "step 85200 \t loss = 0.000, train_acc = 1.000 (3.383 sec/step)\n",
      "step 85210 \t loss = 0.046, train_acc = 1.000 (3.375 sec/step)\n",
      "step 85220 \t loss = 0.517, train_acc = 0.800 (3.458 sec/step)\n",
      "step 85230 \t loss = 0.064, train_acc = 1.000 (3.310 sec/step)\n",
      "step 85240 \t loss = 4.633, train_acc = 0.800 (3.341 sec/step)\n",
      "step 85250 \t loss = 0.105, train_acc = 1.000 (3.365 sec/step)\n",
      "step 85260 \t loss = 0.041, train_acc = 1.000 (3.391 sec/step)\n",
      "step 85270 \t loss = 0.797, train_acc = 0.700 (3.341 sec/step)\n",
      "step 85280 \t loss = 0.043, train_acc = 1.000 (3.350 sec/step)\n",
      "step 85290 \t loss = 0.004, train_acc = 1.000 (3.409 sec/step)\n",
      "step 85300 \t loss = 0.009, train_acc = 1.000 (3.352 sec/step)\n",
      "step 85310 \t loss = 0.392, train_acc = 0.800 (3.365 sec/step)\n",
      "step 85320 \t loss = 0.798, train_acc = 0.800 (3.359 sec/step)\n",
      "step 85330 \t loss = 0.094, train_acc = 1.000 (3.319 sec/step)\n",
      "step 85340 \t loss = 0.405, train_acc = 0.900 (3.367 sec/step)\n",
      "step 85350 \t loss = 0.003, train_acc = 1.000 (3.337 sec/step)\n",
      "step 85360 \t loss = 0.869, train_acc = 0.900 (3.375 sec/step)\n",
      "step 85370 \t loss = 0.002, train_acc = 1.000 (3.388 sec/step)\n",
      "step 85380 \t loss = 0.014, train_acc = 1.000 (3.298 sec/step)\n",
      "step 85390 \t loss = 0.203, train_acc = 0.900 (3.373 sec/step)\n",
      "step 85400 \t loss = 0.007, train_acc = 1.000 (3.309 sec/step)\n",
      "step 85410 \t loss = 0.156, train_acc = 0.900 (3.410 sec/step)\n",
      "step 85420 \t loss = 0.127, train_acc = 0.900 (3.419 sec/step)\n",
      "step 85430 \t loss = 0.025, train_acc = 1.000 (3.381 sec/step)\n",
      "step 85440 \t loss = 0.013, train_acc = 1.000 (3.397 sec/step)\n",
      "step 85450 \t loss = 0.194, train_acc = 0.900 (3.394 sec/step)\n",
      "step 85460 \t loss = 0.069, train_acc = 1.000 (3.377 sec/step)\n",
      "step 85470 \t loss = 0.077, train_acc = 1.000 (3.340 sec/step)\n",
      "step 85480 \t loss = 0.033, train_acc = 1.000 (3.370 sec/step)\n",
      "step 85490 \t loss = 0.003, train_acc = 1.000 (3.472 sec/step)\n",
      "VALIDATION \t acc = 0.534 (3.626 sec)\n",
      "step 85500 \t loss = 0.070, train_acc = 1.000 (3.355 sec/step)\n",
      "step 85510 \t loss = 0.002, train_acc = 1.000 (3.353 sec/step)\n",
      "step 85520 \t loss = 0.093, train_acc = 1.000 (3.390 sec/step)\n",
      "step 85530 \t loss = 1.716, train_acc = 0.800 (3.352 sec/step)\n",
      "step 85540 \t loss = 0.001, train_acc = 1.000 (3.397 sec/step)\n",
      "step 85550 \t loss = 0.018, train_acc = 1.000 (3.438 sec/step)\n",
      "step 85560 \t loss = 0.014, train_acc = 1.000 (3.408 sec/step)\n",
      "step 85570 \t loss = 0.051, train_acc = 1.000 (3.404 sec/step)\n",
      "step 85580 \t loss = 0.023, train_acc = 1.000 (3.383 sec/step)\n",
      "step 85590 \t loss = 0.404, train_acc = 0.900 (3.390 sec/step)\n",
      "step 85600 \t loss = 0.298, train_acc = 0.900 (3.441 sec/step)\n",
      "step 85610 \t loss = 0.426, train_acc = 0.900 (3.304 sec/step)\n",
      "step 85620 \t loss = 0.194, train_acc = 0.900 (3.324 sec/step)\n",
      "step 85630 \t loss = 0.000, train_acc = 1.000 (3.345 sec/step)\n",
      "step 85640 \t loss = 0.059, train_acc = 1.000 (3.335 sec/step)\n",
      "step 85650 \t loss = 0.029, train_acc = 1.000 (3.352 sec/step)\n",
      "step 85660 \t loss = 0.063, train_acc = 1.000 (3.361 sec/step)\n",
      "step 85670 \t loss = 0.330, train_acc = 0.900 (3.307 sec/step)\n",
      "step 85680 \t loss = 0.000, train_acc = 1.000 (3.326 sec/step)\n",
      "step 85690 \t loss = 0.278, train_acc = 0.800 (3.420 sec/step)\n",
      "step 85700 \t loss = 0.231, train_acc = 0.900 (3.352 sec/step)\n",
      "step 85710 \t loss = 0.249, train_acc = 0.900 (3.439 sec/step)\n",
      "step 85720 \t loss = 0.385, train_acc = 0.800 (3.390 sec/step)\n",
      "step 85730 \t loss = 0.196, train_acc = 0.900 (3.378 sec/step)\n",
      "step 85740 \t loss = 0.725, train_acc = 0.700 (3.343 sec/step)\n",
      "step 85750 \t loss = 0.055, train_acc = 1.000 (3.361 sec/step)\n",
      "step 85760 \t loss = 0.016, train_acc = 1.000 (3.368 sec/step)\n",
      "step 85770 \t loss = 0.008, train_acc = 1.000 (3.358 sec/step)\n",
      "step 85780 \t loss = 0.000, train_acc = 1.000 (3.332 sec/step)\n",
      "step 85790 \t loss = 0.000, train_acc = 1.000 (3.377 sec/step)\n",
      "step 85800 \t loss = 0.004, train_acc = 1.000 (3.353 sec/step)\n",
      "step 85810 \t loss = 0.218, train_acc = 0.800 (3.317 sec/step)\n",
      "step 85820 \t loss = 0.102, train_acc = 0.900 (3.394 sec/step)\n",
      "step 85830 \t loss = 0.179, train_acc = 0.900 (3.334 sec/step)\n",
      "step 85840 \t loss = 0.152, train_acc = 0.900 (3.381 sec/step)\n",
      "step 85850 \t loss = 0.012, train_acc = 1.000 (3.351 sec/step)\n",
      "step 85860 \t loss = 0.022, train_acc = 1.000 (3.342 sec/step)\n",
      "step 85870 \t loss = 0.003, train_acc = 1.000 (3.362 sec/step)\n",
      "step 85880 \t loss = 0.017, train_acc = 1.000 (3.334 sec/step)\n",
      "step 85890 \t loss = 0.160, train_acc = 1.000 (3.349 sec/step)\n",
      "step 85900 \t loss = 0.003, train_acc = 1.000 (3.314 sec/step)\n",
      "step 85910 \t loss = 0.100, train_acc = 0.900 (3.322 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 85920 \t loss = 0.001, train_acc = 1.000 (3.369 sec/step)\n",
      "step 85930 \t loss = 0.231, train_acc = 0.900 (3.387 sec/step)\n",
      "step 85940 \t loss = 0.145, train_acc = 1.000 (3.464 sec/step)\n",
      "step 85950 \t loss = 0.000, train_acc = 1.000 (3.391 sec/step)\n",
      "step 85960 \t loss = 0.080, train_acc = 0.900 (3.343 sec/step)\n",
      "step 85970 \t loss = 0.271, train_acc = 0.800 (3.382 sec/step)\n",
      "step 85980 \t loss = 0.079, train_acc = 0.900 (3.355 sec/step)\n",
      "step 85990 \t loss = 0.008, train_acc = 1.000 (3.382 sec/step)\n",
      "step 86000 \t loss = 0.005, train_acc = 1.000 (3.383 sec/step)\n",
      "step 86010 \t loss = 0.043, train_acc = 1.000 (3.331 sec/step)\n",
      "step 86020 \t loss = 0.314, train_acc = 0.800 (3.341 sec/step)\n",
      "step 86030 \t loss = 0.012, train_acc = 1.000 (3.359 sec/step)\n",
      "step 86040 \t loss = 0.116, train_acc = 1.000 (3.366 sec/step)\n",
      "step 86050 \t loss = 0.276, train_acc = 0.900 (3.324 sec/step)\n",
      "step 86060 \t loss = 0.225, train_acc = 0.900 (3.396 sec/step)\n",
      "step 86070 \t loss = 0.080, train_acc = 0.900 (3.345 sec/step)\n",
      "step 86080 \t loss = 0.118, train_acc = 1.000 (3.381 sec/step)\n",
      "step 86090 \t loss = 0.663, train_acc = 0.800 (3.381 sec/step)\n",
      "step 86100 \t loss = 0.461, train_acc = 0.800 (3.409 sec/step)\n",
      "step 86110 \t loss = 0.029, train_acc = 1.000 (3.348 sec/step)\n",
      "step 86120 \t loss = 0.000, train_acc = 1.000 (3.350 sec/step)\n",
      "step 86130 \t loss = 0.048, train_acc = 1.000 (3.377 sec/step)\n",
      "step 86140 \t loss = 0.230, train_acc = 0.900 (3.464 sec/step)\n",
      "step 86150 \t loss = 0.080, train_acc = 0.900 (3.308 sec/step)\n",
      "step 86160 \t loss = 0.005, train_acc = 1.000 (3.306 sec/step)\n",
      "step 86170 \t loss = 0.027, train_acc = 1.000 (3.339 sec/step)\n",
      "step 86180 \t loss = 0.008, train_acc = 1.000 (3.321 sec/step)\n",
      "step 86190 \t loss = 0.004, train_acc = 1.000 (3.330 sec/step)\n",
      "step 86200 \t loss = 0.564, train_acc = 0.700 (3.364 sec/step)\n",
      "step 86210 \t loss = 0.081, train_acc = 0.900 (3.389 sec/step)\n",
      "step 86220 \t loss = 0.006, train_acc = 1.000 (3.355 sec/step)\n",
      "step 86230 \t loss = 0.147, train_acc = 0.900 (3.350 sec/step)\n",
      "step 86240 \t loss = 0.016, train_acc = 1.000 (3.353 sec/step)\n",
      "step 86250 \t loss = 0.733, train_acc = 0.900 (3.388 sec/step)\n",
      "step 86260 \t loss = 0.005, train_acc = 1.000 (3.385 sec/step)\n",
      "step 86270 \t loss = 0.041, train_acc = 1.000 (3.378 sec/step)\n",
      "step 86280 \t loss = 0.168, train_acc = 0.900 (3.357 sec/step)\n",
      "step 86290 \t loss = 0.029, train_acc = 1.000 (3.335 sec/step)\n",
      "step 86300 \t loss = 0.750, train_acc = 0.900 (3.390 sec/step)\n",
      "step 86310 \t loss = 0.003, train_acc = 1.000 (3.347 sec/step)\n",
      "step 86320 \t loss = 0.051, train_acc = 1.000 (3.364 sec/step)\n",
      "step 86330 \t loss = 0.245, train_acc = 1.000 (3.332 sec/step)\n",
      "step 86340 \t loss = 0.691, train_acc = 0.900 (3.367 sec/step)\n",
      "step 86350 \t loss = 0.187, train_acc = 0.900 (3.311 sec/step)\n",
      "step 86360 \t loss = 0.079, train_acc = 1.000 (3.398 sec/step)\n",
      "step 86370 \t loss = 0.014, train_acc = 1.000 (3.391 sec/step)\n",
      "step 86380 \t loss = 0.025, train_acc = 1.000 (3.323 sec/step)\n",
      "step 86390 \t loss = 0.001, train_acc = 1.000 (3.377 sec/step)\n",
      "step 86400 \t loss = 0.422, train_acc = 0.900 (3.399 sec/step)\n",
      "step 86410 \t loss = 0.565, train_acc = 0.800 (3.363 sec/step)\n",
      "step 86420 \t loss = 0.454, train_acc = 0.800 (3.341 sec/step)\n",
      "step 86430 \t loss = 0.606, train_acc = 0.900 (3.325 sec/step)\n",
      "step 86440 \t loss = 0.106, train_acc = 1.000 (3.363 sec/step)\n",
      "step 86450 \t loss = 0.457, train_acc = 0.800 (3.412 sec/step)\n",
      "step 86460 \t loss = 0.062, train_acc = 1.000 (3.384 sec/step)\n",
      "step 86470 \t loss = 0.207, train_acc = 0.800 (3.332 sec/step)\n",
      "step 86480 \t loss = 0.025, train_acc = 1.000 (3.357 sec/step)\n",
      "step 86490 \t loss = 0.005, train_acc = 1.000 (3.346 sec/step)\n",
      "step 86500 \t loss = 0.004, train_acc = 1.000 (3.363 sec/step)\n",
      "step 86510 \t loss = 0.001, train_acc = 1.000 (3.372 sec/step)\n",
      "step 86520 \t loss = 0.036, train_acc = 1.000 (3.354 sec/step)\n",
      "step 86530 \t loss = 0.485, train_acc = 0.700 (3.431 sec/step)\n",
      "step 86540 \t loss = 0.426, train_acc = 0.800 (3.346 sec/step)\n",
      "step 86550 \t loss = 0.305, train_acc = 0.900 (3.334 sec/step)\n",
      "step 86560 \t loss = 0.050, train_acc = 1.000 (3.351 sec/step)\n",
      "step 86570 \t loss = 0.015, train_acc = 1.000 (3.316 sec/step)\n",
      "step 86580 \t loss = 0.075, train_acc = 1.000 (3.347 sec/step)\n",
      "step 86590 \t loss = 0.216, train_acc = 0.900 (3.355 sec/step)\n",
      "step 86600 \t loss = 0.000, train_acc = 1.000 (3.359 sec/step)\n",
      "step 86610 \t loss = 0.002, train_acc = 1.000 (3.315 sec/step)\n",
      "step 86620 \t loss = 0.030, train_acc = 1.000 (3.332 sec/step)\n",
      "step 86630 \t loss = 0.452, train_acc = 0.800 (3.345 sec/step)\n",
      "step 86640 \t loss = 0.061, train_acc = 1.000 (3.372 sec/step)\n",
      "step 86650 \t loss = 0.018, train_acc = 1.000 (3.365 sec/step)\n",
      "step 86660 \t loss = 0.085, train_acc = 1.000 (3.346 sec/step)\n",
      "step 86670 \t loss = 0.005, train_acc = 1.000 (3.351 sec/step)\n",
      "step 86680 \t loss = 0.001, train_acc = 1.000 (3.351 sec/step)\n",
      "step 86690 \t loss = 0.101, train_acc = 1.000 (3.313 sec/step)\n",
      "step 86700 \t loss = 0.320, train_acc = 0.900 (3.348 sec/step)\n",
      "step 86710 \t loss = 0.012, train_acc = 1.000 (3.324 sec/step)\n",
      "step 86720 \t loss = 0.146, train_acc = 0.900 (3.329 sec/step)\n",
      "step 86730 \t loss = 0.345, train_acc = 0.900 (3.385 sec/step)\n",
      "step 86740 \t loss = 0.042, train_acc = 1.000 (3.368 sec/step)\n",
      "step 86750 \t loss = 0.001, train_acc = 1.000 (3.394 sec/step)\n",
      "step 86760 \t loss = 0.078, train_acc = 0.900 (3.369 sec/step)\n",
      "step 86770 \t loss = 0.067, train_acc = 1.000 (3.351 sec/step)\n",
      "step 86780 \t loss = 0.012, train_acc = 1.000 (3.429 sec/step)\n",
      "step 86790 \t loss = 0.005, train_acc = 1.000 (3.362 sec/step)\n",
      "step 86800 \t loss = 0.000, train_acc = 1.000 (3.354 sec/step)\n",
      "step 86810 \t loss = 0.019, train_acc = 1.000 (3.361 sec/step)\n",
      "step 86820 \t loss = 0.021, train_acc = 1.000 (3.336 sec/step)\n",
      "step 86830 \t loss = 0.238, train_acc = 0.900 (3.350 sec/step)\n",
      "step 86840 \t loss = 0.002, train_acc = 1.000 (3.339 sec/step)\n",
      "step 86850 \t loss = 0.012, train_acc = 1.000 (3.384 sec/step)\n",
      "step 86860 \t loss = 0.064, train_acc = 1.000 (3.417 sec/step)\n",
      "step 86870 \t loss = 0.087, train_acc = 1.000 (3.397 sec/step)\n",
      "step 86880 \t loss = 0.311, train_acc = 0.900 (3.337 sec/step)\n",
      "step 86890 \t loss = 0.257, train_acc = 0.800 (3.346 sec/step)\n",
      "step 86900 \t loss = 0.089, train_acc = 1.000 (3.388 sec/step)\n",
      "step 86910 \t loss = 0.197, train_acc = 0.900 (3.320 sec/step)\n",
      "step 86920 \t loss = 0.002, train_acc = 1.000 (3.328 sec/step)\n",
      "step 86930 \t loss = 0.228, train_acc = 0.900 (3.395 sec/step)\n",
      "step 86940 \t loss = 0.540, train_acc = 0.900 (3.346 sec/step)\n",
      "step 86950 \t loss = 1.907, train_acc = 0.500 (3.327 sec/step)\n",
      "step 86960 \t loss = 0.150, train_acc = 0.900 (3.368 sec/step)\n",
      "step 86970 \t loss = 0.005, train_acc = 1.000 (3.388 sec/step)\n",
      "step 86980 \t loss = 0.015, train_acc = 1.000 (3.367 sec/step)\n",
      "step 86990 \t loss = 0.002, train_acc = 1.000 (3.358 sec/step)\n",
      "step 87000 \t loss = 0.000, train_acc = 1.000 (3.358 sec/step)\n",
      "step 87010 \t loss = 0.014, train_acc = 1.000 (3.356 sec/step)\n",
      "step 87020 \t loss = 0.001, train_acc = 1.000 (3.337 sec/step)\n",
      "step 87030 \t loss = 3.799, train_acc = 0.900 (3.345 sec/step)\n",
      "step 87040 \t loss = 0.195, train_acc = 0.900 (3.327 sec/step)\n",
      "step 87050 \t loss = 0.295, train_acc = 0.800 (3.324 sec/step)\n",
      "step 87060 \t loss = 0.606, train_acc = 0.900 (3.335 sec/step)\n",
      "step 87070 \t loss = 0.325, train_acc = 0.900 (3.310 sec/step)\n",
      "step 87080 \t loss = 0.397, train_acc = 0.800 (3.362 sec/step)\n",
      "step 87090 \t loss = 0.004, train_acc = 1.000 (3.335 sec/step)\n",
      "step 87100 \t loss = 0.202, train_acc = 0.900 (3.389 sec/step)\n",
      "step 87110 \t loss = 0.002, train_acc = 1.000 (3.348 sec/step)\n",
      "step 87120 \t loss = 1.199, train_acc = 0.800 (3.389 sec/step)\n",
      "step 87130 \t loss = 0.216, train_acc = 0.900 (3.353 sec/step)\n",
      "step 87140 \t loss = 0.002, train_acc = 1.000 (3.372 sec/step)\n",
      "step 87150 \t loss = 0.019, train_acc = 1.000 (3.429 sec/step)\n",
      "step 87160 \t loss = 0.009, train_acc = 1.000 (3.358 sec/step)\n",
      "step 87170 \t loss = 1.511, train_acc = 0.900 (3.383 sec/step)\n",
      "step 87180 \t loss = 0.062, train_acc = 1.000 (3.403 sec/step)\n",
      "step 87190 \t loss = 0.326, train_acc = 0.900 (3.368 sec/step)\n",
      "step 87200 \t loss = 0.360, train_acc = 0.900 (3.327 sec/step)\n",
      "step 87210 \t loss = 0.139, train_acc = 1.000 (3.350 sec/step)\n",
      "step 87220 \t loss = 0.025, train_acc = 1.000 (3.358 sec/step)\n",
      "step 87230 \t loss = 0.200, train_acc = 1.000 (3.331 sec/step)\n",
      "step 87240 \t loss = 0.039, train_acc = 1.000 (3.388 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 87250 \t loss = 0.006, train_acc = 1.000 (3.363 sec/step)\n",
      "step 87260 \t loss = 0.203, train_acc = 0.900 (3.360 sec/step)\n",
      "step 87270 \t loss = 0.015, train_acc = 1.000 (3.387 sec/step)\n",
      "step 87280 \t loss = 0.148, train_acc = 0.900 (3.390 sec/step)\n",
      "step 87290 \t loss = 0.545, train_acc = 0.800 (3.378 sec/step)\n",
      "step 87300 \t loss = 1.441, train_acc = 0.900 (3.397 sec/step)\n",
      "step 87310 \t loss = 0.006, train_acc = 1.000 (3.356 sec/step)\n",
      "step 87320 \t loss = 0.063, train_acc = 1.000 (3.360 sec/step)\n",
      "step 87330 \t loss = 0.018, train_acc = 1.000 (3.317 sec/step)\n",
      "step 87340 \t loss = 0.068, train_acc = 1.000 (3.329 sec/step)\n",
      "step 87350 \t loss = 0.033, train_acc = 1.000 (3.338 sec/step)\n",
      "step 87360 \t loss = 0.926, train_acc = 0.700 (3.360 sec/step)\n",
      "step 87370 \t loss = 0.115, train_acc = 1.000 (3.375 sec/step)\n",
      "step 87380 \t loss = 0.001, train_acc = 1.000 (3.340 sec/step)\n",
      "step 87390 \t loss = 0.245, train_acc = 0.900 (3.365 sec/step)\n",
      "VALIDATION \t acc = 0.546 (3.616 sec)\n",
      "step 87400 \t loss = 0.003, train_acc = 1.000 (3.349 sec/step)\n",
      "step 87410 \t loss = 0.004, train_acc = 1.000 (3.302 sec/step)\n",
      "step 87420 \t loss = 0.022, train_acc = 1.000 (3.338 sec/step)\n",
      "step 87430 \t loss = 0.262, train_acc = 0.800 (3.345 sec/step)\n",
      "step 87440 \t loss = 0.389, train_acc = 0.800 (3.372 sec/step)\n",
      "step 87450 \t loss = 0.232, train_acc = 0.900 (3.406 sec/step)\n",
      "step 87460 \t loss = 0.004, train_acc = 1.000 (3.393 sec/step)\n",
      "step 87470 \t loss = 0.000, train_acc = 1.000 (3.311 sec/step)\n",
      "step 87480 \t loss = 0.154, train_acc = 0.900 (3.337 sec/step)\n",
      "step 87490 \t loss = 0.143, train_acc = 0.900 (3.371 sec/step)\n",
      "step 87500 \t loss = 0.015, train_acc = 1.000 (3.334 sec/step)\n",
      "step 87510 \t loss = 0.000, train_acc = 1.000 (3.384 sec/step)\n",
      "step 87520 \t loss = 0.002, train_acc = 1.000 (3.379 sec/step)\n",
      "step 87530 \t loss = 0.002, train_acc = 1.000 (3.331 sec/step)\n",
      "step 87540 \t loss = 0.057, train_acc = 1.000 (3.391 sec/step)\n",
      "step 87550 \t loss = 0.895, train_acc = 0.700 (3.348 sec/step)\n",
      "step 87560 \t loss = 0.098, train_acc = 1.000 (3.353 sec/step)\n",
      "step 87570 \t loss = 0.056, train_acc = 1.000 (3.345 sec/step)\n",
      "step 87580 \t loss = 0.061, train_acc = 1.000 (3.367 sec/step)\n",
      "step 87590 \t loss = 0.285, train_acc = 0.900 (3.377 sec/step)\n",
      "step 87600 \t loss = 0.306, train_acc = 0.900 (3.389 sec/step)\n",
      "step 87610 \t loss = 0.009, train_acc = 1.000 (3.335 sec/step)\n",
      "step 87620 \t loss = 0.007, train_acc = 1.000 (3.369 sec/step)\n",
      "step 87630 \t loss = 0.166, train_acc = 0.900 (3.328 sec/step)\n",
      "step 87640 \t loss = 0.186, train_acc = 0.900 (3.377 sec/step)\n",
      "step 87650 \t loss = 0.132, train_acc = 1.000 (3.351 sec/step)\n",
      "step 87660 \t loss = 0.202, train_acc = 0.900 (3.337 sec/step)\n",
      "step 87670 \t loss = 0.001, train_acc = 1.000 (3.392 sec/step)\n",
      "step 87680 \t loss = 0.149, train_acc = 0.900 (3.324 sec/step)\n",
      "step 87690 \t loss = 0.016, train_acc = 1.000 (3.357 sec/step)\n",
      "step 87700 \t loss = 0.306, train_acc = 0.900 (3.342 sec/step)\n",
      "step 87710 \t loss = 0.106, train_acc = 0.900 (3.317 sec/step)\n",
      "step 87720 \t loss = 0.021, train_acc = 1.000 (3.381 sec/step)\n",
      "step 87730 \t loss = 0.374, train_acc = 0.900 (3.356 sec/step)\n",
      "step 87740 \t loss = 0.195, train_acc = 0.900 (3.356 sec/step)\n",
      "step 87750 \t loss = 0.354, train_acc = 0.900 (3.355 sec/step)\n",
      "step 87760 \t loss = 0.012, train_acc = 1.000 (3.377 sec/step)\n",
      "step 87770 \t loss = 0.271, train_acc = 0.900 (3.315 sec/step)\n",
      "step 87780 \t loss = 0.002, train_acc = 1.000 (3.451 sec/step)\n",
      "step 87790 \t loss = 0.000, train_acc = 1.000 (3.310 sec/step)\n",
      "step 87800 \t loss = 0.748, train_acc = 0.700 (3.357 sec/step)\n",
      "step 87810 \t loss = 0.001, train_acc = 1.000 (3.326 sec/step)\n",
      "step 87820 \t loss = 0.020, train_acc = 1.000 (3.381 sec/step)\n",
      "step 87830 \t loss = 0.027, train_acc = 1.000 (3.331 sec/step)\n",
      "step 87840 \t loss = 0.000, train_acc = 1.000 (3.308 sec/step)\n",
      "step 87850 \t loss = 0.062, train_acc = 1.000 (3.386 sec/step)\n",
      "step 87860 \t loss = 0.001, train_acc = 1.000 (3.398 sec/step)\n",
      "step 87870 \t loss = 0.580, train_acc = 0.900 (3.342 sec/step)\n",
      "step 87880 \t loss = 0.270, train_acc = 0.900 (3.345 sec/step)\n",
      "step 87890 \t loss = 0.321, train_acc = 0.900 (3.317 sec/step)\n",
      "step 87900 \t loss = 0.141, train_acc = 0.900 (3.375 sec/step)\n",
      "step 87910 \t loss = 0.243, train_acc = 0.800 (3.365 sec/step)\n",
      "step 87920 \t loss = 0.007, train_acc = 1.000 (3.377 sec/step)\n",
      "step 87930 \t loss = 0.210, train_acc = 0.800 (3.366 sec/step)\n",
      "step 87940 \t loss = 0.008, train_acc = 1.000 (3.440 sec/step)\n",
      "step 87950 \t loss = 0.003, train_acc = 1.000 (3.357 sec/step)\n",
      "step 87960 \t loss = 0.000, train_acc = 1.000 (3.323 sec/step)\n",
      "step 87970 \t loss = 0.017, train_acc = 1.000 (3.388 sec/step)\n",
      "step 87980 \t loss = 0.050, train_acc = 1.000 (3.354 sec/step)\n",
      "step 87990 \t loss = 0.062, train_acc = 1.000 (3.392 sec/step)\n",
      "step 88000 \t loss = 0.072, train_acc = 1.000 (3.315 sec/step)\n",
      "step 88010 \t loss = 0.000, train_acc = 1.000 (3.332 sec/step)\n",
      "step 88020 \t loss = 0.166, train_acc = 0.900 (3.359 sec/step)\n",
      "step 88030 \t loss = 0.011, train_acc = 1.000 (3.327 sec/step)\n",
      "step 88040 \t loss = 0.031, train_acc = 1.000 (3.329 sec/step)\n",
      "step 88050 \t loss = 0.007, train_acc = 1.000 (3.343 sec/step)\n",
      "step 88060 \t loss = 0.002, train_acc = 1.000 (3.364 sec/step)\n",
      "step 88070 \t loss = 0.003, train_acc = 1.000 (3.306 sec/step)\n",
      "step 88080 \t loss = 0.003, train_acc = 1.000 (3.369 sec/step)\n",
      "step 88090 \t loss = 0.087, train_acc = 1.000 (3.414 sec/step)\n",
      "step 88100 \t loss = 0.023, train_acc = 1.000 (3.330 sec/step)\n",
      "step 88110 \t loss = 0.056, train_acc = 1.000 (3.368 sec/step)\n",
      "step 88120 \t loss = 0.344, train_acc = 0.900 (3.367 sec/step)\n",
      "step 88130 \t loss = 0.002, train_acc = 1.000 (3.322 sec/step)\n",
      "step 88140 \t loss = 0.042, train_acc = 1.000 (3.353 sec/step)\n",
      "step 88150 \t loss = 2.070, train_acc = 0.500 (3.380 sec/step)\n",
      "step 88160 \t loss = 0.725, train_acc = 0.900 (3.360 sec/step)\n",
      "step 88170 \t loss = 0.051, train_acc = 1.000 (3.373 sec/step)\n",
      "step 88180 \t loss = 0.026, train_acc = 1.000 (3.307 sec/step)\n",
      "step 88190 \t loss = 0.009, train_acc = 1.000 (3.356 sec/step)\n",
      "step 88200 \t loss = 0.000, train_acc = 1.000 (3.313 sec/step)\n",
      "step 88210 \t loss = 0.005, train_acc = 1.000 (3.302 sec/step)\n",
      "step 88220 \t loss = 0.006, train_acc = 1.000 (3.324 sec/step)\n",
      "step 88230 \t loss = 0.006, train_acc = 1.000 (3.341 sec/step)\n",
      "step 88240 \t loss = 0.404, train_acc = 0.900 (3.363 sec/step)\n",
      "step 88250 \t loss = 0.984, train_acc = 0.800 (3.315 sec/step)\n",
      "step 88260 \t loss = 0.400, train_acc = 0.800 (3.330 sec/step)\n",
      "step 88270 \t loss = 0.000, train_acc = 1.000 (3.309 sec/step)\n",
      "step 88280 \t loss = 0.012, train_acc = 1.000 (3.325 sec/step)\n",
      "step 88290 \t loss = 0.798, train_acc = 0.800 (3.488 sec/step)\n",
      "step 88300 \t loss = 0.462, train_acc = 0.700 (3.303 sec/step)\n",
      "step 88310 \t loss = 0.002, train_acc = 1.000 (3.358 sec/step)\n",
      "step 88320 \t loss = 0.381, train_acc = 0.900 (3.384 sec/step)\n",
      "step 88330 \t loss = 0.006, train_acc = 1.000 (3.363 sec/step)\n",
      "step 88340 \t loss = 0.004, train_acc = 1.000 (3.346 sec/step)\n",
      "step 88350 \t loss = 1.116, train_acc = 0.900 (3.340 sec/step)\n",
      "step 88360 \t loss = 0.016, train_acc = 1.000 (3.340 sec/step)\n",
      "step 88370 \t loss = 0.003, train_acc = 1.000 (3.390 sec/step)\n",
      "step 88380 \t loss = 0.000, train_acc = 1.000 (3.325 sec/step)\n",
      "step 88390 \t loss = 0.044, train_acc = 1.000 (3.320 sec/step)\n",
      "step 88400 \t loss = 0.365, train_acc = 0.900 (3.348 sec/step)\n",
      "step 88410 \t loss = 0.236, train_acc = 0.900 (3.343 sec/step)\n",
      "step 88420 \t loss = 0.036, train_acc = 1.000 (3.375 sec/step)\n",
      "step 88430 \t loss = 0.100, train_acc = 0.900 (3.333 sec/step)\n",
      "step 88440 \t loss = 0.066, train_acc = 1.000 (3.334 sec/step)\n",
      "step 88450 \t loss = 0.010, train_acc = 1.000 (3.311 sec/step)\n",
      "step 88460 \t loss = 0.150, train_acc = 1.000 (3.321 sec/step)\n",
      "step 88470 \t loss = 0.127, train_acc = 1.000 (3.339 sec/step)\n",
      "step 88480 \t loss = 0.080, train_acc = 1.000 (3.356 sec/step)\n",
      "step 88490 \t loss = 0.014, train_acc = 1.000 (3.437 sec/step)\n",
      "step 88500 \t loss = 0.008, train_acc = 1.000 (3.391 sec/step)\n",
      "step 88510 \t loss = 0.000, train_acc = 1.000 (3.377 sec/step)\n",
      "step 88520 \t loss = 0.000, train_acc = 1.000 (3.378 sec/step)\n",
      "step 88530 \t loss = 0.000, train_acc = 1.000 (3.373 sec/step)\n",
      "step 88540 \t loss = 0.001, train_acc = 1.000 (3.354 sec/step)\n",
      "step 88550 \t loss = 0.016, train_acc = 1.000 (3.371 sec/step)\n",
      "step 88560 \t loss = 0.000, train_acc = 1.000 (3.387 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 88570 \t loss = 0.000, train_acc = 1.000 (3.316 sec/step)\n",
      "step 88580 \t loss = 0.520, train_acc = 0.900 (3.387 sec/step)\n",
      "step 88590 \t loss = 0.054, train_acc = 1.000 (3.350 sec/step)\n",
      "step 88600 \t loss = 0.029, train_acc = 1.000 (3.326 sec/step)\n",
      "step 88610 \t loss = 0.256, train_acc = 0.900 (3.351 sec/step)\n",
      "step 88620 \t loss = 0.211, train_acc = 0.900 (3.378 sec/step)\n",
      "step 88630 \t loss = 0.007, train_acc = 1.000 (3.349 sec/step)\n",
      "step 88640 \t loss = 0.099, train_acc = 0.900 (3.377 sec/step)\n",
      "step 88650 \t loss = 0.264, train_acc = 0.900 (3.349 sec/step)\n",
      "step 88660 \t loss = 0.011, train_acc = 1.000 (3.347 sec/step)\n",
      "step 88670 \t loss = 0.776, train_acc = 0.900 (3.379 sec/step)\n",
      "step 88680 \t loss = 0.105, train_acc = 0.900 (3.342 sec/step)\n",
      "step 88690 \t loss = 0.873, train_acc = 0.900 (3.371 sec/step)\n",
      "step 88700 \t loss = 0.000, train_acc = 1.000 (3.394 sec/step)\n",
      "step 88710 \t loss = 0.160, train_acc = 0.900 (3.363 sec/step)\n",
      "step 88720 \t loss = 0.022, train_acc = 1.000 (3.361 sec/step)\n",
      "step 88730 \t loss = 0.077, train_acc = 1.000 (3.364 sec/step)\n",
      "step 88740 \t loss = 0.056, train_acc = 1.000 (3.328 sec/step)\n",
      "step 88750 \t loss = 0.032, train_acc = 1.000 (3.450 sec/step)\n",
      "step 88760 \t loss = 0.028, train_acc = 1.000 (3.349 sec/step)\n",
      "step 88770 \t loss = 0.083, train_acc = 0.900 (3.356 sec/step)\n",
      "step 88780 \t loss = 0.004, train_acc = 1.000 (3.354 sec/step)\n",
      "step 88790 \t loss = 0.053, train_acc = 1.000 (3.299 sec/step)\n",
      "step 88800 \t loss = 0.115, train_acc = 1.000 (3.325 sec/step)\n",
      "step 88810 \t loss = 0.079, train_acc = 1.000 (3.341 sec/step)\n",
      "step 88820 \t loss = 0.425, train_acc = 0.900 (3.353 sec/step)\n",
      "step 88830 \t loss = 0.012, train_acc = 1.000 (3.333 sec/step)\n",
      "step 88840 \t loss = 0.292, train_acc = 1.000 (3.336 sec/step)\n",
      "step 88850 \t loss = 0.068, train_acc = 1.000 (3.319 sec/step)\n",
      "step 88860 \t loss = 0.133, train_acc = 0.900 (3.393 sec/step)\n",
      "step 88870 \t loss = 0.215, train_acc = 0.900 (3.347 sec/step)\n",
      "step 88880 \t loss = 2.363, train_acc = 0.800 (3.389 sec/step)\n",
      "step 88890 \t loss = 0.023, train_acc = 1.000 (3.375 sec/step)\n",
      "step 88900 \t loss = 0.001, train_acc = 1.000 (3.355 sec/step)\n",
      "step 88910 \t loss = 0.000, train_acc = 1.000 (3.408 sec/step)\n",
      "step 88920 \t loss = 0.027, train_acc = 1.000 (3.299 sec/step)\n",
      "step 88930 \t loss = 0.002, train_acc = 1.000 (3.350 sec/step)\n",
      "step 88940 \t loss = 0.208, train_acc = 0.900 (3.356 sec/step)\n",
      "step 88950 \t loss = 0.027, train_acc = 1.000 (3.321 sec/step)\n",
      "step 88960 \t loss = 1.254, train_acc = 0.700 (3.375 sec/step)\n",
      "step 88970 \t loss = 0.038, train_acc = 1.000 (3.348 sec/step)\n",
      "step 88980 \t loss = 0.013, train_acc = 1.000 (3.386 sec/step)\n",
      "step 88990 \t loss = 0.030, train_acc = 1.000 (3.375 sec/step)\n",
      "step 89000 \t loss = 0.587, train_acc = 0.900 (3.347 sec/step)\n",
      "step 89010 \t loss = 0.056, train_acc = 1.000 (3.469 sec/step)\n",
      "step 89020 \t loss = 0.080, train_acc = 0.900 (3.319 sec/step)\n",
      "step 89030 \t loss = 0.092, train_acc = 1.000 (3.299 sec/step)\n",
      "step 89040 \t loss = 0.321, train_acc = 1.000 (3.409 sec/step)\n",
      "step 89050 \t loss = 0.392, train_acc = 0.900 (3.359 sec/step)\n",
      "step 89060 \t loss = 0.093, train_acc = 0.900 (3.337 sec/step)\n",
      "step 89070 \t loss = 0.022, train_acc = 1.000 (3.319 sec/step)\n",
      "step 89080 \t loss = 0.004, train_acc = 1.000 (3.320 sec/step)\n",
      "step 89090 \t loss = 0.357, train_acc = 0.900 (3.343 sec/step)\n",
      "step 89100 \t loss = 0.361, train_acc = 0.800 (3.384 sec/step)\n",
      "step 89110 \t loss = 0.002, train_acc = 1.000 (3.381 sec/step)\n",
      "step 89120 \t loss = 0.000, train_acc = 1.000 (3.357 sec/step)\n",
      "step 89130 \t loss = 0.002, train_acc = 1.000 (3.356 sec/step)\n",
      "step 89140 \t loss = 0.009, train_acc = 1.000 (3.320 sec/step)\n",
      "step 89150 \t loss = 0.004, train_acc = 1.000 (3.333 sec/step)\n",
      "step 89160 \t loss = 0.003, train_acc = 1.000 (3.343 sec/step)\n",
      "step 89170 \t loss = 0.000, train_acc = 1.000 (3.378 sec/step)\n",
      "step 89180 \t loss = 0.068, train_acc = 1.000 (3.409 sec/step)\n",
      "step 89190 \t loss = 0.002, train_acc = 1.000 (3.316 sec/step)\n",
      "step 89200 \t loss = 0.627, train_acc = 0.900 (3.339 sec/step)\n",
      "step 89210 \t loss = 0.062, train_acc = 1.000 (3.342 sec/step)\n",
      "step 89220 \t loss = 0.210, train_acc = 0.900 (3.307 sec/step)\n",
      "step 89230 \t loss = 0.091, train_acc = 0.900 (3.351 sec/step)\n",
      "step 89240 \t loss = 0.524, train_acc = 0.900 (3.380 sec/step)\n",
      "step 89250 \t loss = 0.020, train_acc = 1.000 (3.359 sec/step)\n",
      "step 89260 \t loss = 0.000, train_acc = 1.000 (3.349 sec/step)\n",
      "step 89270 \t loss = 1.367, train_acc = 0.800 (3.308 sec/step)\n",
      "step 89280 \t loss = 0.006, train_acc = 1.000 (3.426 sec/step)\n",
      "step 89290 \t loss = 0.410, train_acc = 0.900 (3.394 sec/step)\n",
      "VALIDATION \t acc = 0.525 (3.631 sec)\n",
      "step 89300 \t loss = 0.247, train_acc = 0.900 (3.386 sec/step)\n",
      "step 89310 \t loss = 0.023, train_acc = 1.000 (3.323 sec/step)\n",
      "step 89320 \t loss = 0.030, train_acc = 1.000 (3.345 sec/step)\n",
      "step 89330 \t loss = 1.750, train_acc = 0.900 (3.455 sec/step)\n",
      "step 89340 \t loss = 0.072, train_acc = 1.000 (3.347 sec/step)\n",
      "step 89350 \t loss = 0.120, train_acc = 1.000 (3.347 sec/step)\n",
      "step 89360 \t loss = 0.172, train_acc = 0.900 (3.307 sec/step)\n",
      "step 89370 \t loss = 0.009, train_acc = 1.000 (3.327 sec/step)\n",
      "step 89380 \t loss = 0.895, train_acc = 0.900 (3.398 sec/step)\n",
      "step 89390 \t loss = 0.072, train_acc = 1.000 (3.382 sec/step)\n",
      "step 89400 \t loss = 0.017, train_acc = 1.000 (3.329 sec/step)\n",
      "step 89410 \t loss = 0.123, train_acc = 0.900 (3.376 sec/step)\n",
      "step 89420 \t loss = 0.001, train_acc = 1.000 (3.332 sec/step)\n",
      "step 89430 \t loss = 0.000, train_acc = 1.000 (3.385 sec/step)\n",
      "step 89440 \t loss = 0.000, train_acc = 1.000 (3.327 sec/step)\n",
      "step 89450 \t loss = 0.396, train_acc = 0.900 (3.344 sec/step)\n",
      "step 89460 \t loss = 0.112, train_acc = 1.000 (3.328 sec/step)\n",
      "step 89470 \t loss = 0.072, train_acc = 0.900 (3.335 sec/step)\n",
      "step 89480 \t loss = 0.011, train_acc = 1.000 (3.365 sec/step)\n",
      "step 89490 \t loss = 0.001, train_acc = 1.000 (3.347 sec/step)\n",
      "step 89500 \t loss = 0.734, train_acc = 0.900 (3.343 sec/step)\n",
      "step 89510 \t loss = 0.935, train_acc = 0.900 (3.317 sec/step)\n",
      "step 89520 \t loss = 0.455, train_acc = 0.800 (3.351 sec/step)\n",
      "step 89530 \t loss = 0.672, train_acc = 0.900 (3.403 sec/step)\n",
      "step 89540 \t loss = 0.142, train_acc = 0.900 (3.352 sec/step)\n",
      "step 89550 \t loss = 0.001, train_acc = 1.000 (3.373 sec/step)\n",
      "step 89560 \t loss = 0.001, train_acc = 1.000 (3.342 sec/step)\n",
      "step 89570 \t loss = 0.018, train_acc = 1.000 (3.336 sec/step)\n",
      "step 89580 \t loss = 0.012, train_acc = 1.000 (3.379 sec/step)\n",
      "step 89590 \t loss = 0.013, train_acc = 1.000 (3.340 sec/step)\n",
      "step 89600 \t loss = 0.088, train_acc = 1.000 (3.315 sec/step)\n",
      "step 89610 \t loss = 0.046, train_acc = 1.000 (3.353 sec/step)\n",
      "step 89620 \t loss = 0.039, train_acc = 1.000 (3.374 sec/step)\n",
      "step 89630 \t loss = 0.100, train_acc = 1.000 (3.349 sec/step)\n",
      "step 89640 \t loss = 0.008, train_acc = 1.000 (3.398 sec/step)\n",
      "step 89650 \t loss = 0.041, train_acc = 1.000 (3.411 sec/step)\n",
      "step 89660 \t loss = 0.022, train_acc = 1.000 (3.314 sec/step)\n",
      "step 89670 \t loss = 0.000, train_acc = 1.000 (3.341 sec/step)\n",
      "step 89680 \t loss = 0.000, train_acc = 1.000 (3.337 sec/step)\n",
      "step 89690 \t loss = 0.000, train_acc = 1.000 (3.377 sec/step)\n",
      "step 89700 \t loss = 0.275, train_acc = 0.800 (3.371 sec/step)\n",
      "step 89710 \t loss = 0.500, train_acc = 0.800 (3.299 sec/step)\n",
      "step 89720 \t loss = 0.313, train_acc = 0.900 (3.382 sec/step)\n",
      "step 89730 \t loss = 0.284, train_acc = 0.900 (3.383 sec/step)\n",
      "step 89740 \t loss = 0.011, train_acc = 1.000 (3.338 sec/step)\n",
      "step 89750 \t loss = 0.003, train_acc = 1.000 (3.387 sec/step)\n",
      "step 89760 \t loss = 0.084, train_acc = 1.000 (3.355 sec/step)\n",
      "step 89770 \t loss = 0.349, train_acc = 0.900 (3.361 sec/step)\n",
      "step 89780 \t loss = 0.015, train_acc = 1.000 (3.488 sec/step)\n",
      "step 89790 \t loss = 0.092, train_acc = 1.000 (3.324 sec/step)\n",
      "step 89800 \t loss = 0.067, train_acc = 1.000 (3.342 sec/step)\n",
      "step 89810 \t loss = 0.017, train_acc = 1.000 (3.378 sec/step)\n",
      "step 89820 \t loss = 0.013, train_acc = 1.000 (3.354 sec/step)\n",
      "step 89830 \t loss = 0.170, train_acc = 1.000 (3.328 sec/step)\n",
      "step 89840 \t loss = 0.009, train_acc = 1.000 (3.345 sec/step)\n",
      "step 89850 \t loss = 0.044, train_acc = 1.000 (3.377 sec/step)\n",
      "step 89860 \t loss = 0.197, train_acc = 0.900 (3.345 sec/step)\n",
      "step 89870 \t loss = 0.048, train_acc = 1.000 (3.343 sec/step)\n",
      "step 89880 \t loss = 0.355, train_acc = 0.900 (3.306 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 89890 \t loss = 0.015, train_acc = 1.000 (3.344 sec/step)\n",
      "step 89900 \t loss = 0.221, train_acc = 0.900 (3.375 sec/step)\n",
      "step 89910 \t loss = 0.010, train_acc = 1.000 (3.388 sec/step)\n",
      "step 89920 \t loss = 0.134, train_acc = 0.900 (3.341 sec/step)\n",
      "step 89930 \t loss = 0.516, train_acc = 0.900 (3.409 sec/step)\n",
      "step 89940 \t loss = 0.929, train_acc = 0.700 (3.348 sec/step)\n",
      "step 89950 \t loss = 1.144, train_acc = 0.900 (3.357 sec/step)\n",
      "step 89960 \t loss = 0.112, train_acc = 1.000 (3.399 sec/step)\n",
      "step 89970 \t loss = 0.043, train_acc = 1.000 (3.398 sec/step)\n",
      "step 89980 \t loss = 0.020, train_acc = 1.000 (3.363 sec/step)\n",
      "step 89990 \t loss = 0.200, train_acc = 0.900 (3.349 sec/step)\n",
      "step 90000 \t loss = 0.765, train_acc = 0.800 (3.375 sec/step)\n",
      "step 90010 \t loss = 0.067, train_acc = 1.000 (3.332 sec/step)\n",
      "step 90020 \t loss = 0.369, train_acc = 0.900 (3.368 sec/step)\n",
      "step 90030 \t loss = 0.256, train_acc = 0.800 (3.330 sec/step)\n",
      "step 90040 \t loss = 0.238, train_acc = 0.900 (3.316 sec/step)\n",
      "step 90050 \t loss = 0.000, train_acc = 1.000 (3.374 sec/step)\n",
      "step 90060 \t loss = 0.270, train_acc = 0.900 (3.330 sec/step)\n",
      "step 90070 \t loss = 0.001, train_acc = 1.000 (3.395 sec/step)\n",
      "step 90080 \t loss = 0.003, train_acc = 1.000 (3.404 sec/step)\n",
      "step 90090 \t loss = 0.077, train_acc = 0.900 (3.368 sec/step)\n",
      "step 90100 \t loss = 0.001, train_acc = 1.000 (3.338 sec/step)\n",
      "step 90110 \t loss = 0.007, train_acc = 1.000 (3.403 sec/step)\n",
      "step 90120 \t loss = 0.138, train_acc = 0.900 (3.363 sec/step)\n",
      "step 90130 \t loss = 0.039, train_acc = 1.000 (3.385 sec/step)\n",
      "step 90140 \t loss = 0.030, train_acc = 1.000 (3.360 sec/step)\n",
      "step 90150 \t loss = 0.982, train_acc = 0.900 (3.331 sec/step)\n",
      "step 90160 \t loss = 0.066, train_acc = 1.000 (3.369 sec/step)\n",
      "step 90170 \t loss = 0.077, train_acc = 0.900 (3.393 sec/step)\n",
      "step 90180 \t loss = 0.012, train_acc = 1.000 (3.291 sec/step)\n",
      "step 90190 \t loss = 0.375, train_acc = 0.800 (3.343 sec/step)\n",
      "step 90200 \t loss = 0.004, train_acc = 1.000 (3.396 sec/step)\n",
      "step 90210 \t loss = 0.000, train_acc = 1.000 (3.357 sec/step)\n",
      "step 90220 \t loss = 0.241, train_acc = 0.900 (3.403 sec/step)\n",
      "step 90230 \t loss = 0.013, train_acc = 1.000 (3.389 sec/step)\n",
      "step 90240 \t loss = 0.023, train_acc = 1.000 (3.407 sec/step)\n",
      "step 90250 \t loss = 0.001, train_acc = 1.000 (3.343 sec/step)\n",
      "step 90260 \t loss = 0.035, train_acc = 1.000 (3.311 sec/step)\n",
      "step 90270 \t loss = 0.000, train_acc = 1.000 (3.325 sec/step)\n",
      "step 90280 \t loss = 0.097, train_acc = 0.900 (3.322 sec/step)\n",
      "step 90290 \t loss = 0.959, train_acc = 0.800 (3.355 sec/step)\n",
      "step 90300 \t loss = 0.596, train_acc = 0.800 (3.414 sec/step)\n",
      "step 90310 \t loss = 0.667, train_acc = 0.900 (3.374 sec/step)\n",
      "step 90320 \t loss = 0.105, train_acc = 0.900 (3.309 sec/step)\n",
      "step 90330 \t loss = 0.473, train_acc = 0.800 (3.330 sec/step)\n",
      "step 90340 \t loss = 0.055, train_acc = 1.000 (3.350 sec/step)\n",
      "step 90350 \t loss = 0.000, train_acc = 1.000 (3.449 sec/step)\n",
      "step 90360 \t loss = 0.017, train_acc = 1.000 (3.363 sec/step)\n",
      "step 90370 \t loss = 0.118, train_acc = 1.000 (3.388 sec/step)\n",
      "step 90380 \t loss = 0.072, train_acc = 1.000 (3.380 sec/step)\n",
      "step 90390 \t loss = 0.000, train_acc = 1.000 (3.378 sec/step)\n",
      "step 90400 \t loss = 0.374, train_acc = 0.900 (3.321 sec/step)\n",
      "step 90410 \t loss = 0.017, train_acc = 1.000 (3.326 sec/step)\n",
      "step 90420 \t loss = 0.048, train_acc = 1.000 (3.334 sec/step)\n",
      "step 90430 \t loss = 1.225, train_acc = 0.800 (3.320 sec/step)\n",
      "step 90440 \t loss = 0.082, train_acc = 1.000 (3.354 sec/step)\n",
      "step 90450 \t loss = 0.005, train_acc = 1.000 (3.357 sec/step)\n",
      "step 90460 \t loss = 0.000, train_acc = 1.000 (3.369 sec/step)\n",
      "step 90470 \t loss = 0.005, train_acc = 1.000 (3.422 sec/step)\n",
      "step 90480 \t loss = 1.927, train_acc = 0.800 (3.407 sec/step)\n",
      "step 90490 \t loss = 0.714, train_acc = 0.800 (3.348 sec/step)\n",
      "step 90500 \t loss = 0.047, train_acc = 1.000 (3.451 sec/step)\n",
      "step 90510 \t loss = 0.412, train_acc = 0.900 (3.361 sec/step)\n",
      "step 90520 \t loss = 0.307, train_acc = 0.900 (3.371 sec/step)\n",
      "step 90530 \t loss = 0.005, train_acc = 1.000 (3.453 sec/step)\n",
      "step 90540 \t loss = 0.012, train_acc = 1.000 (3.305 sec/step)\n",
      "step 90550 \t loss = 0.008, train_acc = 1.000 (3.357 sec/step)\n",
      "step 90560 \t loss = 0.506, train_acc = 0.900 (3.327 sec/step)\n",
      "step 90570 \t loss = 0.058, train_acc = 1.000 (3.334 sec/step)\n",
      "step 90580 \t loss = 0.015, train_acc = 1.000 (3.393 sec/step)\n",
      "step 90590 \t loss = 0.033, train_acc = 1.000 (3.375 sec/step)\n",
      "step 90600 \t loss = 0.000, train_acc = 1.000 (3.325 sec/step)\n",
      "step 90610 \t loss = 0.057, train_acc = 1.000 (3.321 sec/step)\n",
      "step 90620 \t loss = 0.001, train_acc = 1.000 (3.360 sec/step)\n",
      "step 90630 \t loss = 0.000, train_acc = 1.000 (3.377 sec/step)\n",
      "step 90640 \t loss = 0.577, train_acc = 0.900 (3.317 sec/step)\n",
      "step 90650 \t loss = 0.207, train_acc = 0.900 (3.305 sec/step)\n",
      "step 90660 \t loss = 0.228, train_acc = 0.900 (3.406 sec/step)\n",
      "step 90670 \t loss = 0.000, train_acc = 1.000 (3.338 sec/step)\n",
      "step 90680 \t loss = 0.981, train_acc = 0.700 (3.337 sec/step)\n",
      "step 90690 \t loss = 0.524, train_acc = 0.900 (3.386 sec/step)\n",
      "step 90700 \t loss = 0.215, train_acc = 1.000 (3.350 sec/step)\n",
      "step 90710 \t loss = 0.056, train_acc = 1.000 (3.361 sec/step)\n",
      "step 90720 \t loss = 0.210, train_acc = 0.900 (3.332 sec/step)\n",
      "step 90730 \t loss = 0.212, train_acc = 0.900 (3.360 sec/step)\n",
      "step 90740 \t loss = 1.112, train_acc = 0.800 (3.389 sec/step)\n",
      "step 90750 \t loss = 0.582, train_acc = 0.900 (3.352 sec/step)\n",
      "step 90760 \t loss = 0.691, train_acc = 0.900 (3.397 sec/step)\n",
      "step 90770 \t loss = 0.006, train_acc = 1.000 (3.382 sec/step)\n",
      "step 90780 \t loss = 0.000, train_acc = 1.000 (3.357 sec/step)\n",
      "step 90790 \t loss = 0.290, train_acc = 0.900 (3.332 sec/step)\n",
      "step 90800 \t loss = 0.096, train_acc = 0.900 (3.346 sec/step)\n",
      "step 90810 \t loss = 0.304, train_acc = 0.900 (3.395 sec/step)\n",
      "step 90820 \t loss = 0.003, train_acc = 1.000 (3.301 sec/step)\n",
      "step 90830 \t loss = 0.261, train_acc = 0.900 (3.367 sec/step)\n",
      "step 90840 \t loss = 0.667, train_acc = 0.800 (3.348 sec/step)\n",
      "step 90850 \t loss = 0.702, train_acc = 0.800 (3.338 sec/step)\n",
      "step 90860 \t loss = 0.045, train_acc = 1.000 (3.383 sec/step)\n",
      "step 90870 \t loss = 0.019, train_acc = 1.000 (3.311 sec/step)\n",
      "step 90880 \t loss = 0.419, train_acc = 0.900 (3.393 sec/step)\n",
      "step 90890 \t loss = 0.006, train_acc = 1.000 (3.382 sec/step)\n",
      "step 90900 \t loss = 0.017, train_acc = 1.000 (3.402 sec/step)\n",
      "step 90910 \t loss = 0.046, train_acc = 1.000 (3.430 sec/step)\n",
      "step 90920 \t loss = 0.000, train_acc = 1.000 (3.363 sec/step)\n",
      "step 90930 \t loss = 0.267, train_acc = 0.900 (3.337 sec/step)\n",
      "step 90940 \t loss = 0.060, train_acc = 1.000 (3.357 sec/step)\n",
      "step 90950 \t loss = 0.387, train_acc = 0.900 (3.334 sec/step)\n",
      "step 90960 \t loss = 0.031, train_acc = 1.000 (3.324 sec/step)\n",
      "step 90970 \t loss = 0.016, train_acc = 1.000 (3.318 sec/step)\n",
      "step 90980 \t loss = 0.033, train_acc = 1.000 (3.325 sec/step)\n",
      "step 90990 \t loss = 0.001, train_acc = 1.000 (3.330 sec/step)\n",
      "step 91000 \t loss = 0.000, train_acc = 1.000 (3.405 sec/step)\n",
      "step 91010 \t loss = 0.699, train_acc = 0.900 (3.354 sec/step)\n",
      "step 91020 \t loss = 0.029, train_acc = 1.000 (3.354 sec/step)\n",
      "step 91030 \t loss = 0.332, train_acc = 0.800 (3.354 sec/step)\n",
      "step 91040 \t loss = 0.077, train_acc = 1.000 (3.349 sec/step)\n",
      "step 91050 \t loss = 0.499, train_acc = 0.900 (3.362 sec/step)\n",
      "step 91060 \t loss = 0.107, train_acc = 0.900 (3.354 sec/step)\n",
      "step 91070 \t loss = 0.033, train_acc = 1.000 (3.386 sec/step)\n",
      "step 91080 \t loss = 0.066, train_acc = 1.000 (3.349 sec/step)\n",
      "step 91090 \t loss = 0.510, train_acc = 0.900 (3.342 sec/step)\n",
      "step 91100 \t loss = 0.051, train_acc = 1.000 (3.327 sec/step)\n",
      "step 91110 \t loss = 0.553, train_acc = 0.900 (3.365 sec/step)\n",
      "step 91120 \t loss = 0.160, train_acc = 0.900 (3.308 sec/step)\n",
      "step 91130 \t loss = 0.299, train_acc = 0.900 (3.317 sec/step)\n",
      "step 91140 \t loss = 0.114, train_acc = 0.900 (3.478 sec/step)\n",
      "step 91150 \t loss = 0.036, train_acc = 1.000 (3.366 sec/step)\n",
      "step 91160 \t loss = 0.061, train_acc = 1.000 (3.368 sec/step)\n",
      "step 91170 \t loss = 0.099, train_acc = 1.000 (3.311 sec/step)\n",
      "step 91180 \t loss = 0.107, train_acc = 1.000 (3.306 sec/step)\n",
      "step 91190 \t loss = 0.560, train_acc = 0.800 (3.337 sec/step)\n",
      "VALIDATION \t acc = 0.536 (3.647 sec)\n",
      "step 91200 \t loss = 0.192, train_acc = 0.900 (3.381 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 91210 \t loss = 0.160, train_acc = 0.900 (3.417 sec/step)\n",
      "step 91220 \t loss = 0.000, train_acc = 1.000 (3.376 sec/step)\n",
      "step 91230 \t loss = 0.534, train_acc = 0.900 (3.413 sec/step)\n",
      "step 91240 \t loss = 0.167, train_acc = 0.900 (3.380 sec/step)\n",
      "step 91250 \t loss = 1.197, train_acc = 0.900 (3.362 sec/step)\n",
      "step 91260 \t loss = 0.018, train_acc = 1.000 (3.322 sec/step)\n",
      "step 91270 \t loss = 0.225, train_acc = 0.900 (3.368 sec/step)\n",
      "step 91280 \t loss = 0.001, train_acc = 1.000 (3.390 sec/step)\n",
      "step 91290 \t loss = 0.568, train_acc = 0.900 (3.325 sec/step)\n",
      "step 91300 \t loss = 0.000, train_acc = 1.000 (3.340 sec/step)\n",
      "step 91310 \t loss = 0.000, train_acc = 1.000 (3.312 sec/step)\n",
      "step 91320 \t loss = 0.012, train_acc = 1.000 (3.389 sec/step)\n",
      "step 91330 \t loss = 0.141, train_acc = 0.900 (3.315 sec/step)\n",
      "step 91340 \t loss = 0.192, train_acc = 0.900 (3.357 sec/step)\n",
      "step 91350 \t loss = 0.057, train_acc = 1.000 (3.335 sec/step)\n",
      "step 91360 \t loss = 0.045, train_acc = 1.000 (3.399 sec/step)\n",
      "step 91370 \t loss = 0.164, train_acc = 0.900 (3.329 sec/step)\n",
      "step 91380 \t loss = 0.010, train_acc = 1.000 (3.334 sec/step)\n",
      "step 91390 \t loss = 0.519, train_acc = 0.900 (3.372 sec/step)\n",
      "step 91400 \t loss = 0.164, train_acc = 0.900 (3.378 sec/step)\n",
      "step 91410 \t loss = 0.278, train_acc = 0.800 (3.423 sec/step)\n",
      "step 91420 \t loss = 1.797, train_acc = 0.700 (3.353 sec/step)\n",
      "step 91430 \t loss = 0.023, train_acc = 1.000 (3.313 sec/step)\n",
      "step 91440 \t loss = 0.313, train_acc = 0.900 (3.331 sec/step)\n",
      "step 91450 \t loss = 0.401, train_acc = 0.900 (3.356 sec/step)\n",
      "step 91460 \t loss = 0.070, train_acc = 1.000 (3.323 sec/step)\n",
      "step 91470 \t loss = 0.110, train_acc = 0.900 (3.350 sec/step)\n",
      "step 91480 \t loss = 0.003, train_acc = 1.000 (3.342 sec/step)\n",
      "step 91490 \t loss = 0.000, train_acc = 1.000 (3.357 sec/step)\n",
      "step 91500 \t loss = 0.011, train_acc = 1.000 (3.331 sec/step)\n",
      "step 91510 \t loss = 0.346, train_acc = 0.900 (3.382 sec/step)\n",
      "step 91520 \t loss = 0.004, train_acc = 1.000 (3.445 sec/step)\n",
      "step 91530 \t loss = 0.001, train_acc = 1.000 (3.361 sec/step)\n",
      "step 91540 \t loss = 0.060, train_acc = 1.000 (3.364 sec/step)\n",
      "step 91550 \t loss = 0.337, train_acc = 0.900 (3.372 sec/step)\n",
      "step 91560 \t loss = 0.711, train_acc = 0.800 (3.454 sec/step)\n",
      "step 91570 \t loss = 0.023, train_acc = 1.000 (3.354 sec/step)\n",
      "step 91580 \t loss = 0.000, train_acc = 1.000 (3.328 sec/step)\n",
      "step 91590 \t loss = 0.000, train_acc = 1.000 (3.334 sec/step)\n",
      "step 91600 \t loss = 1.819, train_acc = 0.900 (3.335 sec/step)\n",
      "step 91610 \t loss = 0.010, train_acc = 1.000 (3.332 sec/step)\n",
      "step 91620 \t loss = 0.848, train_acc = 0.800 (3.337 sec/step)\n",
      "step 91630 \t loss = 0.023, train_acc = 1.000 (3.323 sec/step)\n",
      "step 91640 \t loss = 0.207, train_acc = 0.900 (3.339 sec/step)\n",
      "step 91650 \t loss = 0.033, train_acc = 1.000 (3.367 sec/step)\n",
      "step 91660 \t loss = 0.305, train_acc = 0.800 (3.368 sec/step)\n",
      "step 91670 \t loss = 0.000, train_acc = 1.000 (3.345 sec/step)\n",
      "step 91680 \t loss = 0.103, train_acc = 1.000 (3.368 sec/step)\n",
      "step 91690 \t loss = 0.005, train_acc = 1.000 (3.324 sec/step)\n",
      "step 91700 \t loss = 0.398, train_acc = 0.900 (3.498 sec/step)\n",
      "step 91710 \t loss = 0.042, train_acc = 1.000 (3.372 sec/step)\n",
      "step 91720 \t loss = 0.004, train_acc = 1.000 (3.362 sec/step)\n",
      "step 91730 \t loss = 0.054, train_acc = 1.000 (3.391 sec/step)\n",
      "step 91740 \t loss = 0.246, train_acc = 0.900 (3.358 sec/step)\n",
      "step 91750 \t loss = 0.084, train_acc = 0.900 (3.426 sec/step)\n",
      "step 91760 \t loss = 0.079, train_acc = 0.900 (3.325 sec/step)\n",
      "step 91770 \t loss = 0.772, train_acc = 0.900 (3.313 sec/step)\n",
      "step 91780 \t loss = 0.542, train_acc = 0.800 (3.396 sec/step)\n",
      "step 91790 \t loss = 0.178, train_acc = 0.900 (3.341 sec/step)\n",
      "step 91800 \t loss = 0.213, train_acc = 0.900 (3.350 sec/step)\n",
      "step 91810 \t loss = 0.007, train_acc = 1.000 (3.354 sec/step)\n",
      "step 91820 \t loss = 0.140, train_acc = 0.900 (3.405 sec/step)\n",
      "step 91830 \t loss = 0.170, train_acc = 0.900 (3.323 sec/step)\n",
      "step 91840 \t loss = 0.053, train_acc = 1.000 (3.300 sec/step)\n",
      "step 91850 \t loss = 0.215, train_acc = 0.900 (3.349 sec/step)\n",
      "step 91860 \t loss = 0.246, train_acc = 0.900 (3.349 sec/step)\n",
      "step 91870 \t loss = 0.042, train_acc = 1.000 (3.307 sec/step)\n",
      "step 91880 \t loss = 0.005, train_acc = 1.000 (3.326 sec/step)\n",
      "step 91890 \t loss = 0.195, train_acc = 0.900 (3.345 sec/step)\n",
      "step 91900 \t loss = 0.045, train_acc = 1.000 (3.371 sec/step)\n",
      "step 91910 \t loss = 0.184, train_acc = 0.900 (3.337 sec/step)\n",
      "step 91920 \t loss = 0.002, train_acc = 1.000 (3.350 sec/step)\n",
      "step 91930 \t loss = 0.012, train_acc = 1.000 (3.314 sec/step)\n",
      "step 91940 \t loss = 0.006, train_acc = 1.000 (3.458 sec/step)\n",
      "step 91950 \t loss = 0.057, train_acc = 1.000 (3.372 sec/step)\n",
      "step 91960 \t loss = 0.440, train_acc = 0.900 (3.355 sec/step)\n",
      "step 91970 \t loss = 0.103, train_acc = 1.000 (3.394 sec/step)\n",
      "step 91980 \t loss = 0.006, train_acc = 1.000 (3.362 sec/step)\n",
      "step 91990 \t loss = 0.003, train_acc = 1.000 (3.355 sec/step)\n",
      "step 92000 \t loss = 0.046, train_acc = 1.000 (3.368 sec/step)\n",
      "step 92010 \t loss = 0.555, train_acc = 0.900 (3.390 sec/step)\n",
      "step 92020 \t loss = 0.503, train_acc = 0.900 (3.340 sec/step)\n",
      "step 92030 \t loss = 0.003, train_acc = 1.000 (3.371 sec/step)\n",
      "step 92040 \t loss = 0.223, train_acc = 0.900 (3.329 sec/step)\n",
      "step 92050 \t loss = 0.017, train_acc = 1.000 (3.334 sec/step)\n",
      "step 92060 \t loss = 0.135, train_acc = 0.900 (3.313 sec/step)\n",
      "step 92070 \t loss = 0.127, train_acc = 0.900 (3.378 sec/step)\n",
      "step 92080 \t loss = 0.111, train_acc = 1.000 (3.391 sec/step)\n",
      "step 92090 \t loss = 0.000, train_acc = 1.000 (3.374 sec/step)\n",
      "step 92100 \t loss = 0.076, train_acc = 1.000 (3.338 sec/step)\n",
      "step 92110 \t loss = 0.011, train_acc = 1.000 (3.348 sec/step)\n",
      "step 92120 \t loss = 0.035, train_acc = 1.000 (3.328 sec/step)\n",
      "step 92130 \t loss = 0.009, train_acc = 1.000 (3.374 sec/step)\n",
      "step 92140 \t loss = 0.051, train_acc = 1.000 (3.396 sec/step)\n",
      "step 92150 \t loss = 0.001, train_acc = 1.000 (3.344 sec/step)\n",
      "step 92160 \t loss = 0.002, train_acc = 1.000 (3.411 sec/step)\n",
      "step 92170 \t loss = 0.000, train_acc = 1.000 (3.367 sec/step)\n",
      "step 92180 \t loss = 0.449, train_acc = 0.800 (3.348 sec/step)\n",
      "step 92190 \t loss = 0.055, train_acc = 1.000 (3.353 sec/step)\n",
      "step 92200 \t loss = 0.002, train_acc = 1.000 (3.390 sec/step)\n",
      "step 92210 \t loss = 0.023, train_acc = 1.000 (3.423 sec/step)\n",
      "step 92220 \t loss = 0.011, train_acc = 1.000 (3.333 sec/step)\n",
      "step 92230 \t loss = 0.195, train_acc = 0.900 (3.367 sec/step)\n",
      "step 92240 \t loss = 0.115, train_acc = 0.900 (3.430 sec/step)\n",
      "step 92250 \t loss = 0.475, train_acc = 0.900 (3.374 sec/step)\n",
      "step 92260 \t loss = 0.255, train_acc = 0.900 (3.324 sec/step)\n",
      "step 92270 \t loss = 0.066, train_acc = 1.000 (3.341 sec/step)\n",
      "step 92280 \t loss = 0.000, train_acc = 1.000 (3.479 sec/step)\n",
      "step 92290 \t loss = 0.000, train_acc = 1.000 (3.337 sec/step)\n",
      "step 92300 \t loss = 0.602, train_acc = 0.800 (3.358 sec/step)\n",
      "step 92310 \t loss = 0.001, train_acc = 1.000 (3.333 sec/step)\n",
      "step 92320 \t loss = 0.019, train_acc = 1.000 (3.367 sec/step)\n",
      "step 92330 \t loss = 0.312, train_acc = 0.900 (3.333 sec/step)\n",
      "step 92340 \t loss = 1.062, train_acc = 0.900 (3.374 sec/step)\n",
      "step 92350 \t loss = 0.042, train_acc = 1.000 (3.357 sec/step)\n",
      "step 92360 \t loss = 0.065, train_acc = 1.000 (3.411 sec/step)\n",
      "step 92370 \t loss = 0.045, train_acc = 1.000 (3.371 sec/step)\n",
      "step 92380 \t loss = 0.001, train_acc = 1.000 (3.414 sec/step)\n",
      "step 92390 \t loss = 0.002, train_acc = 1.000 (3.387 sec/step)\n",
      "step 92400 \t loss = 0.211, train_acc = 0.900 (3.379 sec/step)\n",
      "step 92410 \t loss = 0.000, train_acc = 1.000 (3.349 sec/step)\n",
      "step 92420 \t loss = 0.001, train_acc = 1.000 (3.342 sec/step)\n",
      "step 92430 \t loss = 0.004, train_acc = 1.000 (3.396 sec/step)\n",
      "step 92440 \t loss = 0.452, train_acc = 0.900 (3.405 sec/step)\n",
      "step 92450 \t loss = 0.099, train_acc = 1.000 (3.384 sec/step)\n",
      "step 92460 \t loss = 0.056, train_acc = 1.000 (3.335 sec/step)\n",
      "step 92470 \t loss = 0.028, train_acc = 1.000 (3.363 sec/step)\n",
      "step 92480 \t loss = 0.001, train_acc = 1.000 (3.359 sec/step)\n",
      "step 92490 \t loss = 1.065, train_acc = 0.900 (3.383 sec/step)\n",
      "step 92500 \t loss = 0.328, train_acc = 0.900 (3.356 sec/step)\n",
      "step 92510 \t loss = 0.035, train_acc = 1.000 (3.336 sec/step)\n",
      "step 92520 \t loss = 0.000, train_acc = 1.000 (3.369 sec/step)\n",
      "step 92530 \t loss = 0.258, train_acc = 0.900 (3.340 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 92540 \t loss = 0.018, train_acc = 1.000 (3.352 sec/step)\n",
      "step 92550 \t loss = 0.006, train_acc = 1.000 (3.362 sec/step)\n",
      "step 92560 \t loss = 0.008, train_acc = 1.000 (3.374 sec/step)\n",
      "step 92570 \t loss = 0.006, train_acc = 1.000 (3.402 sec/step)\n",
      "step 92580 \t loss = 3.099, train_acc = 0.800 (3.319 sec/step)\n",
      "step 92590 \t loss = 1.690, train_acc = 0.400 (3.368 sec/step)\n",
      "step 92600 \t loss = 0.068, train_acc = 1.000 (3.410 sec/step)\n",
      "step 92610 \t loss = 0.003, train_acc = 1.000 (3.389 sec/step)\n",
      "step 92620 \t loss = 0.061, train_acc = 1.000 (3.369 sec/step)\n",
      "step 92630 \t loss = 0.000, train_acc = 1.000 (3.377 sec/step)\n",
      "step 92640 \t loss = 0.108, train_acc = 0.900 (3.351 sec/step)\n",
      "step 92650 \t loss = 0.107, train_acc = 0.900 (3.391 sec/step)\n",
      "step 92660 \t loss = 0.015, train_acc = 1.000 (3.331 sec/step)\n",
      "step 92670 \t loss = 0.128, train_acc = 0.900 (3.346 sec/step)\n",
      "step 92680 \t loss = 0.040, train_acc = 1.000 (3.331 sec/step)\n",
      "step 92690 \t loss = 0.005, train_acc = 1.000 (3.344 sec/step)\n",
      "step 92700 \t loss = 0.008, train_acc = 1.000 (3.357 sec/step)\n",
      "step 92710 \t loss = 0.377, train_acc = 0.900 (3.353 sec/step)\n",
      "step 92720 \t loss = 0.229, train_acc = 0.900 (3.360 sec/step)\n",
      "step 92730 \t loss = 0.004, train_acc = 1.000 (3.313 sec/step)\n",
      "step 92740 \t loss = 0.008, train_acc = 1.000 (3.332 sec/step)\n",
      "step 92750 \t loss = 0.058, train_acc = 1.000 (3.354 sec/step)\n",
      "step 92760 \t loss = 0.000, train_acc = 1.000 (3.354 sec/step)\n",
      "step 92770 \t loss = 0.043, train_acc = 1.000 (3.344 sec/step)\n",
      "step 92780 \t loss = 0.006, train_acc = 1.000 (3.339 sec/step)\n",
      "step 92790 \t loss = 1.034, train_acc = 0.800 (3.340 sec/step)\n",
      "step 92800 \t loss = 0.121, train_acc = 0.900 (3.342 sec/step)\n",
      "step 92810 \t loss = 0.035, train_acc = 1.000 (3.338 sec/step)\n",
      "step 92820 \t loss = 0.496, train_acc = 0.800 (3.349 sec/step)\n",
      "step 92830 \t loss = 0.520, train_acc = 0.800 (3.353 sec/step)\n",
      "step 92840 \t loss = 0.293, train_acc = 0.900 (3.384 sec/step)\n",
      "step 92850 \t loss = 0.001, train_acc = 1.000 (3.357 sec/step)\n",
      "step 92860 \t loss = 0.171, train_acc = 1.000 (3.310 sec/step)\n",
      "step 92870 \t loss = 0.010, train_acc = 1.000 (3.409 sec/step)\n",
      "step 92880 \t loss = 0.000, train_acc = 1.000 (3.427 sec/step)\n",
      "step 92890 \t loss = 0.000, train_acc = 1.000 (3.373 sec/step)\n",
      "step 92900 \t loss = 0.000, train_acc = 1.000 (3.362 sec/step)\n",
      "step 92910 \t loss = 0.001, train_acc = 1.000 (3.305 sec/step)\n",
      "step 92920 \t loss = 0.097, train_acc = 1.000 (3.309 sec/step)\n",
      "step 92930 \t loss = 0.044, train_acc = 1.000 (3.366 sec/step)\n",
      "step 92940 \t loss = 0.008, train_acc = 1.000 (3.382 sec/step)\n",
      "step 92950 \t loss = 0.114, train_acc = 0.900 (3.354 sec/step)\n",
      "step 92960 \t loss = 0.000, train_acc = 1.000 (3.385 sec/step)\n",
      "step 92970 \t loss = 0.000, train_acc = 1.000 (3.378 sec/step)\n",
      "step 92980 \t loss = 0.030, train_acc = 1.000 (3.328 sec/step)\n",
      "step 92990 \t loss = 0.000, train_acc = 1.000 (3.324 sec/step)\n",
      "step 93000 \t loss = 0.021, train_acc = 1.000 (3.363 sec/step)\n",
      "step 93010 \t loss = 0.209, train_acc = 0.900 (3.372 sec/step)\n",
      "step 93020 \t loss = 0.005, train_acc = 1.000 (3.400 sec/step)\n",
      "step 93030 \t loss = 0.227, train_acc = 0.800 (3.431 sec/step)\n",
      "step 93040 \t loss = 0.378, train_acc = 0.900 (3.412 sec/step)\n",
      "step 93050 \t loss = 0.000, train_acc = 1.000 (3.372 sec/step)\n",
      "step 93060 \t loss = 0.000, train_acc = 1.000 (3.340 sec/step)\n",
      "step 93070 \t loss = 0.408, train_acc = 0.900 (3.336 sec/step)\n",
      "step 93080 \t loss = 0.250, train_acc = 0.900 (3.334 sec/step)\n",
      "step 93090 \t loss = 0.162, train_acc = 0.900 (3.374 sec/step)\n",
      "VALIDATION \t acc = 0.530 (3.619 sec)\n",
      "step 93100 \t loss = 0.268, train_acc = 0.900 (3.385 sec/step)\n",
      "step 93110 \t loss = 0.108, train_acc = 1.000 (3.375 sec/step)\n",
      "step 93120 \t loss = 2.377, train_acc = 0.900 (3.364 sec/step)\n",
      "step 93130 \t loss = 0.047, train_acc = 1.000 (3.397 sec/step)\n",
      "step 93140 \t loss = 0.002, train_acc = 1.000 (3.356 sec/step)\n",
      "step 93150 \t loss = 0.580, train_acc = 0.900 (3.344 sec/step)\n",
      "step 93160 \t loss = 0.000, train_acc = 1.000 (3.417 sec/step)\n",
      "step 93170 \t loss = 0.035, train_acc = 1.000 (3.401 sec/step)\n",
      "step 93180 \t loss = 0.000, train_acc = 1.000 (3.347 sec/step)\n",
      "step 93190 \t loss = 0.024, train_acc = 1.000 (3.321 sec/step)\n",
      "step 93200 \t loss = 0.070, train_acc = 1.000 (3.433 sec/step)\n",
      "step 93210 \t loss = 0.001, train_acc = 1.000 (3.370 sec/step)\n",
      "step 93220 \t loss = 0.026, train_acc = 1.000 (3.345 sec/step)\n",
      "step 93230 \t loss = 0.045, train_acc = 1.000 (3.425 sec/step)\n",
      "step 93240 \t loss = 0.007, train_acc = 1.000 (3.339 sec/step)\n",
      "step 93250 \t loss = 0.092, train_acc = 1.000 (3.382 sec/step)\n",
      "step 93260 \t loss = 0.161, train_acc = 0.900 (3.396 sec/step)\n",
      "step 93270 \t loss = 0.190, train_acc = 0.900 (3.370 sec/step)\n",
      "step 93280 \t loss = 0.447, train_acc = 0.800 (3.388 sec/step)\n",
      "step 93290 \t loss = 0.080, train_acc = 0.900 (3.363 sec/step)\n",
      "step 93300 \t loss = 0.006, train_acc = 1.000 (3.336 sec/step)\n",
      "step 93310 \t loss = 0.018, train_acc = 1.000 (3.393 sec/step)\n",
      "step 93320 \t loss = 0.104, train_acc = 1.000 (3.359 sec/step)\n",
      "step 93330 \t loss = 0.025, train_acc = 1.000 (3.315 sec/step)\n",
      "step 93340 \t loss = 0.048, train_acc = 1.000 (3.498 sec/step)\n",
      "step 93350 \t loss = 0.000, train_acc = 1.000 (3.300 sec/step)\n",
      "step 93360 \t loss = 0.762, train_acc = 0.800 (3.393 sec/step)\n",
      "step 93370 \t loss = 0.012, train_acc = 1.000 (3.347 sec/step)\n",
      "step 93380 \t loss = 0.143, train_acc = 1.000 (3.354 sec/step)\n",
      "step 93390 \t loss = 0.022, train_acc = 1.000 (3.319 sec/step)\n",
      "step 93400 \t loss = 0.390, train_acc = 0.800 (3.348 sec/step)\n",
      "step 93410 \t loss = 0.027, train_acc = 1.000 (3.358 sec/step)\n",
      "step 93420 \t loss = 0.007, train_acc = 1.000 (3.354 sec/step)\n",
      "step 93430 \t loss = 0.001, train_acc = 1.000 (3.344 sec/step)\n",
      "step 93440 \t loss = 0.003, train_acc = 1.000 (3.359 sec/step)\n",
      "step 93450 \t loss = 0.440, train_acc = 0.900 (3.403 sec/step)\n",
      "step 93460 \t loss = 0.016, train_acc = 1.000 (3.376 sec/step)\n",
      "step 93470 \t loss = 0.014, train_acc = 1.000 (3.349 sec/step)\n",
      "step 93480 \t loss = 0.006, train_acc = 1.000 (3.345 sec/step)\n",
      "step 93490 \t loss = 0.180, train_acc = 0.900 (3.434 sec/step)\n",
      "step 93500 \t loss = 0.374, train_acc = 0.700 (3.370 sec/step)\n",
      "step 93510 \t loss = 0.001, train_acc = 1.000 (3.338 sec/step)\n",
      "step 93520 \t loss = 0.000, train_acc = 1.000 (3.365 sec/step)\n",
      "step 93530 \t loss = 0.123, train_acc = 0.900 (3.398 sec/step)\n",
      "step 93540 \t loss = 0.035, train_acc = 1.000 (3.333 sec/step)\n",
      "step 93550 \t loss = 0.006, train_acc = 1.000 (3.361 sec/step)\n",
      "step 93560 \t loss = 0.382, train_acc = 0.800 (3.351 sec/step)\n",
      "step 93570 \t loss = 0.012, train_acc = 1.000 (3.417 sec/step)\n",
      "step 93580 \t loss = 0.004, train_acc = 1.000 (3.375 sec/step)\n",
      "step 93590 \t loss = 0.022, train_acc = 1.000 (3.349 sec/step)\n",
      "step 93600 \t loss = 0.000, train_acc = 1.000 (3.407 sec/step)\n",
      "step 93610 \t loss = 0.561, train_acc = 0.900 (3.334 sec/step)\n",
      "step 93620 \t loss = 0.186, train_acc = 1.000 (3.359 sec/step)\n",
      "step 93630 \t loss = 0.206, train_acc = 0.900 (3.416 sec/step)\n",
      "step 93640 \t loss = 0.592, train_acc = 0.800 (3.393 sec/step)\n",
      "step 93650 \t loss = 1.064, train_acc = 0.900 (3.305 sec/step)\n",
      "step 93660 \t loss = 0.002, train_acc = 1.000 (3.335 sec/step)\n",
      "step 93670 \t loss = 0.285, train_acc = 0.900 (3.381 sec/step)\n",
      "step 93680 \t loss = 0.501, train_acc = 0.800 (3.357 sec/step)\n",
      "step 93690 \t loss = 0.003, train_acc = 1.000 (3.408 sec/step)\n",
      "step 93700 \t loss = 0.031, train_acc = 1.000 (3.370 sec/step)\n",
      "step 93710 \t loss = 0.021, train_acc = 1.000 (3.423 sec/step)\n",
      "step 93720 \t loss = 1.496, train_acc = 0.900 (3.370 sec/step)\n",
      "step 93730 \t loss = 0.040, train_acc = 1.000 (3.415 sec/step)\n",
      "step 93740 \t loss = 0.004, train_acc = 1.000 (3.394 sec/step)\n",
      "step 93750 \t loss = 0.643, train_acc = 0.900 (3.321 sec/step)\n",
      "step 93760 \t loss = 0.597, train_acc = 0.900 (3.361 sec/step)\n",
      "step 93770 \t loss = 0.023, train_acc = 1.000 (3.344 sec/step)\n",
      "step 93780 \t loss = 0.596, train_acc = 0.800 (3.369 sec/step)\n",
      "step 93790 \t loss = 0.065, train_acc = 1.000 (3.489 sec/step)\n",
      "step 93800 \t loss = 0.319, train_acc = 0.900 (3.315 sec/step)\n",
      "step 93810 \t loss = 0.011, train_acc = 1.000 (3.342 sec/step)\n",
      "step 93820 \t loss = 0.302, train_acc = 1.000 (3.345 sec/step)\n",
      "step 93830 \t loss = 0.001, train_acc = 1.000 (3.359 sec/step)\n",
      "step 93840 \t loss = 0.010, train_acc = 1.000 (3.319 sec/step)\n",
      "step 93850 \t loss = 0.101, train_acc = 1.000 (3.319 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 93860 \t loss = 0.149, train_acc = 1.000 (3.369 sec/step)\n",
      "step 93870 \t loss = 0.933, train_acc = 0.800 (3.370 sec/step)\n",
      "step 93880 \t loss = 0.001, train_acc = 1.000 (3.373 sec/step)\n",
      "step 93890 \t loss = 0.957, train_acc = 0.900 (3.385 sec/step)\n",
      "step 93900 \t loss = 0.121, train_acc = 1.000 (3.374 sec/step)\n",
      "step 93910 \t loss = 0.003, train_acc = 1.000 (3.391 sec/step)\n",
      "step 93920 \t loss = 0.001, train_acc = 1.000 (3.411 sec/step)\n",
      "step 93930 \t loss = 0.076, train_acc = 1.000 (3.326 sec/step)\n",
      "step 93940 \t loss = 0.004, train_acc = 1.000 (3.367 sec/step)\n",
      "step 93950 \t loss = 0.725, train_acc = 0.700 (3.393 sec/step)\n",
      "step 93960 \t loss = 0.001, train_acc = 1.000 (3.316 sec/step)\n",
      "step 93970 \t loss = 0.207, train_acc = 0.900 (3.457 sec/step)\n",
      "step 93980 \t loss = 0.089, train_acc = 0.900 (3.387 sec/step)\n",
      "step 93990 \t loss = 0.000, train_acc = 1.000 (3.370 sec/step)\n",
      "step 94000 \t loss = 0.011, train_acc = 1.000 (3.385 sec/step)\n",
      "step 94010 \t loss = 0.051, train_acc = 1.000 (3.398 sec/step)\n",
      "step 94020 \t loss = 0.000, train_acc = 1.000 (3.396 sec/step)\n",
      "step 94030 \t loss = 0.168, train_acc = 0.900 (3.344 sec/step)\n",
      "step 94040 \t loss = 0.428, train_acc = 0.800 (3.387 sec/step)\n",
      "step 94050 \t loss = 0.034, train_acc = 1.000 (3.406 sec/step)\n",
      "step 94060 \t loss = 1.102, train_acc = 0.900 (3.351 sec/step)\n",
      "step 94070 \t loss = 0.421, train_acc = 0.900 (3.359 sec/step)\n",
      "step 94080 \t loss = 0.000, train_acc = 1.000 (3.376 sec/step)\n",
      "step 94090 \t loss = 0.069, train_acc = 1.000 (3.359 sec/step)\n",
      "step 94100 \t loss = 0.814, train_acc = 0.800 (3.388 sec/step)\n",
      "step 94110 \t loss = 0.057, train_acc = 1.000 (3.369 sec/step)\n",
      "step 94120 \t loss = 0.050, train_acc = 1.000 (3.437 sec/step)\n",
      "step 94130 \t loss = 0.000, train_acc = 1.000 (3.416 sec/step)\n",
      "step 94140 \t loss = 0.000, train_acc = 1.000 (3.381 sec/step)\n",
      "step 94150 \t loss = 0.089, train_acc = 1.000 (3.357 sec/step)\n",
      "step 94160 \t loss = 0.007, train_acc = 1.000 (3.349 sec/step)\n",
      "step 94170 \t loss = 0.060, train_acc = 1.000 (3.390 sec/step)\n",
      "step 94180 \t loss = 0.052, train_acc = 1.000 (3.319 sec/step)\n",
      "step 94190 \t loss = 0.006, train_acc = 1.000 (3.376 sec/step)\n",
      "step 94200 \t loss = 0.158, train_acc = 1.000 (3.359 sec/step)\n",
      "step 94210 \t loss = 0.004, train_acc = 1.000 (3.329 sec/step)\n",
      "step 94220 \t loss = 0.000, train_acc = 1.000 (3.386 sec/step)\n",
      "step 94230 \t loss = 0.654, train_acc = 0.900 (3.392 sec/step)\n",
      "step 94240 \t loss = 0.007, train_acc = 1.000 (3.338 sec/step)\n",
      "step 94250 \t loss = 0.247, train_acc = 0.900 (3.325 sec/step)\n",
      "step 94260 \t loss = 0.012, train_acc = 1.000 (3.419 sec/step)\n",
      "step 94270 \t loss = 1.301, train_acc = 0.700 (3.382 sec/step)\n",
      "step 94280 \t loss = 0.007, train_acc = 1.000 (3.389 sec/step)\n",
      "step 94290 \t loss = 0.234, train_acc = 0.900 (3.346 sec/step)\n",
      "step 94300 \t loss = 0.023, train_acc = 1.000 (3.359 sec/step)\n",
      "step 94310 \t loss = 0.000, train_acc = 1.000 (3.377 sec/step)\n",
      "step 94320 \t loss = 0.009, train_acc = 1.000 (3.448 sec/step)\n",
      "step 94330 \t loss = 0.021, train_acc = 1.000 (3.390 sec/step)\n",
      "step 94340 \t loss = 0.181, train_acc = 0.900 (3.359 sec/step)\n",
      "step 94350 \t loss = 0.000, train_acc = 1.000 (3.359 sec/step)\n",
      "step 94360 \t loss = 0.206, train_acc = 0.900 (3.333 sec/step)\n",
      "step 94370 \t loss = 0.480, train_acc = 0.800 (3.349 sec/step)\n",
      "step 94380 \t loss = 1.140, train_acc = 0.800 (3.401 sec/step)\n",
      "step 94390 \t loss = 0.364, train_acc = 0.800 (3.387 sec/step)\n",
      "step 94400 \t loss = 0.009, train_acc = 1.000 (3.368 sec/step)\n",
      "step 94410 \t loss = 0.923, train_acc = 0.900 (3.351 sec/step)\n",
      "step 94420 \t loss = 0.157, train_acc = 0.900 (3.329 sec/step)\n",
      "step 94430 \t loss = 1.186, train_acc = 0.900 (3.374 sec/step)\n",
      "step 94440 \t loss = 0.463, train_acc = 0.800 (3.351 sec/step)\n",
      "step 94450 \t loss = 0.336, train_acc = 0.900 (3.362 sec/step)\n",
      "step 94460 \t loss = 0.014, train_acc = 1.000 (3.347 sec/step)\n",
      "step 94470 \t loss = 0.598, train_acc = 0.800 (3.465 sec/step)\n",
      "step 94480 \t loss = 0.008, train_acc = 1.000 (3.372 sec/step)\n",
      "step 94490 \t loss = 0.234, train_acc = 0.800 (3.359 sec/step)\n",
      "step 94500 \t loss = 0.613, train_acc = 0.900 (3.362 sec/step)\n",
      "step 94510 \t loss = 0.112, train_acc = 0.900 (3.346 sec/step)\n",
      "step 94520 \t loss = 0.400, train_acc = 0.900 (3.373 sec/step)\n",
      "step 94530 \t loss = 0.351, train_acc = 0.900 (3.327 sec/step)\n",
      "step 94540 \t loss = 0.222, train_acc = 0.900 (3.338 sec/step)\n",
      "step 94550 \t loss = 0.032, train_acc = 1.000 (3.340 sec/step)\n",
      "step 94560 \t loss = 0.000, train_acc = 1.000 (3.359 sec/step)\n",
      "step 94570 \t loss = 0.042, train_acc = 1.000 (3.339 sec/step)\n",
      "step 94580 \t loss = 0.150, train_acc = 0.900 (3.338 sec/step)\n",
      "step 94590 \t loss = 0.103, train_acc = 1.000 (3.355 sec/step)\n",
      "step 94600 \t loss = 0.150, train_acc = 0.900 (3.344 sec/step)\n",
      "step 94610 \t loss = 0.028, train_acc = 1.000 (3.395 sec/step)\n",
      "step 94620 \t loss = 0.372, train_acc = 0.900 (3.349 sec/step)\n",
      "step 94630 \t loss = 0.001, train_acc = 1.000 (3.375 sec/step)\n",
      "step 94640 \t loss = 0.239, train_acc = 0.900 (3.383 sec/step)\n",
      "step 94650 \t loss = 0.002, train_acc = 1.000 (3.361 sec/step)\n",
      "step 94660 \t loss = 0.005, train_acc = 1.000 (3.379 sec/step)\n",
      "step 94670 \t loss = 0.002, train_acc = 1.000 (3.392 sec/step)\n",
      "step 94680 \t loss = 0.001, train_acc = 1.000 (3.329 sec/step)\n",
      "step 94690 \t loss = 0.015, train_acc = 1.000 (3.351 sec/step)\n",
      "step 94700 \t loss = 0.097, train_acc = 0.900 (3.359 sec/step)\n",
      "step 94710 \t loss = 0.015, train_acc = 1.000 (3.346 sec/step)\n",
      "step 94720 \t loss = 0.028, train_acc = 1.000 (3.327 sec/step)\n",
      "step 94730 \t loss = 1.136, train_acc = 0.800 (3.367 sec/step)\n",
      "step 94740 \t loss = 0.452, train_acc = 0.900 (3.399 sec/step)\n",
      "step 94750 \t loss = 0.298, train_acc = 0.900 (3.344 sec/step)\n",
      "step 94760 \t loss = 0.388, train_acc = 0.900 (3.362 sec/step)\n",
      "step 94770 \t loss = 0.004, train_acc = 1.000 (3.374 sec/step)\n",
      "step 94780 \t loss = 0.003, train_acc = 1.000 (3.365 sec/step)\n",
      "step 94790 \t loss = 0.006, train_acc = 1.000 (3.333 sec/step)\n",
      "step 94800 \t loss = 0.036, train_acc = 1.000 (3.350 sec/step)\n",
      "step 94810 \t loss = 0.017, train_acc = 1.000 (3.367 sec/step)\n",
      "step 94820 \t loss = 0.001, train_acc = 1.000 (3.339 sec/step)\n",
      "step 94830 \t loss = 0.001, train_acc = 1.000 (3.423 sec/step)\n",
      "step 94840 \t loss = 0.000, train_acc = 1.000 (3.389 sec/step)\n",
      "step 94850 \t loss = 0.000, train_acc = 1.000 (3.375 sec/step)\n",
      "step 94860 \t loss = 0.431, train_acc = 0.900 (3.352 sec/step)\n",
      "step 94870 \t loss = 0.137, train_acc = 0.900 (3.369 sec/step)\n",
      "step 94880 \t loss = 0.238, train_acc = 0.900 (3.385 sec/step)\n",
      "step 94890 \t loss = 0.026, train_acc = 1.000 (3.390 sec/step)\n",
      "step 94900 \t loss = 0.085, train_acc = 1.000 (3.366 sec/step)\n",
      "step 94910 \t loss = 0.173, train_acc = 0.900 (3.379 sec/step)\n",
      "step 94920 \t loss = 0.633, train_acc = 0.900 (3.403 sec/step)\n",
      "step 94930 \t loss = 0.188, train_acc = 0.900 (3.374 sec/step)\n",
      "step 94940 \t loss = 0.191, train_acc = 0.900 (3.331 sec/step)\n",
      "step 94950 \t loss = 0.001, train_acc = 1.000 (3.366 sec/step)\n",
      "step 94960 \t loss = 0.690, train_acc = 0.900 (3.374 sec/step)\n",
      "step 94970 \t loss = 0.145, train_acc = 1.000 (3.373 sec/step)\n",
      "step 94980 \t loss = 0.152, train_acc = 0.900 (3.412 sec/step)\n",
      "step 94990 \t loss = 0.307, train_acc = 0.900 (3.355 sec/step)\n",
      "VALIDATION \t acc = 0.531 (3.659 sec)\n",
      "step 95000 \t loss = 0.541, train_acc = 0.900 (3.357 sec/step)\n",
      "step 95010 \t loss = 0.008, train_acc = 1.000 (3.390 sec/step)\n",
      "step 95020 \t loss = 0.027, train_acc = 1.000 (3.348 sec/step)\n",
      "step 95030 \t loss = 0.594, train_acc = 0.700 (3.359 sec/step)\n",
      "step 95040 \t loss = 0.005, train_acc = 1.000 (3.400 sec/step)\n",
      "step 95050 \t loss = 0.088, train_acc = 0.900 (3.338 sec/step)\n",
      "step 95060 \t loss = 0.019, train_acc = 1.000 (3.346 sec/step)\n",
      "step 95070 \t loss = 0.021, train_acc = 1.000 (3.375 sec/step)\n",
      "step 95080 \t loss = 0.000, train_acc = 1.000 (3.385 sec/step)\n",
      "step 95090 \t loss = 0.001, train_acc = 1.000 (3.342 sec/step)\n",
      "step 95100 \t loss = 0.383, train_acc = 0.800 (3.344 sec/step)\n",
      "step 95110 \t loss = 1.527, train_acc = 0.900 (3.419 sec/step)\n",
      "step 95120 \t loss = 0.628, train_acc = 0.900 (3.377 sec/step)\n",
      "step 95130 \t loss = 0.077, train_acc = 1.000 (3.383 sec/step)\n",
      "step 95140 \t loss = 0.024, train_acc = 1.000 (3.320 sec/step)\n",
      "step 95150 \t loss = 1.150, train_acc = 0.900 (3.373 sec/step)\n",
      "step 95160 \t loss = 0.338, train_acc = 0.800 (3.418 sec/step)\n",
      "step 95170 \t loss = 0.000, train_acc = 1.000 (3.366 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 95180 \t loss = 0.648, train_acc = 0.900 (3.342 sec/step)\n",
      "step 95190 \t loss = 0.000, train_acc = 1.000 (3.358 sec/step)\n",
      "step 95200 \t loss = 0.014, train_acc = 1.000 (3.339 sec/step)\n",
      "step 95210 \t loss = 0.051, train_acc = 1.000 (3.337 sec/step)\n",
      "step 95220 \t loss = 0.000, train_acc = 1.000 (3.356 sec/step)\n",
      "step 95230 \t loss = 0.074, train_acc = 1.000 (3.341 sec/step)\n",
      "step 95240 \t loss = 1.468, train_acc = 0.900 (3.323 sec/step)\n",
      "step 95250 \t loss = 0.048, train_acc = 1.000 (3.387 sec/step)\n",
      "step 95260 \t loss = 0.158, train_acc = 0.900 (3.399 sec/step)\n",
      "step 95270 \t loss = 0.021, train_acc = 1.000 (3.364 sec/step)\n",
      "step 95280 \t loss = 0.018, train_acc = 1.000 (3.398 sec/step)\n",
      "step 95290 \t loss = 0.225, train_acc = 0.900 (3.364 sec/step)\n",
      "step 95300 \t loss = 0.235, train_acc = 0.900 (3.375 sec/step)\n",
      "step 95310 \t loss = 0.042, train_acc = 1.000 (3.373 sec/step)\n",
      "step 95320 \t loss = 0.173, train_acc = 0.800 (3.379 sec/step)\n",
      "step 95330 \t loss = 1.579, train_acc = 0.900 (3.334 sec/step)\n",
      "step 95340 \t loss = 0.045, train_acc = 1.000 (3.322 sec/step)\n",
      "step 95350 \t loss = 0.137, train_acc = 0.900 (3.386 sec/step)\n",
      "step 95360 \t loss = 0.013, train_acc = 1.000 (3.386 sec/step)\n",
      "step 95370 \t loss = 0.011, train_acc = 1.000 (3.320 sec/step)\n",
      "step 95380 \t loss = 0.023, train_acc = 1.000 (3.501 sec/step)\n",
      "step 95390 \t loss = 0.319, train_acc = 0.900 (3.317 sec/step)\n",
      "step 95400 \t loss = 0.797, train_acc = 0.800 (3.489 sec/step)\n",
      "step 95410 \t loss = 0.704, train_acc = 0.800 (3.334 sec/step)\n",
      "step 95420 \t loss = 1.111, train_acc = 0.900 (3.419 sec/step)\n",
      "step 95430 \t loss = 0.069, train_acc = 1.000 (3.374 sec/step)\n",
      "step 95440 \t loss = 0.000, train_acc = 1.000 (3.448 sec/step)\n",
      "step 95450 \t loss = 0.001, train_acc = 1.000 (3.334 sec/step)\n",
      "step 95460 \t loss = 0.006, train_acc = 1.000 (3.345 sec/step)\n",
      "step 95470 \t loss = 0.000, train_acc = 1.000 (3.320 sec/step)\n",
      "step 95480 \t loss = 0.162, train_acc = 0.900 (3.331 sec/step)\n",
      "step 95490 \t loss = 0.083, train_acc = 1.000 (3.329 sec/step)\n",
      "step 95500 \t loss = 0.042, train_acc = 1.000 (3.315 sec/step)\n",
      "step 95510 \t loss = 0.016, train_acc = 1.000 (3.348 sec/step)\n",
      "step 95520 \t loss = 0.026, train_acc = 1.000 (3.446 sec/step)\n",
      "step 95530 \t loss = 0.375, train_acc = 0.900 (3.372 sec/step)\n",
      "step 95540 \t loss = 0.952, train_acc = 0.800 (3.365 sec/step)\n",
      "step 95550 \t loss = 0.001, train_acc = 1.000 (3.330 sec/step)\n",
      "step 95560 \t loss = 0.174, train_acc = 0.900 (3.354 sec/step)\n",
      "step 95570 \t loss = 0.061, train_acc = 1.000 (3.355 sec/step)\n",
      "step 95580 \t loss = 0.034, train_acc = 1.000 (3.359 sec/step)\n",
      "step 95590 \t loss = 0.048, train_acc = 1.000 (3.412 sec/step)\n",
      "step 95600 \t loss = 0.594, train_acc = 0.800 (3.371 sec/step)\n",
      "step 95610 \t loss = 0.011, train_acc = 1.000 (3.370 sec/step)\n",
      "step 95620 \t loss = 0.031, train_acc = 1.000 (3.363 sec/step)\n",
      "step 95630 \t loss = 0.052, train_acc = 1.000 (3.342 sec/step)\n",
      "step 95640 \t loss = 0.405, train_acc = 0.900 (3.414 sec/step)\n",
      "step 95650 \t loss = 0.011, train_acc = 1.000 (3.358 sec/step)\n",
      "step 95660 \t loss = 0.025, train_acc = 1.000 (3.349 sec/step)\n",
      "step 95670 \t loss = 0.420, train_acc = 0.900 (3.307 sec/step)\n",
      "step 95680 \t loss = 0.000, train_acc = 1.000 (3.353 sec/step)\n",
      "step 95690 \t loss = 0.013, train_acc = 1.000 (3.364 sec/step)\n",
      "step 95700 \t loss = 0.209, train_acc = 0.800 (3.329 sec/step)\n",
      "step 95710 \t loss = 0.005, train_acc = 1.000 (3.371 sec/step)\n",
      "step 95720 \t loss = 0.307, train_acc = 0.900 (3.319 sec/step)\n",
      "step 95730 \t loss = 0.638, train_acc = 0.800 (3.469 sec/step)\n",
      "step 95740 \t loss = 0.013, train_acc = 1.000 (3.358 sec/step)\n",
      "step 95750 \t loss = 0.009, train_acc = 1.000 (3.376 sec/step)\n",
      "step 95760 \t loss = 0.139, train_acc = 0.900 (3.383 sec/step)\n",
      "step 95770 \t loss = 0.027, train_acc = 1.000 (3.342 sec/step)\n",
      "step 95780 \t loss = 0.012, train_acc = 1.000 (3.392 sec/step)\n",
      "step 95790 \t loss = 0.191, train_acc = 0.800 (3.324 sec/step)\n",
      "step 95800 \t loss = 0.098, train_acc = 0.900 (3.317 sec/step)\n",
      "step 95810 \t loss = 0.213, train_acc = 0.900 (3.425 sec/step)\n",
      "step 95820 \t loss = 0.006, train_acc = 1.000 (3.436 sec/step)\n",
      "step 95830 \t loss = 0.009, train_acc = 1.000 (3.420 sec/step)\n",
      "step 95840 \t loss = 0.082, train_acc = 1.000 (3.365 sec/step)\n",
      "step 95850 \t loss = 0.034, train_acc = 1.000 (3.357 sec/step)\n",
      "step 95860 \t loss = 0.037, train_acc = 1.000 (3.408 sec/step)\n",
      "step 95870 \t loss = 0.011, train_acc = 1.000 (3.317 sec/step)\n",
      "step 95880 \t loss = 0.024, train_acc = 1.000 (3.343 sec/step)\n",
      "step 95890 \t loss = 0.075, train_acc = 1.000 (3.312 sec/step)\n",
      "step 95900 \t loss = 0.000, train_acc = 1.000 (3.364 sec/step)\n",
      "step 95910 \t loss = 0.012, train_acc = 1.000 (3.388 sec/step)\n",
      "step 95920 \t loss = 0.000, train_acc = 1.000 (3.343 sec/step)\n",
      "step 95930 \t loss = 0.016, train_acc = 1.000 (3.370 sec/step)\n",
      "step 95940 \t loss = 0.096, train_acc = 0.900 (3.386 sec/step)\n",
      "step 95950 \t loss = 0.002, train_acc = 1.000 (3.337 sec/step)\n",
      "step 95960 \t loss = 0.002, train_acc = 1.000 (3.330 sec/step)\n",
      "step 95970 \t loss = 0.004, train_acc = 1.000 (3.479 sec/step)\n",
      "step 95980 \t loss = 0.051, train_acc = 1.000 (3.354 sec/step)\n",
      "step 95990 \t loss = 0.105, train_acc = 0.900 (3.368 sec/step)\n",
      "step 96000 \t loss = 0.021, train_acc = 1.000 (3.377 sec/step)\n",
      "step 96010 \t loss = 0.000, train_acc = 1.000 (3.304 sec/step)\n",
      "step 96020 \t loss = 0.025, train_acc = 1.000 (3.478 sec/step)\n",
      "step 96030 \t loss = 0.148, train_acc = 0.900 (3.368 sec/step)\n",
      "step 96040 \t loss = 0.870, train_acc = 0.900 (3.404 sec/step)\n",
      "step 96050 \t loss = 0.042, train_acc = 1.000 (3.376 sec/step)\n",
      "step 96060 \t loss = 0.023, train_acc = 1.000 (3.362 sec/step)\n",
      "step 96070 \t loss = 0.150, train_acc = 0.900 (3.316 sec/step)\n",
      "step 96080 \t loss = 0.110, train_acc = 0.900 (3.389 sec/step)\n",
      "step 96090 \t loss = 0.000, train_acc = 1.000 (3.363 sec/step)\n",
      "step 96100 \t loss = 0.036, train_acc = 1.000 (3.369 sec/step)\n",
      "step 96110 \t loss = 1.131, train_acc = 0.700 (3.423 sec/step)\n",
      "step 96120 \t loss = 0.004, train_acc = 1.000 (3.369 sec/step)\n",
      "step 96130 \t loss = 0.944, train_acc = 0.900 (3.355 sec/step)\n",
      "step 96140 \t loss = 0.557, train_acc = 0.900 (3.375 sec/step)\n",
      "step 96150 \t loss = 0.477, train_acc = 0.900 (3.319 sec/step)\n",
      "step 96160 \t loss = 0.194, train_acc = 0.900 (3.374 sec/step)\n",
      "step 96170 \t loss = 0.985, train_acc = 0.800 (3.333 sec/step)\n",
      "step 96180 \t loss = 0.003, train_acc = 1.000 (3.380 sec/step)\n",
      "step 96190 \t loss = 0.000, train_acc = 1.000 (3.356 sec/step)\n",
      "step 96200 \t loss = 0.030, train_acc = 1.000 (3.375 sec/step)\n",
      "step 96210 \t loss = 0.003, train_acc = 1.000 (3.331 sec/step)\n",
      "step 96220 \t loss = 0.000, train_acc = 1.000 (3.405 sec/step)\n",
      "step 96230 \t loss = 0.019, train_acc = 1.000 (3.354 sec/step)\n",
      "step 96240 \t loss = 0.047, train_acc = 1.000 (3.407 sec/step)\n",
      "step 96250 \t loss = 0.111, train_acc = 1.000 (3.322 sec/step)\n",
      "step 96260 \t loss = 0.089, train_acc = 0.900 (3.365 sec/step)\n",
      "step 96270 \t loss = 0.178, train_acc = 0.800 (3.414 sec/step)\n",
      "step 96280 \t loss = 0.074, train_acc = 1.000 (3.345 sec/step)\n",
      "step 96290 \t loss = 0.139, train_acc = 1.000 (3.397 sec/step)\n",
      "step 96300 \t loss = 0.001, train_acc = 1.000 (3.372 sec/step)\n",
      "step 96310 \t loss = 0.100, train_acc = 0.900 (3.346 sec/step)\n",
      "step 96320 \t loss = 1.353, train_acc = 0.900 (3.321 sec/step)\n",
      "step 96330 \t loss = 0.625, train_acc = 0.800 (3.353 sec/step)\n",
      "step 96340 \t loss = 0.308, train_acc = 0.900 (3.320 sec/step)\n",
      "step 96350 \t loss = 0.289, train_acc = 0.900 (3.385 sec/step)\n",
      "step 96360 \t loss = 0.498, train_acc = 0.900 (3.353 sec/step)\n",
      "step 96370 \t loss = 0.000, train_acc = 1.000 (3.413 sec/step)\n",
      "step 96380 \t loss = 0.008, train_acc = 1.000 (3.340 sec/step)\n",
      "step 96390 \t loss = 0.020, train_acc = 1.000 (3.385 sec/step)\n",
      "step 96400 \t loss = 0.000, train_acc = 1.000 (3.365 sec/step)\n",
      "step 96410 \t loss = 0.084, train_acc = 0.900 (3.302 sec/step)\n",
      "step 96420 \t loss = 0.468, train_acc = 0.900 (3.367 sec/step)\n",
      "step 96430 \t loss = 0.131, train_acc = 0.900 (3.361 sec/step)\n",
      "step 96440 \t loss = 0.177, train_acc = 0.800 (3.327 sec/step)\n",
      "step 96450 \t loss = 0.000, train_acc = 1.000 (3.393 sec/step)\n",
      "step 96460 \t loss = 0.002, train_acc = 1.000 (3.379 sec/step)\n",
      "step 96470 \t loss = 0.001, train_acc = 1.000 (3.397 sec/step)\n",
      "step 96480 \t loss = 0.021, train_acc = 1.000 (3.394 sec/step)\n",
      "step 96490 \t loss = 0.001, train_acc = 1.000 (3.374 sec/step)\n",
      "step 96500 \t loss = 0.000, train_acc = 1.000 (3.369 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 96510 \t loss = 0.000, train_acc = 1.000 (3.342 sec/step)\n",
      "step 96520 \t loss = 0.610, train_acc = 0.700 (3.373 sec/step)\n",
      "step 96530 \t loss = 0.009, train_acc = 1.000 (3.385 sec/step)\n",
      "step 96540 \t loss = 0.218, train_acc = 0.900 (3.372 sec/step)\n",
      "step 96550 \t loss = 0.018, train_acc = 1.000 (3.335 sec/step)\n",
      "step 96560 \t loss = 0.092, train_acc = 1.000 (3.347 sec/step)\n",
      "step 96570 \t loss = 0.002, train_acc = 1.000 (3.397 sec/step)\n",
      "step 96580 \t loss = 0.060, train_acc = 1.000 (3.376 sec/step)\n",
      "step 96590 \t loss = 1.709, train_acc = 0.800 (3.372 sec/step)\n",
      "step 96600 \t loss = 0.857, train_acc = 0.800 (3.322 sec/step)\n",
      "step 96610 \t loss = 0.030, train_acc = 1.000 (3.326 sec/step)\n",
      "step 96620 \t loss = 0.107, train_acc = 0.900 (3.446 sec/step)\n",
      "step 96630 \t loss = 0.155, train_acc = 0.900 (3.371 sec/step)\n",
      "step 96640 \t loss = 0.264, train_acc = 0.900 (3.397 sec/step)\n",
      "step 96650 \t loss = 0.172, train_acc = 0.900 (3.365 sec/step)\n",
      "step 96660 \t loss = 0.185, train_acc = 0.900 (3.333 sec/step)\n",
      "step 96670 \t loss = 0.005, train_acc = 1.000 (3.392 sec/step)\n",
      "step 96680 \t loss = 0.001, train_acc = 1.000 (3.364 sec/step)\n",
      "step 96690 \t loss = 0.113, train_acc = 0.900 (3.354 sec/step)\n",
      "step 96700 \t loss = 0.441, train_acc = 0.800 (3.323 sec/step)\n",
      "step 96710 \t loss = 0.033, train_acc = 1.000 (3.375 sec/step)\n",
      "step 96720 \t loss = 0.011, train_acc = 1.000 (3.410 sec/step)\n",
      "step 96730 \t loss = 1.104, train_acc = 0.800 (3.346 sec/step)\n",
      "step 96740 \t loss = 0.051, train_acc = 1.000 (3.343 sec/step)\n",
      "step 96750 \t loss = 0.136, train_acc = 0.900 (3.366 sec/step)\n",
      "step 96760 \t loss = 0.499, train_acc = 0.900 (3.395 sec/step)\n",
      "step 96770 \t loss = 0.098, train_acc = 1.000 (3.323 sec/step)\n",
      "step 96780 \t loss = 0.048, train_acc = 1.000 (3.386 sec/step)\n",
      "step 96790 \t loss = 0.011, train_acc = 1.000 (3.367 sec/step)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model Setup\n",
    "'''\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(BATCH_SIZE, 32, 32, 3))\n",
    "x_resized = tf.image.resize_images(x, (224, 224))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(BATCH_SIZE))\n",
    "is_training = tf.placeholder(dtype=tf.bool)\n",
    "\n",
    "net = vgg16(x_resized, y, is_training)\n",
    "\n",
    "'''\n",
    "Loss, Metrics, and Optimization Setup\n",
    "'''\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y, #GT probability distribution\n",
    "        logits=net.fc3, # unscaled log prob\n",
    "        name='sparse_softmax_cross_entropy')\n",
    "\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "train_loss_summary = tf.summary.scalar('training_loss', reduced_loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        beta1=BETA1,\n",
    "        beta2=BETA2,\n",
    "        name='AdamOptimizer')\n",
    "train_op = optimizer.minimize(reduced_loss)\n",
    "\n",
    "pred = tf.nn.softmax(\n",
    "        logits=net.fc3,\n",
    "        name='softmax')\n",
    "pred_class = tf.cast(tf.argmax(pred, axis=1), tf.int32)\n",
    "acc = tf.reduce_mean(tf.cast(\n",
    "        tf.equal(y, pred_class),\n",
    "        tf.float32))\n",
    "\n",
    "train_acc_summary = tf.summary.scalar('training_accuracy', acc)\n",
    "\n",
    "\n",
    "'''\n",
    "TensorBoard Setup\n",
    "'''\n",
    "all_train_summary = tf.summary.merge_all()\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(SNAPSHOT_DIR,\n",
    "        graph=tf.get_default_graph())\n",
    "\n",
    "'''\n",
    "Tensorflow Saver Setup\n",
    "'''\n",
    "saver = tf.train.Saver(var_list=tf.global_variables(),\n",
    "                       max_to_keep=SNAPSHOT_MAX)\n",
    "\n",
    "'''\n",
    "Tensorflow Session Setup\n",
    "'''\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.group(tf.global_variables_initializer(),\n",
    "                tf.local_variables_initializer())\n",
    "sess.run(init)\n",
    "\n",
    "'''\n",
    "Load Pretrained Weights (ImageNet)\n",
    "'''\n",
    "net.load_pretrained_weights(sess)\n",
    "\n",
    "'''\n",
    "Declare Validation Loop\n",
    "'''\n",
    "def run_validation():\n",
    "    global best_acc\n",
    "    \n",
    "    start_t = time()\n",
    "    overall_acc = 0\n",
    "    overall_loss = 0\n",
    "    for j in range(0, n_validation, BATCH_SIZE):\n",
    "        # Assemble Batch\n",
    "        idx = validation_indices[j:(j+BATCH_SIZE)]\n",
    "        x_batch = data_x[idx,...]\n",
    "        y_batch = data_y[idx,...]\n",
    "        \n",
    "        feed_dict = {x:x_batch,\n",
    "                 y:y_batch,\n",
    "                 is_training: False}\n",
    "        loss_v, acc_v, pred_v = sess.run(\n",
    "                [reduced_loss, acc, pred],\n",
    "                feed_dict=feed_dict)\n",
    "        overall_acc += acc_v\n",
    "        overall_loss += loss_v\n",
    "        \n",
    "        \n",
    "    duration = time() - start_t\n",
    "    overall_acc /= (n_validation / BATCH_SIZE)\n",
    "    overall_loss /= (n_validation / BATCH_SIZE)\n",
    "    \n",
    "    overall_acc_summary = tf.Summary()\n",
    "    overall_acc_summary.value.add(tag='validation_accuracy', simple_value=overall_acc)\n",
    "    overall_loss_summary = tf.Summary()\n",
    "    overall_loss_summary.value.add(tag='validation_loss', simple_value=overall_loss)\n",
    "\n",
    "    summary_writer.add_summary(overall_acc_summary, step)\n",
    "    summary_writer.add_summary(overall_loss_summary, step)\n",
    "    \n",
    "    print('VALIDATION \\t acc = {:.3f} ({:.3f} sec)'.format(\n",
    "                overall_acc, duration))\n",
    "    if overall_acc > best_acc:\n",
    "        print('New Best Accuracy {:.3f} > Old Best {:.3f}.  Saving...'.format(\n",
    "                overall_acc, best_acc))\n",
    "        best_acc = overall_acc\n",
    "        save(saver, sess, SNAPSHOT_DIR, step)\n",
    "        \n",
    "'''\n",
    "Main Training Loop\n",
    "'''\n",
    "step = 0\n",
    "epoch = 0\n",
    "best_acc = 0\n",
    "while epoch < NUM_EPOCH:\n",
    "    step += 1\n",
    "    # Allocate Space For Batch\n",
    "    x_batch = np.zeros((BATCH_SIZE,) + data_x.shape[1:], dtype=np.float32)\n",
    "    y_batch = np.zeros((BATCH_SIZE,) + data_y.shape[1:], dtype=np.int32)\n",
    "    \n",
    "    # Run Validation\n",
    "    if step % batches_per_epoch == 0:\n",
    "        epoch += 1\n",
    "        run_validation()\n",
    "        \n",
    "    # Form Training Batch\n",
    "    start_t = time()\n",
    "    for i in range(BATCH_SIZE):\n",
    "        idx = next(train_indices)\n",
    "        x_batch[i,...] = data_x[idx, ...]\n",
    "        y_batch[i,...] = data_y[idx, ...]\n",
    "    \n",
    "    # Data Augmentation\n",
    "    if random.random() < 0.5:\n",
    "        x_batch = np.fliplr(x_batch)\n",
    "        \n",
    "    # Prepare Feed Dictionary\n",
    "    feed_dict = {x:x_batch,\n",
    "                 y:y_batch,\n",
    "                 is_training: True}\n",
    "    # Run Training Summary\n",
    "    if step % SUMMARY_EVERY == 0:\n",
    "        loss_v, _, summary_v, acc_v, pred_v = sess.run(\n",
    "                [reduced_loss, train_op, all_train_summary, acc, pred],\n",
    "                feed_dict=feed_dict)\n",
    "        summary_writer.add_summary(summary_v, step)\n",
    "        duration = time() - start_t\n",
    "        print('step {:d} \\t loss = {:.3f}, train_acc = {:.3f} ({:.3f} sec/step)'.format(\n",
    "                step, loss_v, acc_v, duration))\n",
    "    else: # Run Simple Train\n",
    "        loss_v, _ = sess.run([reduced_loss, train_op],\n",
    "                feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
