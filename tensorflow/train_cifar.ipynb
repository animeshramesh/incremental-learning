{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo:\n",
    "- Experiment with normalization while creating triplets\n",
    "- Do you need dropout in the regressor network?\n",
    "- Simultaneous feature learning?\n",
    "- See when are results bad/equal/better? See which classes they correspond to.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import optimistic_restore, save, load\n",
    "import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "HYPERPARAMS\n",
    "'''\n",
    "BATCH_SIZE = 10\n",
    "DATA_PATH = '/media/red/capstone/data/cifar-100/feature_vectors.pkl'\n",
    "INPUT_SIZE = '321,321'\n",
    "LEARNING_RATE = 2.5e-4\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.99\n",
    "NUM_CLASSES = 40\n",
    "NUM_STEPS = 20001\n",
    "RANDOM_SEED = 1234\n",
    "RESTORE_FROM = './deeplab_resnet.ckpt'\n",
    "SAVE_NUM_IMAGES = 2\n",
    "SAVE_PRED_EVERY = 1000\n",
    "SNAPSHOT_MAX = 10\n",
    "SNAPSHOT_DIR = './snapshots/'\n",
    "WEIGHT_DECAY = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load in Data\n",
    "'''\n",
    "\n",
    "# ANIMESSSSSHHHHHHHHHH   HAAAAALLLLPPPPPPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Tensorflow Session Setup\n",
    "'''\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.group(tf.global_variables_initializer(),\n",
    "                tf.local_variables_initializer())\n",
    "sess.run(init)\n",
    "\n",
    "'''\n",
    "Model Setup\n",
    "'''\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(-1, 32, 32, 3))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(-1, NUM_CLASSES))\n",
    "\n",
    "net = []\n",
    "net.append(layers.conv2d(\n",
    "        input=x,\n",
    "        shape=(3,3,3,32),\n",
    "        padding='SAME',\n",
    "        activation='relu',\n",
    "        name='conv1_1'\n",
    "        ))\n",
    "net.append(layers.conv2d(\n",
    "        input=net[-1],\n",
    "        shape=(3,3,32,32),\n",
    "        padding='SAME',\n",
    "        activation='relu',\n",
    "        name='conv1_2'\n",
    "        ))\n",
    "net.append(tf.nn.max_pool(\n",
    "        value=net[-1],\n",
    "        ksize=[1, 2, 2, 1],\n",
    "        strides=[1,2,2,1],\n",
    "        padding='SAME',\n",
    "        name='pool_1'\n",
    "        ))\n",
    "\n",
    "net.append(layers.conv2d(\n",
    "        input=net[-1],\n",
    "        shape=(3,3,32,64),\n",
    "        padding='SAME',\n",
    "        activation='relu',\n",
    "        name='conv2_1'\n",
    "        ))\n",
    "net.append(layers.conv2d(\n",
    "        input=net[-1],\n",
    "        shape=(3,3,64,64),\n",
    "        padding='SAME',\n",
    "        activation='relu',\n",
    "        name='conv2_2'\n",
    "        ))\n",
    "net.append(tf.nn.max_pool(\n",
    "        value=net[-1],\n",
    "        ksize=[1, 2, 2, 1],\n",
    "        strides=[1,2,2,1],\n",
    "        padding='SAME',\n",
    "        name='pool_2'\n",
    "        ))\n",
    "\n",
    "net.append(tf.contrib.layers.flatten(\n",
    "        inputs=net[-1],\n",
    "        scope='flat_1'\n",
    "        ))\n",
    "net.append(layers.fc(\n",
    "        input=net[-1],\n",
    "        units=1024,\n",
    "        activation='relu',\n",
    "        name='fc_1'\n",
    "        ))\n",
    "net.append(tf.nn.dropout(\n",
    "        x=layers[-1],\n",
    "        keep_prob=0.5,\n",
    "        name='dropout_fc_1'\n",
    "        ))\n",
    "net.append(layers.fc(\n",
    "        input=net[-1],\n",
    "        units=1024,\n",
    "        activation='relu',\n",
    "        name='fc_2'\n",
    "        ))\n",
    "net.append(tf.nn.dropout(\n",
    "        x=net[-1],\n",
    "        keep_prob=0.5,\n",
    "        name='dropout_fc_2'\n",
    "        ))\n",
    "net.append(layers.fc(\n",
    "        input=net[-1],\n",
    "        units=NUM_CLASSES,\n",
    "        activation='linear',\n",
    "        name='fc_3'\n",
    "        ))\n",
    "pred = tf.nn.softmax(\n",
    "        logits=net[-1],\n",
    "        name='softmax')\n",
    "\n",
    "'''\n",
    "Loss and Optimization Setup\n",
    "'''\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=y, #GT probability distribution\n",
    "        logits=net[-1], # unscaled log prob\n",
    "        name='softmax_cross_entropy')\n",
    "\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        beta1=BETA1,\n",
    "        beta2=BETA2,\n",
    "        name='AdamOptimizer')\n",
    "train_op = optimizer.minimize(reduced_loss)\n",
    "\n",
    "'''\n",
    "TensorBoard Setup\n",
    "'''\n",
    "all_summary = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(SNAPSHOT_DIR,\n",
    "        graph=tf.get_default_graph())\n",
    "\n",
    "'''\n",
    "Tensorflow Saver Setup\n",
    "'''\n",
    "saver = tf.train.Saver(var_list=tf.global_variables(),\n",
    "                       max_to_keep=SNAPSHOT_MAX)\n",
    "\n",
    "'''\n",
    "Main Training Loop\n",
    "'''\n",
    "for step in range(NUM_STEPS):\n",
    "    start_t = time()\n",
    "    # Fill this in!\n",
    "    feed_dict = {x:,\n",
    "                 y:}\n",
    "    if step % SAVE_PRED_EVERY == 0:\n",
    "        loss_v, _, summary_v  = sess.run([reduced_loss, train_op, all_summary],\n",
    "                feed_dict=feed_dict)\n",
    "        summary_writer.add_summary(reduced_loss, step)\n",
    "        save(saver, sess, SNAPSHOT_DIR, step)\n",
    "    else:\n",
    "        loss_v, _ = sess.run([loss, train_op],\n",
    "                feed_dict=feed_dict)\n",
    "    duration = time() - start_t\n",
    "    print('step {:d} \\t loss = {:.3f}, ({:.3f} sec/step)'.format(\n",
    "        step, loss_v, duration))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
